% glossary.tex
% mainfile: perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\chapter{Glossary}
%
\Epigraph{Dictionaries are inherently circular in nature.}
	 {\emph{``Self Reference in word definitions'',
	        David~Levary~et~al.}}

\begin{description}
\item[Associativity:]\index{Associativity}
	주어진 캐쉬에서 모든 캐쉬 라인이 이 캐쉬 내에서 동일하게 해쉬 될 때
	동시에 가져질 수 있는 캐쉬 라인의 갯수.
	가능한 해쉬 값마다 네개의 캐쉬 라인까지를 가질 수 있는 캐쉬는
	``four-way set-associative'' 캐쉬라 명명되며, 각 해쉬 값마다 하나의
	캐쉬 라인만을 가질 수 있는 캐쉬는 ``direct-mapped'' 캐쉬라 불립니다.
	Associativity 가 전체 용량과 동일한 캐쉬는 ``fully associative'' 캐쉬라
	불립니다.
	Fully associative 캐쉬는 associativity 미스를 제거하는 장점을 가지나
	하드웨어의 제한 때문에 fully associative 캐쉬는 일반적으로 그 크기가
	제한됩니다.
	현대의 마이크로프로세서에서 볼 수 있는 큰 캐쉬의 associativity 는
	일반적으로 2-way 에서 8-way 사이입니다.

\iffalse

\item[Associativity:]\index{Associativity}
	The number of cache lines that can be held simultaneously in
	a given cache, when all of these cache lines hash identically
	in that cache.
	A cache that could hold four cache lines for each possible
	hash value would be termed a ``four-way set-associative'' cache,
	while a cache that could hold only one cache line for each
	possible hash value would be termed a ``direct-mapped'' cache.
	A cache whose associativity was equal to its capacity would
	be termed a ``fully associative'' cache.
	Fully associative caches have the advantage of eliminating
	associativity misses, but, due to hardware limitations,
	fully associative caches are normally quite limited in size.
	The associativity of the large caches found on modern microprocessors
	typically range from two-way to eight-way.

\fi

\item[Associativity Miss:]\index{Associativity miss}
	연관된 CPU 가 최근에 캐쉬의 주어진 셋에 그것에 맞는 것보다 많은 데이터
	해쉬에 접근했기 때문에 발생하는 캐쉬 미스.
	Fully associative cache 는 associativity 미스를 갖지 않습니다 (또는,
	동일하게, fully associative 캐쉬에서는 associativity 와 capacity 미스가
	동일합니다).
\item[Atomic:]\index{Atomic}
	오퍼레이션은 중간의 상태를 관측될 수 없다면 ``atomic (원자적)'' 하다고
	여겨집니다.
	예를 들어, 대부분의 CPU 에서 제대로 정렬된 포인터로의 스토어는
	어토믹한데, 다른 CPU 들은 그 과거 값이나 새 값을 볼 수 있지만 새 값과
	과거 값의 어떤 조각들이 포함된 혼합된 값을 볼 수는 없는 것이 보장되기
	때문입니다.
\item[Atomic Read-Modify-Write Operation:]\index{Atomic read-modify-write operation}
	메모리 읽기와 쓰기가 둘 다 원자적인 atomic 오퍼레이션은 atomic
	read-modify-write 오퍼레이션, 또는 짧게 atomic RMW 오퍼레이션이라
	여겨집니다.
	쓰여지는 값은 읽힌 값에 보통 의존적이지만, \co{atomic_xchg()} 는 이
	규칙을 증명하는 예외입니다.

\iffalse

\item[Associativity Miss:]\index{Associativity miss}
	A cache miss incurred because the corresponding CPU has recently
	accessed more data hashing to a given set of the cache than will
	fit in that set.
	Fully associative caches are not subject to associativity misses
	(or, equivalently, in fully associative caches, associativity
	and capacity misses are identical).
\item[Atomic:]\index{Atomic}
	An operation is considered ``atomic'' if it is not possible to
	observe any intermediate state.
	For example, on most CPUs, a store to a properly aligned pointer
	is atomic, because other CPUs will see either the old value or
	the new value, but are guaranteed not to see some mixed value
	containing some pieces of the new and old values.
\item[Atomic Read-Modify-Write Operation:]\index{Atomic read-modify-write operation}
	An atomic operation that both reads and writes memory is
	considered an atomic read-modify-write operation, or atomic RMW
	operation for short.
	Although the value written usually depends on the value read,
	\co{atomic_xchg()} is the exception that proves this rule.

\fi

\item[Bounded Wait Free:]\index{Bounded wait free}
	모든 쓰레드가 특정 유한 시간 내에 진행을 하며, 이 특정 시간의 한계가
	정해진 경우의 진행 보장.
\item[Cache:]\index{Cache}
	현대 컴퓨터 시스템에서, CPU 는 빈전하게 사용되는 데이터를 잡아두기 위해
	캐쉬를 갖습니다.
	이 캐쉬는 매우 간단한 해쉬 함수를 사용하나, 각 해쉬 버켓이 (하드웨어
	종류에서는 ``set'' 이라 명명됩니다) 제한된 수의 데이터 항목만을 가질 수
	있는 하드웨어 해쉬 테이블로 생각될 수 있습니다.
	각 캐쉬의 해쉬 버켓 각각이 가질 수 있는 데이터 항목의 갯수는 이 캐쉬의
	``associativity'' 라고 명명됩니다.
	이 데이터 항목들은 보통 ``cache line (캐쉬 라인)'' 이라 불리는데, CPU
	와 메모리 사이를 순환하는 데이터의 고정 길이 블록으로 생각될 수
	있습니다.

\iffalse

\item[Bounded Wait Free:]\index{Bounded wait free}
	A forward-progress guarantee in which every thread makes
	progress within a specific finite period of time, the specific
	time being the bound.
\item[Cache:]\index{Cache}
	In modern computer systems, CPUs have caches in which to hold
	frequently used data.
	These caches can be thought of as hardware hash tables with very
	simple hash functions,
	but in which each hash bucket (termed a ``set'' by hardware types)
	can hold only a limited number of data items.
	The number of data items that can be held by each of a cache's hash
	buckets is termed the cache's ``associativity''.
	These data items are normally called ``cache lines'', which
	can be thought of a fixed-length blocks of data that circulate
	among the CPUs and memory.

\fi

\item[Cache Coherence:]\index{Cache coherence}
	특정 변수의 값의 흐름이 그 변수에 대해서 최소한 하나의 전역적인 값의
	순서로 일관적이게 이루어지는 것으로 모든 CPU 에게 보여지는, 대부분의
	현대 SMP 기계들의 속성.
	Cache coherence (캐쉬 일관성) 은 또한 특정 변수로의 복수의 스토어의
	마지막에 모든 CPU 가 이 변수의 마지막 값에 동의할 것을 보장합니다.
	캐쉬 일관성은 단일 변수에의 값의 흐름에만 적용됨에 주의하십시오.
	대조적으로, 특정 기계를 위한 메모리 일관성 모델은 여러 변수에의 로드와
	스토어가 일어나는 것으로 보이는 순서를 설명합니다.
	더 많은 정보를 위해선
	Section~\ref{sec:memorder:Cache Coherence} 를 참고하세요.

\iffalse

\item[Cache Coherence:]\index{Cache coherence}
	A property of most modern SMP machines where all CPUs will
	observe a sequence of values for a given variable that is
	consistent with at least one global order of values for
	that variable.
	Cache coherence also guarantees that at the end of a group
	of stores to a given variable, all CPUs will agree
	on the final value for that variable.
	Note that cache coherence applies only to the series of values
	taken on by a single variable.
	In contrast, the memory consistency model for a given machine
	describes the order in which loads and stores to groups of
	variables will appear to occur.
	See Section~\ref{sec:memorder:Cache Coherence}
	for more information.

\fi

\item[Cache Coherence Protocol:]\index{Cache coherence protocol}
	일반적으로 하드웨어로 구현되며 메모리 일관성과 순서를 강제하고 다른 CPU
	들이 각자의 캐쉬에 있는 데이터에 대해 비일관된 시각을 갖는 것을
	방지하는 통신 규약.
\item[Cache Geometry:]\index{Cache geometry}
	캐쉬의 용량과 associativity 는 geometry 라 명명됩니다.
	각 캐쉬는 2차원 배열로 생각될 수 있는데, 같은 해쉬 값을 갖는 캐쉬
	라인이 열들 (``set'') 을 구성하고 다른 해쉬 값을 갖는 캐쉬 라인들이 행
	(``way'') 을 구성합니다. 
	캐쉬의 associativity 는 행의 갯수이며 (따라서 ``way'' 라
	불립니다--2- y set-associative 캐쉬는 두개의 ``way'' 를 갖습니다),
	캐쉬의 용량은 열의 수에 행의 수를 곱한 값입니다.

\iffalse

\item[Cache Coherence Protocol:]\index{Cache coherence protocol}
	A communications protocol, normally implemented in hardware,
	that enforces memory consistency and ordering, preventing
	different CPUs from seeing inconsistent views of data held
	in their caches.
\item[Cache Geometry:]\index{Cache geometry}
	The size and associativity of a cache is termed its geometry.
	Each cache may be thought of as a two-dimensional array,
	with rows of cache lines (``sets'') that have the same hash
	value, and columns of cache lines (``ways'') in which every
	cache line has a different hash value.
	The associativity of a given cache is its number of
	columns (hence the name ``way''---a two-way set-associative
	cache has two ``ways''), and the size of the cache is its
	number of rows multiplied by its number of columns.

\fi

\item[Cache Line:]\index{Cache line}
	(1) CPU 와 메모리 사이를 순환하는 데이터의 단위로 일반적으로 크지 않은
	2의 승수.
	(2) 하나의 캐쉬 라인 단위의 데이터를 담아두는 게 가능한 CPU 캐쉬의
	물리적 지역.
	(3) 하나의 캐쉬 라인 단위의 데이터를 담아주는 게 가능한, 그러나 또한
	캐쉬 라인 범위로 정렬된 메모리 상의 물리 지역.
	예를 들어, 메모리 상의 캐쉬 라인의 첫번째 워드의 주소는 256-바이트
	캐쉬라인의 시스템에서는 0x00 으로 끝날 겁니다.

\iffalse

\item[Cache Line:]\index{Cache line}
	(1) The unit of data that circulates among the CPUs and memory,
	usually a moderate power of two in size.
	Typical cache-line sizes range from 16 to 256 bytes. \\
	(2) A physical location in a CPU cache capable of holding
	one cache-line unit of data. \\
	(3) A physical location in memory capable of holding one
	cache-line unit of data, but that it also aligned
	on a cache-line boundary.
	For example, the address of the first word of a cache line
	in memory will end in 0x00 on systems with 256-byte cache lines.

\fi

\item[Cache Miss:]\index{Cache miss}
	캐쉬 미스는 CPU 에게 필요한 데이터가 해당 CPU 의 캐쉬에 없을 때
	발생합니다.
	그 데이터는 여러 이유로 없을 수 있는데, 그 이유들은 다음을 포함합니다:
	(1) 이 CPU 는 이전에 해당 데이터에 액세스한 적이 없음 (``startup'' 또는
	``warmup'' 미스),
	(2) 이 CPU 는 최근에 캐쉬에 들어갈 수 있는 것보다 많은 데이터에 액세스
	했으며, 따라서 기존의 데이터 일부는 제거되었음 (``capacity'' 미스),
	(3) 이 CPU 는 최근에 해당 set 에\footnote{
		하드웨어 캐쉬 명명법에서, ``set'' 은 소프트웨어 캐쉬를 논할 때
		사용되는 ``bucket'' 이라는 용어와 같은 의미를 갖습니다.}
	그 set 이 담아둘 수 있는 것보다 많은 데이터를 액세스 했음
	(``associativity'' 미스),
	(4) 이 CPU 의 해당 데이터로의 액세스 후에 다른 CPU 가 해당 데이터에
	(또는 같은 캐쉬 라인의 다른 데이터에) 쓰기를 했음  (``communication
	미스''), 또는
	(5) 이 CPU 가 아마도 현재 해당 라인이 다른 CPU 의 캐쉬에 복사되어 있는
	관계로 현재 read-only 인 캐쉬 라인에 쓰기를 시도했음.

\iffalse

\item[Cache Miss:]\index{Cache miss}
	A cache miss occurs when data needed by the CPU is not in
	that CPU's cache.
	The data might be missing because of a number of reasons,
	including:
	(1) this CPU has never accessed the data before
	(``startup'' or ``warmup'' miss),
	(2) this CPU has recently accessed more
	data than would fit in its cache, so that some of the older
	data had to be removed (``capacity'' miss),
	(3) this CPU
	has recently accessed more data in a given set\footnote{
		In hardware-cache terminology, the word ``set''
		is used in the same way that the word ``bucket''
		is used when discussing software caches.}
	than that set could hold (``associativity'' miss),
	(4) some other CPU has written to the data (or some other
	data in the same cache line) since this CPU has accessed it
	(``communication miss''), or
	(5) this CPU attempted to write to a cache line that is
	currently read-only, possibly due to that line being replicated
	in other CPUs' caches.

\fi

\item[Capacity Miss:]\index{Capacity miss}
	연관된 CPU 가 최근에 캐쉬에 들어갈 수 있는 것보다 많은 데이터를 액세스
	했기 때문에 발생하는 캐쉬 미스.
\item[Clash Free:]\index{Clash free}
	경쟁이 없는 경우엔 최소한 한의 쓰레드가 유한한 시간 내에 진행을
	만들어내는 진행 보장.
\item[Code Locking:]\index{Code locking}
	하나의 ``전역 락'' 이 크리티컬 섹션 집합을 보호하는 데 사용되어 해당
	집합으로의 어떤 쓰레드의 액세스는 이 쓰레드가 어떤 데이터에 접근하려
	하는가가 아니라 현재 그 크리티컬 섹션 집합을 지배하고 있는 쓰레드의
	집합에 의해서만 허락되거나 거부되는 간단한 락킹 설계.
	Code locking 이 사용되는 프로그램의 확장성은 해당 코드에 의해
	제한됩니다; 이 데이터 집합의 크기를 늘리는 것은 일반적으로 확장성을
	증가시키지 않습니다 (사실, ``락 경쟁'' 을 늘림으로써 확장성을
	\emph{감소} 시킬 겁니다).
	``Data locking'' 의 반대.

\iffalse

\item[Capacity Miss:]\index{Capacity miss}
	A cache miss incurred because the corresponding CPU has recently
	accessed more data than will fit into the cache.
\item[Clash Free:]\index{Clash free}
	A forward-progress guarantee in which, in the absence of
	contention, at least one thread makes progress within a finite
	period of time.
\item[Code Locking:]\index{Code locking}
	A simple locking design in which a ``global lock'' is used to protect
	a set of critical sections, so that access by a given thread
	to that set is
	granted or denied based only on the set of threads currently
	occupying the set of critical sections, not based on what
	data the thread intends to access.
	The scalability of a code-locked program is limited by the code;
	increasing the size of the data set will normally not increase
	scalability (in fact, will typically \emph{decrease} scalability
	by increasing ``lock contention'').
	Contrast with ``data locking''.

\fi

\item[Communication Miss:]\index{Communication miss}
	이 CPU 가 어떤 캐쉬 라인에 마지막으로 액세스 한 후에 다른 CPU 가 그
	캐쉬 라인에 쓰기를 했기 때문에 발생하는 캐쉬 미스.
\item[Concurrent:]\index{Concurrent}
	이 책에서는 병렬 (parallel) 의 유사어.
	이 두 용어 사이의 최근의 구별에 대한 토론을 위해선
	\cpageref{sec:app:questions:What is the Difference Between ``Concurrent'' and ``Parallel''?}
	\cref{sec:app:questions:What is the Difference Between ``Concurrent'' and ``Parallel''?}
	를 보시기 바랍니다.
\item[Critical Section:]\index{Critical section}
	어떤 동기화 메커니즘으로 보호되어 그 수행이 그 기능으로 제한되는 코드의
	섹션.
	예를 들어, 크리티컬 섹션들의 한 집합이 같은 전역 락으로 보호된다면,
	한번에 이 크리티컬 섹션들 중 하나만이 수행될 겁니다.
	어떤 쓰레드가 그런 크리티컬 섹션 중 하나에서 수행 중이라면 모든 다른
	쓰레드는 해당 크리티컬 섹션 집합의 어떤 것이든 수행하기 전에 이 첫번째
	쓰레드가 완료되길 기다려야만 합니다.

\iffalse

\item[Communication Miss:]\index{Communication miss}
	A cache miss incurred because some other CPU has written to
	the cache line since the last time this CPU accessed it.
\item[Concurrent:]\index{Concurrent}
	In this book, a synonym of parallel.
	Please see \cref{sec:app:questions:What is the Difference Between ``Concurrent'' and ``Parallel''?}
	on \cpageref{sec:app:questions:What is the Difference Between ``Concurrent'' and ``Parallel''?}
	for a discussion of the recent distinction between these two
	terms.
\item[Critical Section:]\index{Critical section}
	A section of code guarded by some synchronization mechanism,
	so that its execution constrained by that primitive.
	For example, if a set of critical sections are guarded by
	the same global lock, then only one of those critical sections
	may be executing at a given time.
	If a thread is executing in one such critical section,
	any other threads must wait until the first thread completes
	before executing any of the critical sections in the set.

\fi

\item[Data Locking:]\index{Data locking}
	데이터 구조의 각 인스턴스가 자신의 락을 갖는 확장 가능한 락킹 설계.
	각 쓰레드가 이 데이터 구조의 다른 인스턴스를 사용한다면, 모든 쓰레드는
	동시에 크리티컬 섹션의 집합에서 수행될 수 있습니다.
	Data locking 은 CPU 의 수를 데이터의 인스턴스의 수가 증가하는만큼
	늘리는 것으로 자동적으로 확장하는 장점을 갖습니다.
	``Code locking'' 과 반대입니다.
\item[Data Race:]\index{Data race}
	여러 CPU 나 쓰레드가 한 변수에 동시에 접근하며 그 액세스들 중 최소
	하나는 스토어이고 그것들 중 하나는 마크되지 않은 경우의 레이스 컨디션
	(race condition).
	Data race 의 존재는 종종 버그의 존재를 암시하지만 data race 의 부재는
	버그의 부재를 암시하지 않음을 알아두는게 중요합니다.
	(``Marked access'' 를 보세요.)
\item[Deadlock Free:]\index{Deadlock free}
	실패의 부재 시에는 최소 하나의 쓰레드가 유한시간 내에 진행을 만들어
	낸다는 진행 보장.

\iffalse

\item[Data Locking:]\index{Data locking}
	A scalable locking design in which each instance of a given
	data structure has its own lock.
	If each thread is using a different instance of the
	data structure, then all of the threads may be executing in
	the set of critical sections simultaneously.
	Data locking has the advantage of automatically scaling to
	increasing numbers of CPUs as the number of instances of
	data grows.
	Contrast with ``code locking''.
\item[Data Race:]\index{Data race}
	A race condition in which several CPUs or threads access
	a variable concurrently, and in which at least one of those
	accesses is a store and at least one of those accesses
	is unmarked.
	It is important to note that while the presence of data races
	often indicates the presence of bugs, the absence of data races
	in no way implies the absence of bugs.
	(See ``Marked access''.)
\item[Deadlock Free:]\index{Deadlock free}
	A forward-progress guarantee in which, in the absence of
	failures, at least one thread makes progress within a finite
	period of time.

\fi

\item[Direct-Mapped Cache:]\index{Direct-mapped cache}
	하나의 way 만을 가지는 캐쉬.
	따라서 특정 해쉬 값에 대해선 하나의 캐쉬 라인 만을 가질 수 있습니다.
\item[Efficiency:]\index{Efficiency}
	보통 어떤 최대값을 실제로 성취할 수 있는 어떤 수치의 비율로 표현되는
	효과의 측정치.
	이 최대 값은 이론적 최대값일 수도 있으나, 병렬 프로그래밍에서는 종종
	연관된 단일 쓰레드에서의 수치 측정값에 기반하고는 합니다.
\item[Embarrassingly Parallel:]\index{Embarrassingly parallel}
	쓰레드를 더하는 것이 연산의 전체 비용을 크게 늘리지 않아서 쓰레드가
	더해짐에 따라 (충분한 CPU 가 있다는 가정 하에) 선형적 속도 향상을
	일으키게 하는 알고리즘 또는 문제.
\item[Exclusive Lock:]\index{Exclusive lock}
	Exclusive lock 은 한번에 하나의 쓰레드만이 이 락에 의해 보호되는
	크리티컬 섹션의 집합에 들어갈 수 있게 허용하는 상호 배타
	메커니즘입니다.

\iffalse

\item[Direct-Mapped Cache:]\index{Direct-mapped cache}
	A cache with only one way, so that it may hold only one cache
	line with a given hash value.
\item[Efficiency:]\index{Efficiency}
	A measure of effectiveness normally expressed as a ratio of
	of some metric actually achieved to some maximum value.
	The maximum value might be a theoretical maximum, but in
	parallel programming is often based on the corresponding
	measured single-threaded metric.
\item[Embarrassingly Parallel:]\index{Embarrassingly parallel}
	A problem or algorithm where adding threads does not significantly
	increase the overall cost of the computation, resulting in
	linear speedups as threads are added (assuming sufficient
	CPUs are available).
\item[Exclusive Lock:]\index{Exclusive lock}
	An exclusive lock is a mutual-exclusion mechanism that
	permits only one thread at a time into the
	set of critical sections guarded by that lock.

\fi

\item[False Sharing:]\index{False sharing}
	두 CPU 가 각각 빈번하게 데이터 항목들 한쌍 중 하나에 쓰기를 하지만 이
	데이터 항목 한쌍은 같은 캐쉬 라인에 위치해 있다면, 이 캐쉬 라인은
	반복적으로 무효화 되어, 이 두 CPU 의 캐쉬들 사이를 왔다갔다 할 겁니다.
	이는 ``cacheline bouncing'' 이라고도 불리는 ``cache thrashing'' 의
	(앞의 것이 리눅스 커뮤니티에서는 가장 흔하게 사용됩니다) 흔한
	이유입니다.
	False sharing 은 성능과 확장성을 모두 극적으로 감소시킬 수 있습니다.
\item[Fragmentation:]\index{Fragmentation}
	사용되지 않은 많은 양의 메모리를 가졌지만 상대적으로 작은 할당 요청을
	만족시킬 수 없는 형태로 배치된 메모리 풀은 fragment 되었다고
	표현됩니다.
	External fragmentation 은 공간이 할당된 메모리 블락들 사이에 놓인 작은
	조각들로 분리되어 있을 때 발생하며, internal fragmentation 은 특정 요청
	또는 요청의 종류가 실제로 요청된 것보다 많은 메모리를 가져갈 때
	발생합니다.
\item[Fully Associative Cache:]\index{Fully associative cache}
	Fully associative cache 는 하나의 set 만을 가져서 용량에 맞는 한 어떤
	메모리의 부분집합이든 담을 수 있습니다.

\iffalse

\item[False Sharing:]\index{False sharing}
	If two CPUs each frequently write to one of a pair of data items,
	but the pair of data items are located in the same cache line,
	this cache line will be repeatedly invalidated, ``ping-ponging''
	back and forth between the two CPUs' caches.
	This is a common cause of ``cache thrashing'', also called
	``cacheline bouncing'' (the latter most commonly in the Linux
	community).
	False sharing can dramatically reduce both performance and
	scalability.
\item[Fragmentation:]\index{Fragmentation}
	A memory pool that has a large amount of unused memory, but
	not laid out to permit satisfying a relatively small request
	is said to be fragmented.
	External fragmentation occurs when the space is divided up
	into small fragments lying between allocated blocks of memory,
	while internal fragmentation occurs when specific requests or
	types of requests have been allotted more memory than they
	actually requested.
\item[Fully Associative Cache:]\index{Fully associative cache}
	A fully associative cache contains only
	one set, so that it can hold any subset of
	memory that fits within its capacity.

\fi

\item[Grace Period:]\index{Grace period}
	Grace period 는 연속적인 시간 구간으로 이 시간 구간의 시작 전에 시작된
	모든 RCU read-side 크리티컬 섹션은 이 시간 구간의 종료 전에 완료됩니다.
	많은 RCU 구현은 각 쓰레드가 최소 하나의 quiescent state 를 지나간
	동안의 시간 간격으로 정의합니다.
	RCU read-side 크리티컬 섹션은 정의상 quiescent state 를 포함할 수
	없으므로, 이 두 정의는 거의 항상 상호교체 가능합니다.
\item[Hazard Pointer:]\index{Hazard pointer}
	레퍼런스 카운터의 확장성 있는 버전으로 객체의 레퍼런스 카운트는 이
	객체를 참조하는 특수 해저드 포인터의 수로 묵시적으로 표현됩니다.
\item[Heisenbug:]\index{Heisenbug}
	그것을 추적하고자 print 문이나 tracing 을 시도하면 시야에서 사라지는
	시간 관계에 민감한 버그.

\iffalse

\item[Grace Period:]\index{Grace period}
	A grace period is any contiguous time interval such that
	any RCU read-side critical section that began before the
	start of that interval has
	completed before the end of that same interval.
	Many RCU implementations define a grace period to be a
	time interval during which each thread has passed through at
	least one quiescent state.
	Since RCU read-side critical sections by definition cannot
	contain quiescent states, these two definitions are almost
	always interchangeable.
\item[Hazard Pointer:]\index{Hazard pointer}
	A scalable counterpart to a reference counter in which an
	object's reference count is represented implicitly by a count
	of the number of special hazard pointers referencing that object.
\item[Heisenbug:]\index{Heisenbug}
	A timing-sensitive bug that disappears from sight when you
	add print statements or tracing in an attempt to track it
	down.

\fi

\item[Hot Spot:]\index{Hot spot}
	매우 많이 사용되어서 연관된 락에 높은 수준의 경쟁을 유발시키는 데이터
	구조.
	이 상황의 한 예는 잘못 골라진 해쉬 함수를 사용하는 해쉬 테이블이
	되겠습니다.
\item[Humiliatingly Parallel:]\index{Humiliatingly parallel}
	쓰레드를 더하는 것이 연산의 전체 비용을 심각하게 \emph{감소} 시켜서
	쓰레드가 더해짐에 따라 상당한 (충분한 CPU 가 있다는 가정 하에) 초선형
	속도향상을 이루는 문제 또는 알고리즘.
\item[Invalidation:]\index{Invalidation}
	어떤 CPU 가 어떤 데이터 항목에 쓰기를 하고자 할 때, 이 CPU 는 먼저 이
	데이터 항목이 다른 CPU 의 캐쉬에 존재하지 않음을 보장해야 합니다.
	필요하다면 이 항목은 쓰기를 하는 CPU 에서 그 복사본을 각자의 캐쉬에
	가지고 있는 모든 CPU 에게 ``invalidation'' 메세지를 보냄으로써 다른 CPU
	의 캐쉬들로부터 그 항목을 제거할 수 있습니다.
\item[IPI:]\index{IPI}
	한 CPU 에서 다른 CPU 로 보내어지는 인터럽트인 프로세서간 인터럽트
	(inter-processor interrupt).
	IPI 는 리눅스 커널에서 많이 사용되는데, 한 예로 스케쥴러에서 CPU 들에게
	이제 높은 우선순위 프로세스가 수행 가능해 졌음을 알리는데 사용됩니다.

\iffalse

\item[Hot Spot:]\index{Hot spot}
	Data structure that is very heavily used, resulting in high
	levels of contention on the corresponding lock.
	One example of this situation would be a hash table with
	a poorly chosen hash function.
\item[Humiliatingly Parallel:]\index{Humiliatingly parallel}
	A problem or algorithm where adding threads significantly
	\emph{decreases} the overall cost of the computation, resulting in
	large superlinear speedups as threads are added (assuming sufficient
	CPUs are available).
\item[Invalidation:]\index{Invalidation}
	When a CPU wishes to write to a data item, it must first ensure
	that this data item is not present in any other CPUs' cache.
	If necessary, the item is removed from the other CPUs' caches
	via ``invalidation'' messages from the writing CPUs to any
	CPUs having a copy in their caches.
\item[IPI:]\index{IPI}
	Inter-processor interrupt, which is an
	interrupt sent from one CPU to another.
	IPIs are used heavily in the Linux kernel, for example, within
	the scheduler to alert CPUs that a high-priority process is now
	runnable.

\fi

\item[IRQ:]\index{IRQ}
	리눅스 커널 커뮤니티에서는 ``interrupt'' 의 약자로도 종종 사용되며
	``irq handler'' 라고도 불리는 인터럽트 요청.
\item[Latency:]\index{Latency}
	특정 오퍼레이션이 완료되기까지 필요한 시간.
\item[Linearizable:]\index{Linearizable}
	어떤 오퍼레이션들의 흐름은 모든 CPU 그리고/또는 쓰레드들의 관측에
	일관된 최소 하나의 전역적 순서를 가질 때 ``linearizable'' 합니다.
	Linearizability 는 많은 연구자들에게 숭상받습니다만, 예상되는 것보다는
	실전에선 덜 유용합니다~\cite{AndreasHaas2012FIFOisnt}.
\item[Lock:]\index{Lock}
	크리티컬 섹션을 보호하는데 사용될 수 있는 소프트웨어 추상화로, 한 예로
	``상호 배타 메커니즘'' 이 있습니다.
	``Exclusive lock'' 은 한번에 하나의 쓰레드만이 해당 락에 의해 보호되는
	크리티컬 섹션 집합에 들어갈 수 있게 하며, ``reader-writer lock'' 은
	읽기를 하는 쓰레드는 여럿을, 그러나 쓰기를 하는 쓰레드는 하나만 해당
	락에 의해 보호되는 크리티컬 섹션 집합에 들어갈 수 있게 허용합니다.
	(분명히 해두자면, reader-writer 락의 크리티컬 섹션에 어떤 쓰기 쓰레드가
	존재한다면 그 락의 크리티컬 섹션에 읽기 쓰레드가 들어가는 걸 금지하며
	그 반대도 마찬가지입니다.)

\iffalse

\item[IRQ:]\index{IRQ}
	Interrupt request, often used as an abbreviation for ``interrupt''
	within the Linux kernel community, as in ``irq handler''.
\item[Latency:]\index{Latency}
	The wall-clock time required for a given operation to complete.
\item[Linearizable:]\index{Linearizable}
	A sequence of operations is ``linearizable'' if there is at
	least one global ordering of the sequence that is consistent
	with the observations of all CPUs and/or threads.
	Linearizability is much prized by many researchers, but less
	useful in practice than one might
	expect~\cite{AndreasHaas2012FIFOisnt}.
\item[Lock:]\index{Lock}
	A software abstraction that can be used to guard critical sections,
	as such, an example of a ``mutual exclusion mechanism''.
	An ``exclusive lock'' permits only one thread at a time into the
	set of critical sections guarded by that lock, while a
	``reader-writer lock'' permits any number of reading
	threads, or but one writing thread, into the set of critical
	sections guarded by that lock.  (Just to be clear, the presence
	of a writer thread in any of a given reader-writer lock's
	critical sections will prevent any reader from entering
	any of that lock's critical sections and vice versa.)

\fi

\item[Lock Contention:]\index{Lock contention}
	락은 기다리는 CPU 가 있는 경우에 많이 사용된다면 경쟁 (contention)으로
	고통받는다고 이야기 됩니다.
	Lock contention 을 줄이는 것은 병렬 알고맂므을 설계할 때와 병렬
	프로그램을 구현할 때 종종 걱정거리입니다.
\item[Lock Free:]\index{Lock free}
	최소 하나의 쓰레드가 유한한 시간 내에 진행을 만들어 내는 진행 보장.
\item[Marked Access:]\index{Marked access}
	액세스가 컴파일러 그리고/또는 하드웨어에 의해 최적화 되는 걸 막기 위해
	\co{READ_ONCE()}, \co{WRITE_ONCE()}, \co{atomic_inc()}, 그 외 기타
	등등의 특수한 함수나 매크로를 사용하는 소스코드 상의 메모리 액세스.
	반대로, 마크되지 않은 액세스는 액세스 되는 객체의 이름을 이야기할
	뿐으로, 다음에서 라인~2 는 라인~1 과 같지만 마크되지 않은 것입니다:
	\begin{VerbatimN}
	WRITE_ONCE(a, READ_ONCE(b) + READ_ONCE(c));
	a = b + c;
	\end{VerbatimN}

\iffalse

\item[Lock Contention:]\index{Lock contention}
	A lock is said to be suffering contention when it is being
	used so heavily that there is often a CPU waiting on it.
	Reducing lock contention is often a concern when designing
	parallel algorithms and when implementing parallel programs.
\item[Lock Free:]\index{Lock free}
	A forward-progress guarantee in which at least one thread makes
	progress within a finite period of time.
\item[Marked Access:]\index{Marked access}
	A source-code memory access that uses a special function or
	macro, such as \co{READ_ONCE()}, \co{WRITE_ONCE()},
	\co{atomic_inc()}, and so on, in order to protect that access
	from compiler and/or hardware optimizations.
	In contrast, an unmarked access simply mentions the name of
	the object being accessed, so that in the following, line~2
	is the unmarked equivalent of line~1:
	\begin{VerbatimN}
	WRITE_ONCE(a, READ_ONCE(b) + READ_ONCE(c));
	a = b + c;
	\end{VerbatimN}

\fi

\item[Memory:]\index{Memory}
	메모리 모델의 시점에서는 값들이 저장되어 있을 수도 있는 메인 메모리,
	캐쉬, 그리고 스토어 버퍼.
	그러나, 이 용어는 캐쉬와 스토어 버퍼는 제외하고 메인 메모리만을
	가리키는데 종종 사용됩니다.
\item[Memory Consistency:]\index{Memory consistency}
	여러 변수들로의 액세스가 어떤 순서로 일어나는 것으로 보일 것인지에 대한
	제약을 발생시키는 속성들의 집합.
	Memory consistency 모델은 학계에서 유명한 매우 제약적인 모델인
	sequential consistency 부터 process conssitency, release consistency,
	그리고 weak consistency 까지 다양합니다.
\item[MESI Protocol:]\index{MESI protocol}
	modified, exclusive, shared, 그리고 invalid (MESI) 상태들을 갖추는 캐쉬
	일관성 프로토콜로, 따라서 이 프로토콜은 캐쉬 내의 캐쉬 라인들이 가질 수
	있는 상태들로부터 이름지어졌습니다.
	Modified 라인은 최근 이 CPU 에 의해 쓰기가 이루어졌고, 연관된 메모리
	위치의 현재 값에 대한 유일한 표현입니다.
	Exclusive 캐쉬 라인은 쓰기가 이루어지지 않았으나 이 CPU 는 언제든
	여기에 쓰기를 할 권리를 가지는데, 이 라인은 다른 CPU 의 캐쉬에 복사본이
	존재하지 않을 것이 (연관된 메인 메모리 위치의 값은 최신값이지만)
	보장되어 있기 때문입니다.
	Shared 캐쉬 라인은 다른 CPU 의 캐쉬에 복사본이 있을 수도 있는데, 이는
	이 CPU 가 이 캐쉬 라인에 쓰기를 하기 전에 다른 CPU 와 상호작용을 해야만
	함을 의미합니다.
	Invalid 캐쉬 라인은 값을 담지 않으며, 대신 메모리부터의 데이터가 로드될
	수 잇는 ``빈 공간'' 을 표현합니다.

\iffalse

\item[Memory:]\index{Memory}
	From the viewpoint of memory models, the main memory,
	caches, and store buffers in which values might be stored.
	However, this term is often used to denote the main memory
	itself, excluding caches and store buffers.
\item[Memory Consistency:]\index{Memory consistency}
	A set of properties that impose constraints on the order in
	which accesses to groups of variables appear to occur.
	Memory consistency models range from sequential consistency,
	a very constraining model popular in academic circles, through
	process consistency, release consistency, and weak consistency.
\item[MESI Protocol:]\index{MESI protocol}
	The
	cache-coherence protocol featuring
	modified, exclusive, shared, and invalid (MESI) states,
	so that this protocol is named after the states that the
	cache lines in a given cache can take on.
	A modified line has been recently written to by this CPU,
	and is the sole representative of the current value of
	the corresponding memory location.
	An exclusive cache line has not been written to, but this
	CPU has the right to write to it at any time, as the line
	is guaranteed not to be replicated into any other CPU's cache
	(though the corresponding location in main memory is up to date).
	A shared cache line is (or might be) replicated in some other
	CPUs' cache, meaning that this CPU must interact with those other
	CPUs before writing to this cache line.
	An invalid cache line contains no value, instead representing
	``empty space'' in the cache into which data from memory might
	be loaded.

\fi

\item[Mutual-Exclusion Mechanism:]\index{Mutual-exclusion mechanism}
	쓰레드들의 ``크리티컬 섹션'' 과 연관된 데이터로의 액세스를 규약하는
	소프트웨어 추상화.
\item[NMI:]\index{NMI}
	Non-maskable interrupt.
	이름이 이야기 하듯, 이는 가려질 (mask) 수 없는 아주 높은 운선순위의
	인터럽트입니다.
	이것들은 프로파일링 같은 하드웨어 특수 목적으로 사용됩니다.
	프로파일링에 NMI 를 사용하는 것의 장점은 이것이 인터럽트가 불능화 된
	상태에서 동작하는 코드를 프로파일 할 수 있다는 겁니다.
\item[NUCA:]\index{NUCA}
	여러 CPU 의 그룹이 캐쉬 그리고/또는 스토어 버퍼를 공유하는 Non-uniform
	cache architecture.
	따라서 그룹 내의 CPU 들은 다른 그룹의 CPU 들과 할 수 있는 것보다 훨씬
	빠르게 캐쉬 라인을 교환할수 있습니다.
	하드웨어 쓰레드를 갖는 CPU 로 구성된 시스템은 일반적으로 NUCA 구조를
	갖습니다.

\iffalse

\item[Mutual-Exclusion Mechanism:]\index{Mutual-exclusion mechanism}
	A software abstraction that regulates threads' access to
	``critical sections'' and corresponding data.
\item[NMI:]\index{NMI}
	Non-maskable interrupt.
	As the name indicates, this is an extremely high-priority
	interrupt that cannot be masked.
	These are used for hardware-specific purposes such as profiling.
	The advantage of using NMIs for profiling is that it allows you
	to profile code that runs with interrupts disabled.
\item[NUCA:]\index{NUCA}
	Non-uniform cache architecture, where groups of CPUs share
	caches and/or store buffers.
	CPUs in a group can therefore exchange cache lines with each
	other much more quickly than they can with CPUs in other groups.
	Systems comprised of CPUs with hardware threads will generally
	have a NUCA architecture.

\fi

\item[NUMA:]\index{NUMA}
	메모리가 여러 뱅크 (bank) 로 쪼개지며 각 뱅크는 ``NUMA node'' 라고
	불리는 CPU 들의 그룹에 더 ``가까운'' non-uniform memory architecture.
	NUMA 머신의 한 예는 Sequent 의 NUMA-Q 시스템으로 네개의 CPU 들이 근처의
	메모리를 가졌습니다.
	주어진 그룹 내의 CPU 는 그들의 메모리에 다른 그룹의 메모리보다 훨씬
	빠르게 액세스 할 수 있습니다.
\item[NUMA Node:]\index{NUMA node}
	거대한 NUMA 머신 내에서 가깝게 위치한 CPU 그룹과 그들에 연관된 메모리.
\item[Obstruction Free:]\index{Obstruction free}
	경쟁의 부재 시, 모든 쓰레드가 유한 시간 내에 진행을 만들어내는 진행
	보장.

\iffalse

\item[NUMA:]\index{NUMA}
	Non-uniform memory architecture, where memory is split into
	banks and each such bank is ``close'' to a group of CPUs,
	the group being termed a ``NUMA node''.
	An example NUMA machine is Sequent's NUMA-Q system, where
	each group of four CPUs had a bank of memory nearby.
	The CPUs in a given group can access their memory much
	more quickly than another group's memory.
\item[NUMA Node:]\index{NUMA node}
	A group of closely placed CPUs and associated memory within
	a larger NUMA machines.
\item[Obstruction Free:]\index{Obstruction free}
	A forward-progress guarantee in which, in the absence of
	contention, every thread makes progress within a finite
	period of time.

\fi

\item[Overhead:]\index{Overhead}
	수행되어야만 하지만 달성되어야만 하는 일에 직접적인 기여를 하지는 않는
	오퍼레이션들.
	예를 들어, 락 획득과 해제는 일반적으로 오버헤드라 여겨지며, 구체적으론
	동기화 오버헤드라 불립니다.
\item[Parallel:]\index{Parallel}
	이 책에서는 concurrent 의 유의어.
	이 두 용어에 대한 최근의 구별에 대한 토론을 위해
	\cpageref{sec:app:questions:What is the Difference Between ``Concurrent'' and ``Parallel''?} 의
	\cref{sec:app:questions:What is the Difference Between ``Concurrent'' and ``Parallel''?}
	를 보시기 바랍니다.
\item[Performance:]\index{Performance}
	일이 이루어지는 비율로 단위 시간 당 일로 표현됩니다.
	이 일이 완전히 직렬화 가능하다면 그 성능은 이 일 항목의 중간 응답시간에
	상응합니다.

\iffalse

\item[Overhead:]\index{Overhead}
	Operations that must be executed, but which do not contribute
	directly to the work that must be accomplished.
	For example, lock acquisition and release is normally considered
	to be overhead, and specifically to be synchronization overhead.
\item[Parallel:]\index{Parallel}
	In this book, a synonym of concurrent.
	Please see \cref{sec:app:questions:What is the Difference Between ``Concurrent'' and ``Parallel''?}
	on \cpageref{sec:app:questions:What is the Difference Between ``Concurrent'' and ``Parallel''?}
	for a discussion of the recent distinction between these two
	terms.
\item[Performance:]\index{Performance}
	Rate at which work is done, expressed as work per unit time.
	If this work is fully serialized, then the performance will
	be the reciprocal of the mean latency of the work items.

\fi

\item[Pipelined CPU:]\index{Pipelined CPU}
	조립 공정 라인과 어떤 면에서 유사하며 그와 같은 장점과 단점을 갖춘, CPU
	내부의 명령의 흐름인 파이프라인을 가진 CPU.
	1960 년대부터 1980 년대 초까지, pipelined CPU 는 슈퍼컴퓨터의
	영역이었으나, 1980 년대 후반부터는 (80486 같은) 마이크로프로세서에서도
	나타나기 시작했습니다.
\item[Process Consistency:]\index{Process consistency}
	각 CPU 의 스토어가 프로그램 순서대로 나타나지만 다른 CPU 들은 다른 CPU
	로부터의 액세스들을 다른 순서로 일어난 것으로 볼 수도 있는 메모리
	일관성 모델.
\item[Program Order:]\index{Program order}
	특정 쓰레드의 명령들이 이제는 가상의 것인, 다음 명령을 진행하기 전에 각
	명령을 완전히 수행하는, ``순서를 지키는'' CPU 에 의해 수행되는 순서.
	(그런 CPU 가 이제는 고대의 전설과 신화로 남게 된 이유는 그것들은
	극단적으로 느렸기 때문입니다.
	이 공룡들은 
	\IXalt{Moore's-Law}{Moore's Law} 가 주도한 CPU 클락 주파수 증가의 많은
	희생자 중 하나였습니다.
	일부는 이 짐승들이 다시 한번 지구를 정복할 거라 주장하지만, 다른
	살마들은 강력히 부정합니다.)

\iffalse

\item[Pipelined CPU:]\index{Pipelined CPU}
	A CPU with a pipeline, which is
	an internal flow of instructions internal to the CPU that
	is in some way similar to an assembly line, with many of
	the same advantages and disadvantages.
	In the 1960s through the early 1980s, pipelined CPUs were the
	province of supercomputers, but started appearing in microprocessors
	(such as the 80486) in the late 1980s.
\item[Process Consistency:]\index{Process consistency}
	A memory-consistency model in which each CPU's stores appear to
	occur in program order, but in which different CPUs might see
	accesses from more than one CPU as occurring in different orders.
\item[Program Order:]\index{Program order}
	The order in which a given thread's instructions
	would be executed by a now-mythical ``in-order'' CPU that
	completely executed each instruction before proceeding to
	the next instruction.
	(The reason such CPUs are now the stuff of ancient myths
	and legends is that they were extremely slow.
	These dinosaurs were one of the many victims of
	\IXalt{Moore's-Law}{Moore's Law}-driven increases in CPU clock frequency.
	Some claim that these beasts will roam the earth once again,
	others vehemently disagree.)

\fi

\item[Quiescent State:]\index{Quiescent state}
	RCU 에서는 RCU 로 보호된 데이터 구조로 잡힌 참조가 존재할 수 없는
	코드 상의 지점으로, 일반적으로는 RCU read-side 크리티컬 섹션 바깥의
	모든 지점.
	모든 쓰레드가 최소 하나의 quiescent state 를 지나가는 시간 기간을
	``grace period'' 라 부릅니다.
\item[Read-Copy Update (RCU):]\index{Read-copy update (RCU)}
	Reader-writer 락킹이나 레퍼런스 카운팅의 대체제로 생각될 수 있는 동기화
	메커니즘.
	RCU 는 읽기 쓰레드에게 극단적으로 낮은 오버헤드의 액세스를 제공하며,
	쓰기 쓰레드는 앞서서부터 존재해 온 읽기 쓰레드에게 이득을 제공하기 위해
	오래된 버전의 데이터를 유지해야 하는 추가적 오버헤드를 일으킵니다.
	읽기 쓰레드는 블록되지도 스핀하지도 않으며, 따라서 데드락에 참여될 수
	없습니다만, 상해버린 데이터를 볼 수 있고 업데이트와 동시에 수행될 수
	있습니다.
	따라서 RCU 는 상한 데이터가 처리될 수 있거나 (라우팅 테이블처럼) 회피될
	수 있는 (리눅스 커널의 System V IPC 구현처럼) 읽기가 대부분인 상황에
	가장 잘 맞습니다.

\iffalse

\item[Quiescent State:]\index{Quiescent state}
	In RCU, a point in the code where there can be no references held
	to RCU-protected data structures, which is normally any point
	outside of an RCU read-side critical section.
	Any interval of time during which all threads pass through at
	least one quiescent state each is termed a ``grace period''.
\item[Read-Copy Update (RCU):]\index{Read-copy update (RCU)}
	A synchronization mechanism that can be thought of as a replacement
	for reader-writer locking or reference counting.
	RCU provides extremely low-overhead access for readers, while
	writers incur additional overhead maintaining old versions
	for the benefit of pre-existing readers.
	Readers neither block nor spin, and thus cannot participate in
	deadlocks, however, they also can see stale data and can
	run concurrently with updates.
	RCU is thus best-suited for read-mostly situations where
	stale data can either be tolerated (as in routing tables)
	or avoided (as in the Linux kernel's System V IPC implementation).

\fi

\item[Read-Side Critical Section:]\index{Read-side critical section}
	어떤 Reader-writer 동기화 메커니즘의 읽기-획득으로 보호되는 코드 섹션.
	예를 들어, 크리티컬 섹션들의 한 집합이 특정 전역 reader-writer 락의
	읽기-획득으로 보호되며 크리티컬 섹션의 다른 집합은 같은 reader-writer
	락의 쓰기-획득으로 보호된다면, 첫번째 집합은 이 락의 read-side 크리티컬
	섹션이 됩니다.
	어떤 수의 쓰레드들이건 read-side 크리티컬 섹션을 동시에 수행할 수
	있습니다만 어떤 쓰레드도 write-side 크리티컬 섹션을 수행하고 있지 않을
	때만 그렇습니다.
\item[Reader-Writer Lock:]\index{Reader-writer lock}
	Reader-writer 락은 읽기를 하는 쓰레드는 수에 관계 없이, 그러나 쓰기를
	하는 쓰레드는 하나만 그 락에 의해 보호되는 크리티컬 섹션에 허용하는
	상호 배타 (mutual exclusive) 메커니즘입니다.
	쓰기를 하고자 하는 쓰레드는 모든 앞서서부터 존재한 읽기를 하는 쓰레드가
	락을 내려놓길 기다려야만 하며, 비슷하게 앞서서부터 존재한 쓰기 쓰레드가
	있다면 쓰기를 하고자 하는 쓰레드는 그 쓰기 쓰레드가 락을 내려놓기를
	기다려야만 합니다.
	Reader-writer 락에의 핵심 걱정거리는 ``fairness (공정성)'' 입니다:
	끝나지 않는 읽기 쓰레드의 흐름은 쓰기 쓰레드를 기아에 빠뜨릴 수 있고
	반대도 마찬가지입니다.

\iffalse

\item[Read-Side Critical Section:]\index{Read-side critical section}
	A section of code guarded by read-acquisition of
	some reader-writer synchronization mechanism.
	For example, if one set of critical sections are guarded by
	read-acquisition of
	a given global reader-writer lock, while a second set of critical
	section are guarded by write-acquisition of that same reader-writer
	lock, then the first set of critical sections will be the
	read-side critical sections for that lock.
	Any number of threads may concurrently execute the read-side
	critical sections, but only if no thread is executing one of
	the write-side critical sections.
\item[Reader-Writer Lock:]\index{Reader-writer lock}
	A reader-writer lock is a mutual-exclusion mechanism that
	permits any number of reading
	threads, or but one writing thread, into the set of critical
	sections guarded by that lock.
	Threads attempting to write must wait until all pre-existing
	reading threads release the lock, and, similarly, if there
	is a pre-existing writer, any threads attempting to write must
	wait for the writer to release the lock.
	A key concern for reader-writer locks is ``fairness'':
	can an unending stream of readers starve a writer or vice versa.

\fi

\item[Real Time:]\index{Real time}
	올바른 결과를 얻는 것만으로는 불충분하고 이 결과를 주어진 시간 내에
	얻어야만 하는 상황.
\item[Scalability:]\index{Scalability}
	주어진 시스템이 얼마나 효과적으로 추가적인 자원을 사용할 수 있는가에
	대한 측정.
	병렬 컴퓨팅의 경우, 이 추가적 자원은 일반적으로 추가되는 CPU 입니다.
\item[Sequence Lock:]\index{Sequence lock}
	쓰기 쓰레드가 존재하는 경우 읽기 쓰레드는 오퍼레이션을 재시도하는
	하나의 reader-writer 동기화 메커니즘.
\item[Sequential Consistency:]\index{Sequential consistency}
	모든 메모리 참조가 하나의 전역적 순서에 일관된 순서로 일어나는 것으로
	보이며 각 CPU 의 메모리 참조는 모든 CPU 에게 program order 로 일어나는
	것으로 보이게 하는 memory-consistency model.
\item[Starvation Free:]\index{Starvation free}
	실패의 부재 시에는 모든 쓰레드가 유한 시간 내에 진행을 만드는 진행
	보장.

\iffalse

\item[Real Time:]\index{Real time}
	A situation in which getting the correct result is not sufficient,
	but where this result must also be obtained within a given amount
	of time.
\item[Scalability:]\index{Scalability}
	A measure of how effectively a given system is able to utilize
	additional resources.
	For parallel computing, the additional resources are usually
	additional CPUs.
\item[Sequence Lock:]\index{Sequence lock}
	A reader-writer synchronization mechanism in which readers
	retry their operations if a writer was present.
\item[Sequential Consistency:]\index{Sequential consistency}
	A memory-consistency model where all memory references appear to occur
	in an order consistent with
	a single global order, and where each CPU's memory references
	appear to all CPUs to occur in program order.
\item[Starvation Free:]\index{Starvation free}
	A forward-progress guarantee in which, in the absence of
	failures, every thread makes progress within a finite
	period of time.

\fi

\item[Store Buffer:]\index{Store buffer}
	연관된 캐쉬라인이 해당 CPU 로 이동하는 사이에 보류된 스토어를 기록해
	두는데 사용되는 CPU 의 작은 내부 레지스터들의 집합.
	``Store queue'' 라고도 불립니다.
\item[Store Forwarding:]\index{Store forwarding}
	소프트웨어가 이 CPU 에 의해 수행된 메모리 오퍼레이션이 program order 로
	수행된 것으로 볼 것을 보장하기 위해 특정 CPU 가 자신의 store buffer 는
	물론이고 캐쉬를 참조하는 조정.
\item[Superscalar CPU:]\index{Superscalar CPU}
	여러 명령을 동시에 수행할 수 있는 scalar (비 vector) CPU.
	이는 여러 명령을 조립 공정 라인 형태로 수행하는 pipelined CPU 에서
	한단계 더 나아간 것입니다---superscalar CPU 에서는 각 파이프라인 단계가
	여러 명령을 처리할 수 있습니다.
	예를 들어, 조건이 정확히 맞는다면 1990년대 중반의 Intel Pentium Pro CPU
	는 클락 사이클 당 두개의 (어떤 경우는 세개) 명령을 수행할 수 있습니다.
	따라서, 200\,MHz Pentim Pro CPU 는 매 초마다 최대 4억개의 명령을 수행
	완료 하거나 종료시킬 (``retire'') 수 있습니다.

\iffalse

\item[Store Buffer:]\index{Store buffer}
	A small set of internal registers used by a given CPU
	to record pending stores
	while the corresponding cache lines are making their
	way to that CPU\@.
	Also called ``store queue''.
\item[Store Forwarding:]\index{Store forwarding}
	An arrangement where a given CPU refers to its store buffer
	as well as its cache so as to ensure that the software sees
	the memory operations performed by this CPU as if they
	were carried out in program order.
\item[Superscalar CPU:]\index{Superscalar CPU}
	A scalar (non-vector) CPU capable of executing multiple instructions
	concurrently.
	This is a step up from a pipelined CPU that executes multiple
	instructions in an assembly-line fashion---in a superscalar
	CPU, each stage of the pipeline would be capable of handling
	more than one instruction.
	For example, if the conditions were exactly right,
	the Intel Pentium Pro CPU from the mid-1990s could
	execute two (and sometimes three) instructions per clock cycle.
	Thus, a 200\,MHz Pentium Pro CPU could ``retire'', or complete the
	execution of, up to 400 million instructions per second.

\fi

\item[Synchronization:]\index{Synchronization}
	CPU 나 쓰레드 사이의 잘못된 상호작용을 막기 위한 수단.
	Synchronization 메커니즘에는 atomic RMW 오퍼레이션, 메모리 배리어,
	락킹, 레퍼런스 카운팅, 해저드 포인터, sequence locking, RCU,
	non-blocking synchronization, 그리고 트랜잭셔널 메모리가 포함됩니다.
\item[Teachable:]\index{Teachable}
	교사들이 자신들은 완전히 이해하고 있다고 빋으며 따라서 가르치길
	편해하는 주제, 컨셉, 방법, 또는 메커니즘.
\item[Throughput:]\index{Throughput}
	단위 시간당 완료되는 일 항목을 갖는 성능 수치.
\item[Transactional Lock Elision (TLE):]\index{Transactional lock elision (TLE)}
	락킹을 에뮬레이션 하기 위한 트랜잭셔널 메모리의 사용.
	동기화는 락으로 보호되는 데이터로의 충돌하는 액세스들에 의해
	이루어집니다.
	어떤 경우, 이는 TLE 가 락 세계의 경쟁을 막기 때문에 성능을
	증가시킵니다~\cite{MartinPohlack2011HTM2TLE,Kleen:2014:SEL:2566590.2576793,PascalFelber2016rwlockElision,SeongJaePark2020HTMRCUlock}.

\iffalse

\item[Synchronization:]\index{Synchronization}
	Means for avoiding destructive interactions among CPUs or threads.
	Synchronization mechanisms include atomic RMW operations, memory
	barriers, locking, reference counting, hazard pointers, sequence
	locking, RCU, non-blocking synchronization, and transactional
	memory.
\item[Teachable:]\index{Teachable}
	A topic, concept, method, or mechanism that teachers believe that
	they understand completely and are therefore comfortable teaching.
\item[Throughput:]\index{Throughput}
	A performance metric featuring work items completed per unit time.
\item[Transactional Lock Elision (TLE):]\index{Transactional lock elision (TLE)}
	The use of transactional memory to emulate locking.
	Synchronization is instead carried out by conflicting accesses
	to the data to be protected by the lock.
	In some cases, this can increase performance because TLE
	avoids contention on the lock
	word~\cite{MartinPohlack2011HTM2TLE,Kleen:2014:SEL:2566590.2576793,PascalFelber2016rwlockElision,SeongJaePark2020HTMRCUlock}.

\fi

\item[Transactional Memory (TM):]\index{Transactional memory (TM)}
	메모리 액세스의 한 그룹을 모아서 그것들을 다른 CPU 나 쓰레드의
	트랜잭션의 관점에서는 어토믹하게 보이게 수행시키는 동기화 메커니즘.
\item[Unteachable:]\index{Unteachable}
	교사가 잘 이해하고 있지 못하며 따라서 가르치길 불편해 하는 주제, 컨셉,
	방법, 또는 메커니즘.
\item[Vector CPU:]\index{Vector CPU}
	하나의 명령을 여러 데이터 항목에 동시에 적용할 수 있는 CPU.
	1960년대 부터 1980년대까지는 슈퍼컴퓨터들만이 vector 능력을
	가졌습니다만, x86 CPU 에서의 MMX 와 PowerPC CPU 에서의 VMX 의 발전은
	vector 처리를 대중화 시켰습니다.

\iffalse

\item[Transactional Memory (TM):]\index{Transactional memory (TM)}
	A synchronization mechanism that gathers groups of memory
	accesses so as to execute them atomically from the viewpoint
	of transactions on other CPUs or threads.
\item[Unteachable:]\index{Unteachable}
	A topic, concept, method, or mechanism that the teacher does
	not understand well is therefore uncomfortable teaching.
\item[Vector CPU:]\index{Vector CPU}
	A CPU that can apply a single instruction to multiple items of
	data concurrently.
	In the 1960s through the 1980s, only supercomputers had vector
	capabilities, but the advent of MMX in x86 CPUs and VMX in
	PowerPC CPUs brought vector processing to the masses.

\fi

\item[Wait Free:]\index{Wait free}
	모든 쓰레드가 유한 시간 내에 진행을 이루어내는 진행 보장.
\item[Write Miss:]\index{Write miss}
	아마도 그것이 다른 CPU 의 캐쉬에 복사본을 가지고 있기 때문에 읽기
	전용인 캐쉬 라인에 쓰기를 시도해서 발생하는 캐쉬 미스.
\item[Write-Side Critical Section:]\index{Write-side critical section}
	어떤 reader-writer 동기화 메커니즘의 쓰기-획득으로 보호되는 코드 섹션.
	예를 들어, 크리티컬 섹션들의 한 집합이 특정 전역 reader-writer 락의
	쓰기-획득으로 보호되며 또다른 크리티컬 섹션들 집합은 같은 reader-writer
	락의 읽기-획득으로 보호된다면, 첫번째 집합은 이 락의 write-side
	크리티컬 섹션이 됩니다.
	한번에 하나의 쓰레드만이 wirte-side 크리티컬 섹션에서 수행되며, 심지어
	연관된 어떤 read-side 크리티컬 섹션에서도 어떤 쓰레드도 수행되고 있지
	않을때만 그렇습니다.

\iffalse

\item[Wait Free:]\index{Wait free}
	A forward-progress guarantee in which every thread makes
	progress within a finite period of time.
\item[Write Miss:]\index{Write miss}
	A cache miss incurred because the corresponding CPU attempted
	to write to a cache line that is read-only, most likely due
	to its being replicated in other CPUs' caches.
\item[Write-Side Critical Section:]\index{Write-side critical section}
	A section of code guarded by write-acquisition of
	some reader-writer synchronization mechanism.
	For example, if one set of critical sections are guarded by
	write-acquisition of
	a given global reader-writer lock, while a second set of critical
	section are guarded by read-acquisition of that same reader-writer
	lock, then the first set of critical sections will be the
	write-side critical sections for that lock.
	Only one thread may execute in the write-side critical section
	at a time, and even then only if there are no threads are
	executing concurrently in any of the corresponding read-side
	critical sections.

\fi

\end{description}
