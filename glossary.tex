% glossary.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\chapter{Glossary and Bibliography}
%
\Epigraph{Dictionaries are inherently circular in nature.}
	 {\emph{``Self Reference in word definitions'',
	        David~Levary~et~al.}}

\begin{description}
\item[Associativity:]
	캐시가 동시에 쥐고 있을 수 있는, 해당 캐시 내에서 동일하게 해시되는
	캐시라인들의 갯수.
	각각의 해시 값 별로 네개의 캐시 라인을 들고 있을 수 있는 캐시는
	``four-way set-associative'' 캐시라 명칭되며, 각각의 해시 값 별로
	한개의 캐시 라인만을 들고 있을 수 있는 캐시는 ``direct-mapped''
	캐시라고 불리워집니다.
	Associativity 가 그 용량과 동일한 캐시는 ``fully associative'' 캐시라
	불리워집니다.
	Fully asociative 캐시는 associativity 미스를 제거할 수 있는 장점이
	있습니다만, 하드웨어적 한계 때문에, fully associative 캐시는 일반적으로
	크기가 제한됩니다.
	최신 마이크로프로세서에 장착되는 커다란 캐시의 associativity 는
	일반적으로 two-way 에서 eight-way 사이입니다.
	\iffalse

	The number of cache lines that can be held simultaneously in
	a given cache, when all of these cache lines hash identically
	in that cache.
	A cache that could hold four cache lines for each possible
	hash value would be termed a ``four-way set-associative'' cache,
	while a cache that could hold only one cache line for each
	possible hash value would be termed a ``direct-mapped'' cache.
	A cache whose associativity was equal to its capacity would
	be termed a ``fully associative'' cache.
	Fully associative caches have the advantage of eliminating
	associativity misses, but, due to hardware limitations,
	fully associative caches are normally quite limited in size.
	The associativity of the large caches found on modern microprocessors
	typically range from two-way to eight-way.
	\fi
\item[Associativity Miss:]
	연관된 CPU 가 최근에 캐시의 특정 set 이 담고 있을 수 있는 것보다 더
	많은, 해당 set 으로 해시되는 데이터를 접근해서 발생하는 캐시 미스.
	Fully associative 캐시는 associativity 미스를 일으키지 않습니다 (또는,
	동일하게, fully associative 캐시에서, associativity 와 capacity 미스는
	동일하다고 말할 수 있겠습니다).
	\iffalse

	A cache miss incurred because the corresponding CPU has recently
	accessed more data hashing to a given set of the cache than will
	fit in that set.
	Fully associative caches are not subject to associativity misses
	(or, equivalently, in fully associative caches, associativity
	and capacity misses are identical).
	\fi
\item[Atomic:]
	특정 오퍼레이션은 그 중간 상태를 관찰할 수 없도록 되어 있다면
	``atomic'' 하다고 여겨집니다.
	예를 들어, 대부분의 CPU 에서, 올바르게 정렬된 포인터로의 store 는
	어토믹한데, 다른 CPU 들은 기존 값 또는 새로운 값을 볼 수 있지만, 새로운
	값의 일부와 기존 값의 일부가 결합된 값을 볼 수는 없도록 보장되기
	때문입니다.
	\iffalse

	An operation is considered ``atomic'' if it is not possible to
	observe any intermediate state.
	For example, on most CPUs, a store to a properly aligned pointer
	is atomic, because other CPUs will see either the old value or
	the new value, but are guaranteed not to see some mixed value
	containing some pieces of the new and old values.
	\fi
\item[Cache:]
	근래의 컴퓨터 시스템들에서 CPU 는 빈번하게 사용되는 데이터를 담고 있을
	캐시를 갖습니다.
	이런 캐시는 매우 간단한 해시 함수를 사용하는 하드웨어로 구현된 해시
	테이블로 생각될 수 있습니다만, 각각의 해시 bucket (하드웨어 타입에서는
	``set'' 이라 명명됩니다) 은 제한된 수의 데이터 항목만을 담고 있을 수
	있습니다.
	각각의 캐시의 해시 bucket 이 담고 있을 수 있는 데이터 항목의 갯수는
	해당 캐시의 ``associativity'' 라고 명칭됩니다.
	이런 데이터 항목들은 일반적으로 ``cache line'' 이라 불리우는데, CPU 와
	메모리 사이에 돌아다니는 고정된 길이의 데이터 블락이라고 생각될 수
	있습니다.
	\iffalse

	In modern computer systems, CPUs have caches in which to hold
	frequently used data.
	These caches can be thought of as hardware hash tables with very
	simple hash functions,
	but in which each hash bucket (termed a ``set'' by hardware types)
	can hold only a limited number of data items.
	The number of data items that can be held by each of a cache's hash
	buckets is termed the cache's ``associativity''.
	These data items are normally called ``cache lines'', which
	can be thought of a fixed-length blocks of data that circulate
	among the CPUs and memory.
	\fi
\item[Cache Coherence:]
	모든 CPU 들이 특정 변수에 대해 일련의 변화되는 값을 보게 되는 대부분의
	근래의 SMP 기계들의 속성은 적어도 해당 변수에 대해 하나의 전역적인 값
	변화의 순서로 일관성을 갖는다는 겁니다.
	Cache coherence 또한 특정 변수에 대한 일련의 store 들의 마지막에는 모든
	CPU 들이 그 변수의 마지막 값에 대해 동의를 할 것을 보장해 줍니다.
	Cache coherence 는 하나의 변수에 의해 얻어진 일련의 값들에 대해서만
	적용됨을 알아두시기 바랍니다.
	반면에, 메모리 일관성 모델은 여러개의 변수들에 대한 load 와 store 가
	어떻게 일어난 것으로 보이게 되는지를 설명합니다.
	더 자세한 내용을 위해선
	Section~\ref{sec:memorder:Cache Coherence} 을
	참고하세요.
	\iffalse

	A property of most modern SMP machines where all CPUs will
	observe a sequence of values for a given variable that is
	consistent with at least one global order of values for
	that variable.
	Cache coherence also guarantees that at the end of a group
	of stores to a given variable, all CPUs will agree
	on the final value for that variable.
	Note that cache coherence applies only to the series of values
	taken on by a single variable.
	In contrast, the memory consistency model for a given machine
	describes the order in which loads and stores to groups of
	variables will appear to occur.
	See Section~\ref{sec:memorder:Cache Coherence}
	for more information.
	\fi
\item[Cache Coherence Protocol:]
	메모리 일관성과 순서를 강제하고 다른 CPU 들이 각자의 캐시에 담겨있는
	데이터의 일관적이지 않은 상태를 보는 것을 막아주는, 일반적으로
	하드웨어로 구현되는 통신 프로토콜.
	\iffalse

	A communications protocol, normally implemented in hardware,
	that enforces memory consistency and ordering, preventing
	different CPUs from seeing inconsistent views of data held
	in their caches.
	\fi
\item[Cache Geometry:]
	캐시의 크기와 associativity 는 그것의 geometry 라 불리웁니다.
	각각의 캐시는 이차원 배열로, 캐시 라인들의 행 (``set'') 은 같은 해시
	값을 갖고, 캐시 라인들의 열 (``ways'') 는 그 안의 모든 캐시 라인이 서로
	다른 해시 값을 갖는 것으로 생각될 수 있습니다.
	특정 캐시의 associativity 는 그 열의 수이고 (따라서 ``way'' 라
	불립니다---two-way set-associative 캐시는 두개의 ``way'' 를 갖습니다),
	캐시의 크기는 행의 수와 열의 수의 곱입니다.
	\iffalse

	The size and associativity of a cache is termed its geometry.
	Each cache may be thought of as a two-dimensional array,
	with rows of cache lines (``sets'') that have the same hash
	value, and columns of cache lines (``ways'') in which every
	cache line has a different hash value.
	The associativity of a given cache is its number of
	columns (hence the name ``way''---a two-way set-associative
	cache has two ``ways''), and the size of the cache is its
	number of rows multiplied by its number of columns.
	\fi
\item[Cache Line:]
	(1) CPU 와 메모리 사이를 돌아다니는 데이터의 단위로, 일반적으로 그
	크기는 2의 거듭제곱입니다.
	일반적인 캐시라인의 크기는 16 바이트에서 256 바이트 사이입니다. \\
	(2) 데이터의 캐시라인 하나 단위를 담아둘 수 있는 CPU 캐시의 물리적
	위치. \\
	(3) 데이터의 캐사라인 하나 단위를 담아둘 수 있는, 그러나 또한 캐시 라인
	경계로 정렬되어 있는 메모리 상의 물리적 위치.
	예를 들어, 256-바이트 캐시라인을 갖는 시스템에서 메모리 상의 캐시
	라인의 첫번째 word 의 주소는 0x00 으로 끝날 겁니다.
	\iffalse

	(1) The unit of data that circulates among the CPUs and memory,
	usually a moderate power of two in size.
	Typical cache-line sizes range from 16 to 256 bytes. \\
	(2) A physical location in a CPU cache capable of holding
	one cache-line unit of data. \\
	(3) A physical location in memory capable of holding one
	cache-line unit of data, but that it also aligned
	on a cache-line boundary.
	For example, the address of the first word of a cache line
	in memory will end in 0x00 on systems with 256-byte cache lines.
	\fi
\item[Cache Miss:]
	CPU 가 필요로 하는 데이터가 해당 CPU 의 캐시 안에 존재하지 않으면
	하나의 캐시 미스가 발생합니다.
	해당 데이터는 여러가지 이유로 캐시에 없을 수 있는데, 다음과 같은
	이유들이 있을 수 있습니다:
	(1) 이 CPU 는 기존에 해당 데이터를 액세스한 적이 없거나(``startup''
	또는 ``warmup'' 미스),
	(2) 이 CPU 는 최근에 자신의 캐시가 담고 있을 수 있는 것보다 더 많은
	데이터에 액세스를 해서, 오래된 데이터 중 일부는 제거되었거나
	(``capacity'' 미스),
	(3) 이 CPU 는 특정 set 에 해당 set\footnote{
		하드웨어 캐시 용어에서, ``set'' 이라는 말은 소프트웨어 캐시를
		논할 때의 ``bucket'' 이란 말과 동일한 의미로 사용됩니다.}
	이 담아둘 수 있는 것보다 많은 데이터에 액세스를 했거나
	(``associativity'' 미스),
	(4) 이 CPU 가 해당 데이터에 액세스한 후에 어떤 다른 CPU 가 해당
	데이터에 (또는 같은 캐시 라인의 어떤 다른 데이터에) 쓰기를 수행해서
	(``communication miss''), 또는
	(5) 이 CPU 가 해당 캐시라인이 다른 CPU 의 캐시에 복사되어 있거나 해서
	read-only 인데 쓰기를 수행해서입니다.
	\iffalse

	A cache miss occurs when data needed by the CPU is not in
	that CPU's cache.
	The data might be missing because of a number of reasons,
	including:
	(1) this CPU has never accessed the data before
	(``startup'' or ``warmup'' miss),
	(2) this CPU has recently accessed more
	data than would fit in its cache, so that some of the older
	data had to be removed (``capacity'' miss),
	(3) this CPU
	has recently accessed more data in a given set\footnote{
		In hardware-cache terminology, the word ``set''
		is used in the same way that the word ``bucket''
		is used when discussing software caches.}
	than that set could hold (``associativity'' miss),
	(4) some other CPU has written to the data (or some other
	data in the same cache line) since this CPU has accessed it
	(``communication miss''), or
	(5) this CPU attempted to write to a cache line that is
	currently read-only, possibly due to that line being replicated
	in other CPUs' caches.
	\fi
\item[Capacity Miss:]
	연관된 CPU 가 최근에 캐시가 담을 수 있는 것보다 많은 데이터를 액세스
	해서 발생하는 캐시 미스.
	\iffalse

	A cache miss incurred because the corresponding CPU has recently
	accessed more data than will fit into the cache.
	\fi
\item[Code Locking:]
	크리티컬 섹션의 한 집합을 보호하기 위해 ``global lock'' 이 사용되어서
	특정 쓰레드의 그런 집합으로의 액세스가 그 쓰레드가 어떤 데이터에
	접근하려 하는가에 의해서가 아니라 현재 그 크리티컬 섹션들의 집합을
	차지하고 있는 쓰레드들의 집합에 기반해서만 허용되거나 거부되는 간단한
	락킹 디자인.
	Code-locking 을 사용하는 프로그램의 확장성은 그 코드에 의해 제한됩니다;
	해당 데이터 집합의 크기를 증가시키는 것은 일반적으로 확장성을
	증가시키지 못할 겁니다 (사실, 일반적으로는 ``lock contention'' 을
	증가시켜서 확장성을 \emph{떨어뜨립니다}).
	``Data locking'' 에 대비됩니다.
	\iffalse

	A simple locking design in which a ``global lock'' is used to protect
	a set of critical sections, so that access by a given thread
	to that set is
	granted or denied based only on the set of threads currently
	occupying the set of critical sections, not based on what
	data the thread intends to access.
	The scalability of a code-locked program is limited by the code;
	increasing the size of the data set will normally not increase
	scalability (in fact, will typically \emph{decrease} scalability
	by increasing ``lock contention'').
	Contrast with ``data locking''.
	\fi
\item[Communication Miss:]
	이 CPU 가 해당 캐시라인에 액세스한 후에 어떤 다른 CPU 가 해당
	캐시라인에 액세스해서 발생하는 캐시미스.
	\iffalse

	A cache miss incurred because some other CPU has written to
	the cache line since the last time this CPU accessed it.
	\fi
\item[Critical Section:]
	어떤 동기화 메커니즘으로 보호되어서 그 수행이 그 기능으로 제한되는
	코드의 부분.
	예를 들어, 크리티컬 섹션들의 한 집합이 같은 global lock 으로
	보호된다면, 한번에 그 크리티컬 섹션들 가운데 하나만이 수행됩니다.
	만약 한 쓰레드가 그런 크리티컬 섹션 가운데 하나를 수행하고 있다면, 모든
	다른 쓰레드는 그 첫번째 쓰레드가 해당 집합 내의 크리티컬 섹션들의
	수행을 모두 완료하기 전까지는 대기해야만 합니다.
	\iffalse

	A section of code guarded by some synchronization mechanism,
	so that its execution constrained by that primitive.
	For example, if a set of critical sections are guarded by
	the same global lock, then only one of those critical sections
	may be executing at a given time.
	If a thread is executing in one such critical section,
	any other threads must wait until the first thread completes
	before executing any of the critical sections in the set.
	\fi
\item[Data Locking:]
	각각의 데이터 구조 인스턴스가 각자의 락을 가지고 있는 확장성 있는 락킹
	디자인.
	각각의 쓰레드가 이 데이터 구조의 서로 다른 인스턴스를 사용한다면, 이
	모든 쓰레드들은 동시에 크리티컬 섹션을 수행하고 있을 수 있습니다.
	데이터 락킹은 증가하는 CPU 의 수와 증가하는 데이터 인스턴스의 갯수에
	따라 자동적으로 확장되는 장점을 갖습니다.
	``Code locking'' 과 대비됩니다.
	\iffalse

	A scalable locking design in which each instance of a given
	data structure has its own lock.
	If each thread is using a different instance of the
	data structure, then all of the threads may be executing in
	the set of critical sections simultaneously.
	Data locking has the advantage of automatically scaling to
	increasing numbers of CPUs as the number of instances of
	data grows.
	Contrast with ``code locking''.
	\fi
\item[Direct-Mapped Cache:]
	하나의 way 만을 가지고 있어서, 하나의 해시값 마다 하나의 캐시라인만을
	담고 있을 수 있는 캐시.
	\iffalse

	A cache with only one way, so that it may hold only one cache
	line with a given hash value.
	\fi
\item[Embarrassingly Parallel:]
	쓰레드를 추가하는 것이 연산 과정의 전체적인 비용을 크게 증가시키지
	않아서 (충분한 CPU 가 사용가능한 상태라는 가정 하에) 쓰레드가 추가됨에
	따라서 선형적으로 속도가 증가하게 되는 문제나 알고리즘.
	\iffalse

	A problem or algorithm where adding threads does not significantly
	increase the overall cost of the computation, resulting in
	linear speedups as threads are added (assuming sufficient
	CPUs are available).
	\fi
\item[Exclusive Lock:]
	한번에 하나의 쓰레드만이 해당 락이 보호하고 있는 크리티컬 섹션이 들어갈
	수 있도록 하는 상호 배타적인 메커니즘.
	\iffalse

	An exclusive lock is a mutual-exclusion mechanism that
	permits only one thread at a time into the
	set of critical sections guarded by that lock.
	\fi
\item[False Sharing:]
	두개의 CPU 가 각각 한 쌍의 데이터 항목 중 하나씩에 빈번하게 쓰기를
	하지만, 이 한쌍의 데이터 항목이 같은 캐시 라인에 위치해 있다면, 이 캐시
	라인은 반복적으로 무효화되어서, 이 두 CPU 의 캐시들 사이를
	``ping-pong'' 하길 반복하게 됩니다.
	이는 ``cache bouncing'' 이라고도 불리는 ``cache thrashing'' 현상의 흔한
	원인입니다 (리눅스 커뮤니티에서는 앞의 표현이 더 흔합니다).
	False sharing 은 성능과 확장성을 모두 크게 떨어뜨릴 수 있습니다.
	\iffalse

	If two CPUs each frequently write to one of a pair of data items,
	but the pair of data items are located in the same cache line,
	this cache line will be repeatedly invalidated, ``ping-ponging''
	back and forth between the two CPUs' caches.
	This is a common cause of ``cache thrashing'', also called
	``cacheline bouncing'' (the latter most commonly in the Linux
	community).
	False sharing can dramatically reduce both performance and
	scalability.
	\fi
\item[Fragmentation:]
	많은 양의 사용되지 않은 메모리가 존재하지만 비교적 작은 메모리 할당
	요청들을 충족해줄 수 있도록 맞춰져 있지 않은 메모리 풀을 단편화
	(fragment) 되었다고 합니다.
	할당된 메모리 블록들 사이에 작은 조각의 메모리 공간이 존재하도록 메모리
	공간이 쪼개졌을 때 external fragmentation 이 발생하며, 특정한 또는
	특정한 종류의 메모리 할당 요청이 실제로 필요한 것보다 많은 메모리를
	할당받았을 때 internal fragmentation 이 발생합니다.
	\iffalse

	A memory pool that has a large amount of unused memory, but
	not laid out to permit satisfying a relatively small request
	is said to be fragmented.
	External fragmentation occurs when the space is divided up
	into small fragments lying between allocated blocks of memory,
	while internal fragmentation occurs when specific requests or
	types of requests have been allotted more memory than they
	actually requested.
	\fi
\item[Fully Associative Cache:]
	Fully associative 캐시는 하나의 set 만을 가지고 있어서, 해당 set 은 그
	용량이 허용하는한 메모리의 어떤 부분집합도 담고 있을 수 있습니다.
	\iffalse

	A fully associative cache contains only
	one set, so that it can hold any subset of
	memory that fits within its capacity.
	\fi
\item[Grace Period:]
	Grace period 는 어떤 시간 간격으로, 해당 시간 간격에 앞서 시작된 모든
	RCU read-side 크리티컬 섹션은 이 시간 간격의 종료 전에 종료됩니다.
	많은 RCU 구현들은 각각의 쓰레드가 최소 하나의 quiescent state 를 지나는
	사이의 시간 간격으로 정의합니다.
	RCU read-side 크리티컬 섹션은 그 정의에 의해 quiescent state 를 포함할
	수 없으므로, 이 두개의 정의는 거의 항상 서로 교체될 수 있습니다.
	\iffalse

	A grace period is any contiguous time interval such that
	any RCU read-side critical section that began before the
	start of that interval has
	completed before the end of that same interval.
	Many RCU implementations define a grace period to be a
	time interval during which each thread has passed through at
	least one quiescent state.
	Since RCU read-side critical sections by definition cannot
	contain quiescent states, these two definitions are almost
	always interchangeable.
	\fi
\item[Heisenbug:]
	추적하기 위해 기록을 추가하거나 print 문을 추가하면 발견되지 않게 되는,
	타이밍에 민감한 버그.
	\iffalse

	A timing-sensitive bug that disappears from sight when you
	add print statements or tracing in an attempt to track it
	down.
	\fi
\item[Hot Spot:]
	매우 많이 사용되어서 연관된 락에 대한 높은 수준의 contention 을
	초래하는 데이터 구조.
	이런 상황의 한 예로는 형편없는 해시 함수를 사용한 해시 테이블이 있을 수
	있습니다.
	\iffalse

	Data structure that is very heavily used, resulting in high
	levels of contention on the corresponding lock.
	One example of this situation would be a hash table with
	a poorly chosen hash function.
	\fi
\item[Humiliatingly Parallel:]
	쓰레드를 추가하면 연산의 전체 비용이 상당히 \emph{줄어들어서} (충분한
	CPU 가 사용가능한 상태라는 가정 하에) 쓰레드를 추가함에 따라 선형적
	속도증가를 초월하는 속도 증가를 초래하는 문제나 알고리즘.
	\iffalse

	A problem or algorithm where adding threads significantly
	\emph{decreases} the overall cost of the computation, resulting in
	large superlinear speedups as threads are added (assuming sufficient
	CPUs are available).
	\fi
\item[Invalidation:]
	한 CPU 가 하나의 데이터 항목에 쓰기를 하려 하면, 해당 CPU 는 먼저 이
	데이터 아이템이 다른 CPU 의 캐시에는 존재하지 않음을 보장해야 합니다.
	만약 필요하다면, 쓰기를 하는 CPU 는 해당 데이터의 사본을 자신의 캐시에
	담고 있는 모든 CPU 에게 ``invalidation'' 메세지를 보내서 다른 CPU 의
	캐시로부터 해당 항목을 제거합니다.
	\iffalse

	When a CPU wishes to write to a data item, it must first ensure
	that this data item is not present in any other CPUs' cache.
	If necessary, the item is removed from the other CPUs' caches
	via ``invalidation'' messages from the writing CPUs to any
	CPUs having a copy in their caches.
	\fi
\item[IPI:]
	하나의 CPU 에서 다른 CPU 로 보내어지는 프로세서 간의 인터럽트.
	IPI 는 리눅스 커널에서 많이 사용되는데, 예를 들어 스케쥴러가 CPU 에게
	높은 우선순위 프로세스가 현재 수행 가능 상태임을 알리는데 사용됩니다.
	\iffalse

	Inter-processor interrupt, which is an
	interrupt sent from one CPU to another.
	IPIs are used heavily in the Linux kernel, for example, within
	the scheduler to alert CPUs that a high-priority process is now
	runnable.
	\fi
\item[IRQ:]
	인터럽트 요청 (Interrupt request) 으로, 리눅스 커널 커뮤니티에서는
	``interrupt'' 의 약자로 사용되어서, ``irq handler'' 와 같은 용례로
	사용됩니다.
	\iffalse

	Interrupt request, often used as an abbreviation for ``interrupt''
	within the Linux kernel community, as in ``irq handler''.
	\fi
\item[Linearizable:]
	일련의 오퍼레이션들은 모든 CPU 들과 / 또는 쓰레드들의 관찰된 내용과
	일관적인 전체적인 해당 오퍼레이션들의 순서가 존재한다면
	``linearizable'' 하다고 표현합니다.
	Linearizability 는 많은 연구자들에 의해 중요시됩니다만, 실용적인
	면에서는 기대되는 것보다 유용하지
	못합니다~\cite{AndreasHaas2012FIFOisnt}.
	\iffalse

	A sequence of operations is ``linearizable'' if there is at
	least one global ordering of the sequence that is consistent
	with the observations of all CPUs and/or threads.
	Linearizability is much prized by many researchers, but less
	useful in practice than one might
	expect~\cite{AndreasHaas2012FIFOisnt}.
	\fi
\item[Lock:]
	크리티컬 섹션을 보호하는데 사용될 수 있는 소프트웨어 추상화의 하나로, 
	``상호 배타성 (mutual exclusion) 메커니즘'' 의 한 예.
	``배타적 락'' 은 한번에 하나의 쓰레드만이 해당 락으로 보호되는 크리티컬
	섹션들의 집합에 들어갈 수 있도록 해주며, ``reader-writer lock'' 은
	읽기를 하는 쓰레드라면 몇개의 쓰레드든지, 쓰기를 하는 쓰레드라면 하나의
	쓰레드만이 해당 락으로 보호되는 크리티컬 섹션들의 집합에 들어갈 수
	있도록 해줍니다.  (분명히 하자면, 주어진 reader-writer 락의 크리티컬
	섹션들 가운데 하나라도 쓰기 쓰레드가 존재한다면, 어떤 읽기를 하는
	쓰레드도 해당 락의 크리티컬 섹션들 가운데 하나도 들어갈 수 없을 것이고,
	그 반대도 마찬가지입니다.)
	\iffalse

	A software abstraction that can be used to guard critical sections,
	as such, an example of a ``mutual exclusion mechanism''.
	An ``exclusive lock'' permits only one thread at a time into the
	set of critical sections guarded by that lock, while a
	``reader-writer lock'' permits any number of reading
	threads, or but one writing thread, into the set of critical
	sections guarded by that lock.  (Just to be clear, the presence
	of a writer thread in any of a given reader-writer lock's
	critical sections will prevent any reader from entering
	any of that lock's critical sections and vice versa.)
	\fi
\item[Lock Contention:]
	락은 매우 많이 사용되어 해당 락을 얻으려 기다리는 CPU 가 많은 경우
	contention 을 겪는다고 표현됩니다.
	병렬 알고리즘을 설계하고 병렬 프로그램을 구현할 때에 Lock contention 을
	줄이는 것이 많은 경우 중요한 고심거리입니다.
	\iffalse

	A lock is said to be suffering contention when it is being
	used so heavily that there is often a CPU waiting on it.
	Reducing lock contention is often a concern when designing
	parallel algorithms and when implementing parallel programs.
	\fi
\item[Memory Consistency:]
	변수들의 그룹에 대한 액세스들의 순서가 어떻게 일어난 것을 보여야만
	하는가에 대한 제약을 만들어내는 속성들의 집합.
	메모리 일관성 모델은 학계에서 인기있으며 매우 강력한 모델인 sequential
	consistency 부터 process consistency, release consistency, 그리고 weak
	consistency 까지 다양합니다.
	\iffalse

	A set of properties that impose constraints on the order in
	which accesses to groups of variables appear to occur.
	Memory consistency models range from sequential consistency,
	a very constraining model popular in academic circles, through
	process consistency, release consistency, and weak consistency.
	\fi
\item[MESI Protocol:]
	Modified, exclusive, shared, 그리고 invalid (MESI) 상태를 갖는 캐시
	일관성 프로토콜로, 이 때문에 이 프로토콜은 해당 캐시의 캐시라인이 가질
	수 있는 상태들의 이름을 본따서 그렇게 이름지어졌습니다.
	Modified 상태의 캐시라인은 최근에 이 CPU 에 의해 쓰기가 되어진 상태로,
	연관된 메모리 영역의 현재 값의 유일한 표현입니다.
	Exclusive 상태의 캐시 라인은 값이 새로 씌여지지는 않았지만, 해당
	캐시라인은 다른 CPU 의 캐시에 복사되지 않았음이 보장되기에 이 CPU 가
	언제든 그 위에 쓰기를 할 권리를 가진 상태입니다 (메인메모리 상의 연관된
	영역은 최신 버전이지만 말입니다).
	Shared 상태의 캐시라인은 어떤 다른 CPU 의 캐시에 복사되어 있는 (또는
	복사되어 있을 수 있는) 상태로, 이 CPU 는 이 캐시 라인에 쓰기를 하기
	전에 그런 다른 CPU 들과 상호작용을 해야만 함을 의미합니다.
	Invalid 상태의 캐시라인은 값을 포함하고 있지 않아서, 메모리로부터
	데이터가 로드되어질 수 있는 상태인 해당 캐시의 ``빈 공간''을
	나타냅니다.
	\iffalse

	The
	cache-coherence protocol featuring
	modified, exclusive, shared, and invalid (MESI) states,
	so that this protocol is named after the states that the
	cache lines in a given cache can take on.
	A modified line has been recently written to by this CPU,
	and is the sole representative of the current value of
	the corresponding memory location.
	An exclusive cache line has not been written to, but this
	CPU has the right to write to it at any time, as the line
	is guaranteed not to be replicated into any other CPU's cache
	(though the corresponding location in main memory is up to date).
	A shared cache line is (or might be) replicated in some other
	CPUs' cache, meaning that this CPU must interact with those other
	CPUs before writing to this cache line.
	An invalid cache line contains no value, instead representing
	``empty space'' in the cache into which data from memory might
	be loaded.
	\fi
\item[Mutual-Exclusion Mechanism:]
	쓰레드의 ``크리티컬 섹션'' 과 연관된 데이터로의 액세스를 조절하는
	소프트웨어 추상화.
	\iffalse

	A software abstraction that regulates threads' access to
	``critical sections'' and corresponding data.
	\fi
\item[NMI:]
	Non-maskable interrupt.
	이름이 이야기하듯, 이는 가려질 수 없는, 매우 높은 우선순위의
	인터럽트입니다.
	이것들은 프로파일링과 같은 하드웨어의 특수한 목적에 사용됩니다.
	프로파일링을 하는데에 NMI 를 사용함으로써 얻을 수 있는 이득은,
	인터럽트를 비활성화 시킨 채 수행되는 코드에 대해서도 프로파일링을 할 수
	있다는 것입니다.
	\iffalse

	Non-maskable interrupt.
	As the name indicates, this is an extremely high-priority
	interrupt that cannot be masked.
	These are used for hardware-specific purposes such as profiling.
	The advantage of using NMIs for profiling is that it allows you
	to profile code that runs with interrupts disabled.
	\fi
\item[NUCA:]
	CPU 들의 그룹들이 캐시 그리고/또는 스토어 버퍼를 공유하는, Non-uniform
	cache architecture.
	따라서 한 그룹 내의 CPU 들은 다른 그룹 내의 CPU 들과 할 수 있는 것에
	비해 같은 그룹 내의 CPU 들과 캐시라인을 더 빠르게 교환할 수 있습니다.
	하드웨어 쓰레드를 갖는 CPU 로 구성된 시스템에서는 일반적으로 NUCA
	아키텍쳐를 갖게 됩니다.
	\iffalse

	Non-uniform cache architecture, where groups of CPUs share
	caches and/or store buffers.
	CPUs in a group can therefore exchange cache lines with each
	other much more quickly than they can with CPUs in other groups.
	Systems comprised of CPUs with hardware threads will generally
	have a NUCA architecture.
	\fi
\item[NUMA:]
	메모리가 뱅크 단위로 쪼개어져 있고 각각의 뱅크는 ``NUMA node'' 라
	불리우는, 특정 CPU 들의 그룹에 ``가까운'' 구조인 Non-uniform memory
	architecture.
	NUMA 기계의 한 예는 Sequent 의 NUMA-Q 시스템으로, 네개의 CPU 들로
	구성된 각각의 그룹들이 하나씩 메모리 뱅크를 근처에 두고 있습니다.
	특정 그룹 내의 CPU 들은 그들의 메모리에 다른 그룹의 메모리보다 훨씬
	빨리 액세스 할 수 있습니다.
	\iffalse

	Non-uniform memory architecture, where memory is split into
	banks and each such bank is ``close'' to a group of CPUs,
	the group being termed a ``NUMA node''.
	An example NUMA machine is Sequent's NUMA-Q system, where
	each group of four CPUs had a bank of memory near by.
	The CPUs in a given group can access their memory much
	more quickly than another group's memory.
	\fi
\item[NUMA Node:]
	커다란 NUMA 기계 내에서의 가까이 위치한 CPU 들과 거기 연관된 메모리의
	그룹.
	하나의 NUMA 노드는 NUMA 구조를 가질 수도 있음을 알아 두시기 바랍니다.
	\iffalse

	A group of closely placed CPUs and associated memory within
	a larger NUMA machines.
	Note that a NUMA node might well have a NUCA architecture.
	\fi
\item[Pipelined CPU:]
	많은 장점과 단점을 가지고 있는, 어떤 의미에선 조립 공정 라인과 비슷한,
	CPU 내부의 인스트럭션들의 내부 흐름인 pipeline 을 가진 CPU.
	1960년애부터 1980년대 초까지, pipeline 을 내장한 CPU 는 슈퍼컴퓨터의
	영역에만 있었습니다만, 1980년대 후반부터는 (80486 과 같은)
	마이크로프로세서에서도 나타나기 시작했습니다.
	\iffalse

	A CPU with a pipeline, which is
	an internal flow of instructions internal to the CPU that
	is in some way similar to an assembly line, with many of
	the same advantages and disadvantages.
	In the 1960s through the early 1980s, pipelined CPUs were the
	province of supercomputers, but started appearing in microprocessors
	(such as the 80486) in the late 1980s.
	\fi
\item[Process Consistency:]
	각각의 CPU 가 자신의 스토어 오퍼레이션은 program order 대로 발생한
	것으로 보이지만 다른 CPU 들은 복수의 CPU 들로부터의 액세스를 다른
	순서로 발생한 것으로 볼 수 있는 메모리 일관성 모델.
	\iffalse

	A memory-consistency model in which each CPU's stores appear to
	occur in program order, but in which different CPUs might see
	accesses from more than one CPU as occurring in different orders.
	\fi
\item[Program Order:]
	특정 쓰레드의 인스트럭션들이 지금에 와서는 미신적 존재가 되어버린, 다음
	인스트럭션의 수행이 진행되기 전에 현재 인스트럭션을 완전히 수행하는,
	``in-order'' CPU 에 의해 수행되는 순서.
	(그런 CPU 들이 이제는 고대의 미신과 전설상의 존재로만남게된것은
	그것들은 엄청나게 느리기 때문입니다.
	이 고대의 공룡들은 Moore's-Law 가 가져온 CPU 클락 주파수 향상의 많은
	희생자들 가운데 하나입니다.
	어떤 사람들은 이 야수들이 지구를 다시 한번 더 정복할 것이라고
	이야기하지만, 그 외의 사람들은 그런 말을 아예 무시합니다.)
	\iffalse

	The order in which a given thread's instructions
	would be executed by a now-mythical ``in-order'' CPU that
	completely executed each instruction before proceeding to
	the next instruction.
	(The reason such CPUs are now the stuff of ancient myths
	and legends is that they were extremely slow.
	These dinosaurs were one of the many victims of
	Moore's-Law-driven increases in CPU clock frequency.
	Some claim that these beasts will roam the earth once again,
	others vehemently disagree.)
	\fi
\item[Quiescent State:]
	RCU 에서, RCU 로 보호되는 데이터 구조로의 레퍼런스가 하나도 잡혀 있지
	않은, 일반적으로는 RCU read-side 크리티컬 섹션의 바깥의 모든 지점.
	모든 쓰레드가 최소한 하나의 quiescent state 를 지나는 동안의 모든 시간
	간격은 ``grace period'' 라고 불리워집니다.
	\iffalse

	In RCU, a point in the code where there can be no references held
	to RCU-protected data structures, which is normally any point
	outside of an RCU read-side critical section.
	Any interval of time during which all threads pass through at
	least one quiescent state each is termed a ``grace period''.
	\fi
\item[Read-Copy Update (RCU):]
	Reader-writer 락킹이나 reference counting 의 대체물로 생각될 수 있는
	하나의 동기화 메커니즘.
	RCU 는 읽기 쓰레드들에게 매우 낮은 오버헤드의 액세스를 제공하는 반면,
	쓰기 쓰레드에게는 앞서 존재한 읽기 쓰레드들의 성능 이득을 위해 기존
	버전을 유지해야하는 추가적 오버헤드를 일으킵니다.
	읽기 쓰레드들은 블락되지도 spin 하지도 않고, 따라서 데드락에 참여될 수
	없습니다만, 정상적인 데이터를 볼 수 있고 업데이트와 동시에 수행될 수
	있습니다.
	따라서 RCU 는 정상적인 데이터가 (라우팅 테이블에서처럼) 지연되거나
	(리눅스 커널의 System V IPC 구현에서처럼) 막아질 수 있는 읽기가
	대부분인 환경에 가장 적합합니다.
	\iffalse

	A synchronization mechanism that can be thought of as a replacement
	for reader-writer locking or reference counting.
	RCU provides extremely low-overhead access for readers, while
	writers incur additional overhead maintaining old versions
	for the benefit of pre-existing readers.
	Readers neither block nor spin, and thus cannot participate in
	deadlocks, however, they also can see stale data and can
	run concurrently with updates.
	RCU is thus best-suited for read-mostly situations where
	stale data can either be tolerated (as in routing tables)
	or avoided (as in the Linux kernel's System V IPC implementation).
	\fi
\item[Read-Side Critical Section:]
	어떤 reader-writer 동기화 메커니즘의 읽기 권한 획득으로 보호되는 코드의
	일부분.
	예를 들어, 한 크리티컬 섹션들의 집합이 특정 전역적 reader-writer 락의
	읽기 권한 획득으로 보호된다면, 크리티컬 섹션들의 첫번째 집합은 그 락의
	read-side 크리티컬 섹션이 됩니다.
	수에 상관없이 복수의 쓰레드들이 read-side 크리티컬 섹션을 동시에 수행할
	수 있습니다만, 어떤 쓰레드도 write-side 크리티컬 섹션을 수행하고 있지
	않은 경우에만 그렇습니다.
	\iffalse

	A section of code guarded by read-acquisition of
	some reader-writer synchronization mechanism.
	For example, if one set of critical sections are guarded by
	read-acquisition of
	a given global reader-writer lock, while a second set of critical
	section are guarded by write-acquisition of that same reader-writer
	lock, then the first set of critical sections will be the
	read-side critical sections for that lock.
	Any number of threads may concurrently execute the read-side
	critical sections, but only if no thread is executing one of
	the write-side critical sections.
	\fi
\item[Reader-Writer Lock:]
	Reader-writer 락은 수에 관계없이 복수의 읽기를 하는 쓰레드들을, 또는 단
	하나의 쓰기 쓰레드들을 해당 락으로 보호되는 크리티컬 섹션들의 집합으로
	들어갈 수 있도록 허용하는 mutual-exclusion 메커니즘입니다.
	쓰기를 하려는 쓰레드는 모든 앞서 존재한, 읽기를 하는 쓰레드들이 해당
	락을 놓을 때까지 기다려야만 하고, 비슷하게, 앞서 존재한 쓰기가
	존재한다면, 쓰기를 하려는 모든 쓰레드는 해당 쓰기 쓰레드가 해당 락을
	놓기를 기다려야 합니다.
	Reader-writer 락에 있어서의 핵심 고려사항은 ``fairness'' 입니다:
	끝나지 않는 읽기 쓰레드의 연속은 쓰기 쓰레드를 starve 시킬 수 있고, 그
	반대도 마찬가지입니다.
	\iffalse

	A reader-writer lock is a mutual-exclusion mechanism that
	permits any number of reading
	threads, or but one writing thread, into the set of critical
	sections guarded by that lock.
	Threads attempting to write must wait until all pre-existing
	reading threads release the lock, and, similarly, if there
	is a pre-existing writer, any threads attempting to write must
	wait for the writer to release the lock.
	A key concern for reader-writer locks is ``fairness'':
	can an unending stream of readers starve a writer or vice versa.
	\fi
\item[Sequential Consistency:]
	모든 메모리 레퍼런스가 하나의 전역적인 순서에 일관적인 순서로 일어난
	것으로 보이도록, 그리고 각각의 CPU 의 메모리 레퍼런스가 모든 CPU 들에게
	프로그램 순서로 일어난 것으로 보이도록 하는 메모리 일관성 모델.
	\iffalse

	A memory-consistency model where all memory references appear to occur
	in an order consistent with
	a single global order, and where each CPU's memory references
	appear to all CPUs to occur in program order.
	\fi
\item[Store Buffer:]
	CPU 에서 지연된 쓰기를 기록하며 그사이 연관된 캐시라인들은 해당 CPU
	에서 사용할 수 있도록 사용되는 CPU 내부의 레지스터들의 작은 집합.
	``Store queue'' 라고도 불립니다.
	\iffalse

	A small set of internal registers used by a given CPU
	to record pending stores
	while the corresponding cache lines are making their
	way to that CPU.
	Also called ``store queue''.
	\fi
\item[Store Forwarding:]
	소프트웨어에게 CPU 가 메모리 오퍼레이션들을 program order 대로 진행한
	것으로 보일 것을 보장하기 위해 CPU 가 스토어 버퍼와 캐시 사이를
	오가도록 하는 하나의 조정.
	\iffalse

	An arrangement where a given CPU refers to its store buffer
	as well as its cache so as to ensure that the software sees
	the memory operations performed by this CPU as if they
	were carried out in program order.
	\fi
\item[Super-Scalar CPU:]
	하나의 scalar (non-vector) CPU 는 여러개의 인스트럭션들을 동시에 수행할
	수 있습니다.
	이는 여러개의 인스트럭션들을 조립 공정의 방식으로 수행하는 pipelined
	CPU 의 진화된 형태입니다---super-scalar CPU 에서는, 각각의 pipeline 의
	stage 가 하나의 인스트럭션 이상을 처리할 수 있게 됩니다.
	예를 들어, 만약 조건이 정확히 맞아 떨어진다면, 1990년대 중반에 나온
	Intel Pentium Pro CPU 는하나의 클락 사이클당 두개의 (그리고 어떤 경우엔
	세개의) 인스트럭션들을 처리할 수 있습니다.
	따라서, 200MHz Pentium Pro CPU 는 초당 최대 4억개의 인스트럭션을 수행
	완료하거나 ``retire'' 시킬 수도 있습니다.
	\iffalse

	A scalar (non-vector) CPU capable of executing multiple instructions
	concurrently.
	This is a step up from a pipelined CPU that executes multiple
	instructions in an assembly-line fashion---in a super-scalar
	CPU, each stage of the pipeline would be capable of handling
	more than one instruction.
	For example, if the conditions were exactly right,
	the Intel Pentium Pro CPU from the mid-1990s could
	execute two (and sometimes three) instructions per clock cycle.
	Thus, a 200\,MHz Pentium Pro CPU could ``retire'', or complete the
	execution of, up to 400 million instructions per second.
	\fi
\item[Teachable:]
	교사가 완전히 이해할 수 있고, 따라서 가리키기 간편한 주제, 컨셉, 방법,
	또는 메커니즘.
	\iffalse

	A topic, concept, method, or mechanism that the teacher understands
	completely and is therefore comfortable teaching.
	\fi
\item[Transactional Memory (TM):]
	오퍼레이션들의 어토믹한 시퀀스이며 atomicity, consistency, isolation 을
	제공하지만 durability 를 제공하지 않는다는 점에서 고전적인 트랜잭션과는
	다른 ``트랜잭션'' 을 지원하는 공유메모리 동기화 설계. 
	트랜잭셔널 메모리는 하드웨어로 구현 (하드웨어 트랜잭셔널 메모리 또는
	HTM 이라 불림) 되거나, 소프트웨어로 구현 (소프트웨어 트랜잭셔널 메모리
	또는 STM 이라 불림) 되거나, 또는 하드웨어와 소프트웨어의 조합으로 구현
	(``unbounded'' 트랜잭셔널 메모리, 또는 UTM 이라 불림) 될 수 있습니다.
	\iffalse

	Shared-memory synchronization scheme featuring ``transactions'',
	each of which is an atomic sequence of operations
	that offers atomicity, consistency, isolation, but differ from
	classic transactions in that they do not offer
	durability.
	Transactional memory may be implemented either in hardware
	(hardware transactional memory, or HTM), in software (software
	transactional memory, or STM), or in a combination of hardware
	and software (``unbounded'' transactional memory, or UTM).
	\fi
\item[Unteachable:]
	교사가 잘 이해하지 못하고 있고, 따라서 가르치기가 어려운 주제, 컨셉,
	방법, 또는 메커니즘.
	\iffalse

	A topic, concept, method, or mechanism that the teacher does
	not understand well is therefore uncomfortable teaching.
	\fi
\item[Vector CPU:]
	하나의 인스트럭션을 여러개의 데이터 항목에 동시적으로 적용시킬 수 있는
	CPU.
	1960년대부터 1980년대까지는 슈퍼컴퓨터들만이 vector 기능을 가지고
	있었습니다만, x86 CPU 들의 MMX 와 PowerPC CPU 들의 VMX 의 발전은 벡터
	처리를 대중들에게 가져다 주었습니다.
	\iffalse

	A CPU that can apply a single instruction to multiple items of
	data concurrently.
	In the 1960s through the 1980s, only supercomputers had vector
	capabilities, but the advent of MMX in x86 CPUs and VMX in
	PowerPC CPUs brought vector processing to the masses.
	\fi
\item[Write Miss:]
	캐시 라인이 다른 CPU 의 캐시에 복사되어있거나 하는 이유로 read-only
	상태인 캐시라인에 CPU 가 쓰기를 시도했기 때문에 발생하는 캐시 미스.
	\iffalse

	A cache miss incurred because the corresponding CPU attempted
	to write to a cache line that is read-only, most likely due
	to its being replicated in other CPUs' caches.
	\fi
\item[Write-Side Critical Section:]
	어떤 reader-writer 동기화 메커니즘의 읽기 권한 획득으로 보호되는 코드의
	부분.
	예를 들어, 한 크리티컬 섹션들의 집합이 특정 global reader-writer 락의
	쓰기 권한 획득으로 보호되어 있고 두번째 크리티컬 섹션 집합은 같은
	reader-writer 락의 읽기 권한 획득으로 보호되어 있다면, 첫번째 크리티컬
	섹션 집합은 해당 락의 write-side 크리티컬 섹션이 됩니다.
	한번에 하나의 쓰레드만이 write-side 크리티컬 섹션을 수행할 수 있으며,
	이 때 어떤 쓰레드도 동시에 연관된 read-side 크리티컬 섹션들을 수행하고
	있지 않아야 합니다.
	\iffalse

	A section of code guarded by write-acquisition of
	some reader-writer synchronization mechanism.
	For example, if one set of critical sections are guarded by
	write-acquisition of
	a given global reader-writer lock, while a second set of critical
	section are guarded by read-acquisition of that same reader-writer
	lock, then the first set of critical sections will be the
	write-side critical sections for that lock.
	Only one thread may execute in the write-side critical section
	at a time, and even then only if there are no threads are
	executing concurrently in any of the corresponding read-side
	critical sections.
	\fi
\end{description}
