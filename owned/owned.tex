% owned/owned.tex

\QuickQuizChapter{chp:Data Ownership}{Data Ownership}
%
\Epigraph{It is mine, I tell you. My own. My precious. Yes, my precious.}
	 {\emph{Gollum in ``The Fellowship of the Ring'', J.R.R.~Tolkien}}

락킹에 따라오는 동기화 오버헤드를 없애는 가장 간단한 방법들 중 하나는 데이터를
쓰레드들 각각에 맞춰 (또는, 커널의 경우라면, CPU 들 사이로) 포장을 해서
데이터의 한 조각은 하나의 쓰레드에 의해서만 접근되고 수정되도록 하는 것입니다.
흥미롭게도, 데이터 소유권은 병렬 설계 기법의 ``큰 세가지 전략'' 을 모두
충족합니다:
이 기법은 쓰레드별로 (또는, 경우에 따라서는 CPU 별로) 데이터를 쪼개고, 모든
지역적 작업을 몰아서 처리하고, 그 극단적인 논리에 의해 동기화 오퍼레이션이
제거됩니다.
따라서 데이터 소유권이 굉장히 많은 곳에서 사용된다는 사실은 놀랄 만한 일이
아니고, 실제로 초심자들도 거의 본능적으로 사용하는 사용 패턴입니다.
사실, 그 사용처는 너무 많아서 이 챕터는 새로운 예제를 소개하지는 않을 것이고,
대신 앞의 챕터들에서 보았던 예제들을 참조하겠습니다.
\iffalse

One of the simplest ways to avoid the synchronization overhead that
comes with locking is to parcel the data out among the threads (or,
in the case of kernels, CPUs)
so that a given piece of data is accessed and modified by only one
of the threads.
Interestingly enough, data ownership covers each of the ``big three''
parallel design techniques:
It partitions over threads (or CPUs, as the case may be),
it batches all local operations,
and its elimination of synchronization operations is weakening
carried to its logical extreme.
It should therefore be no surprise that data ownership is used extremely
heavily, in fact, it is one usage pattern that even novices use almost
instinctively.
In fact, it is used so heavily that this chapter will not introduce
any new examples, but will instead reference examples from previous
chapters.
\fi

\QuickQuiz{}
	어떤 형태의 데이터 소유권이 C 나 C++ 를 사용해서 (예를 들어, pthreads
	를 사용해서) 공유 메모리 병렬 프로그램을 만들 때 방지하기가 극단적으로
	어려울까요?
	\iffalse

	What form of data ownership is extremely difficult
	to avoid when creating shared-memory parallel programs
	(for example, using pthreads) in C or C++?
	\fi
\QuickQuizAnswer{
	함수 안에서의 auto 변수들의 사용입니다.
	기본적으로, 이것들은 현재 함수를 수행하고 있는 쓰레드에 소유됩니다.
	\iffalse

	Use of auto variables in functions.
	By default, these are private to the thread executing the
	current function.
	\fi
} \QuickQuizEnd

데이터 소유권을 적용하는 다양한 방법이 존재합니다.
Section~\ref{sec:owned:Multiple Processes} 에서는 각 쓰레드가 자신의 개인적
주소 공간을 갖는, 데이터 소유권의 논리적 극단을 보여드립니다.
Section~\ref{sec:owned:Partial Data Ownership and pthreads} 에서는 반대의
극단을 소개하는데, 데이터가 공유되지만 다른 쓰레드들은 데이터에의 다른 접근
권한을 갖는 경우입니다.
Section~\ref{sec:owned:Function Shipping} 에서는 함수 전달을 서명하는데, 다른
쓰레드들이 특정 쓰레드가 소유하는 데이터에 간접적인 액세스를 하도록 허용하는
방법입니다.
Section~\ref{sec:owned:Designated Thread} 에서는 어떻게 특정 쓰레드들이 특정
함수와 그에 연관된 데이터들의 소유권을 할당받을 수 있는지 설명합니다.
Section~\ref{sec:owned:Privatization} 에서는 공유 데이터를 사용하는 알고리즘을
데이터 소유권을 사용하도록 변환함으로써 성능을 개선시키는 것에 대해 논의해
봅니다.
마지막으로, Section~\ref{sec:owned:Other Uses of Data Ownership} 에서는 데이터
소유권을 일등시민으로 두는 몇가지 소프트웨어 환경을 나열해 봅니다.
\iffalse

There are a number of approaches to data ownership.
Section~\ref{sec:owned:Multiple Processes} presents the logical extreme
in data ownership, where each thread has its own private address space.
Section~\ref{sec:owned:Partial Data Ownership and pthreads} looks at
the opposite extreme, where the data is shared, but different threads
own different access rights to the data.
Section~\ref{sec:owned:Function Shipping} describes function shipping,
which is a way of allowing other threads to have indirect access to
data owned by a particular thread.
Section~\ref{sec:owned:Designated Thread} describes how designated
threads can be assigned ownership of a specified function and the
related data.
Section~\ref{sec:owned:Privatization} discusses improving performance
by transforming algorithms with shared data to instead use data ownership.
Finally, Section~\ref{sec:owned:Other Uses of Data Ownership} lists
a few software environments that feature data ownership as a
first-class citizen.
\fi

\section{Multiple Processes}
\label{sec:owned:Multiple Processes}

Section~\ref{sec:toolsoftrade:Scripting Languages}
에서 다음의 예를 소개한 바 있습니다:
\iffalse

Section~\ref{sec:toolsoftrade:Scripting Languages}
introduced the following example:
\fi

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\scriptsize
\begin{verbatim}
  1 compute_it 1 > compute_it.1.out &
  2 compute_it 2 > compute_it.2.out &
  3 wait
  4 cat compute_it.1.out
  5 cat compute_it.2.out
\end{verbatim}
\end{minipage}
\vspace{5pt}

이 예는 \co{compute_it} 프로그램의 두개의 인스턴스를 메모리를 공유하지 않는
별개의 프로세스들을 통해 병렬로 수행합니다.
따라서, 해당 프로세스의 모든 데이터는 그 프로세스에 소유되어 있어서, 위 예제의
모든 데이터는 소유되어 있습니다.
이 방법은 거의 모든 동기화 오버헤드를 제거합니다.
결과로 만들어지는 극단적인 단순함과 최적의 성능의 조합은 상당히 매력적입니다.
\iffalse

This example runs two instances of the \co{compute_it} program in
parallel, as separate processes that do not share memory.
Therefore, all data in a given process is owned by that process,
so that almost the entirety of data in the above example is owned.
This approach almost entirely eliminates synchronization overhead.
The resulting combination of extreme simplicity and optimal performance
is obviously quite attractive.
\fi

\QuickQuiz{}
	Section~\ref{sec:owned:Multiple Processes} 에서 보인 예제에 남아있는
	동기화 작업은 무엇이 있을까요?
	\iffalse

	What synchronization remains in the example shown in
	Section~\ref{sec:owned:Multiple Processes}?
	\fi
\QuickQuizAnswer{
	\co{sh} 의 \co{&} 오퍼레이터를 통한 쓰레드들의 생성과 \co{sh} 의
	\co{wait} 명령을 통한 쓰레드 종료 기다리기입니다.

	물론, 프로세스들이 예를 들어 \co{shmget()} 이나 \co{mmap()} 시스템 콜을
	이용해 명시적으로 메모리를 공유한다면 이 공유 메모리 영역을 접근하거나
	업데이트하는 데에는 명시적인 동기화가 필요할 것입니다.
	프로세스들은 또한 다음의 프로세스간 통신 메커니즘들 중 어떤 것이든
	사용할 수도 있을 겁니다.
	\begin{enumerate}
	\item	System V 세마포어.
	\item	System V 메세지 큐.
	\item	UNIX-domain 소켓.
	\item	TCP/IP, UDP, 그리고 모든 다른 것들의 호스트를 포함한 네트워킹
		프로토콜.
	\item	파일 락킹.
	\item	\co{O_CREAT} 과 \co{O_EXCL} 플래그와 함께 사용되는 \co{open()}
		시스템콜.
	\item	\co{rename()} 시스템콜의 사용.
	\end{enumerate}
	\iffalse

	The creation of the threads via the \co{sh} \co{&} operator
	and the joining of thread via the \co{sh} \co{wait}
	command.

	Of course, if the processes explicitly share memory, for
	example, using the \co{shmget()} or \co{mmap()} system
	calls, explicit synchronization might well be needed when
	acccessing or updating the shared memory.
	The processes might also synchronize using any of the following
	interprocess communications mechanisms:
	\begin{enumerate}
	\item	System V semaphores.
	\item	System V message queues.
	\item	UNIX-domain sockets.
	\item	Networking protocols, including TCP/IP, UDP, and a whole
		host of others.
	\item	File locking.
	\item	Use of the \co{open()} system call with the
		\co{O_CREAT} and \co{O_EXCL} flags.
	\item	Use of the \co{rename()} system call.
	\end{enumerate}
	\fi
	가능한 동기화 메커니즘의 전체 리스트를 만드는 것은 독자의 몫으로
	둘텐데, 이는 굉장히 긴 리스트가 될 것입니다.
	놀랍도록 많은 수의 예상치 못한 시스템콜들이 동기화 메커니즘으로 나타날
	수 있습니다.
	\iffalse

	A complete list of possible synchronization mechanisms is left
	as an exercise to the reader, who is warned that it will be
	an extremely long list.
	A surprising number of unassuming system calls can be pressed
	into service as synchronization mechanisms.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	Section~\ref{sec:owned:Multiple Processes} 에서 보여진 예제에 어떤
	공유된 데이터가 있나요?
	\iffalse

	Is there any shared data in the example shown in
	Section~\ref{sec:owned:Multiple Processes}?
	\fi
\QuickQuizAnswer{
	이건 철학적인 질문입니다.

	``아니오'' 라는 답을 원하는 사람들은 프로세스들이 정의에 의해 메모리를
	공유하지 않는다고 주장할 수도 있을 겁니다.
	\iffalse

	That is a philosophical question.

	Those wishing the answer ``no'' might argue that processes by
	definition do not share memory.
	\fi

	``예'' 라고 대답하고 싶은 사람들은 공유 메모리를 필요로 하지 않는 많은
	동기화 메커니즘들의 리스트를 나열하고 커널은 공유된 상태를 가질 것임을
	이야기 할 수 있고, 아마도 심지어는 프로세스 ID (PID) 의 할당은 공유된
	데이터에 해당된다고 주장할 수도 있습니다.

	그런 주장들은 매우 지적인 행위이고 불행한 학교 친구나 동료들에게서
	점수를 딸 수 있는, 지적이라는 느낌을 받을 수 있는 훌륭한 방법이기도
	하며, (특히!) 유용한 일이 이루어지기를 막아버리는 행위입니다.
	\iffalse

	Those wishing to answer ``yes'' might list a large number of
	synchronization mechanisms that do not require shared memory,
	note that the kernel will have some shared state, and perhaps
	even argue that the assignment of process IDs (PIDs) constitute
	shared data.

	Such arguments are excellent intellectual exercise, and are
	also a wonderful way of feeling intelligent, scoring points
	against hapless classmates or colleagues,
	and (especially!) avoiding getting anything useful done.
	\fi
} \QuickQuizEnd

\co{sh} 에서 했던 것과 똑같은 패턴을 C 로도 구현할 수 있는데,
Listings~\ref{lst:toolsoftrade:Using the fork() Primitive}
and~\ref{lst:toolsoftrade:Using the wait() Primitive} 에 그 구현이 그려져
있습니다.

다음 섹션은 공유 메모리 병렬 프로그램에서의 데이터 소유권의 사용에 대해 논의해
봅니다.
\iffalse

This same pattern can be written in C as well as in \co{sh}, as illustrated by
Listings~\ref{lst:toolsoftrade:Using the fork() Primitive}
and~\ref{lst:toolsoftrade:Using the wait() Primitive}.

The next section discusses use of data ownership in shared-memory
parallel programs.
\fi

\section{Partial Data Ownership and pthreads}
\label{sec:owned:Partial Data Ownership and pthreads}

Chapter~\ref{chp:Counting} 는 데이터 소유권을 많이 사용하고 있습니다만, 한가지
새로운 방식을 가지고 있습니다.
쓰레드들은 다른 쓰레드들에 의해 소유되는 데이터를 수정할 수 없도록 되어있지만,
그것들을 읽을 수는 있습니다.
한마디로, 여기서의 공유메모리 사용은 소유권과 접근 권한들에의 더 많은, 묘한
개념들을 허용합니다.
\iffalse

Chapter~\ref{chp:Counting} makes heavy use of data ownership,
but adds a twist.
Threads are not allowed to modify data owned by other threads,
but they are permitted to read it.
In short, the use of shared memory allows more nuanced notions
of ownership and access rights.
\fi

예를 들어,
page~\pageref{lst:count:Per-Thread Statistical Counters} 의
Listing~\ref{lst:count:Per-Thread Statistical Counters} 에 있는
쓰레드별 통계적 카운터 구현을 생각해 봅시다.
여기서, \co{inc_count()} 는 연관된 쓰레드의 \co{counter} 인스턴스를 수정할
뿐입니다만, \co{read_count()} 는 모든 쓰레드의 \co{counter} 인스턴스들을
접근하되 수정하지는 않습니다.
\iffalse

For example, consider the per-thread statistical counter implementation
shown in
Listing~\ref{lst:count:Per-Thread Statistical Counters} on
page~\pageref{lst:count:Per-Thread Statistical Counters}.
Here, \co{inc_count()} updates only the corresponding thread's
instance of \co{counter},
while \co{read_count()} accesses, but does not modify, all
threads' instances of \co{counter}.
\fi

\QuickQuiz{}
	각각의 쓰레드가 자신의 쓰레드별 변수만을 읽을 수 있지만 다른 쓰레드의
	인스턴스들에는 쓰기를 할 수도 있는 부분적 데이터 소유권도 말이 될까요?
	\iffalse

	Does it ever make sense to have partial data ownership where
	each thread reads only its own instance of a per-thread variable,
	but writes to other threads' instances?
	\fi
\QuickQuizAnswer{
	놀랍게도, 그렇습니다.
	한가지 예는 쓰레드들이 다른 쓰레드의 메일함에 메세지를 보내고, 각
	쓰레드는 자신이 보낸 메세지를 일단 그 메세지가 읽혀졌다면 지워야 할
	책임을 갖는 간단한 메세지 전달 시스템입니다.
	그런 알고리즘의 구현은 다른 알고리즘들을 비슷한 소유권 패턴으로 구분해
	보는 일과 함께 독자의 몫으로 남겨두겠습니다.
	\iffalse

	Amazingly enough, yes.
	One example is a simple message-passing system where threads post
	messages to other threads' mailboxes, and where each thread
	is responsible for removing any message it sent once that message
	has been acted on.
	Implementation of such an algorithm is left as an exercise for the
	reader, as is the task of identifying other algorithms with
	similar ownership patterns.
	\fi
} \QuickQuizEnd

순수한 데이터 소유권은 일반적이고 할 뿐더러 유용한데,
page~\pageref{sec:SMPdesign:Resource Allocator Caches} 부터 시작되는
Section~\ref{sec:SMPdesign:Resource Allocator Caches} 에서 이야기된
쓰레드별 메모리 할당자 캐시가 한 예입니다.
이 알고리즘에서, 각 쓰레드의 캐시는 그 쓰레드에게 완전히 사유되어 있습니다.
\iffalse

Pure data ownership is also both common and useful, for example, the
per-thread memory-allocator caches discussed in
Section~\ref{sec:SMPdesign:Resource Allocator Caches}
starting on
page~\pageref{sec:SMPdesign:Resource Allocator Caches}.
In this algorithm, each thread's cache is completely private to that
thread.
\fi

\section{Function Shipping}
\label{sec:owned:Function Shipping}

앞의 섹션에서는 쓰레드들이 다른 쓰레드들의 데이터에 접근할 수 있는 약한 형태의
데이터 소유권에 대해 이야기했습니다.
이런 형태는 함수에 필요한 데이터를 가져다 주는 것으로 생각될 수 있습니다.
대안적인 접근법은 데이터에 함수를 가져다 주는 것입니다.

그런 접근법이
page~\pageref{sec:count:Signal-Theft Limit Counter Design} 에서 시작하는
Section~\ref{sec:count:Signal-Theft Limit Counter Design} 중
page~\pageref{lst:count:Signal-Theft Limit Counter Value-Migration Functions}
의
Listing~\ref{lst:count:Signal-Theft Limit Counter Value-Migration Functions}
에 있는 \co{flush_local_count_sig()} 와 \co{flush_local_count()} 함수로 그려져
있습니다.

\iffalse
The previous section described a weak form of data ownership where
threads reached out to other threads' data.
This can be thought of as bringing the data to the functions that
need it.
An alternative approach is to send the functions to the data.

Such an approach is illustrated in
Section~\ref{sec:count:Signal-Theft Limit Counter Design}
beginning on
page~\pageref{sec:count:Signal-Theft Limit Counter Design},
in particular the \co{flush_local_count_sig()} and
\co{flush_local_count()} functions in
Listing~\ref{lst:count:Signal-Theft Limit Counter Value-Migration Functions}
on
page~\pageref{lst:count:Signal-Theft Limit Counter Value-Migration Functions}.
\fi

\co{flush_local_count_sig()} 함수는 전달되는 함수처럼 동작하는 시그널
핸들러입니다.
\co{flush_local_count()} 의 \co{pthread_kill()} 함수는 시그널을 보내고---함수를
전달하는 행위--- 전달된 함수가 실행되기를 기다립니다.
이 전달된 함수는 일반적이지 않은, 동시적으로 수행되는 \co{add_count()} 나
\co{sub_count()} 함수들과의 상호작용의 필요로 인해 추가된 복잡성을 갖습니다 (
page~\pageref{lst:count:Signal-Theft Limit Counter Add Function} 의
Listing~\ref{lst:count:Signal-Theft Limit Counter Add Function} 와
page~\pageref{lst:count:Signal-Theft Limit Counter Subtract Function} 의
Listing~\ref{lst:count:Signal-Theft Limit Counter Subtract Function} 를
참고하세요).
\iffalse

The \co{flush_local_count_sig()} function is a signal handler that
acts as the shipped function.
The \co{pthread_kill()} function in \co{flush_local_count()}
sends the signal---shipping the function---and then waits until
the shipped function executes.
This shipped function has the not-unusual added complication of
needing to interact with any concurrently executing \co{add_count()}
or \co{sub_count()} functions (see
Listing~\ref{lst:count:Signal-Theft Limit Counter Add Function}
on
page~\pageref{lst:count:Signal-Theft Limit Counter Add Function} and
Listing~\ref{lst:count:Signal-Theft Limit Counter Subtract Function}
on
page~\pageref{lst:count:Signal-Theft Limit Counter Subtract Function}).
\fi

\QuickQuiz{}
	함수를 전달하는데 POSIX 시그널 외에 어떤 다른 메커니즘이 사용될 수
	있을까요?
	\iffalse

	What mechanisms other than POSIX signals may be used for function
	shipping?
	\fi
\QuickQuizAnswer{
	그런 메커니즘에는 상당히 많은 것들이 있는데, 다음의 것들을 포함합니다:
	\begin{enumerate}
	\item	System V 메세지 큐.
	\item	공유 메모리 디큐
		(Section~\ref{sec:SMPdesign:Double-Ended Queue} 를 참고하세요).
	\item	공유 메모리 메일함.
	\item	UNIX-domain 소켓.
	\item	RPC, HTTP, XML, SOAP, 그 외 여러가지 높은 레벨의 프로토콜들과
		결합되어 사용될 수도 있는 TCP/IP 또는 UDP.
	\end{enumerate}
	전체 리스트의 완성은 성실한 독자들의 몫으로 남겨둘텐데, 그 리스트는
	굉장히 길 수 있다는 점을 경고해 둡니다.
	\iffalse

	There is a very large number of such mechanisms, including:
	\begin{enumerate}
	\item	System V message queues.
	\item	Shared-memory dequeue (see
		Section~\ref{sec:SMPdesign:Double-Ended Queue}).
	\item	Shared-memory mailboxes.
	\item	UNIX-domain sockets.
	\item	TCP/IP or UDP, possibly augmented by any number of
		higher-level protocols, including RPC, HTTP,
		XML, SOAP, and so on.
	\end{enumerate}
	Compilation of a complete list is left as an exercise to
	sufficiently single-minded readers, who are warned that the
	list will be extremely long.
	\fi
} \QuickQuizEnd

\section{Designated Thread}
\label{sec:owned:Designated Thread}

앞의 섹션들에서는 각 쓰레드가 데이터 복사본을 또는 데이터의 특정 부분을
소유하는 여러가지 방법들을 설명했습니다.
반대로, 이 섹션에서는 특별한 선택된 쓰레드가 프로그램이 일을 하는데 필요한
데이터를 소유하는 함수적 분해 접근법을 설명합니다.
Section~\ref{sec:count:Eventually Consistent Implementation} 에서 설명했던
결과적으로 일관적인 카운터 구현이 예를 제공합니다.
이 구현은
Listing~\ref{lst:count:Array-Based Per-Thread Eventually Consistent Counters} 의
line~15-32 에서 보이는 \co{eventual()} 함수를 수행하는 정해진 쓰레드를 가지고
있습니다.
이 \co{eventual()} 쓰레드는 주기적으로 쓰레드별 카운트를 글로벌 카운터로
가져와서 글로벌 카운터로의 접근이 이름이 말하는 바와 같이 결과적으로는 실제
값에 수렴하게 합니다.
\iffalse

The earlier sections describe ways of allowing each thread to keep its
own copy or its own portion of the data.
In contrast, this section describes a functional-decomposition approach,
where a special designated thread owns the rights to the data
that is required to do its job.
The eventually consistent counter implementation described in
Section~\ref{sec:count:Eventually Consistent Implementation} provides an example.
This implementation has a designated thread that runs the
\co{eventual()} function shown on lines~15-32 of
Listing~\ref{lst:count:Array-Based Per-Thread Eventually Consistent Counters}.
This \co{eventual()} thread periodically pulls the per-thread counts
into the global counter, so that accesses to the global counter will,
as the name says, eventually converge on the actual value.
\fi

\QuickQuiz{}
	하지만
	Listing~\ref{lst:count:Array-Based Per-Thread Eventually Consistent Counters}
	의 line~15-32 에 보여진 \co{eventual()} 함수의 어떤 데이터로 실제로는
	\co{eventual()} 쓰레드에게 소유되어 있지 않습니다!
	이게 어떻게 데이터 소유권인가요???
	\iffalse

	But none of the data in the \co{eventual()} function shown on
	lines~15-32 of
	Listing~\ref{lst:count:Array-Based Per-Thread Eventually Consistent Counters}
	is actually owned by the \co{eventual()} thread!
	In just what way is this data ownership???
	\fi
\QuickQuizAnswer{
	핵심 문구는 ``데이터로의 권한을 소유한다'' 입니다.
	이 경우, 질문되는 권한은 해당 그림의 line~1 에 정의된 쓰레드별
	\co{counter} 변수에 접근할 수 있는 권한을 말합니다.
	이 상황은
	Section~\ref{sec:owned:Partial Data Ownership and pthreads} 에서 설명된
	것과 비슷한 상황입니다.
	\iffalse

	The key phrase is ``owns the rights to the data''.
	In this case, the rights in question are the rights to access
	the per-thread \co{counter} variable defined on line~1
	of the figure.
	This situation is similar to that described in
	Section~\ref{sec:owned:Partial Data Ownership and pthreads}.
	\fi

	하지만, 정말로 \co{eventual()} 쓰레드에 의해 소유되는 데이터도
	존재하는데, 해당 그림의 line~17 과 18 에 정의되어 있는 \co{t} 와
	\co{sum} 변수들입니다.

	정해진 쓰레드의 다른 예를 보려면, 리눅스 커널의 커널 쓰레드들을 보면
	되는데, 예컨대 \co{kthread_create()} 와 \co{kthread_run()} 으로
	생성되는 것들을 보시기 바랍니다.
	\iffalse

	However, there really is data that is owned by the \co{eventual()}
	thread, namely the \co{t} and \co{sum} variables defined on
	lines~17 and~18 of the figure.

	For other examples of designated threads, look at the kernel
	threads in the Linux kernel, for example, those created by
	\co{kthread_create()} and \co{kthread_run()}.
	\fi
} \QuickQuizEnd

\section{Privatization}
\label{sec:owned:Privatization}

공유 메모리 병렬 프로그램의 성능과 확장성을 개선하는 한가지 방법은 공유된
데이터를 특정 쓰레드에 의해 소유된 사유 데이터로 변환하는 것입니다.

이런 방법의 좋은 예가
Section~\ref{sec:SMPdesign:Dining Philosophers Problem} 의 Quick Quiz 중 하나의
답변에 있는데, 식사하는 철학자 문제를 데이터 사유화를 통해 교재의 표준적인
해결책보다 훨씬 좋은 성능과 확장성으로 해결하는 해결책입니다.
원래의 문제는 다섯명의 철학자들이 테이블에 앉아있고 인접한 두 철학자 사이에
하나의 포크만이 놓여 있어서 최대 두명의 철학자들만이 동시에 식사를 할 수 있게
되어 있었습니다.
\iffalse

One way of improving the performance and scalability of a shared-memory
parallel program is to transform it so as to convert shared data to
private data that is owned by a particular thread.

An excellent example of this is shown in the answer to one of the
Quick Quizzes in
Section~\ref{sec:SMPdesign:Dining Philosophers Problem},
which uses privatization to produce a solution to the
Dining Philosophers problem with much better performance and scalability
than that of the standard textbook solution.
The original problem has five philosophers sitting around the table
with one fork between each adjacent pair of philosophers, which permits
at most two philosophers to eat concurrently.
\fi

우린 여기에 다섯개의 포크를 추가함으로써 각각의 철학자가 그 또는 그녀 자신만의
포크 한쌍을 가질 수 있게 하는것으로 간단히 문제에 사유화를 적용할 수 있습니다.
이 방법은 모든 다섯명의 철학자들이 동시에 식사를 할 수 있도록 하고, 또한 그런
종류의 문제의 확산을 주목할만하게 감소시킬 수 있습니다.

다른 경우에는, 사유화는 비용을 의미합니다.
예를 들어,
page~\pageref{lst:count:Simple Limit Counter Add, Subtract, and Read} 의
Listing~\ref{lst:count:Simple Limit Counter Add, Subtract, and Read} 에 나온
간단한 리미트 카운터를 생각해 봅시다.
이는 쓰레드들이 서로의 데이터를 읽을 수 있지만 자신의 데이터만 업데이트 할 수
있도록 허용되는 알고리즘의 한가지 예입니다.
해당 알고리즘을 간단히 살펴본 결과 쓰레드간의 접근은 \co{read_count()} 의
합산을 위한 루프 뿐임을 알 수 있었습니다.
이 루프가 사라진다면, 더 효과적인 순수한 데이터 소유권으로 옮겨갈 수
있습니다만, \co{read_count()} 의 덜 정확한 결과값을 비용으로 지불하게 될겁니다.
\iffalse

We can trivially privatize this problem by providing an additional five
forks, so that each philosopher has his or her own private pair of forks.
This allows all five philosophers to eat concurrently, and also offers
a considerable reduction in the spread of certain types of disease.

In other cases, privatization imposes costs.
For example, consider the simple limit counter shown in
Listing~\ref{lst:count:Simple Limit Counter Add, Subtract, and Read} on
page~\pageref{lst:count:Simple Limit Counter Add, Subtract, and Read}.
This is an example of an algorithm where threads can read each others'
data, but are only permitted to update their own data.
A quick review of the algorithm shows that the only cross-thread
accesses are in the summation loop in \co{read_count()}.
If this loop is eliminated, we move to the more-efficient pure
data ownership, but at the cost of a less-accurate result
from \co{read_count()}.
\fi

\QuickQuiz{}
	여전히 쓰레드별 데이터의 완전한 사유화를 유지하면서 좋은 정확도를 얻을
	수도 있을까요?
	\iffalse

	Is it possible to obtain greater accuracy while still
	maintaining full privacy of the per-thread data?
	\fi
\QuickQuizAnswer{
	네.
	한가지 방법은 \co{read_count()} 가 자신의 쓰레드별 변수를 더하도록 하는
	것입니다.
	이렇게 되면 완전한 소유권과 성능을 유지하지만 정확도에 있어서는 아주
	조금 개선이 될텐데, 특히나 매우 많은 수의 쓰레드들이 존재하는
	시스템에서 그럴 겁니다.

	또다른 방법은 \co{read_count()} 가 함수 전달을 사용하는 것으로, 예를
	들면 쓰레드별 시그널과 같은 형태가 되겠습니다.
	이 방법은 정확도를 매우 많이 개선시킬 것입니다만, \co{read_count()} 의
	성능에 대해선 상당한 비용을 갖게 될겁니다.

	하지만, 이런 방법들 모두 카운터 업데이트의 일반적인 경우에 있어서의
	캐시 라인 바운싱 (cache-line bouncing) 을 제거해주는 이점을 가질
	겁니다.
	\iffalse

	Yes.
	One approach is for \co{read_count()} to add the value
	of its own per-thread variable.
	This maintains full ownership and performance, but only
	a slight improvement in accuracy, particularly on systems
	with very large numbers of threads.

	Another approach is for \co{read_count()} to use function
	shipping, for example, in the form of per-thread signals.
	This greatly improves accuracy, but at a significant performance
	cost for \co{read_count()}.

	However, both of these methods have the advantage of eliminating
	cache-line bouncing for the common case of updating counters.
	\fi
} \QuickQuizEnd

요약하자면, 사유화는 병렬 프로그래머의 도구상자에 있는 강력한 도구입니다만
충분한 고려 없이 사용되어선 안됩니다.
모든 다른 동기화 도구들처럼, 이 방법 역시 성능과 확장성을 떨어뜨리고 복잡도를
높일 수 있는 잠재적 가능성이 존재합니다.
\iffalse

In short, privatization is a powerful tool in the parallel programmer's
toolbox, but it must nevertheless be used with care.
Just like every other synchronization primitive, it has the potential
to increase complexity while decreasing performance and scalability.
\fi

\section{Other Uses of Data Ownership}
\label{sec:owned:Other Uses of Data Ownership}

데이터 소유권은 데이터가 쓰레드간 액세스나 업데이트의 필요가 적거나 없을 수
있도록 분할 될 수 있을 때에 가장 잘 동작합니다.
다행히도, 이런 상황은 합당하게도 흔하고, 다양한 병렬 프로그래밍 환경에
존재합니다.

데이터 소유권의 예에는 다음의 것들도 포함됩니다:
\iffalse

Data ownership works best when the data can be partitioned so that there
is little or no need for cross thread access or update.
Fortunately, this situation is reasonably common, and in a wide variety
of parallel-programming environments.

Examples of data ownership include:
\fi

\begin{enumerate}
\item	MPI~\cite{MPIForum2008} 와 BOINC~\cite{BOINC2008} 같은 모든 메세지 전달
	환경.
\item	Map-reduce~\cite{MapReduce2008MIT}.
\item	RPC, 웹 서비스, 그리고 백엔드 데이터베이스 서버를 갖는 수많은
	시스템들과 같은 클라이언트-서버 시스템들.
\item	아무것도 공유하지 않는 데이터베이스 시스템들.
\item	프로세스별로 분리된 주소공간을 갖는 Fork-join 시스템들.
\item	Erlang 언어와 같은 프로세스 기반 병렬성.
\item	쓰레드 환경에서 C 언어의 스택 위에 할당되는 auto 변수들과 같은 사유
	변수들.
\item	특히나 GPGPU 에 적합한, 많은 병렬 선형 대수 알고리즘들.\footnote{
		하지만 굉장히 많은 다른 부류의 어플리케이션들 또한 GPGPU 로
		포팅되었음을 알아두시기
		바랍니다~\cite{NormMatloff2013ParProcBook,AMD2017OpenCL,NVidia2017GPGPU,NVidia2017GPGPU-university}.}
\item	네트워킹에 최적화 되어서 각각의 네트워크 연결 (\emph{flow} 라고도
	불립니다~\cite{Shenker89,ZhangPhD,McKenney90}) 이 특정 쓰레드로
	할당되는 운영체제 커널들.
	이런 방법의 최근의 한 예는 IX
	운영체제입니다~\cite{Belay:2016:IOS:3014162.2997641}.
	IX 는 Section~\ref{sec:defer:Read-Copy Update (RCU)} 에서 설명할 동기화
	메커니즘을 사용하는 공유 데이터 구조를 일부 갖습니다.
\iffalse

\item	All message-passing environments, such as MPI~\cite{MPIForum2008}
	and BOINC~\cite{BOINC2008}.
\item	Map-reduce~\cite{MapReduce2008MIT}.
\item	Client-server systems, including RPC, web services, and
	pretty much any system with a back-end database server.
\item	Shared-nothing database systems.
\item	Fork-join systems with separate per-process address spaces.
\item	Process-based parallelism, such as the Erlang language.
\item	Private variables, for example, C-language on-stack auto variables,
	in threaded environments.
\item	Many parallel linear-algebra algorithms, especially those
	well-suited for GPGPUs.\footnote{
		But note that a great many other classes of applications
		have also been ported to
		GPGPUs~\cite{NormMatloff2013ParProcBook,AMD2017OpenCL,NVidia2017GPGPU,NVidia2017GPGPU-university}.}
\item	Operating-system kernels adapted for networking, where each connection
	(also called \emph{flow}~\cite{Shenker89,ZhangPhD,McKenney90})
	is assigned to a specific thread.
	One recent example of this approach is the IX operating
	system~\cite{Belay:2016:IOS:3014162.2997641}.
	IX does have some shared data structures, which use synchronization
	mechanisms to be described in
	Section~\ref{sec:defer:Read-Copy Update (RCU)}.
\fi
\end{enumerate}

데이터 소유권은 아마도 존재하는 것들 중 가장 감사받지 못하고 있는 동기화
메커니즘입니다.
제대로 사용된다면, 이것은 적수를 찾기 어려울 만큼의 간단함과 성능, 그리고
확장성을 제공합니다.
아마도 이것의 간단함이 이것이 누리기 마땅한 존중을 받게 합니다.
바라건대 데이터 소유권의 섬세함과 힘에 대한 감사함이 늘어나는 것은 더 많은
존중을 이끌어내어서 더 훌륭한 성능과 확장성에 줄어든 복잡성을 이끌어낼 수 있게
할것입니다.
\iffalse

Data ownership is perhaps the most underappreciated synchronization
mechanism in existence.
When used properly, it delivers unrivaled simplicity, performance,
and scalability.
Perhaps its simplicity costs it the respect that it deserves.
Hopefully a greater appreciation for the subtlety and power of data ownership
will lead to greater level of respect, to say nothing of leading to
greater performance and scalability coupled with reduced complexity.
\fi

% populate with problems showing benefits of coupling data ownership with
% other approaches. For example, work-stealing schedulers. Perhaps also
% move memory allocation here, though its current location is quite good.
