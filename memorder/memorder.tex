% memorder/memorder.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\QuickQuizChapter{chp:Advanced Synchronization: Memory Ordering}{Advanced Synchronization: Memory Ordering}{qqzmemorder}
\OriginallyPublished{Chapter}{chp:Advanced Synchronization: Memory Ordering}{Advanced Synchronization: Memory Ordering}{the Linux kernel}{Howells2009membartxt}
\OriginallyPublished{Chapter}{chp:Advanced Synchronization: Memory Ordering}{Advanced Synchronization: Memory Ordering}{Linux Weekly News}{JadeAlglave2017LWN-LKMM-1,JadeAlglave2017LWN-LKMM-2}
\OriginallyPublished{Chapter}{chp:Advanced Synchronization: Memory Ordering}{Advanced Synchronization: Memory Ordering}{ASPLOS '18}{Alglave:2018:FSC:3173162.3177156}
%
\Epigraph{The art of progress is to preserve order amid change and to preserve change amid order.}{\emph{Alfred North Whitehead}}

인과관계와 순서관계는 매우 직관적이며, 해커들은 종종 이 컨셉에 사로잡혀
있습니다.
이 직관은 순차적 코드만이 아니라 락킹과 같이 표준적인 상호 배제 메커니즘을
사용하는 병렬 코드를 작성하고 분석하고 디버깅할 때에 상당히 도움이 됩니다.
불행히도, 이 직관은 그런 메커니즘을 사용할 수 없는 코드에서는 완전히
망가집니다.
그런 코드 구현의 한가지 예는 표준 상호 배제 메커니즘 그 자체이며, 다른 예는
완화된 동기화를 사용하는 빠른 수행경로 구현들입니다.
직관에 대한 모욕에도 불구하고, 어떤 사람들은 그런 완화됨이 덕목이라고
주장합니다~\cite{JadeAlglave2013-WeaknessIsVirtue}.
덕목이든 악덕이든, 이 챕터는 여러분이 메모리 순서 규칙에 대한 이해를 도울텐데
이는 연습과 함께 동기화 기능과 성능에 치명적인 빠른 수행경로를 구현하는데
충분할 겁니다.

\iffalse

Causality and sequencing are deeply intuitive, and hackers often
have a strong grasp of these concepts.
These intuitions can be quite helpful when writing, analyzing, and
debugging not only sequential code, but also parallel code that makes
use of standard mutual-exclusion mechanisms such as locking.
Unfortunately, these intuitions break down completely in face of
code that fails to use such mechanisms.
One example of such code implements the standard mutual-exclusion
mechanisms themselves, while another example implements fast
paths that use weaker synchronization.
Insults to intuition notwithstanding, some argue that weakness is a
virtue~\cite{JadeAlglave2013-WeaknessIsVirtue}.
Virtue or vice, this chapter will help you gain an understanding of
memory ordering, that, with practice, will be sufficient to implement
synchronization primitives and performance-critical fast paths.

\fi

\Cref{sec:memorder:Ordering: Why and How?}
는 실제 컴퓨터 시스템이 메모리 참조를 재배치 할 수 있음을 보이고, 왜 그러는지
이유를 보이며, 바라지 않는 재배치를 어떻게 막는지에 대한 정보를 제공합니다.
\Cref{sec:memorder:Tricks and Traps,%
sec:memorder:Compile-Time Consternation}
는 그걸 모르는 병렬 프로그래머를 고통스럽게 할 수 있는 하드웨어와 컴파일러에서
발생하는 문제들을 각각 다룹니다.
\Cref{sec:memorder:Higher-Level Primitives}
는 메모리 순서 규칙을 높은 수준의 추상화로 모델링 하는 것의 장점을 봅니다.
\Cref{sec:memorder:Hardware Specifics}
는 일부 하드웨어 플랫폼에서의 볻 ㅏ자세한 부분을 다룹니다.
마지막으로, \cref{sec:memorder:Where is Memory Ordering Needed?}
는 일부 유용한 경험적 법칙을 제공합니다.

\iffalse

\Cref{sec:memorder:Ordering: Why and How?}
will demonstrate that real computer systems can reorder memory references,
give some reasons why they do so, and provide some information on how
to prevent undesired reordering.
\Cref{sec:memorder:Tricks and Traps,%
sec:memorder:Compile-Time Consternation}
will cover the types of pain that hardware and compilers, respectively,
can inflict on unwary parallel programmers.
\Cref{sec:memorder:Higher-Level Primitives}
gives an overview of the benefits of modeling memory ordering at
higher levels of abstraction.
\Cref{sec:memorder:Hardware Specifics}
follows up with more detail on a few representative hardware platforms.
Finally, \cref{sec:memorder:Where is Memory Ordering Needed?}
provides some useful rules of thumb.

\fi

\QuickQuiz{
	이 챕터는 첫번째 판본 이후로 다시 작성되었습니다.
	메모리 순서 규칙은 2014년 이후로 \emph{그렇게나} 바뀌었나요?

	\iffalse

	This chapter has been rewritten since the first edition.
	Did memory ordering change all \emph{that} since 2014?

	\fi

}\QuickQuizAnswer{
	이전의 메모리 순서규칙 섹션은 2005년의 Linux Journal 기사
	두편~\cite{PaulMcKenney2005i,PaulMcKenney2005j} 에 그 기원을 두고
	있었습니다.
	그 이후, C 와 C++ 메모리 모델이~\cite{PeteBecker2011N3242} 정형화
	되었고 (그리고
	비평되었고~\cite{MarkBatty2013OOTA-WorkingNote,Boehm:2014:OGA:2618128.2618134,Vafeiadis:2015:CCO:2775051.2676995,conf/esop/BattyMNPS15,Lahav:2017:RSC:3140587.3062352,OlivierGiroux2017-P0668R1}),
	컴퓨터 시스템을 위한 수행 가능한 정형적 메모리 모델이 표준화
	되었으며~\cite{Maranget2012TutorialARMPower,PaulEMcKenney2011ppcmem,test6-pdf,JadeAlglave2011ppcmem,Alglave:2013:SVW:2450268.2450306,JadeAlglave2013-cav,Alglave:2014:HCM:2594291.2594347,PaulEMcKenney2014weakaxiom,Flur:2017:MCA:3093333.3009839,ARMv8A:2017},
	리눅스 커널을 위한 메모리 모델조차 존재하게 되었는데~\cite{JadeAlglave2017LWN-LKMM-1,JadeAlglave2017LWN-LKMM-2,Alglave:2018:FSC:3173162.3177156},
	이를 바탕으로 C11 과 리눅스 메모리 모델의 차이를 설명하는 논문도
	나왔습니다~\cite{PaulEMcKenney2016P0124R6-LKMM}.

	2005년 이후의 이 모든 진보를 두고 보면, 완전 다시 작성할 시간이 된게
	분명했습니다!

	\iffalse

	The earlier memory-ordering section had its roots in a pair of
	Linux Journal articles~\cite{PaulMcKenney2005i,PaulMcKenney2005j}
	dating back to 2005.
	Since then, the C and C++ memory models~\cite{PeteBecker2011N3242}
	have been formalized
	(and critiqued~\cite{MarkBatty2013OOTA-WorkingNote,Boehm:2014:OGA:2618128.2618134,Vafeiadis:2015:CCO:2775051.2676995,conf/esop/BattyMNPS15,Lahav:2017:RSC:3140587.3062352,OlivierGiroux2017-P0668R1}),
	executable formal memory models for computer systems have become the
	norm~\cite{Maranget2012TutorialARMPower,PaulEMcKenney2011ppcmem,test6-pdf,JadeAlglave2011ppcmem,Alglave:2013:SVW:2450268.2450306,JadeAlglave2013-cav,Alglave:2014:HCM:2594291.2594347,PaulEMcKenney2014weakaxiom,Flur:2017:MCA:3093333.3009839,ARMv8A:2017},
	and there is even a memory model for the Linux
	kernel~\cite{JadeAlglave2017LWN-LKMM-1,JadeAlglave2017LWN-LKMM-2,Alglave:2018:FSC:3173162.3177156},
	along with a paper describing differences between the C11 and
	Linux memory models~\cite{PaulEMcKenney2016P0124R6-LKMM}.

	Given all this progress since 2005, it was high time for a
	full rewrite!

	\fi

}\QuickQuizEnd

\section{Ordering: Why and How?}
\label{sec:memorder:Ordering: Why and How?}
%
\epigraph{Nothing is orderly till people take hold of it.
	  Everything in creation lies around loose.}
	 {\emph{Henry Ward Beecher, updated}}

메모리 순서 규칙을 위한 한가지 동기는
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}
(\path{C-SB+o-o+o-o.litmus}) 의 사소해 보이는 리트머스 테스트에서 볼 수 있는데,
첫눈에 보면 \co{exists} 절이 절대 발동되지 않을 것으로 보일 수도 있을
겁니다.\footnote{
	순수주의자들은 \co{exists} 절이 절대 \emph{만족} 되지 ㅇ낳는다고
	주장하겠지만, 여기서의 ``발동'' 은 단정을 은유합니다.}
어쨌건, \co{exists} 절에 보인 것처럼 \nbco{0:r2=0} 라면,\footnote{
	즉, 쓰레드~\co{P0()} 의 지역 변수 \co{r2} 의 인스턴스가 0이란
	이야기입니다.
	리트머스 테스트 명명법을 위해선
	\cref{sec:formal:Anatomy of a Litmus Test} 를 참고하시기 발바니다.}
우린 쓰레드~\co{P0()} 의 \co{x1} 으로부터 \co{r2} 로의 로드가 쓰레드~\co{P1()}
의 \co{x1} 으로의 스토어 전에 일어났을 것을 바랄 수도 있을텐데, 이는 더 나아가
쓰레드~\co{P1()} 의 \co{x0} 로부터 \co{r2} 로의 로드가 쓰레드~\co{P0()} 의
\co{x0} 로의 스토어 전에 이루어져서 \nbco{1:r2=2} 이길, 따라서 \co{exists} 절이
발동되지 않길 바랄 수도 있습니다.
이 예는 대칭적이며, 따라서 \nbco{1:r2=0} 가 \nbco{0:r2=2} 를 보장하길 바랄수도
있을 겁니다.
불행히도, 메모리 배리어의 부재가 이 희망을 깨부숩니다.
CPU 는 쓰레드~\co{P0()} 와 쓰레드~\co{P1()} 의 문장들을 재배치할 권리를 갖는데,
x86 처럼 상대적으로 강한 순서 규칙의 시스템에서도 그렇습니다.

\iffalse

One motivation for memory ordering can be seen in the trivial-seeming
litmus test in
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}
(\path{C-SB+o-o+o-o.litmus}),
which at first glance might
appear to guarantee that the \co{exists} clause never triggers.\footnote{
	Purists would instead insist that the \co{exists} clause is
	never \emph{satisfied}, but we use ``trigger'' here by
	analogy with assertions.}
After all, if \nbco{0:r2=0} as shown in the \co{exists} clause,\footnote{
	That is, Thread~\co{P0()}'s instance of local variable \co{r2}
	equals zero.
	See \cref{sec:formal:Anatomy of a Litmus Test}
	for documentation of litmus-test nomenclature.}
we might hope that Thread~\co{P0()}'s load from~\co{x1} into \co{r2}
must have happened before Thread~\co{P1()}'s store to~\co{x1}, which
might raise further hopes that Thread~\co{P1()}'s load from~\co{x0}
into \co{r2} must happen after Thread~\co{P0()}'s store to~\co{x0},
so that \nbco{1:r2=2}, thus not triggering the \co{exists} clause.
The example is symmetric, so similar reasoning might lead
us to hope that \nbco{1:r2=0} guarantees that \nbco{0:r2=2}.
Unfortunately, the lack of memory barriers dashes these hopes.
The CPU is within its rights to reorder
the statements within both Thread~\co{P0()} and Thread~\co{P1()},
even on relatively strongly ordered systems such as x86.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-SB+o-o+o-o@whole.fcv}
\caption{Memory Misordering: Store-Buffering Litmus Test}
\label{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}
\end{listing}

\QuickQuiz{
	컴파일러 또한
	\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test} 의
	쓰레드~\co{P0()} 와 쓰레드~\co{P1()} 의 메모리 액세스를 재배치 할 수
	있습니다, 그렇죠?

	\iffalse

	The compiler can also reorder Thread~\co{P0()}'s and
	Thread~\co{P1()}'s memory accesses in
	\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test},
	right?

	\fi

}\QuickQuizAnswer{
	일반적으로 컴파일러 최적화는 CPU 가 할 수 있는 것보다 더 확장적이고
	심오한 재배치를 진행합니다.
	하지만 이 경우, \co{READ_ONCE()} 와 \co{WRITE_ONCE()} 의 volatile
	액세스는 컴파일러의 재배치를 막습니다.
	그것 외에도 많은 다른 것들을 막으며, 따라서 이 챕터의 예제들은
	\co{READ_ONCE()} 와 \co{WRITE_ONCE()} 를 널리 사용할 겁니다.
	\co{READ_ONCE()} 와 \co{WRITE_ONCE()} 의 필요에 대한 세부사항을 위해선
	\cref{sec:memorder:Compile-Time Consternation} 를 참고하세요.

	\iffalse

	In general, compiler optimizations carry out more extensive
	and profound reorderings than CPUs can.
	However, in this case, the volatile accesses in
	\co{READ_ONCE()} and \co{WRITE_ONCE()}
	prevent the compiler from reordering.
	And also from doing much else as well, so the examples in this
	chapter will be making heavy use of
	\co{READ_ONCE()} and \co{WRITE_ONCE()}.
	See \cref{sec:memorder:Compile-Time Consternation}
	for more detail on the need for \co{READ_ONCE()} and \co{WRITE_ONCE()}.

	\fi

}\QuickQuizEnd

이 재배치에 대한 의지는
\co{litmus7}~\cite{Alglave:2014:HCM:2594291.2594347} 와 같은 도구를 이용해
확인할 수 있는데, 이 도구는 이 반직관적인 순서가 제 x86 랩톱에서 100,000,000
시도 중 314회 발생함을 보였습니다.
충분히 이상하게도, 두개의 로드가 값 2를 반환하는 완전히 합법적인 결과는 덜
빈번하게 발생했는데, 이 경우 오직 167회였습니다.\footnote{
	결과는 정확한 하드웨어 구성, 시스템이 얼마나 부하를 받았는지, 그외에도
	여러가지에 따라 민감하게 달라질 수 있음에 주의하십시오.}
여기서의 교훈은 분명합니다: 반직관성의 증가는 확률의 감소를 암시하지는
않습니다!

\iffalse

This willingness to reorder can be confirmed using tools such as
\co{litmus7}~\cite{Alglave:2014:HCM:2594291.2594347},
which found that the counter-intuitive ordering happened
314 times out of 100,000,000 trials on my x86 laptop.
Oddly enough, the perfectly legal outcome where both loads return the
value 2 occurred less frequently, in this case, only 167 times.\footnote{
	Please note that results are sensitive to the exact hardware
	configuration,
	how heavily the system is loaded, and much else besides.}
The lesson here is clear: Increased counter-intuitivity does not necessarily
imply decreased probability!
% Run on June 23, 2017:
% litmus7 -r 1000 -carch X86 C-SB+o-o+o-o.litmus
% Test C-SB+o-o+o-o Allowed
% Histogram (4 states)
% 314   *>0:r2=0; 1:r2=0;
% 49999625:>0:r2=2; 1:r2=0;
% 49999894:>0:r2=0; 1:r2=2;
% 167   :>0:r2=2; 1:r2=2;

\fi

이어지는 섹션들은 이 직관이 정확히 어디서 부서지는지 보이고, 여러분이 이 함정을
피하는 걸 도울 메모리 순서 규칙에 대한 마음자세를 알려줍니다.

\Cref{sec:memorder:Why Hardware Misordering?}
는 왜 하드웨어가 메모리 액세스를 잘못 순서잡는지 간략히 설명하고,
\cref{sec:memorder:How to Force Ordering?}
는 여러분이 그런 잘못된 순서잡기를 어떻게 방해할 수 있는지 짧게 설명합니다.
마지막으로, \cref{sec:memorder:Basic Rules of Thumb}
는 기본적인 경험적 규칙 몇가지를 나열하는데, 이는 뒤의 섹션들에서 더 정리될
겁니다.
이 섹션은 하드웨어 순서 재배치에만 집중합니다만, 컴파일러가 하드웨어가 여지껏
꿈꿔왔던 것보다 훨씬 더 적극적으로 재배치를 함이 분명시 됩니다.
하지만 그 주제는 나중에
\cref{sec:memorder:Compile-Time Consternation} 에서 다룰 겁니다.

\iffalse

The following sections show exactly where this intuition breaks down,
and then puts forward a mental model of memory ordering that can help
you avoid these pitfalls.

\Cref{sec:memorder:Why Hardware Misordering?}
gives a brief overview of why hardware misorders memory accesses, and then
\cref{sec:memorder:How to Force Ordering?}
gives an equally brief overview of how you can thwart such misordering.
Finally, \cref{sec:memorder:Basic Rules of Thumb}
lists some basic rules of thumb, which will be further refined in
later sections.
These sections focus on hardware reordering, but rest assured that compilers
reorder much more aggressively than hardware ever dreamed of doing.
But that topic will be taken up later in
\cref{sec:memorder:Compile-Time Consternation}.

\fi

\subsection{Why Hardware Misordering?}
\label{sec:memorder:Why Hardware Misordering?}

하지만 일단 왜 잘못된 메모리 순서잡기가 일어나는 걸까요?
CPU 는 스스로 순서를 추적할 수 없나요?
무언가를 추적하는 것, 그게 어쨌건 우리가 컴퓨터를 갖는 이유 아닌가요?

실제로 많은 사람들이 그들의 컴퓨터가 사물을 추적하고 있을 것을 기대합니다만,
또한 많은 사람들은 사물을 빠르게 추적할 것을 강요합니다.
그러나, \cref{chp:Hardware and its Habits} 에서 보았듯이, 메인메모리는
메모리로부터 하나의 변수를 읽어오는데 필요한 시간동안 수백개의 명령을 수행할 수
있는 현대의 CPU 속도를 따라가지 못합니다.
따라서 CPU 들은 계속해서 커져가는 캐쉬를 사용하는데,
\cref{fig:cpu:System Hardware Architecture} 에서 본 것과 같으며, 이는 특정 CPU
에 의한 특정 변수의 첫번째 읽기는
\cref{sec:cpu:Cache Misses} 에서 본 것처럼 비싼 \emph{캐쉬 미스} 를 일으키지만
해당 CPU 에서의 뒤따르는 그 변수에 대한 반복된 읽기는 최초의 캐쉬 미스가 그
변수를 그 CPU 의 캐쉬에 적재시켰으므로 매우 빠르게 처리될 겁니다.

\iffalse

But why does memory misordering happen in the first place?
Can't CPUs keep track of ordering on their own?
Isn't that why we have computers in the first place, to keep track of things?

Many people do indeed expect their computers to keep track of things,
but many also insist that they keep track of things quickly.
However, as seen in \cref{chp:Hardware and its Habits},
main memory cannot keep up with modern CPUs, which can execute
hundreds of instructions in the time required to fetch a single variable
from memory.
CPUs therefore sport increasingly large caches, as seen back in
\cref{fig:cpu:System Hardware Architecture}, which means that
although the first load by a given CPU from a given variable will
result in an expensive \emph{cache miss} as was discussed in
\cref{sec:cpu:Cache Misses}, subsequent
repeated loads from that variable by that CPU might execute
very quickly because the initial cache miss will have loaded that
variable into that CPU's cache.

\fi

하지만, 여러 CPU 로부터의 공유된 변수들로의 빈번한 동시의 스토어를 처리할 필요
또한 생깁니다.
일관된 캐쉬 시스템에서는 캐쉬들이 특정 변수에 대한 여러 복사본을 쥐고 있다면 그
변수에 대한 모든 복사본이 같은 값을 가져야만 합니다.
이는 동시의 로드를 위해선 굉장히 잘 동작하지만 동시의 스토어에 대해서는 그렇지
않습니다: 각 스토어는 기존 값을 갖는 모든 복사본에 대해 뭔가를 해야만 하는데
(또다른 캐쉬 미스!), 유한한 빛의 속도와 원자적 물질의 본성을 생각하면, 성격
급한 소프트웨어 해커가 원하는 것보다는 더 느릴 겁니다.

\iffalse

However, it is also necessary to accommodate frequent concurrent stores
from multiple CPUs to a set of shared variables.
In cache-coherent systems, if the caches hold multiple copies of a given
variable, all the copies of that variable must have the same value.
This works extremely well for concurrent loads, but not so well for
concurrent stores:  Each store must do something about all
copies of the old value (another cache miss!), which, given the finite
speed of light and the atomic nature of matter, will be slower
than impatient software hackers would like.

\fi

\begin{figure}[tb]
\centering
\resizebox{2.5in}{!}{\includegraphics{memorder/SystemArchSB}}
\caption{System Architecture With Store Buffers}
\label{fig:memorder:System Architecture With Store Buffers}
\end{figure}

따라서 CPU 들은
\cref{fig:memorder:System Architecture With Store Buffers} 에 보인 것처럼
스토어 버퍼를 사용합니다.
특정 CPU 가 해당 CPU 의 캐쉬에 존재하지 않는 변수에 스토어를 할 때, 그 새 값은
해당 CPU 의 스토어 버퍼에 위치해집니다.
그러면 CPU 는 이 스토어가 다른 CPU 들의 캐쉬에 있는 변수들의 기존 값들 모두와
뭔가를 할동안 기다리지 않고 곧바로 다음 명령을 수행할 수 있습니다.

\iffalse

CPUs therefore come equipped with store buffers, as shown in
\cref{fig:memorder:System Architecture With Store Buffers}.
When a given CPU stores to a variable
not present in that CPU's cache, then the new value
is instead placed in that CPU's store buffer.
The CPU can then proceed immediately, without having to wait for the
store to do something about all the old values of that variable
residing in other CPUs' caches.

\fi

\begin{figure}[tb]
\centering
\resizebox{2.4in}{!}{\includegraphics{cartoons/r-2014-Out-of-order}}
\caption{CPUs Can Do Things Out of Order}
\ContributedBy{Figure}{fig:memorder:CPUs Can Do Things Out of Order}{Melissa Broussard}
\end{figure}

스토어 버퍼가 성능을 크게 향상시킬 수 있지만, 이는 명령들과 메모리 참조가
알맞지 않은 순서로 수행될 수 있게 하는데, 이는 결국
\cref{fig:memorder:CPUs Can Do Things Out of Order} 에 보인 것처럼 상당한
혼란을 야기할 수 있습니다.

\iffalse

Although store buffers can greatly increase performance, they can cause
instructions and memory references to execute out of order, which can
in turn cause serious confusion, as fancifully illustrated in
\cref{fig:memorder:CPUs Can Do Things Out of Order}.

\fi

\begin{table*}[tbp]
\rowcolors{6}{}{lightgray}
\renewcommand*{\arraystretch}{1.1}
\small
\centering\OneColumnHSpace{-0.1in}
\begin{tabular}{rllllll}
	\toprule
	& \multicolumn{3}{c}{CPU 0} & \multicolumn{3}{c}{CPU 1} \\
	\cmidrule(l){2-4} \cmidrule(l){5-7}
	& Instruction & Store Buffer & Cache &
		Instruction & Store Buffer & Cache \\
	\cmidrule{1-1} \cmidrule(l){2-4} \cmidrule(l){5-7}
	1 & (Initial state) & & \tco{x1==0} &
		(Initial state) & & \tco{x0==0} \\
	2 & \tco{x0 = 2;} & \tco{x0==2} & \tco{x1==0} &
		\tco{x1 = 2;} & \tco{x1==2} & \tco{x0==0} \\
	3 & \tco{r2 = x1;} (0) & \tco{x0==2} & \tco{x1==0} &
		\tco{r2 = x0;} (0) & \tco{x1==2} & \tco{x0==0} \\
	4 & (Read-invalidate) & \tco{x0==2} & \tco{x0==0} &
		(Read-invalidate) & \tco{x1==2} & \tco{x1==0} \\
	5 & (Finish store) & & \tco{x0==2} &
		(Finish store) & & \tco{x1==2} \\
	\bottomrule
\end{tabular}
\caption{Memory Misordering: Store-Buffering Sequence of Events}
\label{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}
\end{table*}

특히, 스토어 버퍼는
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}
에 보인 것과 같은 메모리 순서 잘못잡기를 일으킵니다.
\Cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}
가 이 잘못된 순서잡기를 일으키는 단계를 보입니다.
첫번째 열은 최초 상태를 보이는데, CPU~0 는 자신의 캐쉬에 \co{x1} 을 갖고 CPU~1
은 자신의 캐쉬에 \co{x0} 를 갖는데 두 변수 모두 값 0을 갖습니다.
\begin{fcvref}[ln:formal:C-SB+o-o+o-o:whole]
두번째 열은 각 CPU 의 스토어
(\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test} 의
\clnref{st0,st1}) 로 인한 상태 변화를 보입니다.
어느 CPU 도 캐쉬 내에 스토어의 대상 변수를 갖지 않으므로, 두 CPU 는 각자의
스토어를 각자의 스토어 버퍼에 저장해 둡니다.
\end{fcvref}

\iffalse

In particular, store buffers cause the memory misordering
illustrated by
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}.
\Cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}
shows the steps leading to this misordering.
Row~1 shows the initial state, where CPU~0 has \co{x1} in its cache
and CPU~1 has \co{x0} in its cache, both variables having a value of zero.
\begin{fcvref}[ln:formal:C-SB+o-o+o-o:whole]
Row~2 shows the state change due to each CPU's store (\clnref{st0,st1} of
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}).
Because neither CPU has the stored-to variable in its cache, both CPUs
record their stores in their respective store buffers.
\end{fcvref}

\fi

\QuickQuiz{
	기다려요!!!
	\Cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}
	의 두번째 열에서 \co{x0} 와 \co{x1} 둘 다 동시에 두 값, 즉 0 과 2를
	갖습니다.
	이게 어떻게 동작할 수 있죠???

	\iffalse

	But wait!!!
	On row~2 of
	\cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}
	both \co{x0} and \co{x1} each have two values at the same time,
	namely zero and two.
	How can that possibly work???

	\fi

}\QuickQuizAnswer{
	일을 간단하게 만들어주는 캐쉬 일관성 프로토콜이 아랫단에 있는데,
	\cref{sec:app:whymb:Cache-Coherence Protocols}
	에서 다뤄졌습니다.
	하지만 동시에 두개의 값을 갖는 변수가 신기하다면,
	\cref{sec:memorder:Variables With Multiple Values} 까지 기다리세요!

	\iffalse

	There is an underlying cache-coherence protocol that straightens
	things out, which are discussed in
	\cref{sec:app:whymb:Cache-Coherence Protocols}.
	But if you think that a given variable having two values at
	the same time is surprising, just wait until you get to
	\cref{sec:memorder:Variables With Multiple Values}!

	\fi

}\QuickQuizEnd

\begin{fcvref}[ln:formal:C-SB+o-o+o-o:whole]
세번째 열은 두개의 로드
(\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test} 의
\clnref{ld0,ld1}) 을 보입니다.
각 CPU 에 의해 읽혀지는 변수는 각 CPU 의 캐쉬에 있어서, 각 로드는 즉시 캐쉬
내의 값을 리턴하는데, 그 값은 두 경우 모두 0입니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-SB+o-o+o-o:whole]
Row~3 shows the two loads (\clnref{ld0,ld1} of
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}).
Because the variable being loaded by each CPU is in that CPU's cache,
each load immediately returns the cached value, which in both cases
is zero.
\end{fcvref}

\fi

하지만 CPU 의 일은 끝나지 않았습니다: 금방이든 나중이든, 그것들은 각자의 스토어
버퍼를 비워야만 합니다.
캐쉬는 \emph{캐쉬라인} 이라 불리는 상대적으로 큰 블록 단위로 데이터를 옮기므로,
그리고 각 캐쉬라인은 여러 변수를 담을 수 있으므로, 각 CPU 는 자신의 스토어 버퍼
내에 있는 변수에 연관된 캐쉬라인의 부분을 업데이트 할 수 있게끔, 그러나 해당
캐쉬라인의 다른 부분을 망치지 않게끔 자신의 캐쉬에 해당 캐쉬라인을 가져야만
합니다.
각 CPU 는 또한 해당 캐쉬라인이 다른 CPU 의 캐쉬에 존재하지 않음을 보장해야
하는데, 이를 위해 읽기 무효화 (read invalidation) 오퍼레이션이 사용됩니다.
네번째 열에서 보인 것처럼, 두 읽기 무효화 오퍼레이션이 완료된 후, 두 CPU 는
캐쉬라인을 주고받아서, CPU~0 의 캐쉬는 이제 \co{x0} 를 가지고 있고 CPU~1 의
캐쉬는 \co{x1} 을 가지고 있게 됩니다.
이 두 변수가 새 집에 일단 도착하면, 각 CPU 는 각자의 스토어 버퍼를 연관된 캐쉬
라인으로 비워낼 수 있어서, 각 변수를 다섯번째 열에 보인 최종 값으로 만듭니다.

\iffalse

But the CPUs are not done yet: Sooner or later, they must empty their
store buffers.
Because caches move data around in relatively large blocks called
\emph{cachelines}, and because each cacheline can hold several
variables, each CPU must get the cacheline into its own cache so
that it can update the portion of that cacheline corresponding
to the variable in its store buffer, but without disturbing any
other part of the cacheline.
Each CPU must also ensure that the cacheline is not present in any other
CPU's cache, for which a read-invalidate operation is used.
As shown on row~4, after both read-invalidate operations complete,
the two CPUs have traded cachelines, so that CPU~0's cache now contains
\co{x0} and CPU~1's cache now contains \co{x1}.
Once these two variables are in their new homes, each CPU can flush
its store buffer into the corresponding cache line, leaving each
variable with its final value as shown on row~5.

\fi

\QuickQuiz{
	하지만 그 값들은 캐쉬에서 메인 메모리로도 비워져야 하지 않나요?

	\iffalse

	But don't the values also need to be flushed from the cache
	to main memory?

	\fi

}\QuickQuizAnswer{
	놀라울 수 있지만, 꼭 그렇진 않습니다!
	일부 시스템에서는 그 두 변수가 무척 많이 사용된다면, 그것들은 CPU 들의
	캐쉬들 사이에서만 오갈뿐, 메인 메모리에는 결코 도착하지 않을 수도
	있습니다.

	\iffalse

	Perhaps surprisingly, not necessarily!
	On some systems,
	if the two variables are being used heavily, they might
	be bounced back and forth between the CPUs' caches and never
	land in main memory.

	\fi

}\QuickQuizEnd

요약하자면, 스토어 버퍼는 CPU 들이 스토어 명령을 효율적으로 처리할 수 있게 하기
위해 필요하지만, 그게 반직관적인 메모리 순서 잘못잡기를 초래할 수 있습니다.

하지만 여러분의 알고리즘이 정말로 메모리 참조가 순서잡히기를 필요로 한다면 뭘
할겁니까?
예를 들어, 여러분이 하나는 드라이버가 수행 중인지 말하고 다른 하나는 그
드라이버를 위해 대기중인 요청이 있는지 말하는 두개의 플래그를 사용해 드라이버와
통신하려 한다고 생각해 봅시다.
요청자는 요청 대기 플래그를 먼저 올리고, 이어서 드라이버 수행중 플래그를
검사해야 하며, 필요하면 그 드라이버를 깨워야 합니다.
드라이버는 모든 대기중 요청을 처리하고 나면, 드라이버 수행중 플래그를 내리고
재시작 되어야 하는지 보기 위해 요청 대기중 플래그를 검사해야 합니다.
이 매우 합리적인 방법은 하드웨어가 스토어와 로드를 순서대로 처리함을 어떻게든
보장하지 않고서는 동작하지 않습니다.
이게 다음 섹션의 주제입니다.

\iffalse

In summary, store buffers are needed to allow CPUs to handle
store instructions efficiently, but they can result in
counter-intuitive memory misordering.

But what do you do if your algorithm really needs its memory
references to be ordered?
For example, suppose that you are communicating with a driver using
a pair of flags, one that says whether or not the driver is running
and the other that says whether there is a request pending for that
driver.
The requester needs to set the request-pending flag, then check
the driver-running flag, and if false, wake the driver.
Once the driver has serviced all the pending requests that it knows about,
it needs to clear its driver-running flag, then check the request-pending
flag to see if it needs to restart.
This very reasonable approach cannot work unless there is some way
to make sure that the hardware processes the stores and loads in order.
This is the subject of the next section.

\fi

\subsection{How to Force Ordering?}
\label{sec:memorder:How to Force Ordering?}

\emph{메모리 배리어} (예를 들어, 리눅스 커널의 \co{smp_mb()}) 를 사용해 순서의
환상을 지키는데 필요한 컴파일러 지시어와 동기화 기능 (예를 들어 락킹과 RCU) 이
존재함이 드러났습니다.
이 메모리 배리어들은
\ARM, \Power{}, Itanium, 그리고 Alpha 에서와 같이 명시적 명령일 수 있고, x86
에서 종종 그런 것처럼 다른 명령에 내포될 수도 있습니다.
이런 표준 동기화 기능은 순서의 환상을 지키므로, 여러분이 가장 쉽게 일을 끝내는
방법은 그저 이 기능들을 사용하고 이 섹션은 그만 읽는 겁니다.

\iffalse

It turns out that there are compiler directives and synchronization
primitives (such as locking and RCU) that are responsible for maintaining
the illusion of ordering through use of \emph{memory barriers} (for
example, \co{smp_mb()} in the Linux kernel).
These memory barriers can be explicit instructions, as they are on
\ARM, \Power{}, Itanium, and Alpha, or they can be implied by other instructions,
as they often are on x86.
Since these standard synchronization primitives preserve the illusion of
ordering, your path of least resistance is to simply use these primitives,
thus allowing you to stop reading this section.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-SB+o-mb-o+o-mb-o@whole.fcv}
\caption{Memory Ordering: Store-Buffering Litmus Test}
\label{lst:memorder:Memory Ordering: Store-Buffering Litmus Test}
\end{listing}

그러나, 여러분이 그 동기화 기능들 자체를 구현해야 한다면, 또는 여러분이 메모리
순서잡기가 어떻게 동작하는지 이해하는데 관심 있다면, 계속 읽으세요!
이 여정의 첫번째 정류장은
\cref{lst:memorder:Memory Ordering: Store-Buffering Litmus Test}
(\path{C-SB+o-mb-o+o-mb-o.litmus}) 인데, 여기선 \co{P0()} 와 \co{P1()} 의
스토어와 로드 사이에 리눅스 커널 전체 메모리 배리어인 \co{smp_mb()} 를 놓는다는
점 외에는
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test} 와
동일합니다.
이 배리어들은 제 x86 랩톱에서 100,000,000 회 시도 끝에 일어나는 반직관적 결과를
막습니다.
흥미롭게도, 이 배리어들로 인해 더해진 오버헤드는 두 로드가 값 2를 리턴하는
올바른 결과를 800,000 회 넘게 일어나게 하는데, 배리어가 없는
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test} 에서의 167
회와 상당히 다른 결과입니다.

\iffalse

However, if you need to implement the synchronization primitives
themselves, or if you are simply interested in understanding how memory
ordering works, read on!
The first stop on the journey is
\cref{lst:memorder:Memory Ordering: Store-Buffering Litmus Test}
(\path{C-SB+o-mb-o+o-mb-o.litmus}),
which places an \co{smp_mb()} Linux-kernel full memory barrier between
the store and load in both \co{P0()} and \co{P1()}, but is otherwise
identical to
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}.
% Test C-SB+o-mb-o+o-mb-o Allowed
% Histogram (3 states)
% 49553298:>0:r2=2; 1:r2=0;
% 49636449:>0:r2=0; 1:r2=2;
% 810253:>0:r2=2; 1:r2=2;
% No
These barriers prevent the counter-intuitive outcome from happening
on 100,000,000 trials on my x86 laptop.
Interestingly enough, the added overhead due to these barriers causes the
legal outcome where both loads return the value two to happen more
than 800,000 times, as opposed to only 167 times for the
barrier-free code in
\cref{lst:memorder:Memory Misordering: Store-Buffering Litmus Test}.

\fi

\begin{table*}[tbp]
\rowcolors{6}{}{lightgray}
\renewcommand*{\arraystretch}{1.1}
\small
\centering\OneColumnHSpace{-0.1in}
\begin{tabular}{rllllll}
	\toprule
	& \multicolumn{3}{c}{CPU 0} & \multicolumn{3}{c}{CPU 1} \\
	\cmidrule(l){2-4} \cmidrule(l){5-7}
	& Instruction & Store Buffer & Cache &
		Instruction & Store Buffer & Cache \\
	\cmidrule{1-1} \cmidrule(l){2-4} \cmidrule(l){5-7}
	1 & (Initial state) & & \tco{x1==0} &
		(Initial state) & & \tco{x0==0} \\
	2 & \tco{x0 = 2;} & \tco{x0==2} & \tco{x1==0} &
		\tco{x1 = 2;} & \tco{x1==2} & \tco{x0==0} \\
	3 & \tco{smp_mb();} & \tco{x0==2} & \tco{x1==0} &
		\tco{smp_mb();} & \tco{x1==2} & \tco{x0==0} \\
	4 & (Read-invalidate) & \tco{x0==2} & \tco{x0==0} &
		(Read-invalidate) & \tco{x1==2} & \tco{x1==0} \\
	5 & (Finish store) & & \tco{x0==2} &
		(Finish store) & & \tco{x1==2} \\
	6 & \tco{r2 = x1;} (2) & & \tco{x1==2} &
		\tco{r2 = x0;} (2) & & \tco{x0==2} \\
	\bottomrule
\end{tabular}
\caption{Memory Ordering: Store-Buffering Sequence of Events}
\label{tab:memorder:Memory Ordering: Store-Buffering Sequence of Events}
\end{table*}

이 배리어들은 순서 규칙에 중요한 효과를 일으키는데,
\cref{tab:memorder:Memory Ordering: Store-Buffering Sequence of Events} 에 보인
것과 같습니다.
처음 두 열은
\cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}
에 보인 것과 같지만, 그리고 세번째 열의 \co{smp_mb()} 명령은 상태를 바꾸지
않지만, 그것들은 스토어들이 (네번째와 다섯번째 열) 로드 (여섯번째 열) 이전에
완료되게 해서
\cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}
에 보인 반직관적 결과를 막습니다.
변수 \co{x0} 와 \co{x1} 은 여전히 두번째 열에서 두개 이상의 값을 갖지만 앞서
약속된대로, \co{smp_mb()} 호출은 결과적으로 일을 간단하게 만들어줌을 유의하시기
바랍니다.

\co{smp_mb()} 와 같은 전체 배리어가 굉장히 강한 순서 보장을 제공하지만, 그
위력은 하드웨어와 컴파일러 최적화 측면에서는 높은 비용으로 제공됩니다.
매우 많은 상황이 훨씬 저렴한 메모리 순서규칙 명령을 사용하는, 또는 아예 메모리
순서 강제 명령을 사용하지 않는 훨씬 완화된 순서 규칙 보장으로 처리될 수
있습니다.

\iffalse

These barriers have a profound effect on ordering, as can be seen in
\cref{tab:memorder:Memory Ordering: Store-Buffering Sequence of Events}.
Although the first two rows are the same as in
\cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}
and although the \co{smp_mb()} instructions on row~3
do not change state
in and of themselves, they do cause the stores to complete
(rows~4 and~5) before the
loads (row~6), which rules out the counter-intuitive outcome shown in
\cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events}.
Note that variables \co{x0} and \co{x1} each still have more than one
value on row~2, however, as promised earlier, the \co{smp_mb()}
invocations straighten things out in the end.

Although full barriers such as \co{smp_mb()} have extremely strong
ordering guarantees, their strength comes at a high price in terms
of foregone hardware and compiler optimizations.
A great many situations can be handled with much weaker ordering guarantees
that use much cheaper memory-ordering instructions, or, in some case, no
memory-ordering instructions at all.

\fi

\begin{table*}[tbp]
\small
\centering\OneColumnHSpace{-0.7in}
\renewcommand*{\arraystretch}{1.1}
\rowcolors{7}{lightgray}{}
\begin{tabular}{lcccccccccccc}\toprule
	& & \multicolumn{4}{c}{Prior Ordered Operation} &
		\multicolumn{7}{c}{Subsequent Ordered Operation} \\
	\cmidrule(l){3-6} \cmidrule(l){7-13}
	Operation Providing Ordering & C &
		Self & R & W & RMW & Self & R & W & DR & DW & RMW & SV \\
	\cmidrule(r){1-1} \cmidrule{2-2} \cmidrule(l){3-6} \cmidrule(l){7-13}
	Store, for example, \tco{WRITE_ONCE()} &  &
		   Y &   &   &     &      &   &   &    &    &     &  Y \\
	Load, for example, \tco{READ_ONCE()} &  &
		   Y &   &   &     &      &   &   &  Y &  Y &     &  Y \\
	\tco{_relaxed()} RMW operation &  &
		   Y &   &   &     &      &   &   &  Y &  Y &     &  Y \\
	\tco{*_dereference()} &  &
		   Y &   &   &     &      &   &   &  Y &  Y &     &  Y \\
	Successful \tco{*_acquire()} &   &
		   R &   &   &     &      & Y & Y &  Y &  Y &   Y &  Y \\
	Successful \tco{*_release()} & C &
		     & Y & Y &   Y &    W &   &   &    &    &     &  Y \\
	\tco{smp_rmb()} &   &
		     & Y &   &   R &      & Y &   &  Y &    &   R &    \\
	\tco{smp_wmb()} &   &
		     &   & Y &   W &      &   & Y &    &  Y &   W &    \\
	\tco{smp_mb()} and \tco{synchronize_rcu()} & CP &
		     & Y & Y &   Y &      & Y & Y &  Y &  Y &   Y &    \\
	Successful full-strength non-\tco{void} RMW & CP &
		   Y & Y & Y &   Y &    Y & Y & Y &  Y &  Y &   Y &  Y \\
	\tco{smp_mb__before_atomic()} & CP &
		     & Y & Y &   Y &      & a & a & a  & a  &   Y &    \\
	\tco{smp_mb__after_atomic()} & CP &
		     & a & a &   Y &      & Y & Y &  Y &  Y &   Y &    \\
	\bottomrule
\end{tabular}

\vspace{5pt}\hfill
\framebox[\width]{\footnotesize\setlength{\tabcolsep}{3pt}
\rowcolors{1}{}{}
\begin{tabular}{lrl}
	Key:	& C: & Ordering is cumulative \\
		& P: & Ordering propagates \\
		& R: & Read, for example, \tco{READ_ONCE()}, or read portion of RMW \\
		& W: & Write, for example, \tco{WRITE_ONCE()}, or write portion of RMW \\
		& Y: & Provides the specified ordering \\
		& a: & Provides specified ordering given intervening RMW atomic operation \\
		& DR: & Dependent read (address dependency, \cref{sec:memorder:Address Dependencies}) \\
		& DW: & Dependent write (address, data, or control dependency, \crefrange{sec:memorder:Address Dependencies}{sec:memorder:Control Dependencies}) \\
		& RMW: & Atomic read-modify-write operation \\
		& Self: & Orders self, as opposed to accesses both before
			  and after \\
		& SV: & Orders later accesses to the same variable \\
	\multicolumn{3}{l}{\emph{Applies to Linux kernel v4.15 and later.}} \\
\end{tabular}
}\OneColumnHSpace{-0.9in}
\caption{Linux-Kernel Memory-Ordering Cheat Sheet}
\label{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
\end{table*}

\Cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
는 리눅스 커널의 순서규칙 기능과 그것들의 보장사항에 대한 요약입니다.
각 열은 순서 규칙을 제공할수도 안할수도 있는 기능 또는 기능들의 카테고리를
보이며, ``Prior Ordered Operation'' 과 ``Subsequent Ordered Operation'' 로
라벨링 된 행은 그에 대해 순서가 잡힐수도 또는 안잡힐 수도 있는 오퍼레이션들을 
보입니다.
``Y'' 를 포함하는 칸은 무조건적으로 순서 규칙이 제공됨을 나타내며 다른 글자들은
순서규칙이 부분적으로 또는 조건적으로 제공됨을 나타냅니다.
빈 칸은 순서규칙이 제공되지 않음을 나타냅니다.

``Store'' 열은 atomic RMW 오퍼레이션의 스토어 부분도 포함합니다.
그에 더해, ``Load'' 열은 성공한 값을 반환하는 \co{_relaxed()} RMW 어토믹
오퍼레이션의 로드 부분을 포함하는데 결합된 ``\co{_relaexed()} RMW operation''
열은 값을 반환하는 경우에 대한 간편한 결합된 레퍼런스를 제공합니다.
성공하지 못한 값을 반환하는 atomic RMW 오퍼레이션을 수행하는 CPU 는 연관된
변수를 모든 다른 CPU 의 캐쉬에서 무효화 시켜야만 합니다.
따라서, 성공하지 못한 값을 반환하는 atomic RMW 오퍼레이션은 스토어의 속성을
많이 갖게 되는데, 이는 ``\co{_relaxed()} RMW operation'' 열은 성공하지 못한
값을 반환하는 atomic RMW 오퍼레이션에도 적용됨을 의미합니다.

\iffalse

\Cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
provides a cheatsheet of the Linux kernel's ordering primitives and their
guarantees.
Each row corresponds to a primitive or category of primitives that might
or might not provide ordering, with the columns labeled
``Prior Ordered Operation'' and ``Subsequent Ordered Operation''
being the operations that might (or might not) be ordered against.
Cells containing ``Y'' indicate that ordering is supplied unconditionally,
while other characters indicate that ordering is supplied only partially or
conditionally.
Blank cells indicate that no ordering is supplied.

The ``Store'' row also covers the store portion of an atomic RMW operation.
In addition, the ``Load'' row covers the load
component of a successful value-returning \co{_relaxed()} RMW atomic
operation, although the combined ``\co{_relaxed()} RMW operation''
line provides a convenient combined reference in the value-returning case.
A CPU executing unsuccessful value-returning atomic RMW operations must
invalidate the corresponding variable from all other CPUs' caches.
Therefore, unsuccessful value-returning atomic RMW operations have many
of the properties of a store, which means that the ``\co{_relaxed()}
RMW operation'' line also applies to unsuccessful value-returning atomic
RMW operations.

\fi

\co{*_acquire} 열은 \co{smp_load_acquire()}, \co{cmpxchg_acquire()},
\co{xchg_acquire()}, 등의 것을 포함합니다; \co{*_release} 열은
\co{smp_store_release()}, \co{rcu_assign_pointer()}, \co{cmpxchg_release()},
\co{xchg_release()} 등을 포함합니다;
``Successful full-strength non-\co{void} RMW'' 열은 \co{atomic_add_return()},
\co{atomic_add_unless()}, \co{atomic_dec_and_test()}, \co{cmpxchg()},
\co{xchg()} 등을 포함합니다.
``Successful'' 이란 단어는 \co{atomic_add_unless()}, \co{cmpxchg_acquire()},
그리고 \co{cmpxchg_release()} 같은, 실패를 파악했을 때에는 메모리나 순서에 어떤
영향도 끼치지 않는 기능들에 적용되는데, 앞의 ``\co{_relaxed()} RMW operation''
열에서 나타내진 것과 같습니다.

``C'' 행은 누적성과 전파성을 나타내는데,
\cref{sec:memorder:Cumulativity,sec:memorder:Propagation} 에서 설명된 바와
같습니다.
최대 두개의 쓰레드만 관여될 때에는 이 행은 무시될 수 있습니다.

\iffalse

The \co{*_acquire} row covers \co{smp_load_acquire()},
\co{cmpxchg_acquire()}, \co{xchg_acquire()}, and so on; the \co{*_release}
row covers \co{smp_store_release()}, \co{rcu_assign_pointer()},
\co{cmpxchg_release()}, \co{xchg_release()}, and so on; and
the ``Successful full-strength non-\co{void} RMW'' row covers
\co{atomic_add_return()}, \co{atomic_add_unless()}, \co{atomic_dec_and_test()},
\co{cmpxchg()}, \co{xchg()}, and so on.
The ``Successful'' qualifiers apply to primitives such as
\co{atomic_add_unless()}, \co{cmpxchg_acquire()}, and \co{cmpxchg_release()},
which have no effect on either memory or on ordering when they indicate
failure, as indicated by the earlier ``\co{_relaxed()} RMW operation'' row.

Column ``C'' indicates cumulativity and propagation, as explained in
\cref{sec:memorder:Cumulativity,sec:memorder:Propagation}.
In the meantime, this column can usually be ignored when there
are at most two threads involved.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	\Cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
	의 열들은 꽤 무작위적이고 혼란스럽게 느껴지네요.
	이 표의 개념적 기반이 있다면 무엇이죠???

	\iffalse

	The rows in
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
	seem quite random and confused.
	Whatever is the conceptual basis of this table???

	\fi

}\QuickQuizAnswerB{
	이 열들은 대략적으로 전력과 오버헤드를 증가시키는 하드웨어 메커니즘에
	연관됩니다.

	\co{WRITE_ONCE()} 열은 단일 변수로의 액세스는 항상 완벽하게
	순서잡힌다는 사실을 보이는데, ``SV'' 행으로 나타내진 바와 같습니다.
	여러 변수로의 액세스에 대한 순서를 제공하는 모든 다른 오퍼레이션들도 이
	같은-변수 순서규칙을 제공함을 알아두십시오.

	\co{READ_ONCE()} 열은 (2021년 기준으로) 컴파일러와 CPU 는 사용자에게
	보이는 투기적 스토어를 사용하지 않아서 앞의 로드에 주소, 데이터, 또는
	수행 측면에서 종속적인 모든 스토어는 이 로드가 완료된 후에 일어나는
	것이 보장됩니다.
	그러나, 이 보장은 이 의존성이
	\cref{sec:memorder:Address- and Data-Dependency Difficulties,%
	sec:memorder:Control-Dependency Calamities}
	에서 설명된 것처럼 주의 깊게 구성되었을 것을 가정합니다.

	\iffalse

	The rows correspond roughly to hardware mechanisms of increasing
	power and overhead.

	The \co{WRITE_ONCE()} row captures the fact that accesses to
	a single variable are always fully ordered, as indicated by
	the ``SV'' column.
	Note that all other operations providing ordering against accesses
	to multiple variables also provide this same-variable ordering.

	The \co{READ_ONCE()} row captures the fact that (as of 2021) compilers
	and CPUs do not indulge in user-visible speculative stores, so that
	any store whose address, data, or execution depends on a prior load
	is guaranteed to happen after that load completes.
	However, this guarantee assumes that these dependencies have
	been constructed carefully, as described in
	\cref{sec:memorder:Address- and Data-Dependency Difficulties,%
	sec:memorder:Control-Dependency Calamities}.

	\fi

	``\co{_relaxed()} RMW operation'' 열은 값을 반환하는 \co{_relaxed()}
	RMW 가 각각 \co{READ_ONCE()} 와 \co{WRITE_ONCE()} 만큼 훌륭한 로드와
	스토어를 한다는 사실을 보입니다.

	\co{*_dereference()} 열은 \co{rcu_dereference()} 와 그 친구들에 의해
	제공되는 주소와 데이터 종속성 순서규칙을 보입니다.
	다시 말하지만 이 종속성은
	\cref{sec:memorder:Address- and Data-Dependency Difficulties} 에서
	설명한 것처럼 주의깊게 구성되어야 합니다.

	``Successful \co{*_acquire()}'' 열은 많은 CPU 가 특별한 ``acquire''
	형태의 로드와 atomic RMW 인스트럭션을 가지고 있으며 많은 다른 CPU 는
	앞의 로드를 뒤의 로드와 스토어에 대해 순서잡는 가벼운 메모리 배리어
	명령을 가지고 있음을 보입니다.

	\iffalse

	The ``\co{_relaxed()} RMW operation'' row captures the fact
	that a value-returning \co{_relaxed()} RMW has done a load and a
	store, which are every bit as good as a \co{READ_ONCE()} and a
	\co{WRITE_ONCE()}, respectively.

	The \co{*_dereference()} row captures the address and data
	dependency ordering provided by \co{rcu_dereference()} and friends.
	Again, these dependencies must been constructed carefully,
	as described in
	\cref{sec:memorder:Address- and Data-Dependency Difficulties}.

	The ``Successful \co{*_acquire()}'' row captures the fact that many
	CPUs have special ``acquire'' forms of loads and of atomic RMW
	instructions,
	and that many other CPUs have lightweight memory-barrier
	instructions that order prior loads against subsequent loads
	and stores.

	\fi

	``Successful \co{*_release()}'' 열은 많은 CPU 가 특별한 ``release''
	형태의 스토어와 atomic RMW 인스트럭션을 가지며 많은 다른 CPU 들은 앞의
	로드와 스토어를 뒤따르는 스토어에 대해 순서잡는 가벼운 메모리 배리어
	명령을 가짐을 보입니다.

	\co{smp_rmb()} 열은 많은 CPU 가 앞의 로드를 뒤따르는 로드에 대해
	순서잡는 가벼운 메모리 배리어 명령을 가짐을 보입니다.
	비슷하게, \co{smp_wmb()} 열은 많은 CPU 가 앞의 스토어를 뒤따르는
	스토어에 대해 순서 잡는 가벼운 메모리 배리어 명령을 가짐을 보입니다.

	지금까지 설명한 순서 오퍼레이션들 중 어느 것도 앞의 스토어가 뒤따르는
	로드에 대해 순서를 잡을 것을 요구하지 않는데, 이는 이 오퍼레이션은 실제
	주요 목적은 앞의 스토어를 뒤따르는 로드에 대해 순서를 바꾸기 위함인
	스토어 버퍼와 상관할 필요가 없음을 말합니다.
	이 오퍼레이션의 가벼움은 정확히 스토어 버퍼에 상관하지 않는다는 정책
	덕입니다.
	그러나, 앞에서 이야기 되었듯 앞의 스토어가 뒤의 스토어와 순서 바뀌는
	것을 방지하기 위해 스토어 버퍼와 상관해야 할때가 생기는데, 이게 이 표의
	나머지 열을 필요하게 합니다.

	\iffalse

	The ``Successful \co{*_release()}'' row captures the fact that many
	CPUs have special ``release'' forms of stores and of atomic RMW
	instructions, and that many other CPUs have lightweight memory-barrier
	instructions that order prior loads and stores against
	subsequent stores.

	The \co{smp_rmb()} row captures the fact that many CPUs have
	lightweight memory-barrier instructions that order prior loads against
	subsequent loads.
	Similarly,
	the \co{smp_wmb()} row captures the fact that many CPUs have
	lightweight memory-barrier instructions that order prior stores against
	subsequent stores.

	None of the ordering operations thus far require prior stores to be
	ordered against subsequent loads, which means that these operations
	need not interfere with store buffers, whose main purpose in life
	is in fact to reorder prior stores against subsequent loads.
	The lightweight nature of these operations is precisely due to
	their policy of store-buffer non-interference.
	However, as noted earlier, it is sometimes necessary to interfere
	with the store buffer in order to prevent prior stores from being
	reordered against later stores, which brings us to the remaining
	rows in this table.

	\fi

	\co{smp_mb()} 열은 Itanium 은 예외지만 대부분의 플랫폼에서 존재하는
	전체 메모리 배리어에 연관됩니다.
	그러나 Itanium 에서조차 \co{smp_mb()} 는
	\cref{sec:memorder:Itanium} 에서 이야기 되듯 \co{READ_ONCE()} 와
	\co{WRITE_ONCE()} 에 대해서는 완전한 순서를 제공합니다.

	``Successful full-strength non-\co{void} RMW'' 열은 일부 플랫폼에서
	(x86 등) atomic RMW 명령은 앞과 뒤에 모두 완전한 순서를 제공함을
	보입니다.
	따라서 리눅스 커널은 full-strength non-\co{void} atomic RMW
	오퍼레이션이 성공했을 때에는 완전한 순서를 제공할 것을 필요로 합니다.
	(Full-strength atomic RMW operation 의 이름은 \co{_relaxed},
	\co{_acquire}, 또는 \co{_release} 로 끝나지 않습니다.)
	앞에서 이야기 되었듯, 이 오퍼레이션이 성공하지 못하는 경우는
	``\co{_relaxed()} RMW operation'' 열에서 다루어집니다.

	\iffalse

	The \co{smp_mb()} row corresponds to the full memory barrier
	available on most platforms, with Itanium being the exception
	that proves the rule.
	However, even on Itanium, \co{smp_mb()} provides full ordering
	with respect to \co{READ_ONCE()} and \co{WRITE_ONCE()},
	as discussed in \cref{sec:memorder:Itanium}.

	The ``Successful full-strength non-\co{void} RMW'' row captures
	the fact that on some platforms (such as x86) atomic RMW instructions
	provide full ordering both before and after.
	The Linux kernel therefore requires that full-strength non-\co{void}
	atomic RMW operations provide full ordering in cases where these
	operations succeed.
	(Full-strength atomic RMW operation's names do not end in
	\co{_relaxed}, \co{_acquire}, or \co{_release}.)
	As noted earlier, the case where these operations do not succeed
	is covered by the ``\co{_relaxed()} RMW operation'' row.

	\fi

	그러나, 리눅스 커널은 \co{void} 나 \co{_relaxed()} atomic RMW
	오퍼레이션에게 어떤 순서규칙도 요구하지 않으며, 그 표준 예가
	\co{atomic_inc()} 입니다.
	따라서, 실패하는 non-\co{void} atomic RMW operation 를 포함해 이
	오퍼레이션은 앞이나 뒤의 모든 액세스에 대해 완전한 순서를 제공하기
	위해선 앞에 \co{smp_mb__before_atomic()} 를, 뒤에
	\co{smp_mb__after_atomic()} 를 배체해야 합니다.
	\co{smp_mb__before_atomic()} (또는, 비슷하게
	\co{smp_mb__after_atomic()}) 와 atomic RMW 오퍼레이션 사이에는 이 표의
	\co{smp_mb__before_atomic()} 과 \co{smp_mb__after_atomic()} 열의 ``a''
	항목으로 나타내어졌듯 어떤 순서도 제공될 이유가 없습니다.

	요약하자면, 이 표의 구조는
	\cref{chp:Hardware and its Habits} 에서 다루어진 물리 법칙에 의해
	제한되는 아랫단 하드웨어의 특성에 기반해 만들어졌습니다.
	즉, 이 표는 무작위적이지 않지만, 여러분이 혼란스러울 수는 있을 겁니다.

	\iffalse

	However, the Linux kernel does not require that either \co{void}
	or \co{_relaxed()} atomic RMW operations provide any ordering
	whatsoever, with the canonical example being \co{atomic_inc()}.
	Therefore, these operations, along with failing non-\co{void}
	atomic RMW operations may be preceded by \co{smp_mb__before_atomic()}
	and followed by \co{smp_mb__after_atomic()} to provide full
	ordering for any accesses preceding or following both.
	No ordering need be provided for accesses between the
	\co{smp_mb__before_atomic()} (or, similarly, the
	\co{smp_mb__after_atomic()}) and the atomic RMW operation, as
	indicated by the ``a'' entries on the \co{smp_mb__before_atomic()}
	and \co{smp_mb__after_atomic()} rows of the table.

	In short, the structure of this table is dictated by the
	properties of the underlying hardware, which are constrained by
	nothing other than the laws of physics, which were covered back in
	\cref{chp:Hardware and its Habits}.
	That is, the table is not random, although it is quite possible
	that you are confused.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	왜
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
	는 \co{smp_mb__after_unlock_lock()} 과 \co{smp_mb__after_spinlock()} 을
	포함하고 있지 않죠?

	\iffalse

	Why is
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
	missing \co{smp_mb__after_unlock_lock()} and
	\co{smp_mb__after_spinlock()}?

	\fi

}\QuickQuizAnswerE{
	이 두 기능은 특수한 경우를 위한 것이며
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet} 에
	들어가기엔 조금 다른 것으로 보입니다.
	\co{smp_mb__after_unlock_lock()} 기능은 락 획득 직후에 놓여질 목적으로
	만들어졌으며, 모든 CPU 가 앞의 크리티컬 섹션에서의 액세스를
	\co{smp_mb__after_unlock_lock()} 뒤의 액세스보다, 그리고 뒤의 크리티컬
	섹션의 모든 액세스보다 전에 일어난 것으로 보게끔 보장합니다.
	여기서 ``모든 CPU'' 는 그 락을 쥐고 있지 않은 CPU 들 역시 포함하며
	``앞의 크리티컬 섹션'' 은 해당 락을 위한 모든 앞의 크리티컬 섹션은
	물론이고 \co{smp_mb__after_unlock_lock()} 을 수행한 CPU 에 의해 해제된
	모든 다른 락을 위한 앞의 크리티컬 섹션까지 포함합니다.

	\co{smp_mb__after_spinlock()} 은 \co{smp_mb__after_unlock_lock()} 과
	동일한 보장사항을 제공하지만, \co{smp_mb__after_spinlock()} 을 수행한
	CPU 에 의해 수행된 다른 액세스들에 대한 추가적 시각 보장을 제공합니다.
	어떤 스토어 S 가 모든 앞의 락 획득 전에 수행되었고 어떤 로드 L 이
	\co{smp_mb__after_spinlock()} 후에 수행되었다고 하면, 모든 CPU 는 S 를
	L 전에 일어난 것으로 보게 됩니다.
	달리 말하자면, 어떤 CPU 가 스토어 S 를 수행하고, 락을 획득하고
	\co{smp_mb__after_spinlock()} 을 수행하고, 로드 L 을 수행하면, 모든 CPU
	는 S 가 L 전에 수행된 것으로 보게 됩니다.

	\iffalse

	These two primitives are rather specialized, and at present
	seem difficult to fit into
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}.
	The \co{smp_mb__after_unlock_lock()} primitive is intended to be placed
	immediately after a lock acquisition, and ensures that all CPUs
	see all accesses in prior critical sections as happening before
	all accesses following the \co{smp_mb__after_unlock_lock()}
	and also before all accesses in later critical sections.
	Here ``all CPUs'' includes those CPUs not holding that lock,
	and ``prior critical sections'' includes all prior critical sections
	for the lock in question as well as all prior critical sections
	for all other locks that were released by the same CPU that executed
	the  \co{smp_mb__after_unlock_lock()}.

	The \co{smp_mb__after_spinlock()} provides the same guarantees
	as does \co{smp_mb__after_unlock_lock()}, but also provides
	additional visibility guarantees for other accesses performed
	by the CPU that executed the \co{smp_mb__after_spinlock()}.
	Given any store S performed prior to any earlier lock acquisition
	and any load L performed after the \co{smp_mb__after_spinlock()},
	all CPUs will see S as happening before~L\@.
	In other words, if a CPU performs a store S, acquires a lock,
	executes an \co{smp_mb__after_spinlock()}, then performs a
	load L, all CPUs will see S as happening before~L\@.

	\fi

}\QuickQuizEndE
}

이 표는 요약일 뿐이며, 따라서 메모리 순서 규칙에 대한 충분한 이해를 대체할 수
없습니다.
그런 이해를 얻기 위해서 다음 섹션이 기본적인 경험적 법칙들을 일부 제공합니다.
\IfTwoColumn{\FloatBarrier}{}

\iffalse

It is important to note that this table is just a cheat sheet,
and is therefore in no way a replacement for a good understanding
of memory ordering.
To begin building such an understanding, the next section will
present some basic rules of thumb.
\IfTwoColumn{\FloatBarrier}{}

\fi

\subsection{Basic Rules of Thumb}
\label{sec:memorder:Basic Rules of Thumb}

이 섹션은 매우 많은 상황에 ``좋고 충분한'' 일부 기본적 경험적 법칙을
제공합니다.
실제로 여러분은 이 경험적 법칙 외에는 별다른 것 없이도 훌륭한 성능과 확장성을
갖는 동시성 코드를 작성할 수 있습니다.
더 잘 정리된 경험적 법칙들은
\cref{sec:memorder:Where is Memory Ordering Needed?} 에서 제공됩니다.

\iffalse

This section presents some basic rules of thumb that are ``good and
sufficient'' for a great many situations.
In fact, you could write a great deal of concurrent code having
excellent performance and scalability without needing anything more
than these rules of thumb.
More sophisticated rules of thumb will be presented in
\cref{sec:memorder:Where is Memory Ordering Needed?}.

\fi

\QuickQuiz{
	하지만 특정 프로젝트가 이 경험적 법칙에 근거해 설계되고 작성될 수
	있는지는 어떻게 하나요?

	\iffalse

	But how can I know that a given project can be designed
	and coded within the confines of these rules of thumb?

	\fi

}\QuickQuizAnswer{
	이 챕터의 나머지 부분들이 정확히 그 질문에 답변하기 위해
	만들어졌습니다!

	\iffalse

	Much of the purpose of the remainder of this chapter is
	to answer exactly that question!

	\fi

}\QuickQuizEnd

\paragraph{쓰레드는 자신의 액세스는 순서대로 보게 된다.}
이 규칙은 공유 변수로의 로드와 스토어가 각각 \co{READ_ONCE()} 과
\co{WRITE_ONCE()} 를 사용한다고 가정합니다.
그렇지 않다면, 컴파일러는 근본적으로 여러분의 코드를 휘저어 버릴 수
있으며\footnote{
	많은 컴파일러 작성자들은 이를 ``최적화'' 라 부르길 선호합니다.}
가끔은 CPU 역시 \cref{sec:memorder:Itanium} 에서 이야기된 것처럼 약간 일을
흐트러트릴 수 있습니다.

\iffalse

\paragraph{A given thread sees its own accesses in order.}
This rule assumes that loads and stores from/to shared variables use
\co{READ_ONCE()} and \co{WRITE_ONCE()}, respectively.
Otherwise, the compiler can profoundly scramble\footnote{
	Many compiler writers prefer the word ``optimize''.}
your code, and sometimes the CPU can do a bit of scrambling as well,
as discussed in \cref{sec:memorder:Itanium}.

\fi

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{memorder/memorybarrier}}
\caption{Memory Barriers Provide Conditional If-Then Ordering}
\label{fig:memorder:Memory Barriers Provide Conditional If-Then Ordering}
\end{figure}

\paragraph{순서 규칙은 조건적 if-then 규칙을 갖습니다.}
\Cref{fig:memorder:Memory Barriers Provide Conditional If-Then Ordering}
가 이 메모리 배리어를 보입니다.
두 메모리 배리어가 충분히 강력하다고 가정하고, CPU~1 의 Y1 액세스가 CPU~0 의
액세스 Y0 후에 이루어졌다면, CPU~1 의 액세스 X1 은 CPU~0 의 X0 액세스 후에
일어날 것이 보장됩니다.
어떤 메모리 배리어가 충분히 강력한지 모르겠다면, \co{smp_mb()} 가 비용이 높긴
하지만 항상 필요한 일을 해줍니다.

\iffalse

\paragraph{Ordering has conditional if-then semantics.}
\Cref{fig:memorder:Memory Barriers Provide Conditional If-Then Ordering}
illustrates this for memory barriers.
Assuming that both memory barriers are strong enough, if CPU~1's access
Y1 happens after CPU~0's access Y0, then CPU~1's access X1 is guaranteed
to happen after CPU~0's access X0.
When in doubt as to which memory barriers are strong enough, \co{smp_mb()}
will always do the job, albeit at a price.

\fi

\QuickQuiz{
	특정 사용처에 있어 어떤 메모리 배리어가 충분히 강력한지 어떻게 알 수
	있죠?

	\iffalse

	How can you tell which memory barriers are strong enough for
	a given use case?

	\fi

}\QuickQuizAnswer{
	아, 그건 대답하는데 이 챕터의 나머지 대부분이 필요할 정도로 깊은
	질문입니다.
	하지만 짧게 대답하자면 \co{smp_mb()} 가 비용이 높긴 하지만 거의 항상
	충분히 강합니다.

	\iffalse

	Ah, that is a deep question whose answer requires most of the
	rest of this chapter.
	But the short answer is that \co{smp_mb()} is almost always
	strong enough, albeit at some cost.

	\fi

}\QuickQuizEnd

\begin{fcvref}[ln:formal:C-SB+o-mb-o+o-mb-o:whole]
\Cref{lst:memorder:Memory Ordering: Store-Buffering Litmus Test}
이 그런 케이스입니다.
\Clnref{P0:mb,P1:mb} 에서의 \co{smp_mb()} 가 그 배리어로 동작하여,
\clnref{P0:st} 에서의 \co{x0} 로의 스토어는 X0 이고, \clnref{P1:st} 에서의
\co{x1} 으로의 스토어는 Y1 이며, \clnref{P1:ld} 에서의 \co{x0} 로드는 X1
입니다.
이 if-then 규칙을 단계별로 적용하면, 우린 \clnref{P1:st} 에서의 \co{x1}
스토어가 \co{P0()} 의 지역변수 \co{r2} 가 값 0으로 되어 있다면 \clnref{P0:ld}
에서의 \co{x1} 로드보다 나중에 벌어졌음을 알게 됩니다.
그러면 이 if-then 규칙은 \clnref{P1:ld} 에서의 \co{x0} 로드는 \clnref{P0:st}
에서의 \co{x0} 스토어보다 나중에 벌어질 거라 말합니다.
달리 말하자면 \co{P1()} 의 지역변수 \co{r2} 는 \co{P0()} 의 지역변수 \co{r2} 가
값 0으로 끝날 \emph{때에만} 값 2로 끝납니다.
이는 메모리 순서 규칙 보장이 절대적이 아니라 조건적이라는 지점을 강조합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-SB+o-mb-o+o-mb-o:whole]
\Cref{lst:memorder:Memory Ordering: Store-Buffering Litmus Test}
is a case in point.
The \co{smp_mb()} on \clnref{P0:mb,P1:mb} serve as the barriers,
the store to \co{x0} on \clnref{P0:st} as X0, the load from \co{x1}
on \clnref{P0:ld} as Y0, the store to \co{x1} on \clnref{P1:st} as Y1,
and the load from \co{x0} on \clnref{P1:ld} as X1.
Applying the if-then rule step by step, we know that the store to
\co{x1} on \clnref{P1:st} happens after the load from \co{x1} on \clnref{P0:ld} if
\co{P0()}'s local variable \co{r2} is set to the value zero.
The if-then rule would then state that the load from \co{x0} on
\clnref{P1:ld} happens after the store to \co{x0} on \clnref{P0:st}.
In other words,
\co{P1()}'s local variable \co{r2} is guaranteed
to end up with the value two \emph{only if}
\co{P0()}'s local variable \co{r2} ends up with the value zero.
This underscores the point that memory ordering guarantees are
conditional, not absolute.
\end{fcvref}

\fi

비록
\cref{fig:memorder:Memory Barriers Provide Conditional If-Then Ordering}
이 특별히 메모리 배리어를 언급하지만, 이 동일한 if-then 규칙이 리눅스 커널의
순서규칙 오퍼레이션 나머지에도 적용됩니다.

\iffalse

Although
\cref{fig:memorder:Memory Barriers Provide Conditional If-Then Ordering}
specifically mentions memory barriers, this same if-then rule applies
to the rest of the Linux kernel's ordering operations.

\fi

\paragraph{순서규칙 오퍼레이션은 반드시 짝을 이루어야 합니다.}
여러분이 한 쓰레드에서의 오퍼레이션을 주의깊게 순서 맞췄지만 다른 쓰레드에서는
그렇게 하지 못했다면, 거기엔 순서가 없습니다.
이 if-then 규칙이 적용되게 하려면 두 쓰레드 모두 순서를 제공해야
합니다.\footnote{
	\Cref{sec:memorder:Propagation} 에서 짝 맞추기는 사이클로 일반화 될
	겁니다.}

\iffalse

\paragraph{Ordering operations must be paired.}
If you carefully order the operations in one thread, but then fail to do
so in another thread, then there is no ordering.
Both threads must provide ordering for the if-then rule to apply.\footnote{
	In \cref{sec:memorder:Propagation}, pairing will be
	generalized to cycles.}

\fi

\paragraph{순서규칙 오퍼레이션은 거의 항상 무언가를 빠르게 만들지 않습니다.}
앞의 스토어가 메모리에 더 빠르게 비워지게 하려고 메모리 배리어를 더하고
싶어진다면, 저항하세요!
순서규칙을 더하는건 일반적으로 속도를 느리게 만듭니다.
물론,
page~\pageref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR} 의
\cref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR} 에서 보았듯 명령을
더하는게 속도를 높이는 경우도 있습니다만, 그런 경우에는 주의 깊은 벤치마킹이
필요합니다.
그리고 그럴때 조차도, \emph{여러분의} 시스템에서는 속도를 약간 향상시켰더라도,
여러분의 사용자들의 시스템에서는 상당한 속도 저하를 일으켰을 수도 있습니다.
또는 여러분의 미래의 시스템에서요.

\iffalse

\paragraph{Ordering operations almost never speed things up.}
If you find yourself tempted to add a memory barrier in an attempt
to force a prior store to be flushed to memory faster, resist!
Adding ordering usually slows things down.
Of course, there are situations where adding instructions speeds things
up, as was shown by
\cref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR} on
page~\pageref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR},
but careful benchmarking is required in such cases.
And even then, it is quite possible that although you sped things up
a little bit on \emph{your} system, you might well have slowed things
down significantly on your users' systems.
Or on your future system.

\fi

\paragraph{순서규칙 오퍼레이션은 마법이 아닙니다.}
여러분의 프로그램이 어떤 경주 조건 때문에 실패한다면, 여러분은 종종 버그를
제거하기 위해 메모리 순서규칙 오퍼레이션을 몇개 집어넣어지고 싶을 겁니다.
그보다 훨씬 나은 반응은 더 높은 단계의 기능들을 주의깊게 설계된 형식으로
사용하는 겁니다.
동시성 프로그래밍에 있어서, 버그가 존재하지 않게끔 설계를 하는게 버그 확률을
낮추기 위해 해킹을 하는 것보다 거의 항상 낫습니다.

\iffalse

\paragraph{Ordering operations are not magic.}
When your program is failing due to some race condition, it is often
tempting to toss in a few memory-ordering operations in an attempt
to barrier your bugs out of existence.
A far better reaction is to use higher-level primitives in a carefully
designed manner.
With concurrent programming, it is almost always better to design your
bugs out of existence than to hack them down to lower probabilities.

\fi

\paragraph{오직 대략적 경험적 법칙만이 존재합니다.}
이 경험적 법칙들이 다른 경험적 법칙들과 마찬가지로 상당한 실제 상황에서 사용될
수 있지만 여기에도 한계가 있습니다.
다음 섹션은 여러분의 이해를 높이는 반면 여러분의 직관을 괴롭히려는 의도로
만들어진 리트머스 테스트를 소개함으로써 이런 한계를 보일 겁니다.
이 리트머스 테스트는
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet} 에서 보인 리눅스
커널 메모리 순서규칙 요약본에 의해 설명된 많은 개념을 명확히 할 것이며, 올바른
도구들을 사용하면~\cite{Alglave:2018:FSC:3173162.3177156} 자동으로 분석될 수
있습니다.
\Cref{sec:memorder:Where is Memory Ordering Needed?} 는 이 요약본으로
되돌아와서 이 모든 사이에 있는 트릭과 함정들로부터의 배움에서 나오는 보다 잘
정리된 경험적 법칙들을 선보입니다.

\iffalse

\paragraph{These are only rough rules of thumb.}
Although these rules of thumb cover the vast majority of situations
seen in actual practice, as with any set of rules of thumb, they
do have their limits.
The next section will demonstrate some of these limits by introducing
trick-and-trap litmus tests that are intended to insult your
intuition while increasing your understanding.
These litmus tests will also illuminate many of the concepts
represented by the Linux-kernel memory-ordering cheat sheet shown in
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet},
and can be automatically analyzed given proper
tooling~\cite{Alglave:2018:FSC:3173162.3177156}.
\Cref{sec:memorder:Where is Memory Ordering Needed?} will
circle back to this cheat sheet, presenting a more sophisticated set of
rules of thumb in light of learnings from all the intervening tricks
and traps.

\fi

\QuickQuiz{
	기다려요!!!
	리트머스 테스트를 자동으로 분석하는 도구를 어디서 구할 수 있나요???

	\iffalse

	Wait!!!
	Where do I find this tooling that automatically analyzes
	litmus tests???

	\fi

}\QuickQuizAnswer{
	거기 필요한 도구들을 설치하기 위해선 v4.17 (또는 그보다 최신) 의 리눅스
	커널 소스코드를 구하고 \path{tools/memory-model/README} 의 내용을
	따르세요.
	그리고 여러분이 고른 리트머스 테스트를 이 도구들로 수행하기 위해선
	나머지 내용을 더 읽으세요.

	\iffalse

	Get version v4.17 (or later) of the Linux-kernel source code,
	then follow the instructions in \path{tools/memory-model/README}
	to install the needed tools.
	Then follow the further instructions to run these tools on the
	litmus test of your choice.

	\fi

}\QuickQuizEnd

\section{Tricks and Traps}
\label{sec:memorder:Tricks and Traps}
%
\epigraph{Knowing where the trap is---that's the first step in evading it.}
	 {\emph{Duke Leto Atreides, ``Dune'', Frank Herbert}}

이제 여러분은 하드웨어가 메모리 액세스 순서를 바꿀 수 있으며 여러분은 그걸 막을
수 있음을 알게 되었으니, 다음 단계는 여러분의 직관에 문제가 있음을 인정하는
겁니다.
이 고통스런 작업은 동시에 여러 값을 가질 수 있는 scalar 변수들을 보이는 코드를
제공할
\cref{sec:memorder:Variables With Multiple Values}, 그리고
직관적으로는 올바르지만 실제 하드웨어에서는 처참하게 실패하는 코드를 보일
\crefthro{sec:memorder:Memory-Reference Reordering}
{sec:memorder:Multicopy Atomicity} 에서 행해집니다.
이 과정을 통해 일단 여러분의 직관이 깨우쳐지면, 다음 섹션들은 메모리 순서
규칙이 따르는 기본 규칙들을 요약합니다.

하지만 먼저, 하나의 변수가 한 시점에 얼마나 많은 값을 가질 수 있는지 봅시다.

\iffalse

Now that you know that hardware can reorder memory accesses and that you
can prevent it from doing so, the next step is to get you to admit
that your intuition has a problem.
This painful task is taken up by
\cref{sec:memorder:Variables With Multiple Values},
which presents some code demonstrating that scalar variables can
take on multiple values simultaneously,
and by
\crefthro{sec:memorder:Memory-Reference Reordering}
{sec:memorder:Multicopy Atomicity},
which show a series of intuitively correct code fragments that fail miserably
on real hardware.
Once your intuition has made it through the grieving process, later
sections will summarize the basic rules that memory ordering follows.

But first, let's take a quick look at just how many values a single
variable might have at a single point in time.

\fi

\subsection{Variables With Multiple Values}
\label{sec:memorder:Variables With Multiple Values}

한 변수가 잘 정의된 값의 연속을 잘 정의된 전역적 순서로 가질거라 생각하는건
자연스러운 일입니다.
불행히도, 이 여정의 다음 단계는 이 안락한 환상에 ``안녕'' 이라고 말합니다.
바라건대, 이미 여러분은
\cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events,%
tab:memorder:Memory Ordering: Store-Buffering Sequence of Events} 의 두번째
열을 통해 이미 ``안녕'' 이라고 말하기 시작했을 수도 있고, 그렇다면 이 섹션의
목적은 이 요점을 집으로 가져가는 것입니다.

\begin{fcvref}[ln:memorder:Software Logic Analyzer]
이를 위해,
\cref{lst:memorder:Software Logic Analyzer}
에 보인 코드 조각을 봅시다.
이 코드 조각은 여러 CPU 들에 의해 병렬적으로 수행됩니다.
\Clnref{setid} 는 현재 CPU 의 ID로 공유 변수를 설정하며, \clnref{init} 는 모든
CPU 들 사이에서 동기화 되는 (불행히도 모든 CPU 군에서 가능한 일은 아닙니다!)
세밀하게 조정되는 하드웨어 ``timebase'' 카운터의 값을 전달하는 \co{gettb()}
함수로부터 여러 변수들을 초기화 하며, \clnrefrange{loop:b}{loop:e} 의 반복문은
이 변수에 이 CPU 가 할당한 값이 얼마나 오래 유지되는지 기록합니다.
물론, CPU 들 가운데 하나는 ``승리'' 할 것이고, 따라서
\clnrefrange{iftmout}{break} 에서의 검사를 통과하지 못해 이 반복문을 빠져나오지
못할 겁니다.
\end{fcvref}

\iffalse

It is natural to think of a variable as taking on a well-defined
sequence of values in a well-defined, global order.
Unfortunately, the next stop on the journey says ``goodbye'' to this comforting fiction.
Hopefully, you already started to say ``goodbye'' in response to row~2 of
\cref{tab:memorder:Memory Misordering: Store-Buffering Sequence of Events,%
tab:memorder:Memory Ordering: Store-Buffering Sequence of Events},
and if so, the purpose of this section is to drive this point home.

\begin{fcvref}[ln:memorder:Software Logic Analyzer]
To this end, consider the program fragment shown in
\cref{lst:memorder:Software Logic Analyzer}.
This code fragment is executed in parallel by several CPUs.
\Clnref{setid} sets a shared variable to the current CPU's ID, \clnref{init}
initializes several variables from a \co{gettb()} function that
delivers the value of a fine-grained hardware ``timebase'' counter that is
synchronized among all CPUs (not available from all CPU architectures,
unfortunately!), and the loop from \clnrefrange{loop:b}{loop:e}
records the length of
time that the variable retains the value that this CPU assigned to it.
Of course, one of the CPUs will ``win'', and would thus never exit
the loop if not for the check on \clnrefrange{iftmout}{break}.
\end{fcvref}

\fi

\QuickQuiz{
	\Cref{lst:memorder:Software Logic Analyzer}
	의 코드 조각이 가지고 있는 실제 하드웨어에서는 옳지 못할 수도 있는
	잘못된 가정은 무엇입니까?

	\iffalse

	What assumption is the code fragment
	in \cref{lst:memorder:Software Logic Analyzer}
	making that might not be valid on real hardware?

	\fi

}\QuickQuizAnswer{
	이 코드는 특정 CPU 가 자신의 값을 보는걸 멈추게 된다면 모두가 합의한
	최종 값을 즉시 보게 될 거라 가정합니다.
	실제 하드웨어에서, CPU 중 일부는 마지막 값으로 수렴하기 전의 중간
	결과들을 여럿 볼수도 있습니다.
	이 섹션의 뒤에서 이야기될 그림의 데이터를 만드는게 사용된 실제 코드는
	따라서 조금 더 복잡합니다.

	\iffalse

	The code assumes that as soon as a given CPU stops
	seeing its own value, it will immediately see the
	final agreed-upon value.
	On real hardware, some of the CPUs might well see several
	intermediate results before converging on the final value.
	The actual code used to produce the data in the figures
	discussed later in this section was therefore somewhat more
	complex.

	\fi

}\QuickQuizEnd

\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Software Logic Analyzer]
\begin{VerbatimL}[commandchars=\\\[\]]
state.variable = mycpu;			\lnlbl[setid]
lasttb = oldtb = firsttb = gettb();	\lnlbl[init]
while (state.variable == mycpu) {	\lnlbl[loop:b]
	lasttb = oldtb;
	oldtb = gettb();
	if (lasttb - firsttb > 1000)	\lnlbl[iftmout]
		break;			\lnlbl[break]
}					\lnlbl[loop:e]
\end{VerbatimL}
\end{fcvlabel}
\caption{Software Logic Analyzer}
\label{lst:memorder:Software Logic Analyzer}
\end{listing}

반복문의 종료에 이어, \co{firsttb} 는 할당 잠시 후 취한 시간값을 가지고
\co{lasttb} 는 할당된 값을 아직 유지하고 있는 공유 변수의 마지막 샘플링 전에
취한 시간값, 또는 이 반복문에 진입하기 전에 이 공유변수의 값이 바뀌었다면
\co{firsttb} 와 같은 값을 취합니다.
이는 각 CPU 의 \co{state.variable} 의 값에 대한 각 CPU 의 532 나노세컨드 동안의
시각을 그릴 수 있게 하는데,
\cref{fig:memorder:A Variable With Multiple Simultaneous Values} 이 그것입니다.
이 데이터는 각자 한쌍의 하드웨어 쓰레드를 갖는 여덟개 코어를 가진 1.5\,GHz
\Power{5} 시스템을 이용해 2006년에 수집되었습니다.
CPU~1, 2, 3, 그리고~4 는 이 값을 기록했으며, CPU~0 은 테스트를 제어했습니다.
시간값 카운터 주기는 약 5.32\,ns 이었는데, 중간 캐쉬 상태의 관측을 허용하기
충분히 세밀했습니다.

\iffalse

Upon exit from the loop, \co{firsttb} will hold a timestamp
taken shortly after the assignment and \co{lasttb} will hold
a timestamp taken before the last sampling of the shared variable
that still retained the assigned value, or a value equal to \co{firsttb}
if the shared variable had changed before entry into the loop.
This allows us to plot each CPU's view of the value of \co{state.variable}
over a 532-nanosecond time period, as shown in
\cref{fig:memorder:A Variable With Multiple Simultaneous Values}.
This data was collected in 2006 on 1.5\,GHz \Power{5} system with 8 cores,
each containing a pair of hardware threads.
CPUs~1, 2, 3, and~4 recorded the values, while CPU~0 controlled the test.
The timebase counter period was about 5.32\,ns, sufficiently fine-grained
to allow observations of intermediate cache states.

\fi

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{memorder/MoreThanOneValue}}
\caption{A Variable With Multiple Simultaneous Values}
\label{fig:memorder:A Variable With Multiple Simultaneous Values}
\end{figure}

각 수평 막대는 특정 CPU 의 시간에 따른 관측 결과를 나타내는데, 왼쪽 회색 영역은
연관 CPU 의 첫번째 측정 전의 시간을 표시합니다.
첫 5\,ns 동안은 CPU~3 만이 이 변수의 값에 대한 의견이 있었습니다.
다음 10\,ns 동안, CPU~2 와~3 은 이 변수의 값에 대해 동의하지 않았으나, 결국은
그 값이 ``2'' 라는데 동의했는데, 이는 실제로 최종적으로 모두가 동의하게 된
값이었습니다.
그러나, CPU~1 은 이 값이 ``1'' 이라고 거의 300\,ns 동안 믿었으며 CPU~4 는 거의
500\,ns 동안 그 값이 ``4'' 라고 믿었습니다.

\iffalse

Each horizontal bar represents the observations of a given CPU over time,
with the gray regions to the left indicating the time before the
corresponding CPU's first measurement.
During the first 5\,ns, only CPU~3 has an opinion about the value of the
variable.
During the next 10\,ns, CPUs~2 and~3 disagree on the value of the variable,
but thereafter agree that the value is~``2'', which is in fact
the final agreed-upon value.
However, CPU~1 believes that the value is~``1'' for almost 300\,ns, and
CPU~4 believes that the value is~``4'' for almost 500\,ns.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	어떻게 CPU 들이 같은 변수에서 \emph{같은 시각} 에 다른 값을 볼 수
	있습니까?

	\iffalse

	How could CPUs possibly have different views of the
	value of a single variable \emph{at the same time?}

	\fi

}\QuickQuizAnswerB{
	\Cref{sec:memorder:Why Hardware Misordering?} 에서 이야기한 바와 같이,
	많은 CPU 가 최근 저장된 값을 기록하는 스토어 버퍼를 가지는데, 이는
	연관된 캐쉬 라인이 해당 CPU 에 도달하기 전까지는 해당 값이 전역적으로
	보이지 않게 합니다.
	따라서, 각 CPU 가 특정 변수에 대한 (자신의 스토어 버퍼 내에 있는)
	자신의 값을 동일한 시각에 보고 있는게---그리고 메인 메모리는 또다른
	값을 가지고 있는게---상당히 가능합니다.
	메모리 배리어가 발명된 이유 중 하나는 소프트웨어가 이런 상황을 우아하게
	처리할 수 있게 하기 위함이었습니다.

	당행히도, 소프트웨어는 여러 CPU 가 같은 변수에 대해 여러 값을 볼수도
	있다는 사실에 별 신경을 쓰지 않습니다.

	\iffalse

	As discussed in
	\cref{sec:memorder:Why Hardware Misordering?},
	many CPUs have store buffers that record the values of
	recent stores, which do not become globally visible until
	the corresponding cache line makes its way to the CPU\@.
	Therefore, it is quite possible for each CPU to see its own value
	for a given variable (in its own store buffer) at a single point
	in time---and for main memory to hold yet another value.
	One of the reasons that memory barriers were invented was
	to allow software to deal gracefully with situations like
	this one.

	Fortunately, software rarely cares about the fact that multiple
	CPUs might see multiple values for the same variable.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	CPU~2 와~3 은 왜 그리 빨리 동의에 도달했으며, CPU~1 과~4 는 그리 오래
	걸렸나요?

	\iffalse

	Why do CPUs~2 and~3 come to agreement so quickly, when it
	takes so long for CPUs~1 and~4 to come to the party?

	\fi

}\QuickQuizAnswerE{
	CPU~2 와~3 은 같은 코어 내의 한쌍의 하드웨어 쓰레드로, 동일한 캐쉬
	계층을 공유하고 따라서 매우 낮은 통신 응답시간을 갖습니다.
	이는 NUMA, 또는, 더 정확히 말하면 NUCA 효과입니다.

	이는 왜 CPU~2 와~3 은 동의하지 않았는지에 대한 답을 이끌어 줍니다.
	한가지 가능한 이유는 그것들 각각은 커다란 공유 캐쉬에 더해 작은 개별
	캐쉬를 가질 수도 있다는 겁니다.
	이 코드 내에 메모리 순서 잡기 오퍼레이션이 부재함과 동의하지 않는 짧은
	10-나노세컨드 시간을 생각하면 또다른 가능한 이유는 명령 재배치 입니다.

	\iffalse

	CPUs~2 and~3 are a pair of hardware threads on the same
	core, sharing the same cache hierarchy, and therefore have
	very low communications latencies.
	This is a NUMA, or, more accurately, a NUCA effect.

	This leads to the question of why CPUs~2 and~3 ever disagree
	at all.
	One possible reason is that they each might have a small amount
	of private cache in addition to a larger shared cache.
	Another possible reason is instruction reordering, given the
	short 10-nanosecond duration of the disagreement and the
	total lack of memory-ordering operations in the code fragment.

	\fi

}\QuickQuizEndE
}

그리고 네개 CPU 의 상황이 흥미로웠다면, 같은 상황이지만 15개 CPU 가 각자
시간~$t=0$ 에 하나의 공유 변수에 각자의 수를 할당하는 경우를 보이는
\cref{fig:memorder:A Variable With More Simultaneous Values} 를 보시기
바랍니다.
이 그림의 두 다이어그램은 모두
\cref{fig:memorder:A Variable With Multiple Simultaneous Values} 에서와 같은
방법으로 그려졌습니다.
유일한 차이는 수평 축의 단위가 시간단위 틱이란 것으로, 각 틱은 약
5.3~나노세컨드입니다.
따라서 전체 수행은 CPU 수의 증가에 맞춰
\cref{fig:memorder:A Variable With Multiple Simultaneous Values}
에 기록된 이벤트에 비해 조금 더 오래 지속됩니다.
위 다이어그램은 전체 그림을 보이며, 아래의 것은 첫 50~틱을 확대해 보입니다.
다시 말하지만, CPU~0 은 이 테스트를 조율하며, 따라서 어떤 값도 기록하지
않습니다.

\iffalse

And if you think that the situation with four CPUs was intriguing, consider
\cref{fig:memorder:A Variable With More Simultaneous Values},
which shows the same situation, but with 15~CPUs each assigning their
number to a single shared variable at time~$t=0$. Both diagrams in the
figure are drawn in the same way as
\cref{fig:memorder:A Variable With Multiple Simultaneous Values}.
The only difference is that the unit of horizontal axis is timebase ticks,
with each tick lasting about 5.3~nanoseconds.
The entire sequence therefore lasts a bit longer than the events recorded in
\cref{fig:memorder:A Variable With Multiple Simultaneous Values},
consistent with the increase in number of CPUs.
The upper diagram shows the overall picture, while the lower one zooms
in on the first 50~timebase ticks.
Again, CPU~0 coordinates the test, so does not record any values.

\fi

\begin{figure*}
\centering
\resizebox{5in}{!}{\includegraphics{memorder/MoreThanOneValue-15CPU}}
\caption{A Variable With More Simultaneous Values}
\ContributedBy{Figure}{fig:memorder:A Variable With More Simultaneous Values}{Akira Yokosawa}
\end{figure*}

모든 CPU 가 결국은 마지막 값은 9 라는데 동의했습니다만 그 전에는 값~15 와~12 가
초기를 이끌었습니다.
아래 다이어그램에 수직선으로 표시된 시간~21 에는 이 변수의 값에 대한 14개의
다른 의견이 있었음을 보십시오.
또한 모든 CPU 가
\cref{fig:memorder:Possible Global Orders With More Simultaneous Values}
에 보인 방향 있는 그래프로 보인 것처럼 순서는 일관적임을 보십시오.
더도 아니고 덜도 아니고, 이 그림들은 메모리 순서 오퍼레이션의 올바른 사용의
중요성을 강조합니다.

\iffalse

All CPUs eventually agree on the final value of~9, but not before
the values~15 and~12 take early leads.
Note that there are fourteen different opinions on the variable's value
at time~21 indicated by the vertical line in the lower diagram.
Note also that all CPUs see sequences whose orderings are consistent with
the directed graph shown in
\cref{fig:memorder:Possible Global Orders With More Simultaneous Values}.
Nevertheless, these figures underscore the importance of
proper use of memory-ordering operations.

\fi

\begin{figure}[htb]
\centering
\resizebox{2.0in}{!}{\includegraphics{memorder/store15tred}}
\caption{Possible Global Orders With More Simultaneous Values}
\label{fig:memorder:Possible Global Orders With More Simultaneous Values}
\end{figure}

한 시점에 하나의 변수는 얼마나 많은 값을 가질 수 있을까요?
시스템의 스토어 버퍼당 하나입니다!
따라서 우리는 변수의 값과 시간의 흐름에 대한 안락한 직관에 작별을 고해야 하는
체계에 진입했습니다.
이는 메모리 순서 오퍼레이션이 필요한 체계입니다.

그러나
\cref{chp:Hardware and its Habits,%
cha:Partitioning and Synchronization Design} 에서의 교훈을 기억하십시오.
모든 CPU 가 같은 변수에 동시에 값을 저장하는 것은 병렬 프로그램을 설계하는
방법이 전혀 아닌데, 최소한 성능과 확장성이 여러분에게 중요한게 아니라면
그렇습니다.

불행히도, 메모리 순서 규칙은 여러분의 직관을 망치는 다른 많은 방법들을 갖고 이
방법들이 모두 성능과 확장성을 망치지는 않습니다.
다음 섹션은 관계없는 메모리 참조의 순서 재배치를 알아봅니다.

\iffalse

How many values can a single variable take on at a single point in
time?
As many as one per store buffer in the system!
We have therefore entered a regime where we must bid a fond farewell to
comfortable intuitions about values of variables and the passage of time.
This is the regime where memory-ordering operations are needed.

But remember well the lessons from
\cref{chp:Hardware and its Habits,%
cha:Partitioning and Synchronization Design}.
Having all CPUs store concurrently to the same variable
is no way to design a parallel program, at least
not if performance and scalability are at all important to you.

Unfortunately, memory ordering has many other ways of insulting your
intuition, and not all of these ways conflict with performance and
scalability.
The next section overviews reordering of unrelated memory reference.

\fi

\subsection{Memory-Reference Reordering}
\label{sec:memorder:Memory-Reference Reordering}

\Cref{sec:memorder:Why Hardware Misordering?}
는 x86 과 같이 상대적으로 강한 순서 규칙의 시스템도 앞의 스토어를 뒤의 로드와
최소한 이 스토어와 로드가 다른 변수를 향한 것일 때에는 순서를 바꿀 수 있음을
보였습니다.
이 섹션은 그 결과를 토대로 다른 로드와 스토어 조합을 알아봅니다.

\iffalse

\Cref{sec:memorder:Why Hardware Misordering?}
showed that even relatively strongly ordered systems like x86
can reorder prior stores with later loads, at least when the
store and load are to different variables.
This section builds on that result, looking at the other combinations of
loads and stores.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-MP+o-wmb-o+o-o@whole.fcv}
\caption{Message-Passing Litmus Test (No Ordering)}
\label{lst:memorder:Message-Passing Litmus Test (No Ordering)}
\end{listing}

\subsubsection{Load Followed By Load}
\label{sec:memorder:Load Followed By Load}

\begin{fcvref}[ln:formal:C-MP+o-wmb-o+o-o:whole]
\Cref{lst:memorder:Message-Passing Litmus Test (No Ordering)}
(\path{C-MP+o-wmb-o+o-o.litmus})
는 고전적인 \emph{message-passing} 리트머스 테스트를 보이는데, \co{x0} 는
메세지이고 \co{x1} 은 메세지가 있는지 없는지 알리는 플래그입니다.
이 테스트에서, \co{smp_wmb()} 는 \co{P0()} 의 스토어가 순서잡히게 강제하지만,
로드를 위해선 어떤 순서규칙도 명시되지 않았습니다.
x86 같은 상대적으로 강한 순서규칙의 아키텍쳐에서는 순서가 강제됩니다.
그러나, 완화된 순서 규칙의 아키텍쳐에서는 종종 그러지
않습니다~\cite{JadeAlglave2011ppcmem}.
따라서, 이 리스트의 \clnref{exists} 에서의 \co{exists} 절은 발동될 수
\emph{있습니다}.
\end{fcvref}

다른 위치로부터의 로드들을 재배치하는 이유 중 하나는 그렇게 하는게 앞의 로드가
캐쉬 미스를 일으키지만 뒤의 로드는 이미 존재하는 경우 수행을 빠르게 해준다는
겁니다.

\iffalse

\begin{fcvref}[ln:formal:C-MP+o-wmb-o+o-o:whole]
\Cref{lst:memorder:Message-Passing Litmus Test (No Ordering)}
(\path{C-MP+o-wmb-o+o-o.litmus})
shows the classic \emph{message-passing} litmus test, where \co{x0} is
the message and \co{x1} is a flag indicating whether or not a message
is available.
In this test, the \co{smp_wmb()} forces \co{P0()} stores to be ordered,
but no ordering is specified for the loads.
Relatively strongly ordered architectures, such as x86, do enforce ordering.
However, weakly ordered architectures often do
not~\cite{JadeAlglave2011ppcmem}.
Therefore, the \co{exists} clause on \clnref{exists} of the listing \emph{can}
trigger.
\end{fcvref}

One rationale for reordering loads from different locations is that doing
so allows execution to proceed when an earlier load misses the cache,
but the values for later loads are already present.

\fi

\QuickQuiz{
	하지만 왜 load-load 재배치를 사용자에게 보이게 하죠?
	중간에 스토어가 없는 흔한 경우에는 수행이 진행되게끔 투기적 수행
	(speculative execution) 을 하게 해서 순서 재배치가 안보이게끔 하는게
	어떤가요?

	\iffalse

	But why make load-load reordering visible to the user?
	Why not just use speculative execution to allow execution to
	proceed in the common case where there are no intervening
	stores, in which case the reordering cannot be visible anyway?

	\fi

}\QuickQuizAnswer{
	그럴 수 있고 많은 경우에 그럽니다, 그러지 않으면 강한 순서규칙의 CPU 는
	실제로 느려질 거거든요.
	그러나, 투기적 수행은 그것만의 단점이 있는데, 특히 투기적 수행이 자주
	롤백되어야 하는 경우, 더구나 배터리 기반 시스템이면 그렇습니다.
	하지만 미래의 시스템은 이 단점을 극복할 수 있을 겁니다.
	그 전까지는, 벤더들이 완화된 순서규칙의 CPU 를 계속 생산할 거라 예상할
	수 있습니다.

	\iffalse

	They can and many do, otherwise systems containing
	strongly ordered CPUs would be slow indeed.
	However, speculative execution does have its downsides, especially
	if speculation must be rolled back frequently, particularly
	on battery-powered systems.
	But perhaps future systems will be able to overcome these
	disadvantages.
	Until then, we can expect vendors to continue producing
	weakly ordered CPUs.

	\fi

}\QuickQuizEnd

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-MP+o-wmb-o+o-rmb-o@whole.fcv}
\caption{Enforcing Order of Message-Passing Litmus Test}
\label{lst:memorder:Enforcing Order of Message-Passing Litmus Test}
\end{listing}

\begin{fcvref}[ln:formal:C-MP+o-wmb-o+o-rmb-o:whole]
따라서, 순서 잡힌 로드에 의존하는 이식성 있는 코드는 명시적 순서 규칙을 더해야
하는데, 예를 들면
\cref{lst:memorder:Enforcing Order of Message-Passing Litmus Test}
(\path{C-MP+o-wmb-o+o-rmb-o.litmus})
의 \clnref{rmb} 에 보인 \co{smp_rmb()} 를 더하는 것으로, 이는 \co{exists} 절이
발동되는 것을 막습니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-MP+o-wmb-o+o-rmb-o:whole]
Thus, portable code relying on ordered loads must
add explicit ordering, for example, the \co{smp_rmb()} shown on
\clnref{rmb} of
\cref{lst:memorder:Enforcing Order of Message-Passing Litmus Test}
(\path{C-MP+o-wmb-o+o-rmb-o.litmus}), which prevents
the \co{exists} clause from triggering.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-LB+o-o+o-o@whole.fcv}
\caption{Load-Buffering Litmus Test (No Ordering)}
\label{lst:memorder:Load-Buffering Litmus Test (No Ordering)}
\end{listing}

\subsubsection{Load Followed By Store}
\label{sec:memorder:Load Followed By Store}

\begin{fcvref}[ln:formal:C-LB+o-o+o-o:whole]
\Cref{lst:memorder:Load-Buffering Litmus Test (No Ordering)}
(\path{C-LB+o-o+o-o.litmus})
는 고전적인 \emph{load-buffering} 리트머스 테스트를 보입니다.
x86 이나 IBM Mainframe 같은 상대적으로 강한 순서규칙의 시스템은 앞의 로드를
뒤의 스토어와 재배치 하지 않습니다만, 많은 완화된 순서규칙의 아키텍쳐는 그런
재배치를 정말로 허용합니다~\cite{JadeAlglave2011ppcmem}.
따라서, \clnref{exists} 의 \co{exists} 절은 정말로 발동될 수 있습니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-LB+o-o+o-o:whole]
\Cref{lst:memorder:Load-Buffering Litmus Test (No Ordering)}
(\path{C-LB+o-o+o-o.litmus})
shows the classic \emph{load-buffering} litmus test.
Although relatively strongly ordered systems such as x86
or the IBM Mainframe do not reorder prior loads with subsequent stores,
many weakly ordered architectures really do allow such
reordering~\cite{JadeAlglave2011ppcmem}.
Therefore, the \co{exists} clause on \clnref{exists} really can trigger.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-LB+o-r+a-o@whole.fcv}
\caption{Enforcing Ordering of Load-Buffering Litmus Test}
\label{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test}
\end{listing}

\begin{fcvref}[ln:formal:C-LB+o-r+a-o:whole]
실제 하드웨어가 이런 재배치를 하는 것은 흔하지
않지만~\cite{LucMaranget2017aarch64}, 이렇게 하길 바라게 되는 한가지 상황은
로드가 캐쉬 미스를 일으키지만 스토어 버퍼는 거의 완전히 차있어서, 그리고 다음
스토어를 위한 캐쉬라인은 준비되어 있을 때입니다.
따라서, 이식성 있는 코드는 모든 필요한 순서규칙을 강제해야 하는데,
\cref{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test}
(\path{C-LB+o-r+a-o.litmus}) 에 보인 것과 같습니다.
\co{smp_store_release()} 와 \co{smp_load_acquire()} 는 \clnref{exists} 의
\co{exists} 절이 결코 발동되지 않게 보장합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-LB+o-r+a-o:whole]
Although it is rare for actual hardware to
exhibit this reordering~\cite{LucMaranget2017aarch64},
one situation where it might be desirable to do so is when a load
misses the cache, the store buffer is nearly full, and the cacheline for
a subsequent store is ready at hand.
Therefore, portable code must enforce any required ordering, for example,
as shown in
\cref{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test}
(\path{C-LB+o-r+a-o.litmus}).
The \co{smp_store_release()} and \co{smp_load_acquire()} guarantee that
the \co{exists} clause on \clnref{exists} never triggers.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-MP+o-o+o-rmb-o@whole.fcv}
\caption{Message-Passing Litmus Test, No Writer Ordering (No Ordering)}
\label{lst:memorder:Message-Passing Litmus Test; No Writer Ordering (No Ordering)}
\end{listing}

\subsubsection{Store Followed By Store}
\label{sec:memorder:Store Followed By Store}

\Cref{lst:memorder:Message-Passing Litmus Test; No Writer Ordering (No Ordering)}
(\path{C-MP+o-o+o-rmb-o.litmus})
는 다시 고전적인 message-passing 리트머스 테스트를 보이는데, \co{P1()} 의
로드를 위해선 \co{smp_rmb()} 를 제공하지만 \co{P0()} 의 스토어에는 어떤
순서규칙도 주지 않습니다.
여기서도 상대적으로 강한 순서규칙의 아키텍쳐는 순서를 강제합니다만 완화된
순서규칙의 아키텍쳐는 꼭 그러지만은 않는데~\cite{JadeAlglave2011ppcmem}, 이는
\co{exists} 절이 발동될 수 있음을 의미합니다.
그런 재배치가 도움될 수 있는 한가지 상황은 스토어 버퍼가 꽉차있고, 또다른
스토어가 수행될 준비가 되어있지만 가장 예전 스토어를 위한 캐쉬라인은 아직 사용
불가할 때입니다.
이런 경우, 스토어가 순서와 다르게 완료될 수 있게 하는건 수행이 진행될 수 있게
합니다.
따라서, 이식성 있는 코드는 명시적으로 스토어의 순서를 맞춰줘야 하는데, 예를
들면
\cref{lst:memorder:Enforcing Order of Message-Passing Litmus Test} 에 보인 것과
같아서, \co{exists} 절이 발동되는 걸 막습니다.

\iffalse

\Cref{lst:memorder:Message-Passing Litmus Test; No Writer Ordering (No Ordering)}
(\path{C-MP+o-o+o-rmb-o.litmus})
once again shows the classic message-passing litmus test, with the
\co{smp_rmb()} providing ordering for \co{P1()}'s loads, but without
any ordering for \co{P0()}'s stores.
Again, the relatively strongly ordered architectures do enforce ordering,
but weakly ordered architectures do not necessarily do
so~\cite{JadeAlglave2011ppcmem}, which means that the
\co{exists} clause can trigger.
One situation in which such reordering could be beneficial is when
the store buffer is full, another store is ready to execute, but the
cacheline needed by the oldest store is not yet available.
In this situation, allowing stores to complete out of order would
allow execution to proceed.
Therefore, portable code must explicitly order the stores, for
example, as shown in
\cref{lst:memorder:Enforcing Order of Message-Passing Litmus Test},
thus preventing the \co{exists} clause from triggering.

\fi

\QuickQuiz{
	강한 순서규칙의 시스템은 왜 불필요한 \co{smp_rmb()} 와 \co{smp_wmb()}
	수행이라는 성능 비용을 지불해야 하죠?
	완화된 순서규칙의 시스템이 그들의 잘못된 순서잡기 선택의 완전한 비용을
	책임져야 하지 않나요???

	\iffalse

	Why should strongly ordered systems pay the performance price
	of unnecessary \co{smp_rmb()} and \co{smp_wmb()} invocations?
	Shouldn't weakly ordered systems shoulder the full cost of
	their misordering choices???

	\fi

}\QuickQuizAnswer{
	그게 정확한 실제 상황입니다.
	강한 순서규칙의 시스템에서 \co{smp_rmb()} 와 \co{smp_wmb()} 는 명령을
	생성하지 않지만 그저 컴파일러에게 제약을 겁니다.
	따라서, 이 경우 완화된 순서규칙의 시스템은 실제로 그들의 메모리 순서
	규칙 선택의 완전한 비용을 내고 있습니다.

	\iffalse

	That is in fact exactly what happens.
	On strongly ordered systems, \co{smp_rmb()} and \co{smp_wmb()}
	emit no instructions, but instead just constrain the compiler.
	Thus, in this case, weakly ordered systems do in fact shoulder
	the full cost of their memory-ordering choices.

	\fi

}\QuickQuizEnd

\subsection{Address Dependencies}
\label{sec:memorder:Address Dependencies}

\emph{주소 종속성 (address dependency)} 는 로드 명령에 의해 반환된 값이 뒤의
메모리 참조 명령에 의해 사용될 주소를 계산하는데 사용될 때 발생합니다.

\iffalse

An \emph{address dependency} occurs when the value returned by a load
instruction is used to compute the address used by a later memory-reference
instruction.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-MP+o-wmb-o+o-addr-o@whole.fcv}
\caption{Message-Passing Address-Dependency Litmus Test (No Ordering Before v4.15)}
\label{lst:memorder:Message-Passing Address-Dependency Litmus Test (No Ordering Before v4.15)}
\end{listing}

\begin{fcvref}[ln:formal:C-MP+o-wmb-o+o-addr-o:whole]
\Cref{lst:memorder:Message-Passing Address-Dependency Litmus Test (No Ordering Before v4.15)}
(\path{C-MP+o-wmb-o+o-addr-o.litmus})
는 메세지 패싱 패턴의 연결 기반 변종을 보입니다.
헤드 포인터는 \co{x1} 으로, \co{int} 변수 \co{y} 를 참조하도록 초기화 되며
(\clnref{init:x1}), \co{y} 는 $1$ 으로 초기화 되어 있습니다 (\clnref{init:y}).
\co{P0()} 는 헤드 포인터 \co{x1} 이 \co{x0} 를 참조하도록 업데이트 하지만
(\clnref{P0:x1}), 그것을 $2$ 로 초기화 한 후이며 (\clnref{P0:x0}) 그 순서를
강제합니다 (\clnref{P0:wmb}).
\co{P1()} 은 헤드 포인터 \co{x1} 을 가져오고 (\clnref{P1:x1}), 이어서 참조된
값을 로드합니다 (\clnref{P1:ref}).
따라서 \clnref{P1:x1} 에서의 로드로부터 \clnref{P1:ref} 사이에 주소 종속성이
존재합니다.
이 경우, \clnref{P1:x1} 에 의해 반환되는 값은 \clnref{P1:ref} 에 의해 사용되는
주소값이지만, 많은 변종이 가능한데,
\end{fcvref}
C-언어 \co{->} 오퍼레이터를 통한 필드 액세스, 더하기, 빼기, 그리고 배열
인덱싱이 포함됩니다.\footnote{
	하지만 리눅스 커널에서 주소 종속성은 배열로의 포인터를 통해
	이루어져야지 배열 인덱스를 통해 이루어져선 안됩니다.}

\iffalse

\begin{fcvref}[ln:formal:C-MP+o-wmb-o+o-addr-o:whole]
\Cref{lst:memorder:Message-Passing Address-Dependency Litmus Test (No Ordering Before v4.15)}
(\path{C-MP+o-wmb-o+o-addr-o.litmus})
shows a linked variant of the message-passing pattern.
The head pointer is \co{x1}, which initially
references the \co{int} variable \co{y} (\clnref{init:x1}), which is in turn
initialized to the value $1$ (\clnref{init:y}).
\co{P0()} updates head pointer \co{x1} to reference \co{x0} (\clnref{P0:x1}),
but only after initializing it to $2$ (\clnref{P0:x0}) and forcing ordering
(\clnref{P0:wmb}).
\co{P1()} picks up the head pointer \co{x1} (\clnref{P1:x1}), and then loads
the referenced value (\clnref{P1:ref}).
There is thus an address dependency from the load on \clnref{P1:x1} to the
load on \clnref{P1:ref}.
In this case, the value returned by \clnref{P1:x1} is exactly the address
used by \clnref{P1:ref}, but many variations are possible,
\end{fcvref}
including field access using the C-language \co{->} operator,
addition, subtraction, and array indexing.\footnote{
	But note that in the Linux kernel, the address dependency must
	be carried through the pointer to the array, not through the
	array index.}

\fi

\begin{fcvref}[ln:formal:C-MP+o-wmb-o+o-addr-o:whole]
어떤 사람들은 \clnref{P1:x1} 의 헤드 포인터로부터의 로드가 \clnref{P1:ref} 의
역참조 전으로 순서잡히길 바랄 수도 있겠는데, 리눅스 v4.15 이후에서는 실제로
그렇습니다.
그러나, v4.15 전에는 DEC Alpha 에서는 그렇지 않은데,
\cref{sec:memorder:Alpha} 에서 자세한 사항이 이야기되어 있듯이 의존적 로드에
예측된 값을 사용하게 할 수 있습니다.
따라서, 오래된 버전의 리눅스에서는
\cref{lst:memorder:Message-Passing Address-Dependency Litmus Test (No Ordering
Before v4.15)} 의 \co{exists} 절이 발동될 수 \emph{있습니다}.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-MP+o-wmb-o+o-addr-o:whole]
One might hope that \clnref{P1:x1}'s load from the head pointer would be ordered
before \clnref{P1:ref}'s dereference, which is in fact the case on Linux v4.15
and later.
However, prior to v4.15, this was not the case on DEC Alpha, which could
in effect use a speculated value for the dependent load, as described
in more detail in \cref{sec:memorder:Alpha}.
Therefore, on older versions of Linux,
\cref{lst:memorder:Message-Passing Address-Dependency Litmus Test (No Ordering Before v4.15)}'s
\co{exists} clause \emph{can} trigger.
\end{fcvref}

\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)]
\begin{VerbatimL}[commandchars=\@\[\]]
C C-MP+o-wmb-o+ld-addr-o

{
y=1;
x1=y;
}

P0(int* x0, int** x1) {
	WRITE_ONCE(*x0, 2);
	smp_wmb();
	WRITE_ONCE(*x1, x0);
}

P1(int** x1) {
	int *r2;
	int r3;

	r2 = lockless_dereference(*x1); // Obsolete @lnlbl[deref]
	r3 = READ_ONCE(*r2);			    @lnlbl[read]
}

exists (1:r2=x0 /\ 1:r3=1)
\end{VerbatimL}
\end{fcvlabel}
\caption{Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)}
\label{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)}
\end{listing}

\begin{fcvref}[ln:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)]
\Cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)}
는 \clnref{read} 의 \co{READ_ONCE()} 를 DEC Alpha 를 제외한 모든 플랫폼에서는
\co{READ_ONCE()} 로 동작하지만 DEC Alpha 에서는 \co{READ_ONCE()} 에 이어
\co{smp_mb()} 를 수행하며 따라서 모든 플랫폼에서 필요한 순서를 강제하게 되는
\co{lockless_dereference()} 로 교체함으로써 v4.15 이전 리눅스 커널에서도 이게
DEC Alpha 에서 안정적으로 동작하게끔 하는 방법을,\footnote{
	\co{lockless_dereference()} 는 v4.15 이후 버전에서는 필요치 않으며,
	따라서 그 리눅스 커널들에서는 존재하지 않음을 알아두시기 바랍니다.
	또한 이 문장을 담고 있는 이 책의 버전에서도 필요치 않습니다.}
즉 \co{exists} 절이 발동되는 걸 막는 방법을 보입니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)]
\Cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)}
% \path{C-MP+o-wmb-o+ld-addr-o.litmus} available at commit bc4b1c3f3b35
% ("styleguide: Loosen restriction on comment in litmus test")
shows how to make this work reliably on pre-v4.15 Linux kernels running on
DEC Alpha, by replacing \clnref{read}'s \co{READ_ONCE()} with
\co{lockless_dereference()},\footnote{
	Note that \co{lockless_dereference()} is not needed on v4.15 and
	later, and therefore is not available in these later Linux kernels.
	Nor is it needed in versions of this book containing this sentence.}
which acts like \co{READ_ONCE()} on all platforms other than DEC Alpha,
where it acts like a \co{READ_ONCE()} followed by an \co{smp_mb()},
thereby forcing the required ordering on all platforms, in turn
preventing the \co{exists} clause from triggering.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-S+o-wmb-o+o-addr-o@whole.fcv}
\caption{S Address-Dependency Litmus Test}
\label{lst:memorder:S Address-Dependency Litmus Test}
\end{listing}

\begin{fcvref}[ln:formal:C-S+o-wmb-o+o-addr-o:whole]
하지만 그 의존적 오퍼레이션이 로드가 아닌 스토어라면, 예를 들어
\cref{lst:memorder:S Address-Dependency Litmus Test}
(\path{C-S+o-wmb-o+o-addr-o.litmus}) 에 보인 것과 같은 \emph{S} 리트머스
테스트~\cite{JadeAlglave2011ppcmem} 같은 경우라면 어떨까요?
어떤 제품 수준 플랫폼도 스토어를 예측하진 않기 때문에, \clnref{P0:x0} 의
\co{WRITE_ONCE()} 는 \clnref{P1:r2} 의 \co{WRITE_ONCE()} 를 덮어쓸 수 없으며,
이는 \clnref{exists} 의 \co{exists} 절이 발동될 수 없음을, 심지어 DEC Alpha
에서도, v4.15 전의 리눅스 커널에서도 그러함을 의미합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-S+o-wmb-o+o-addr-o:whole]
But what happens if the dependent operation is a store rather than
a load, for example, in the \emph{S}
litmus test~\cite{JadeAlglave2011ppcmem} shown in
\cref{lst:memorder:S Address-Dependency Litmus Test}
(\path{C-S+o-wmb-o+o-addr-o.litmus})?
Because no production-quality platform speculates stores,
it is not possible for the \co{WRITE_ONCE()} on \clnref{P0:x0} to overwrite
the \co{WRITE_ONCE()} on \clnref{P1:r2}, meaning that the \co{exists}
clause on \clnref{exists} cannot trigger, even on DEC Alpha, even
in pre-v4.15 Linux kernels.
\end{fcvref}

\fi

\QuickQuizSeries{%
\QuickQuizB{
	하지만 \emph{모든} 플랫폼이
	\cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15),%
	lst:memorder:S Address-Dependency Litmus Test}
	의 \co{exists} 절을 정말로 발동시키지 않음을 어떻게 알죠?

	\iffalse

	But how do we know that \emph{all} platforms really avoid
	triggering the \co{exists} clauses in
	\cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15),%
	lst:memorder:S Address-Dependency Litmus Test}?

	\fi

}\QuickQuizAnswerB{
	여기에 답하기 위해선 세개의 주요 플랫폼 그룹을 정의하는게 필요합니다:
	(1)~Total-store-order (TSO) 플랫폼,
	(2)~Weakly ordered (완화된 순서의) 플랫폼, 그리고
	(3)~DEC Alpha.

	\begin{fcvref}[ln:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)]
	TSO 플랫폼은 모든 메모리 참조 쌍의 순서를 지키는데 앞의 스토어와 뒤의
	로드에 대해서만은 예외입니다.
	\Cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)}
	의 \clnref{deref,read} 에서의 주소 종속성은 로드에 뒤이어 다른 로드가
	오는 것이므로, TSO 플랫폼은 이 주소 종속성을 지킵니다.
	\end{fcvref}
	\begin{fcvref}[ln:formal:C-S+o-wmb-o+o-addr-o:whole]
	이것들은 또한
	\cref{lst:memorder:S Address-Dependency Litmus Test}
	의 \clnref{P1:x1,P1:r2} 에서의 주소 종속성 역시 지키는데 이는 로드 뒤에
	스토어가 따라오는 것이기 때문입니다.
	주소 종속성은 로드로부터 시작되어야 하므로, TSO 플랫폼은 암시적이지만
	완벽하게 이를 지킵니다만 컴파일러 최적화는 가능하므로 \co{READ_ONCE()}
	는 필요합니다.
	\end{fcvref}

\iffalse

	Answering this requires identifying three major groups of platforms:
	(1)~Total-store-order (TSO) platforms,
	(2)~Weakly ordered platforms, and
	(3)~DEC Alpha.

	\begin{fcvref}[ln:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)]
	The TSO platforms order all pairs of memory references except for
	prior stores against later loads.
	Because the address dependency on \clnref{deref,read} of
	\cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)}
	is instead a load followed by another load, TSO platforms preserve
	this address dependency.
	\end{fcvref}
	\begin{fcvref}[ln:formal:C-S+o-wmb-o+o-addr-o:whole]
	They also preserve the address dependency on \clnref{P1:x1,P1:r2} of
	\cref{lst:memorder:S Address-Dependency Litmus Test}
	because this is a load followed by a store.
	Because address dependencies must start with a load, TSO platforms
	implicitly but completely respect them, give or take compiler
	optimizations, hence the need for \co{READ_ONCE()}.
	\end{fcvref}

\fi

	완화된 순서의 플랫폼은 연관없는 액세스의 순서는 지키지 않을 수
	있습니다.
	그러나,
	\cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15),%
	lst:memorder:S Address-Dependency Litmus Test}
	의 주소 종속성은 연관없지 않습니다: 주소 종속성이 존재합니다.
	하드웨어는 종속성을 추적하고 필요한 순서를 지켜줍니다.

	\iffalse

	Weakly ordered platforms don't necessarily maintain ordering of
	unrelated accesses.
	However, the address dependencies in
	\cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15),%
	lst:memorder:S Address-Dependency Litmus Test}
	are not unrelated: There is an address dependency.
	The hardware tracks dependencies and maintains the needed
	ordering.

	\fi

	\begin{fcvref}[ln:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)]
	이 완화된 순서규칙 플랫폼의 규칙에 대한 하나의 (유명한) 예외가 있는데,
	그 예외는 DEC Alpha 의 로드 대 로드 주소 종속성입니다.
	그리고 이게 왜 v4.15 전의 리눅스 커널에서 DEC Alpha 는 이제는 사용되지 않는,
	\cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)}
	의 \clnref{deref} 에 보인 \co{lockless_dereference()} 에 의해 메모리
	배리어를 명시적으로 필요했던 이유입니다.
	\end{fcvref}
	\begin{fcvref}[ln:formal:C-S+o-wmb-o+o-addr-o:whole]
	그러나, DEC Alpha 역시 로드 대 스토어 주소 종속성은 추적하는데,
	\cref{lst:memorder:S Address-Dependency Litmus Test}
	의 \clnref{P1:x1} 에서 v4.15 전의 리눅스 커널에서도
	\co{lockless_dereference()} 를 필요로 하지 않는 이유입니다.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)]
	There is one (famous) exception to this rule for weakly ordered
	platforms, and that exception is DEC Alpha for load-to-load
	address dependencies.
	And this is why, in Linux kernels predating v4.15, DEC Alpha
	requires the explicit memory barrier supplied for it by the
	now-obsolete \co{lockless_dereference()} on \clnref{deref} of
	\cref{lst:memorder:Enforced Ordering of Message-Passing Address-Dependency Litmus Test (Before v4.15)}.
	\end{fcvref}
	\begin{fcvref}[ln:formal:C-S+o-wmb-o+o-addr-o:whole]
	However, DEC Alpha does track load-to-store address dependencies,
	which is why \clnref{P1:x1} of
	\cref{lst:memorder:S Address-Dependency Litmus Test}
	does not need a \co{lockless_dereference()}, even in Linux
	kernels predating v4.15.
	\end{fcvref}

	\fi

	정리하자면, 현재의 플랫폼들은 TSO 플랫폼들 (x86, mainframe,
	SPARC,~\dots) 에서처럼 주소 종속성을 묵시적으로 지켜주거나, 주소
	종속성을 위한 하드웨어 추적 기능을 가지거나 (\ARM, PowerPC,
	MIPS,~\dots), \co{READ_ONCE()} (v4.15 이후 리눅스 커널에서의 DEC
	Alpha) 또는 \co{rcu_dereference()} (v4.14 이전 리눅스 커널에서의 DEC
	Alpha) 에 의해 제공되는 메모리 배리어를 필요로 합니다.

	\iffalse

	To sum up, current platforms either respect address dependencies
	implicitly, as is the case for TSO platforms (x86, mainframe,
	SPARC,~\dots), have hardware tracking for address dependencies
	(\ARM, PowerPC, MIPS,~\dots), have the required memory barriers
	supplied by \co{READ_ONCE()} (DEC Alpha in Linux kernel v4.15 and
	later), or supplied by
	\co{rcu_dereference()} (DEC Alpha in Linux kernel v4.14 and earlier).

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	SP, MP, LB, 이제는~S 까지.
	이 리트머스 테스트 약자들은 어디서 왔고 누가 이걸 따라갈 수 있겠습니까?

	\iffalse

	SP, MP, LB, and now~S\@.
	Where do all these litmus-test abbreviations come from and
	how can anyone keep track of them?

	\fi

}\QuickQuizAnswerE{
	최고의 일람표는
	\co{test6.pdf}~\cite{test6-pdf} 입니다.
	불행히도, 모든 약자가 SB (store buffering), MP (message passing),
	그리고 LB (load buffering) 처럼 알기 쉬운 확장을 갖지는 않으나, 최소한
	약자들의 리스트는 이미 사용 가능합니다.

	\iffalse

	The best scorecard is the infamous
	\co{test6.pdf}~\cite{test6-pdf}.
	Unfortunately, not all of the abbreviations have catchy
	expansions like SB (store buffering), MP (message passing),
	and LB (load buffering), but at least the list of abbreviations
	is readily available.

	\fi

}\QuickQuizEndE
}

그러나,
\cref{sec:memorder:Address- and Data-Dependency Difficulties} 에서 이야기 했듯
주소 종속성은 잘못 짜이기 쉽고 컴파일러 최적화에 의해 쉽게 깨짐에 유의하는게
중요합니다.

\iffalse

However, it is important to note that address dependencies can
be fragile and easily broken by compiler optimizations, as discussed in
\cref{sec:memorder:Address- and Data-Dependency Difficulties}.

\fi

\subsection{Data Dependencies}
\label{sec:memorder:Data Reordering}

\emph{Data dependency (데이터 종속성)} 은 어떤 로드 명령에 의해 반환된 값이
뒤의 스토어 명령에 의해 저장되는 데이터를 계산하는데 사용될 때 발생합니다.
앞의 ``데이터'' 에 유의하세요: 어떤 로드에 의해 반환된 값이 뒤의 스토어 명령에
의해 사용되는 주소를 계산하는데 사용된다면 그건 주소 종속성이 됩니다.

\iffalse

A \emph{data dependency} occurs when the value returned by a load
instruction is used to compute the data stored by a later store
instruction.
Note well the ``data'' above: If the value returned by a load
was instead used to compute the address used by a later store
instruction, that would instead be an address dependency.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-LB+o-r+o-data-o@whole.fcv}
\caption{Load-Buffering Data-Dependency Litmus Test}
\label{lst:memorder:Load-Buffering Data-Dependency Litmus Test}
\end{listing}

\begin{fcvref}[ln:formal:C-LB+o-r+o-data-o:whole]
\Cref{lst:memorder:Load-Buffering Data-Dependency Litmus Test}
(\path{C-LB+o-r+o-data-o.litmus})
는
\cref{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test}
와 유사하지만 \co{P1()} 의 \clnref{ld,st} 사이 순서가 acquire load 대신 데이터
종속성으로 강제된다는 점이 다릅니다:
\Clnref{ld} 에 의해 로드되는 값이 \clnref{st} 에서 스토어 하는 값입니다.
이 데이터 종속성에 의해 제공되는 순서 규칙은 \co{exists} 절이 발동되는 것을
막는 데에 충분합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-LB+o-r+o-data-o:whole]
\Cref{lst:memorder:Load-Buffering Data-Dependency Litmus Test}
(\path{C-LB+o-r+o-data-o.litmus})
is similar to
\cref{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test},
except that \co{P1()}'s ordering between \clnref{ld,st} is
enforced not by an acquire load, but instead by a data dependency:
The value loaded by \clnref{ld} is what \clnref{st} stores.
The ordering provided by this data dependency is sufficient to prevent
the \co{exists} clause from triggering.
\end{fcvref}

\fi

\Cref{sec:memorder:Address- and Data-Dependency Difficulties} 
에서 이야기했듯, 주소 종속성에서와 마찬가지로 데이터 종속성은 잘못 짜이기 쉽고
컴파일러 최적화에 의해 쉽게 부서집니다.
실제로, 데이터 종속성은 주소 종속성보다도 더 잘못 짜이기가 쉽습니다.
그 이유는 주소 종속성은 일반적으로 포인터 값을 사용하기 때문입니다.
대조적으로,
\cref{lst:memorder:Load-Buffering Data-Dependency Litmus Test} 에서 보인 것과
같이 데이터 종속성을 단하나의 값을 통해 옮기고 싶어지게 마련이며, 이는
컴파일러가 이를 최적화해 제거해 버리기 충분합니다.
한가지만 예를 들자면, 로드된 정수가 상수 0으로 곱해진다면, 컴파일러는 그 결과가
0임을 알아서 로드된 값을 0으로 치환하여 이 종속성을 깨버릴 수 있습니다.

\iffalse

Just as with address dependencies, data dependencies are
fragile and can be easily broken by compiler optimizations, as discussed in
\cref{sec:memorder:Address- and Data-Dependency Difficulties}.
In fact, data dependencies can be even more fragile than are address
dependencies.
The reason for this is that address dependencies normally involve
pointer values.
In contrast, as shown in
\cref{lst:memorder:Load-Buffering Data-Dependency Litmus Test},
it is tempting to carry data dependencies through integral values,
which the compiler has much more freedom to optimize into nonexistence.
For but one example, if the integer loaded was multiplied by the constant
zero, the compiler would know that the result was zero, and could therefore
substitute the constant zero for the value loaded, thus breaking
the dependency.

\fi

\QuickQuiz{
	\begin{fcvref}[ln:formal:C-LB+o-r+o-data-o:whole]
	하지만 기다려요!!!
	\Cref{lst:memorder:Load-Buffering Data-Dependency Litmus Test}
	의 \clnref{ld} 는 이 로드를 휘발성으로 기록하는 \co{READ_ONCE()} 를
	사용하는데, 이는 컴파일러가 그 값이 나중에 0으로 곱해짐을 안다 하더라도
	로드 명령을 만들어야 함을 의미합니다.
	그런데 어떻게 컴파일러가 이 데이터 종속성을 깰 수 있죠?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:formal:C-LB+o-r+o-data-o:whole]
	But wait!!!
	\Clnref{ld} of
	\cref{lst:memorder:Load-Buffering Data-Dependency Litmus Test}
	uses \co{READ_ONCE()}, which marks the load as volatile,
	which means that the compiler absolutely must emit the load
	instruction even if the value is later multiplied by zero.
	So how can the compiler possibly break this data dependency?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	맞습니다, 컴파일러느 휘발성 로드를 위해 로드 명령을 반드시 만들어야
	합니다.
	하지만 그 값을 0으로 곱한다면 이 컴파일러는 그 곱셈의 결과를 0으로
	대체할 수가 있는데, 이는 많은 플랫폼에서 데이터 종속성을 깨버릴 겁니다.

	더 나쁠 수 있는게, 종속된 스토어가 \co{WRITE_ONCE()} 를 사용하지
	않는다면 컴파일러는 이를 로드 앞으로 옮겨버릴 수 있어서 TSO
	플랫폼에서조차 순서를 제공하지 못하게 할 수 있습니다.

	\iffalse

	Yes, the compiler absolutely must emit a load instruction for
	a volatile load.
	But if you multiply the value loaded by zero, the compiler is
	well within its rights to substitute a constant zero for the
	result of that multiplication, which will break the data
	dependency on many platforms.

	Worse yet, if the dependent store does not use \co{WRITE_ONCE()},
	the compiler could hoist it above the load, which would cause
	even TSO platforms to fail to provide ordering.

	\fi

}\QuickQuizEnd

요약하자면, 여러분은 컴파일러가 데이터 종속성을 깨버리는 걸 막을 때에만 거기
의존할 수 있습니다.

\iffalse

In short, you can rely on data dependencies only if you prevent the
compiler from breaking them.

\fi

\subsection{Control Dependencies}
\label{sec:memorder:Control Dependencies}

\emph{Control dependency (제어 종속성)} 은 로드 명령에 의해 반환되는 값이 뒤의
스토어 명령이 수행될지 말지를 결정하기 위해 검사될 때 발생합니다.
``뒤의 스토어 명령'' 에 주목하세요: 많은 플랫폼이 로드 대 로드 제어 종속성을
지키지 않습니다.

\iffalse

A \emph{control dependency} occurs when the value returned by a load
instruction is tested to determine whether or not a later store instruction
is executed.
Note well the ``later store instruction'': Many platforms do not respect
load-to-load control dependencies.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-LB+o-r+o-ctrl-o@whole.fcv}
\caption{Load-Buffering Control-Dependency Litmus Test}
\label{lst:memorder:Load-Buffering Control-Dependency Litmus Test}
\end{listing}

\begin{fcvref}[ln:formal:C-LB+o-r+o-ctrl-o:whole]
\Cref{lst:memorder:Load-Buffering Control-Dependency Litmus Test}
(\path{C-LB+o-r+o-ctrl-o.litmus})
는 또다른 로드 버퍼링 예를 보이는데, 이번에는 \clnref{ld} 에서의 로드와
\clnref{st} 에서의 스토어의 순서를 맞추기 위해 제어 종속성을 (\clnref{if})
사용합니다.
이 순서 강제는 \co{exists} 절이 발동되는걸 막기에 충분합니다.
\end{fcvref}

그러나, 제어 종속성은 데이터 종속성보다도 최적화로 사라지기 쉬우며,
\cref{sec:memorder:Control-Dependency Calamities}
가 여러분의 컴파일러가 제어 종속성을 깨버리는 걸 막기 위해 따라야 할 규칙들을
설명합니다.

\iffalse

\begin{fcvref}[ln:formal:C-LB+o-r+o-ctrl-o:whole]
\Cref{lst:memorder:Load-Buffering Control-Dependency Litmus Test}
(\path{C-LB+o-r+o-ctrl-o.litmus})
shows another load-buffering example, this time using a control
dependency (\clnref{if}) to order the load on \clnref{ld} and the store on
\clnref{st}.
The ordering is sufficient to prevent the \co{exists} from triggering.
\end{fcvref}

However, control dependencies are even more susceptible to being optimized
out of existence than are data dependencies, and
\cref{sec:memorder:Control-Dependency Calamities}
describes some of the rules that must be followed in order to prevent
your compiler from breaking your control dependencies.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-MP+o-r+o-ctrl-o@whole.fcv}
\caption{Message-Passing Control-Dependency Litmus Test (No Ordering)}
\label{lst:memorder:Message-Passing Control-Dependency Litmus Test (No Ordering)}
\end{listing}

\begin{fcvref}[ln:formal:C-MP+o-r+o-ctrl-o:whole]
제어 종속성은 로드에서 스토어로의 순서만을 제공함을 반복할 가치가 있습니다.
따라서,
\cref{lst:memorder:Message-Passing Control-Dependency Litmus Test (No Ordering)}
(\path{C-MP+o-r+o-ctrl-o.litmus})
의 \clnrefrange{ld1}{ld2} 에 보인 제어 종속성은 순서를 제공하지 \emph{않으며},
따라서 \co{exists} 절이 발동되는 것을 막지 \emph{않습니다}.
\end{fcvref}

요약하자면, 제어 종속성은 유용할 수 있으나 관리하기 어려운 항목입니다.
따라서 여러분은 성능 고려사항이 다른 해법을 허용치 않을 때에만 그걸 사용해야
합니다.

\iffalse

\begin{fcvref}[ln:formal:C-MP+o-r+o-ctrl-o:whole]
It is worth reiterating that control dependencies provide ordering only
from loads to stores.
Therefore, the load-to-load control dependency shown on \clnrefrange{ld1}{ld2} of
\cref{lst:memorder:Message-Passing Control-Dependency Litmus Test (No Ordering)}
(\path{C-MP+o-r+o-ctrl-o.litmus})
does \emph{not} provide ordering, and therefore does \emph{not}
prevent the \co{exists} clause from triggering.
\end{fcvref}

In summary, control dependencies can be useful, but they are
high-maintenance items.
You should therefore use them only when performance considerations
permit no other solution.

\fi

\QuickQuiz{
	제어 종속성은 언어 표준에 의해 강제시 된다면 더 강해지지 않을까요?

	\iffalse

	Wouldn't control dependencies be more robust if they were
	mandated by language standards???

	\fi

}\QuickQuizAnswer{
	물론입니다!
	그리고 아마도 충분한 미래에는 그렇게 될겁니다.

	\iffalse

	But of course!
	And perhaps in the fullness of time they will be so mandated.

	\fi

}\QuickQuizEnd

\subsection{Cache Coherence}
\label{sec:memorder:Cache Coherence}

Cache-coherent (캐쉬 일관성이 지켜지는) 플랫폼에서, 모든 CPU 는 특정 변수의
로드와 스토어 순서에 대해 동의하게 됩니다.
다행히도, \co{READ_ONCE()} 와 \co{WRITE_ONCE()} 가 사용된다면 거의 모든
플랫폼이 cache-coherent 하게 되는데,
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
의 ``SV'' 행에 표시된 바와 같습니다.
불행히도, 이 속성은 여러번 이름지어질 정도로 유명한데, ``single-variable
SC'',\footnote{
	SC 는 sequentially consistent 를 의미함을 기억하세요.}
``single-copy atomic''~\cite{Stone:1995:SP:623262.623912},
그리고 간단히 ``coherence''~\cite{JadeAlglave2011ppcmem} 라는 이름이
사용되어왔습니다.
이 개념을 위한 또다른 용어를 발명해서 혼란을 가중시키기보다는 이 책에서는
``cache coherence (캐쉬 일관성)'' 또는 ``coherence (일관성)'' 라는 용어를
사용하겠습니다.

\iffalse

On cache-coherent platforms, all CPUs agree on the order of loads and
stores to a given variable.
Fortunately, when \co{READ_ONCE()} and \co{WRITE_ONCE()} are used,
almost all platforms are cache-coherent, as indicated by the ``SV''
column of the cheat sheet shown in
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}.
Unfortunately, this property is so popular that it has been named
multiple times, with ``single-variable SC'',\footnote{
	Recall that SC stands for sequentially consistent.}
``single-copy atomic''~\cite{Stone:1995:SP:623262.623912},
and just plain ``coherence''~\cite{JadeAlglave2011ppcmem}
having seen use.
Rather than further compound the confusion by inventing yet another term
for this concept, this book uses ``cache coherence'' and ``coherence''
interchangeably.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-CCIRIW+o+o+o-o+o-o@whole.fcv}
\caption{Cache-Coherent IRIW Litmus Test}
\label{lst:memorder:Cache-Coherent IRIW Litmus Test}
\end{listing}

\begin{fcvref}[ln:formal:C-CCIRIW+o+o+o-o+o-o:whole]
\cref{lst:memorder:Cache-Coherent IRIW Litmus Test}
(\path{C-CCIRIW+o+o+o-o+o-o.litmus})
는 캐쉬 일관성을 테스트하는 리트머스 테스트를 보이는데, ``IRIW'' 는
``independent reads of independent writes'' 를 의미합니다.
이 리트머스 테스트는 하나의 변수만을 사용하므로 \co{P2()} 와 \co{P3()} 는
\co{P0()} 와 \co{P1()} 의 스토어 순서에 동의해야만 합니다.
달리 말하면 \co{P2()} 가 \co{P0()} 의 스토어가 먼저 왔다고 믿는다면 \co{P3()}
는 \co{P1()} 의 스토어가 먼저 왔다고 믿지 말아야 합니다.
그리고 실제로 \clnref{exists} 의 \co{exists} 절은 이 상황이 나타나면 발동될
겁니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-CCIRIW+o+o+o-o+o-o:whole]
\cref{lst:memorder:Cache-Coherent IRIW Litmus Test}
(\path{C-CCIRIW+o+o+o-o+o-o.litmus})
shows a litmus test that tests for cache coherence,
where ``IRIW'' stands
for ``independent reads of independent writes''.
Because this litmus test uses only one variable,
\co{P2()} and \co{P3()} must agree
on the order of \co{P0()}'s and \co{P1()}'s stores.
In other words, if \co{P2()} believes that \co{P0()}'s store
came first, then \co{P3()} had better not believe that
\co{P1()}'s store came first.
And in fact the \co{exists} clause on \clnref{exists} will trigger if this
situation arises.
\end{fcvref}

\fi

\QuickQuiz{
	하지만
	\cref{lst:memorder:Cache-Coherent IRIW Litmus Test}
	에서, \co{P2()} 의 \co{r1} 과 \co{r2} 가 값~2 와~1 을 각각 관측했고
	\co{P3()} 의 \co{r2} 와 \co{r4} 가 값~1 과~2 를 각각 관측한다면 그저
	나쁜 결과가 되지 않나요?

	\iffalse

	But in
	\cref{lst:memorder:Cache-Coherent IRIW Litmus Test},
	wouldn't be just as bad if \co{P2()}'s \co{r1} and \co{r2}
	obtained the values~2 and~1, respectively, while \co{P3()}'s
	\co{r3} and \co{r4} obtained the values~1 and~2, respectively?

	\fi

}\QuickQuizAnswer{
	맞아요, 그럴 겁니다.
	그 결과를 확인하기 위해 \co{exists} 절을 수정하고 어떻게 되는지 한번
	보세요.

	\iffalse

	Yes, it would.
	Feel free to modify the \co{exists} clause to
	check for that outcome and see what happens.

	\fi

}\QuickQuizEnd

하나의 메모리 영역으로의 겹치는 다른 크기의 로드와 스토어가 (C-언어의
\co{union} 키워드를 이용해 셋업될 수도 있겠습니다) 비슷한 순서 보장을 제공할
거라 예상하고 싶을 수 있습니다.
그러나, Flur et al.~\cite{Flur:2017:MCA:3093333.3009839} 은 그런 보장이 실제
하드웨어에서는 위배될 수 있음을 보이는 놀랍도록 간단한 리트머스 테스트를
발견했습니다.
따라서 코드가 특정 변수에 겹치지 않는 같은 크기의 정렬된 액세스만을 하도록
강제할 필요가 있는데, 적어도 이식성이 고려사항이라면 그렇습니다.\footnote{
	모든 스토어에 atomic RMW 오퍼레이션을 (예를 들어 \co{xchg()})
	사용하는게 sequentially consistent 순서 규칙을 제공할 거라 믿을 이유도
	있지만 이 역시 아직 증명된 바 없습니다.}

더 많은 변수와 쓰레드를 더하는건 재배치와 다른 반직관적 행동을 할 영역을 늘리게
되는데, 다음 섹션에서 이를 이야기 합니다.

\iffalse

It is tempting to speculate that different-sized overlapping loads
and stores to a single region of memory (as might be set up using
the C-language \co{union} keyword) would provide similar ordering
guarantees.
However, Flur et al.~\cite{Flur:2017:MCA:3093333.3009839} discovered some
surprisingly simple litmus tests that demonstrate that such guarantees
can be violated on real hardware.
It is therefore necessary to restrict code to non-overlapping
same-sized aligned accesses to a given variable, at least if portability
is a consideration.\footnote{
	There is reason to believe that using atomic RMW operations
	(for example, \co{xchg()}) for all the stores will
	provide sequentially consistent ordering, but this has not
	yet been proven either way.}

Adding more variables and threads increases the scope for reordering
and other counter-intuitive behavior, as discussed in the next section.

\fi

\subsection{Multicopy Atomicity}
\label{sec:memorder:Multicopy Atomicity}

\begin{figure}[tb]
\centering
\resizebox{3.0in}{!}{\includegraphics{memorder/SystemArchBus}}
\caption{Global System Bus And Multi-Copy Atomicity}
\label{fig:memorder:Global System Bus And Multi-Copy Atomicity}
\end{figure}

완벽히 \emph{multicopy atomic}~\cite{Stone:1995:SP:623262.623912} 플랫폼에서
수행되는 쓰레드는 스토어의 순서들에 대해 다른 변수들에 대해서조차 동의할 것이
보장됩니다.
그런 시스템에 대한 유용한 상상적 모델은
\cref{fig:memorder:Global System Bus And Multi-Copy Atomicity}
에 보인 단일 버스 아키텍쳐입니다.
만약 각 스토어가 버스 상의 메세지로 귀결된다면, 그리고 그 버스가 한번에 하나의
스토어만 수용할 수 있다면, 모든 CPU 쌍은 그들이 관측하는 모든 스토어의 순서에
대해 동의할 겁니다.
불행히도, 컴퓨터 시스템을 스토어 버퍼나 캐쉬조차 없이 이 그림에 보인대로
구축하는 것은 아주 느린 계산을 초래할 겁니다.
따라서 multicopy atomicity 를 제공하는데 관심 있는 대부분의 CPU 제조사는 그대신
모든 CPU 가 모든 스토어에 대한 순서에 동의해야 한다는 요구사항에서 해당
스토어를 가하는 CPU 는 배제하여 약간 더 완화된
\emph{other-multicopy atomicity}~\cite[Section B2.3]{ARMv8A:2017} 를
제공합니다.\footnote{
	2021년 초 기준으로, \ARMv8 과 x86 는 other-multicopy atomicity 를
	제공하고, IBM mainframe 은 완벽한 multicopy atomicity 를 제공하며, PPC
	는 어떤 multicopy atomicity 도 제공하지 않습니다.
	보다 자세한 내용은
	\cref{tab:memorder:Summary of Memory Ordering} 에 있습니다.}
이는 CPU 의 부분집합만이 스토어를 한다면, 다른 CPU 들은 스토어의 순서에
동의하며, 따라서 ``other-multicopy atomicity'' 에 ``other'' 가 붙었습니다.
Multicopy-atomic 플랫폼과 달리 other-multicopy-atomic 플랫폼에서는 스토어를
하는 CPU 는 자신의 스토어를 일찍 관측하는게 허용되는데, 이는 뒤따르는 로드가
스토어 버퍼에서 새로 저장된 값을 직접 보는게 가능하게 하여 성능을 개선합니다.

\iffalse

Threads running on a fully
\emph{multicopy atomic}~\cite{Stone:1995:SP:623262.623912}
platform are guaranteed
to agree on the order of stores, even to different variables.
A useful mental model of such a system is the single-bus architecture
shown in
\cref{fig:memorder:Global System Bus And Multi-Copy Atomicity}.
If each store resulted in a message on the bus, and if the bus could
accommodate only one store at a time, then any pair of CPUs would
agree on the order of all stores that they observed.
Unfortunately, building a computer system as shown in the figure, without
store buffers or even caches, would result in glacially slow computation.
Most CPU vendors interested in providing multicopy atomicity therefore
instead provide the slightly weaker
\emph{other-multicopy atomicity}~\cite[Section B2.3]{ARMv8A:2017},
which excludes the CPU doing a given store from the requirement that all
CPUs agree on the order of all stores.\footnote{
	As of early 2021, \ARMv8 and x86 provide other-multicopy atomicity,
	IBM mainframe provides full multicopy atomicity, and PPC
	provides no multicopy atomicity at all.
	More detail is shown in
	\cref{tab:memorder:Summary of Memory Ordering}.}
This means that if only a subset of CPUs are doing stores, the
other CPUs will agree on the order of stores, hence the ``other''
in ``other-multicopy atomicity''.
Unlike multicopy-atomic platforms, within other-multicopy-atomic platforms,
the CPU doing the store is permitted to observe its
store early, which allows its later loads to obtain the newly stored
value directly from the store buffer, which improves performance.

\fi

\QuickQuiz{
	Multicopy atomic 과 other-multicopy atomic 에서 다른 행동을 보이는
	구체적 예를 들어줄 수 있을까요?

	\iffalse

	Can you give a specific example showing different behavior for
	multicopy atomic on the one hand and other-multicopy atomic
	on the other?

	\fi

}\QuickQuizAnswer{
\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-MP-OMCA+o-o-o+o-rmb-o@whole.fcv}
\caption{Litmus Test Distinguishing Multicopy Atomic From Other Multicopy Atomic}
\label{lst:memorder:Litmus Test Distinguishing Multicopy Atomic From Other Multicopy Atomic}
\end{listing}%
%
	\Cref{lst:memorder:Litmus Test Distinguishing Multicopy Atomic From Other Multicopy Atomic}
	(\path{C-MP-OMCA+o-o-o+o-rmb-o.litmus})
	이 그런 테스트를 보입니다.

	\begin{fcvref}[ln:formal:C-MP-OMCA+o-o-o+o-rmb-o:whole]
	Multicopy-atomic 플랫폼에서, \co{P0()} 의 \clnref{P0:st} 에서의 \co{x}
	스토어는 \co{y} 로의 스토어 전에 \co{P1()} 을 포함한 모두에게 보여져야
	합니다.
	따라서, \co{P1()} 의 \clnref{P1:y} 에서의 \co{y} 로드가 값 1 을
	리턴한다면, \clnref{P1:x} 에서의 그것의 \co{x} 로드 그래야 하는데,
	\clnref{P1:rmb} 에서의 \co{smp_rmb()} 가 이 두 로드를 순서대로 수행되게
	하기 때문입니다.
	그러니, \clnref{exists} 의 \co{exists} 절은 multicopy-atomic 플랫폼에서
	발동될 수 없습니다.
	\end{fcvref}

	\iffalse

	\Cref{lst:memorder:Litmus Test Distinguishing Multicopy Atomic From Other Multicopy Atomic}
	(\path{C-MP-OMCA+o-o-o+o-rmb-o.litmus})
	shows such a test.

	\begin{fcvref}[ln:formal:C-MP-OMCA+o-o-o+o-rmb-o:whole]
	On a multicopy-atomic platform, \co{P0()}'s store to \co{x} on
	\clnref{P0:st} must become visible to both \co{P0()} and \co{P1()}
	simultaneously.
	Because this store becomes visible to \co{P0()} on \clnref{P0:ld}, before
	\co{P0()}'s store to \co{y} on \clnref{P0:y}, \co{P0()}'s store to
	\co{x} must become visible before its store to \co{y} everywhere,
	including \co{P1()}.
	Therefore, if \co{P1()}'s load from \co{y} on \clnref{P1:y} returns the
	value 1, so must its load from \co{x} on \clnref{P1:x}, given that
	the \co{smp_rmb()} on \clnref{P1:rmb} forces these two loads to execute
	in order.
	Therefore, the \co{exists} clause on \clnref{exists} cannot trigger on a
	multicopy-atomic platform.
	\end{fcvref}

	\fi

	반대로, other-multicopy-atomic 플랫폼에서 \co{P0()} 는 자신의 스토어를
	일찍 볼 수 있으며, 따라서 \co{P1()} 에서의 두 스토어의 가시성의
	순서에는 어떤 제약도 없어서 결과적으로 \co{exists} 절이 발동될 수
	있습니다.

	\iffalse

	In contrast, on an other-multicopy-atomic platform, \co{P0()}
	could see its own store early, so that there would be no constraint
	on the order of visibility of the two stores from \co{P1()},
	which in turn allows the \co{exists} clause to trigger.

	\fi

}\QuickQuizEnd

모든 플랫폼이 multi-copy atomicity 의 어떤 변종을 제공하는 날이 언젠가는
오겠지만, 그 전까지는 non-multicopy-atomic 플랫폼이 존재하므로 소프트웨어는
이를 처리해야 합니다.

\iffalse

Perhaps there will come a day when all platforms provide some flavor
of multi-copy atomicity, but
in the meantime, non-multicopy-atomic platforms do exist, and so software
must deal with them.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-WRC+o+o-data-o+o-rmb-o@whole.fcv}
\caption{WRC Litmus Test With Dependencies (No Ordering)}
\label{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
\end{listing}

\begin{fcvref}[ln:formal:C-WRC+o+o-data-o+o-rmb-o:whole]
\Cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
(\path{C-WRC+o+o-data-o+o-rmb-o.litmus})
이 multicopy atomicity 를 보이는데, 즉 multicopy-atomic 플랫폼에서
\clnref{exists} 의 \co{exists} 절은 발동될 수 없습니다.
대조적으로, non-multicopy-atomic 플랫폼에서 \co{P1()} 의 액세스가 데이터
종속성으로 순서 잡히고 \co{P2()} 의 액세스가 \co{smp_rmb()} 에 의해
순서잡힘에도 불구하고 \co{exists} 절은 발동될 수 있습니다.
Multicopy atomicity 의 정의는 모든 쓰레드가 스토어의 순서에 동의할 것을
요구하며 이는 모든 스토어가 모든 쓰레드에 동시에 도달하는 것으로 생각될 수
있습니다.
따라서, non-multicopy-atomic 플랫폼은 스토어가 다른 쓰레드에 다른 시간에 도달할
수 있게 합니다.
특히, \co{P0()} 의 스토어는 그게 \co{P2()} 에 도달하기 한참 전에 \co{P1()} 에
도달할 수도 있는데, 이는 \co{P1()} 의 스토어가 \co{P0()} 의 스토어가 도달하기
전에 \co{P2()} 에 도달할 수도 있을 가능성을 제기합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-WRC+o+o-data-o+o-rmb-o:whole]
\Cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
(\path{C-WRC+o+o-data-o+o-rmb-o.litmus})
demonstrates multicopy atomicity, that is, on a multicopy-atomic platform,
the \co{exists} clause on \clnref{exists} cannot trigger.
In contrast, on a non-multicopy-atomic
platform this \co{exists} clause can trigger, despite
\co{P1()}'s accesses being ordered by a data dependency and \co{P2()}'s
accesses being ordered by an \co{smp_rmb()}.
Recall that the definition of multicopy atomicity requires that all
threads agree on the order of stores, which can be thought of as
all stores reaching all threads at the same time.
Therefore, a non-multicopy-atomic platform can have a store reach
different threads at different times.
In particular, \co{P0()}'s store might reach \co{P1()} long before it
reaches \co{P2()}, which raises the possibility that \co{P1()}'s store
might reach \co{P2()} before \co{P0()}'s store does.
\end{fcvref}

\fi

\begin{figure}[tb]
\centering
\resizebox{3.0in}{!}{\includegraphics{memorder/NonMCAplatform}}
\caption{Shared Store Buffers And Multi-Copy Atomicity}
\label{fig:memorder:Shared Store Buffers And Multi-Copy Atomicity}
\end{figure}

이는 일반적인 물리법칙으로 제한되는 실제 시스템이 왜
\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
의 \co{exists} 절을 발동하지 않는지에 대한 질문을 자아냅니다.
그런 실제 시스템에 대한 만화적 그림이
\cref{fig:memorder:Shared Store Buffers And Multi-Copy Atomicity} 에 보입니다.
CPU~0 과 CPU~1 은 스토어 버퍼를 공유하며, CPU~2 와~3 도 마찬가지입니다.
이는 CPU~1 이 스토어 버퍼에서 값을 로드할 수 있으며, 따라서 CPU~0 이 스토어 한
값을 즉각 볼 가능성이 있습니다.
대조적으로, CPU~2 와~3 은 연관된 캐쉬 라인이 그들에게 넘어오기까지 기다려야
합니다.

\iffalse

This leads to the question of why a real system constrained by the
usual laws of physics would ever trigger the \co{exists} clause of
\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}.
The cartoonish diagram of a such a real system is shown in
\cref{fig:memorder:Shared Store Buffers And Multi-Copy Atomicity}.
CPU~0 and CPU~1 share a store buffer, as do CPUs~2 and~3.
This means that CPU~1 can load a value out of the store buffer, thus
potentially immediately seeing a value stored by CPU~0.
In contrast, CPUs~2 and~3 will have to wait for the corresponding cache
line to carry this new value to them.

\fi

\QuickQuiz{
	그럼 누가 공유된 스토어 버퍼를 갖는 시스템을 설계하려 \emph{생각이나}
	하겠나요???

	\iffalse

	Then who would even \emph{think} of designing a system with shared
	store buffers???

	\fi
	:
}\QuickQuizAnswer{
	이는 실제로 코어당 여러 하드웨어 쓰레드를 갖는 모든 시스템의 기본적
	설계입니다.
	하드웨어 관점에서는 자연스럽다는 겁니다!

	\iffalse

	This is in fact a very natural design for any system having
	multiple hardware threads per core.
	Natural from a hardware point of view, that is!

	\fi

}\QuickQuizEnd

\begin{table*}[tbp]
\small
\centering\OneColumnHSpace{-0.8in}
\renewcommand*{\arraystretch}{1.1}
\rowcolors{10}{}{lightgray}
\begin{tabular}{rlllllll}\toprule
	& \multicolumn{1}{c}{\tco{P0()}} & \multicolumn{2}{c}{\tco{P0()} \& \tco{P1()}} &
		\multicolumn{1}{c}{\tco{P1()}} & \multicolumn{3}{c}{\tco{P2()}} \\
	\cmidrule(l){2-2} \cmidrule(l){3-4} \cmidrule(lr){5-5} \cmidrule(l){6-8}
	& Instruction & Store Buffer & Cache & Instruction &
			Instruction & Store Buffer & Cache \\
	\cmidrule{1-1} \cmidrule(l){2-2} \cmidrule(l){3-4}
		\cmidrule(lr){5-5} \cmidrule(l){6-8}
	1 & (Initial state) & & \tco{y==0} &
		(Initial state) &
			(Initial state) & & \tco{x==0} \\
	2 & \tco{x = 1;} & \tco{x==1} & \tco{y==0} &
		 & & & \tco{x==0} \\
	3 & (Read-Invalidate \tco{x}) & \tco{x==1} & \tco{y==0} & \tco{r1 = x} (1)
		 & & & \tco{x==0} \\
	4 &  & \tco{x==1} \tco{y==1} & \tco{y==0} & \tco{y = r1}
		 & \tco{r2 = y} & & \tco{x==0} \\
	5 &  & \tco{x==1} & \tco{y==1} & (Finish store)
		 & (Read \tco{y}) & & \tco{x==0} \\
	6 & (Respond \tco{y}) & \tco{x==1} & \tco{y==1} &
		 & (\tco{r2==1}) & & \tco{x==0} \tco{y==1} \\
	7 & & \tco{x==1} & \tco{y==1} &
		 & \tco{smp_rmb()} & & \tco{x==0} \tco{y==1} \\
	8 & & \tco{x==1} & \tco{y==1} &
		 & \tco{r3 = x (0)} & & \tco{x==0} \tco{y==1} \\
	9 & & \tco{x==1} & \tco{x==0} \tco{y==1} &
		 & (Respond \tco{x}) & & \tco{y==1} \\
	10 & (Finish store) & & \tco{x==1} \tco{y==1} &
		 &  & & \tco{y==1} \\
	\bottomrule
\end{tabular}
\caption{Memory Ordering: WRC Sequence of Events}
\label{tab:memorder:Memory Ordering: WRC Sequence of Events}
\end{table*}

\Cref{tab:memorder:Memory Ordering: WRC Sequence of Events}
가
\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
의 \co{exists} 절을 발동시킬 수 있는 사건들의 순서를 보입니다.
이 사건들의 순서는 \co{P0()} 와 \co{P1()} 이 캐쉬와 스토어 버퍼를
\cref{fig:memorder:Shared Store Buffers And Multi-Copy Atomicity} 에 보인 것과
같은 방식으로 공유한다는데 의존적입니다.

\iffalse

\Cref{tab:memorder:Memory Ordering: WRC Sequence of Events}
shows one sequence of events that can result in the \co{exists} clause in
\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
triggering.
This sequence of events will depend critically on \co{P0()} and
\co{P1()} sharing both cache and a store buffer in the manner shown in
\cref{fig:memorder:Shared Store Buffers And Multi-Copy Atomicity}.

\fi

\QuickQuiz{
	그러나 \co{P0()} 와 \co{P1()} 은 스토어 버퍼와 캐쉬를 공유하지만
	\co{P2()} 는 자신만의 그것들을 하나씩 갖는다는건 공평하지 않지
	않나요???

	\iffalse

	But just how is it fair that \co{P0()} and \co{P1()} must share a store
	buffer and a cache, but \co{P2()} gets one each of its very own???

	\fi

}\QuickQuizAnswer{
	아마도
	\cref{fig:memorder:Shared Store Buffers And Multi-Copy Atomicity}
	에 보인 것처럼 \co{P2()} 의 스토어 버퍼와 캐쉬를 공유하는 \co{P3()} 가
	존재할 겁니다.
	하지만 꼭 그래야 하는건 아니죠.
	어떤 플랫폼은 다른 코어가 다른 수의 쓰레드를 불능화 시킬 수 있게 해서
	하드웨어가 워크로드의 필요에 맞춰 조정될 수 있게 합니다.
	예를 들어, 워크로드의 싱글쓰레드 기반 크리티컬 패쓰 부분은 하나의
	쓰레드만 켜져 있는 코어에 할당되어서 이 싱글쓰레드가 이 워크로드의
	부분이 해당 코어의 전체 능력을 사용하게 할 수 있습니다.
	워크로드의 다른 더 병렬적이지만 캐쉬 미스에 취약한 부분은 모든 하드웨어
	쓰레드가 켜져 있는 코어에 할당되어 더 나은 처리량을 제공할 수도 있을
	겁니다.
	이 향상된 처리량은 하나의 하드웨어 쓰레드는 캐쉬 미스로 인해 멈춰 있는
	동안 다른 하드웨어 쓰레드는 진전을 낼 수 있다는 사실 때문일 수
	있습니다.

	그런 경우, 성능 요구사항이 인간 관점의 공평성을 넘어섭니다.

	\iffalse

	Presumably there is a \co{P3()}, as is in fact shown in
	\cref{fig:memorder:Shared Store Buffers And Multi-Copy Atomicity},
	that shares \co{P2()}'s store buffer and cache.
	But not necessarily.
	Some platforms allow different cores to disable different numbers
	of threads, allowing the hardware to adjust to the needs of the
	workload at hand.
	For example, a single-threaded critical-path portion of the workload
	might be assigned to a core with only one thread enabled, thus
	allowing the single thread running that portion of the workload
	to use the entire capabilities of that core.
	Other more highly parallel but cache-miss-prone portions of the
	workload might be assigned to cores with all hardware threads
	enabled to provide improved throughput.
	This improved throughput could be due to the fact that while one
	hardware thread is stalled on a cache miss, the other hardware
	threads can make forward progress.

	In such cases, performance requirements override quaint human
	notions of fairness.

	\fi

}\QuickQuizEnd

\begin{fcvref}[ln:formal:C-WRC+o+o-data-o+o-rmb-o:whole]
첫번째 열은 초기 상태를 보이는데, \co{y} 의 초기값은 \co{P0()} 와 \co{P1()} 의
공유 캐쉬에 있으며 \co{x} 의 초기값은 \co{P2()} 의 캐쉬에 있습니다.

두번째 열은 \clnref{P0:x} 에서의 \co{P0()} 의 스토어의 즉각적 효과를 보입니다.
\co{x} 를 포함하는 캐쉬라인은 \co{P0()} 와 \co{P1()} 의 공유 캐쉬에 존재하지
않으므로 새 값 (\co{1}) 은 공유 스토어 버퍼에 저장됩니다.

세번째 열은 두 전환을 보입니다.
먼저, \co{P0()} 는 \co{x} 를 포함하는 캐쉬라인을 가져오기 위해 read-invalidate
오퍼레이션을 일으켜서 \co{x} 의 새 값을 공유 스토어 버퍼 밖으로 비워지게
합니다.
두번째로, \co{P1()} 은 \co{x} 를 로드하는데 (\clnref{P1:x}), \co{x} 의 새 값은
공유 스토어 버퍼에서 곧바로 얻을 수 있기 때문에 즉시 완료됩니다.

\iffalse

\begin{fcvref}[ln:formal:C-WRC+o+o-data-o+o-rmb-o:whole]
Row~1 shows the initial state, with the initial value of \co{y} in
\co{P0()}'s and \co{P1()}'s shared cache, and the initial value of \co{x} in
\co{P2()}'s cache.

Row~2 shows the immediate effect of \co{P0()} executing its store on \clnref{P0:x}.
Because the cacheline containing \co{x} is not in \co{P0()}'s and \co{P1()}'s
shared cache, the new value (\co{1}) is stored in the shared store buffer.

Row~3 shows two transitions.
First, \co{P0()} issues a read-invalidate operation to fetch the cacheline
containing \co{x} so that it can flush the new value for \co{x} out of
the shared store buffer.
Second, \co{P1()} loads from \co{x} (\clnref{P1:x}), an operation that completes
immediately because the new value of \co{x} is immediately available
from the shared store buffer.

\fi

네번째 열 역시 두개의 전환을 보입니다.
먼저, \co{P1()} 의 \co{y} 로의 스토어가 (\clnref{P1:y}) 즉각 효과를 발휘해 새
값을 공유 스토어 버퍼에 넣습니다.
두번째로, \co{P2()} 의 \co{y} 로드 시작을 보입니다 (\clnref{P2:y}).

다섯번째 열은 두 전환을 이어 보입니다.
먼저, \co{P1()} 이 \co{y} 스토어를 완료해서 공유 스토어 버퍼를 캐쉬로
비워냅니다.
두번째로, \co{P2()} 가 \co{y} 를 담는 캐쉬라인을 요청합니다.

여섯번째 열은 \co{P2()} 가 \co{y} 를 담는 캐쉬라인을 받는 걸 보이는데, 이는
\co{r2} 로의 로드를 마칠 수 있게 하는데, 여기선 값 \co{1} 을 얻게 됩니다.

일곱번째 열은 \co{P2()} 가 \co{smp_rmb()} 를 수행하는 것을 (\clnref{P2:rmb})
보이는데, 이로 인해 두 로드는 순서를 지킵니다.

여덟번째 열은 \co{P2()} 가 \co{x} 로드를 수행하는걸 보이는데, \co{P2()} 의
캐쉬에서 값 0을 즉각 가져옵니다.

\iffalse

Row~4 also shows two transitions.
First, it shows the immediate effect of \co{P1()} executing its store to
\co{y} (\clnref{P1:y}), placing the new value into the shared store buffer.
Second, it shows the start of \co{P2()}'s load from \co{y} (\clnref{P2:y}).

Row~5 continues the tradition of showing two transitions.
First, it shows \co{P1()} complete its store to \co{y}, flushing
from the shared store buffer to the cache.
Second, it shows \co{P2()} request the cacheline containing \co{y}.

Row~6 shows \co{P2()} receive the cacheline containing \co{y}, allowing
it to finish its load into \co{r2}, which takes on the value \co{1}.

Row~7 shows \co{P2()} execute its \co{smp_rmb()} (\clnref{P2:rmb}), thus keeping
its two loads ordered.

Row~8 shows \co{P2()} execute its load from \co{x}, which immediately
returns with the value zero from \co{P2()}'s cache.

\fi

아홉번째 열은 \co{P2()} 가 \emph{마침내} 세번째 열에서의 \co{P0()} 의 \co{x} 를
담는 캐쉬라인에 대한 요구에 응답함을 보입니다.

마지막으로, 열번째 열은 \co{P0()} 가 스토어를 마쳐서 \co{x} 에 대한 그것의 값을
공유 스토어 버퍼에서 공유 캐쉬로 비우는 것을 보입니다.

\Clnref{exists} 에서의 \co{exists} 절이 발동되었음을 유의하세요.
\co{r1} 와 \co{r2} 의 값은 모두 1이며, \co{r3} 의 마지막 값은 0입니다.
이 기묘한 결과는 \co{P0()} 의 \co{x} 의 새 값이 \co{P2()} 와의 통신 한참 전에
\co{P1()} 에게 소통되었기 때문에 발생했습니다.
\end{fcvref}

\iffalse

Row~9 shows \co{P2()} \emph{finally} responding to \co{P0()}'s request for
the cacheline containing \co{x}, which was made way back up on row~3.

Finally, row~10 shows \co{P0()} finish its store, flushing its value of
\co{x} from the shared store buffer to the shared cache.

Note well that the \co{exists} clause on \clnref{exists} has triggered.
The values of \co{r1} and \co{r2} are both the value one, and
the final value of \co{r3} the value zero.
This strange result occurred because \co{P0()}'s new value of \co{x} was
communicated to \co{P1()} long before it was communicated to \co{P2()}.
\end{fcvref}

\fi

\QuickQuiz{
	\begin{fcvref}[ln:formal:C-WRC+o+o-data-o+o-rmb-o:whole]
	\cref{tab:memorder:Memory Ordering: WRC Sequence of Events} 에서
	\co{P1()} 의 스토어에 비해 \co{P0()} 의 스토어는 대체 왜 그렇게 느렸던
	거죠?
	달리 말하자면,
	\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
	의 \clnref{exists} 에서의 \co{exists} 절은 실제 시스템에서 정말로
	발동되나요?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:formal:C-WRC+o+o-data-o+o-rmb-o:whole]
	Referring to
	\cref{tab:memorder:Memory Ordering: WRC Sequence of Events},
	why on earth would \co{P0()}'s store take so long to complete when
	\co{P1()}'s store complete so quickly?
	In other words, does the \co{exists} clause on \clnref{exists} of
	\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
	really trigger on real systems?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	이게 정말 발동될 수 있다는 진실을 받아들이십시오.
	Akira Yokosawa 는 이 리트머스 테스트를 \Power{8} 시스템에서 수행하기
	위해 \co{litmus7} 툴을 사용했습니다.
	1,000,000,000 회의 수행 중 4회 \co{exists} 절이 발동되었습니다.
	따라서, \co{exists} 절이 발동되는 것은 백만분의 일 확률이 아니고
	일억분의 일 확률입니다.
	그러나 이는 정말로 실제 시스템에서 발동됩니다.

	\iffalse

	You need to face the fact that it really can trigger.
	Akira Yokosawa used the \co{litmus7} tool to run this litmus test
	on a \Power{8} system.
	Out of 1,000,000,000 runs, 4 triggered the \co{exists} clause.
	Thus, triggering the \co{exists} clause is not merely a one-in-a-million
	occurrence, but rather a one-in-a-hundred-million occurrence.
	But it nevertheless really does trigger on real systems.

	\fi

}\QuickQuizEnd

종속성이 순서를 제공하지만 그건 각 쓰레드에 국한되기 때문에 이 반직관적인
결과가 발생합니다.
이 세개 쓰레드의 예는 더 강한 순서를 필요로 하는데, 그것이
\crefthro{sec:memorder:Cumulativity}
{sec:memorder:Release-Acquire Chains} 의 주제입니다.

\iffalse

This counter-intuitive result happens because although dependencies
do provide ordering, they provide it only within the confines of their
own thread.
This three-thread example requires stronger ordering, which
is the subject of
\crefthro{sec:memorder:Cumulativity}
{sec:memorder:Release-Acquire Chains}.

\fi

\subsubsection{Cumulativity}
\label{sec:memorder:Cumulativity}

\Cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
에 보인 세개 쓰레드의 예는 \emph{누적되는 (cumulative)} 순서, 또는
\emph{cumulativity} 를 필요로 합니다.
누적되는 메모리 순서 오퍼레이션은 그것을 앞서는 액세스만이 아니라 같은 변수에
대한 모든 쓰레드의 이전 액세스의 순서를 잡습니다.

\iffalse

The three-thread example shown in
\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}
requires \emph{cumulative} ordering, or \emph{cumulativity}.
A cumulative memory-ordering operation orders not just any given
access preceding it, but also earlier accesses by any thread to that
same variable.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-WRC+o+o-r+a-o@whole.fcv}
\caption{WRC Litmus Test With Release}
\label{lst:memorder:WRC Litmus Test With Release}
\end{listing}

종속성은 cumulativity 를 제공하지 않는데,
page~\pageref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet} 의
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet} 에 있는
\co{READ_ONCE()} 열의 ``C'' 칸이 비어있는 이유입니다.
그러나, ``C'' 칸의 ``C'' 로 나타내진 것처럼, release 오퍼레이션은 cumulativity
를 제공합니다.
따라서,
\cref{lst:memorder:WRC Litmus Test With Release}
(\path{C-WRC+o+o-r+a-o.litmus})
는
\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)} 의 데이터
종속성을 release 오퍼레이션으로 교체합니다.
\begin{fcvref}[ln:formal:C-WRC+o+o-r+a-o:whole]
Release 오퍼레이션은 cumulative 하므로 그 순서는
\cref{lst:memorder:WRC Litmus Test With Release} 의 \clnref{P1:x} 에서의
\co{P1()} 에 의한 \co{x} 로드만이 아니라 \clnref{P0:x} 에서의 \co{P0()} 의
\co{x} 스토어에도 순서가 적용됩니다---그러나 그 로드가 스토어 된 값을 반환했을
때만 그런데, 이는 \clnref{exists} 의 \co{exists} 절의 \co{1:r1=1} 과
맞아떨어집니다.
이는 \co{P2()} 의 load-acquire 가 \clnref{P2:x} 에서의 \co{x} 로드가
\clnref{P0:x} 에서의 스토어 뒤에 일어나게 강제하여, 반환된 값은 1이며,
\co{2:r3=0} 에 맞지 않게 되므로, 결국 \co{exists} 절이 발동되는걸 막습니다.
\end{fcvref}

\iffalse

Dependencies do not provide cumulativity,
which is why the ``C'' column is blank for the \co{READ_ONCE()} row
of \cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
on
page~\pageref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}.
However, as indicated by the ``C'' in their ``C'' column,
release operations do provide cumulativity.
Therefore,
\cref{lst:memorder:WRC Litmus Test With Release}
(\path{C-WRC+o+o-r+a-o.litmus})
substitutes a release operation for
\cref{lst:memorder:WRC Litmus Test With Dependencies (No Ordering)}'s
data dependency.
\begin{fcvref}[ln:formal:C-WRC+o+o-r+a-o:whole]
Because the release operation is cumulative, its ordering applies not only to
\cref{lst:memorder:WRC Litmus Test With Release}'s
load from \co{x} by \co{P1()} on \clnref{P1:x}, but also to the store to \co{x}
by \co{P0()} on \clnref{P0:x}---but only if that load returns the value stored,
which matches the \co{1:r1=1} in the \co{exists} clause on \clnref{exists}.
This means that \co{P2()}'s load-acquire suffices to force the
load from \co{x} on \clnref{P2:x} to happen after the store on \clnref{P0:x}, so
the value returned is one, which does not match \co{2:r3=0}, which
in turn prevents the \co{exists} clause from triggering.
\end{fcvref}

\fi

\begin{figure*}[tbp]
\centering
\includegraphics{memorder/memorybarriercum}
\caption{Cumulativity}
\label{fig:memorder:Cumulativity}
\end{figure*}

\begin{fcvref}[ln:formal:C-WRC+o+o-r+a-o:whole]
이 순서 규칙은
\cref{fig:memorder:Cumulativity} 에 그림으로 그려져 있습니다.
또한 cumulativity 는 시간상의 한 단계에만 제한되지 않음을 알아두세요.
\clnref{P0:x} 의 스토어 전에 어떤 쓰레드에 의해서든 \co{x} 로의 스토어나 로드가
있었다면 그 앞의 로드나 스토어는 \clnref{P2:x} 에서의 로드 전으로 순서잡힐
겁니다, \co{r1} 과 \co{r2} 가 둘 다 값 \co{1} 을 가지고 있을 경우에만 그렇긴
하지만요.
\end{fcvref}

요약하자면, cumulative 순서 오퍼레이션을 사용하는 것은 일부 상황에서
non-multicopy-atomic 행동을 제거할 수 있습니다.
그러나 cumulativity 역시 제한이 있는데, 다음 섹션에서 이를 알아봅니다.

\iffalse

\begin{fcvref}[ln:formal:C-WRC+o+o-r+a-o:whole]
These ordering constraints are depicted graphically in
\cref{fig:memorder:Cumulativity}.
Note also that cumulativity is not limited to a single step back in time.
If there was another load from \co{x} or store to \co{x} from any thread
that came before the store on \clnref{P0:x}, that prior load or store would also
be ordered before the load on \clnref{P2:x}, though only if both \co{r1} and
\co{r2} both end up containing the value \co{1}.
\end{fcvref}

In short, use of cumulative ordering operations can suppress
non-multicopy-atomic behaviors in some situations.
Cumulativity nevertheless has limits, which are examined in the next section.

\fi

\subsubsection{Propagation}
\label{sec:memorder:Propagation}

\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
\Cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
(\path{C-W+RWC+o-r+a-o+o-mb-o.litmus})
는 심지어 완전한 메모리 배리어가 있다 하더라도 발생하는 cumulativity 와
store-release 의 한계를 보입니다.
문제는 \clnref{P0:sr} 의 \co{smp_store_release()} 가 cumulativity 를 갖는다
해도, 그리고 그 cumulativity 가 \clnref{P2:ld} 의 \co{P2()} 의 로드를
순서잡는다 해도, \co{smp_store_release()} 의 순서는 \co{P1()} 의 로드
(\clnref{P1:ld}) 와 \co{P2()} 의 스토어 (\clnref{P2:st}) 를 거쳐 전파될 수
없다는 겁니다.
이는 \clnref{exists} 의 \co{exists} 절이 정말로 발동될 수 있음을 의미합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
\Cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
(\path{C-W+RWC+o-r+a-o+o-mb-o.litmus})
shows the limitations of cumulativity and store-release,
even with a full memory barrier.
The problem is that although the \co{smp_store_release()} on
\clnref{P0:sr} has cumulativity, and although that cumulativity does
order \co{P2()}'s load on \clnref{P2:ld}, the \co{smp_store_release()}'s
ordering cannot propagate through the combination of \co{P1()}'s
load (\clnref{P1:ld}) and \co{P2()}'s store (\clnref{P2:st}).
This means that the \co{exists} clause on \clnref{exists} really can trigger.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-W+RWC+o-r+a-o+o-mb-o@whole.fcv}
\caption{W+RWC Litmus Test With Release (No Ordering)}
\label{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
\end{listing}

\QuickQuiz{
	하지만 그 리트머스 테스트에 최소 세개의 쓰레드가 존재하지 않는다면
	전파에 대해선 걱정할 필요가 없을 거예요, 그렇죠?

	\iffalse

	But it is not necessary to worry about propagation unless
	there are at least three threads in the litmus test, right?

	\fi

}\QuickQuizAnswer{
\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-R+o-wmb-o+o-mb-o@whole.fcv}
\caption{R Litmus Test With Write Memory Barrier (No Ordering)}
\label{lst:memorder:R Litmus Test With Write Memory Barrier (No Ordering)}
\end{listing}%
%
	틀렸습니다.

	\begin{fcvref}[ln:formal:C-R+o-wmb-o+o-mb-o:whole]
	\Cref{lst:memorder:R Litmus Test With Write Memory Barrier (No Ordering)}
	(\path{C-R+o-wmb-o+o-mb-o.litmus})
	가 한쌍의 쓰레드 사이에 store-to-store 와 load-to-store 연결만이
	존재하기 때문에 전파를 필요로 하는 두개 쓰레드 리트머스 테스트를
	보입니다.
	\co{P0()} 가 \co{smp_wmb()} 를 사용하고 \co{P1()} 이 \co{smp_mb()} 를
	사용해 완전하게 순서잡혀 있지만, 일시적이지 않은 연결의 본성은
	\clnref{exists} 의 \co{exists} 절이 정말 발동될 수 있음을 의미합니다.
	이 발동을 막으려면, \clnref{wmb} 의 \co{smp_wmb()} 는 \co{smp_mb()} 가
	되어서 각 임시적이지 않은 연결에 한번씩 해서 두번 전파가 이루어지게
	해야 합니다.
	\end{fcvref}

	\iffalse


	Wrong.

	\begin{fcvref}[ln:formal:C-R+o-wmb-o+o-mb-o:whole]
	\Cref{lst:memorder:R Litmus Test With Write Memory Barrier (No Ordering)}
	(\path{C-R+o-wmb-o+o-mb-o.litmus})
	shows a two-thread litmus test that requires propagation due to
	the fact that it only has store-to-store and load-to-store
	links between its pair of threads.
	Even though \co{P0()} is fully ordered by the \co{smp_wmb()} and
	\co{P1()} is fully ordered by the \co{smp_mb()}, the
	counter-temporal nature of the links means that
	the \co{exists} clause on \clnref{exists} really can trigger.
	To prevent this triggering, the \co{smp_wmb()} on \clnref{wmb}
	must become an \co{smp_mb()}, bringing propagation into play
	twice, once for each non-temporal link.
	\end{fcvref}

	\fi

}\QuickQuizEnd

\QuickQuizLabel{\MemorderQQLitmusTestR}

\begin{figure}[tbp]
\centering
\resizebox{\twocolumnwidth}{!}{\includegraphics{memorder/fr}}
\caption{Load-to-Store is Counter-Temporal}
\label{fig:memorder:Load-to-Store is Counter-Temporal}
\end{figure}

이 상황이 완전히 반직관적으로 보일 수도 있겠습니다만, 빛의 속도는 유한하고
컴퓨터의 크기는 0이 아님을 기억하세요.
따라서 \co{P2()} 의 \co{z} 로의 스토어의 효과가 \co{P1()} 에 전파되기 위해선
시간이 걸리며, 이는 \co{P1()} 의 \co{z} 읽기가 훨씬 나중에 이루어질 수 있으나
여전히 과거 값인 0을 읽을 수 있음을 의미합니다.
이 상황은
\cref{fig:memorder:Load-to-Store is Counter-Temporal} 에 보여져 있습니다:
로드가 이전 값을 봄은 이 로드가 새 값의 스토어보다 시간상으로 먼저 이루어졌음을
의미하지 \emph{않습니다}.

\iffalse

This situation might seem completely counter-intuitive, but keep
in mind that the speed of light is finite and computers are of
non-zero size.
It therefore takes time for the effect of the \co{P2()}'s store to
\co{z} to propagate to \co{P1()}, which in turn means that it is possible
that \co{P1()}'s read from \co{z} happens much later in time, but
nevertheless still sees the old value of zero.
This situation is depicted in
\cref{fig:memorder:Load-to-Store is Counter-Temporal}:
Just because a load sees the old value does \emph{not} mean that
this load executed at an earlier time than did the store of the
new value.

\fi

\Cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
또한 두개가 아닌 세개의 프로세스가 존재할 때의 메모리 배리어 짝 맞추기 한계를
보입니다.
이 더 복잡한 리트머스 테스트는 \emph{사이클} 이 존재한다고도 말해질 수 있는데,
메모리 배리어 짝맞추기는 두개 쓰레드 사이클의 특수한 경우입니다.
\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
\Cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)} 의 사이클은
\co{P0()} (\clnref{P0:st, P0:sr}), \co{P1()} (\clnref{P1:la,P1:ld}), \co{P2()}
(\clnref{P2:st,P2:mb,P2:ld}), 그리고 다시 \co{P0()} (\clnref{P0:st}) 를 거쳐
이루어집니다.
\co{exists} 절이 이 사이클을 파악합니다:
\co{1:r1=1} 은 \clnref{P1:la} 에서의 \co{smp_load_acquire()} 이 \clnref{P0:sr}
에서의 \co{smp_store_release()} 에 의해 저장된 값을 반환했음을 의미하고,
\co{1:r2=0} 는 \clnref{P2:st} 에서의 \co{WRITE_ONCE()} 가 \clnref{P1:ld} 에서의
\co{READ_ONCE()} 에 의해 반환된 값에 영향을 미치기엔 너무 늦게 이루어졌으며
마지막으로 \co{2:r3=0} 가 \clnref{P0:st} 에서의 \co{WRITE_ONCE()} 는
\clnref{P2:ld} 에서의 \co{READ_ONCE()} 에 의해 반환되는 값에 영향을 끼치기엔
너무 늦었음을 나타냅니다.
이 경우, \co{exists} 절이 발동될 수 있다는 사실은 이 사이클이 \emph{허가}
되었음을 의미합니다.
대조적으로, \co{exists} 절이 발동될 수 없는 경우에는 사이클이 \emph{금지}
되었다고 말해집니다.
\end{fcvref}

\iffalse

Note that
\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
also shows the limitations of memory-barrier pairing, given that
there are not two but three processes.
These more complex litmus tests can instead be said to have \emph{cycles},
where memory-barrier pairing is the special case of a two-thread cycle.
\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
The cycle in
\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
goes through \co{P0()} (\clnref{P0:st,P0:sr}), \co{P1()} (\clnref{P1:la,P1:ld}),
\co{P2()} (\clnref{P2:st,P2:mb,P2:ld}), and back to \co{P0()} (\clnref{P0:st}).
The \co{exists} clause delineates this cycle:
the \co{1:r1=1} indicates that the \co{smp_load_acquire()} on \clnref{P1:la}
returned the value stored by the \co{smp_store_release()} on \clnref{P0:sr},
the \co{1:r2=0} indicates that the \co{WRITE_ONCE()} on \clnref{P2:st} came
too late to affect the value returned by the \co{READ_ONCE()} on \clnref{P1:ld},
and finally the \co{2:r3=0} indicates that the
\co{WRITE_ONCE()} on \clnref{P0:st} came too late to affect the value returned
by the \co{READ_ONCE()} on \clnref{P2:ld}.
In this case, the fact that the \co{exists} clause can trigger means that
the cycle is said to be \emph{allowed}.
In contrast, in cases where the \co{exists} clause cannot trigger,
the cycle is said to be \emph{prohibited}.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-W+RWC+o-mb-o+a-o+o-mb-o@whole.fcv}
\caption{W+WRC Litmus Test With More Barriers}
\label{lst:memorder:W+WRC Litmus Test With More Barriers}
\end{listing}

\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
하지만
\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}?
의 \clnref{exists} 에 있는 \co{exists} 절을 유지해야 한다면 어떻게 될까요?
한가지 방법은 \co{P0()} 의 \co{smp_store_release()} 를
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
이 cumulativity 만이 아니라 전파 (propagation) 도 갖는다고 말하는 \co{smp_mb()}
로 교체하는 것입니다.
\end{fcvref}
그 결과는
\cref{lst:memorder:W+WRC Litmus Test With More Barriers}
(\path{C-W+RWC+o-mb-o+a-o+o-mb-o.litmus}) 에 보여져 있습니다.

\iffalse

\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
But what if we need to keep the \co{exists} clause on \clnref{exists} of
\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}?
One solution is to replace \co{P0()}'s \co{smp_store_release()}
with an \co{smp_mb()}, which
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
shows to have not only cumulativity, but also propagation.
\end{fcvref}
The result is shown in
\cref{lst:memorder:W+WRC Litmus Test With More Barriers}
(\path{C-W+RWC+o-mb-o+a-o+o-mb-o.litmus}).

\fi

\QuickQuiz{
	\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
	\co{smp_mb()} 가 전파 속성을 갖는데 왜
	\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
	의 \clnref{P2:mb} 에 있는 \co{smp_mb()} 는 왜 \co{exists} 절의 발동을
	막지 않죠?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
	But given that \co{smp_mb()} has the propagation property,
	why doesn't the \co{smp_mb()} on \clnref{P2:mb} of
	\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
	prevent the \co{exists} clause from triggering?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
	대략적 경험적 법칙으로써, \co{smp_mb()} 배리어의 전파 속성은 프로세스
	간의 하나의 load-to-store 연결에만 순서를 유지하기에 충분합니다.
	불행히도,
	\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
	는 하나가 아닌 두개의 load-to-store 링크를 갖는데, 첫번째는
	\clnref{P1:ld} 에서의 \co{READ_ONCE()} 로부터 \clnref{P2:st} 의
	\co{WRITE_ONCE()} 로의 것이며 두번째 것은 \clnref{P2:ld} 의
	\co{READ_ONCE()} 로부터 \clnref{P0:st} 의 \co{WRITE_ONCE()} 로의
	것입니다.
	따라서, \co{exists} 절의 발동을 막기 위해선 하나가 아닌 두개의
	\co{smp_mb()} 가 필요합니다.
	\end{fcvref}

	이 경험적 법치에 대한 특수한 예외로, release-acquire 연결은 프로세스
	간에 하나의 load-to-store 링크를 가질 수 있어서 여전히 사이클을 막을 수
	있습니다.

	\iffalse

	\begin{fcvref}[ln:formal:C-W+RWC+o-r+a-o+o-mb-o:whole]
	As a rough rule of thumb, the \co{smp_mb()} barrier's
	propagation property is sufficient to maintain ordering
	through only one load-to-store link between
	processes.
	Unfortunately,
	\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}
	has not one but two load-to-store links, with the
	first being from the \co{READ_ONCE()} on \clnref{P1:ld} to the
	\co{WRITE_ONCE()} on \clnref{P2:st} and the second being from
	the \co{READ_ONCE()} on \clnref{P2:ld} to the \co{WRITE_ONCE()}
	on \clnref{P0:st}.
	Therefore, preventing the \co{exists} clause from triggering
	should be expected to require not one but two
	instances of \co{smp_mb()}.
	\end{fcvref}

	As a special exception to this rule of thumb, a release-acquire
	chain can have one load-to-store link between processes
	and still prohibit the cycle.

	\fi

}\QuickQuizEnd

\begin{figure}[tbp]
\centering
\resizebox{\twocolumnwidth}{!}{\includegraphics{memorder/co}}
\caption{Store-to-Store is Counter-Temporal}
\label{fig:memorder:Store-to-Store is Counter-Temporal}
\end{figure}

완벽성을 위해,
\cref{fig:memorder:Store-to-Store is Counter-Temporal}
는 동일한 변수로의 스토어 그룹들 가운데 ``이기는'' 스토어가 가장 나중에 시작된
스토어일 필요는 없음을 보입니다.
이는
page~\pageref{fig:memorder:A Variable With More Simultaneous Values} 의
\cref{fig:memorder:A Variable With More Simultaneous Values}
를 주의 깊게 본 사람에겐 놀랍지 않을 겁니다.

\iffalse

For completeness,
\cref{fig:memorder:Store-to-Store is Counter-Temporal}
shows that the ``winning'' store among a group of stores to the
same variable is not necessarily the store that started last.
This should not come as a surprise to anyone who carefully examined
\cref{fig:memorder:A Variable With More Simultaneous Values}
on
page~\pageref{fig:memorder:A Variable With More Simultaneous Values}.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-2+2W+o-wmb-o+o-wmb-o@whole.fcv}
\caption{2+2W Litmus Test With Write Barriers}
\label{lst:memorder:2+2W Litmus Test With Write Barriers}
\end{listing}

\QuickQuiz{
	하지만
	\cref{lst:memorder:2+2W Litmus Test With Write Barriers}
	(\path{C-2+2W+o-wmb-o+o-wmb-o.litmus}) 에 보인 것처럼 순서잡힌 스토어만
	갖는 리트머스 테스트에서, 연구자들은 \ARM\ 과 Power 같은 완화된 순서
	규칙의 시스템에서도 사이클이 금지됨을 보였습니다~\cite{test6-pdf}.
	그런데 store-to-store 가 정말 \emph{항상} 임시적이지 않나요???

	\iffalse

	But for litmus tests having only ordered stores, as shown in
	\cref{lst:memorder:2+2W Litmus Test With Write Barriers}
	(\path{C-2+2W+o-wmb-o+o-wmb-o.litmus}),
	research shows that the cycle is prohibited, even in weakly
	ordered systems such as \ARM\ and Power~\cite{test6-pdf}.
	Given that, are store-to-store really \emph{always}
	counter-temporal???

	\fi

}\QuickQuizAnswer{
	이 리트머스 테스트는 실제로 매우 흥미롭습니다.
	이것의 순서는 일반적인 완화된 순서 규칙 하드웨어 설계에서도 자연스럽게
	이루어지는 것으로 보인느데, 이는 연관된 물리 법칙과 캐쉬 일관성
	프로토콜 수학으로부터의 소중한 선물로 여겨질 수 있겠습니다.

	\begin{fcvref}[ln:formal:C-2+2W+o-wmb-o+o-wmb-o:whole]
	불행히도, 훨씬 나은 대안적 구현을 갖는 이 선물을 위한 소프트웨어
	사용처를 누구도 찾지 못했습니다.
	따라서, C11 도 리눅스 커널 메모리 모델도
	\cref{lst:memorder:2+2W Litmus Test With Write Barriers} 에 연관된 어떤
	보장을 제공하지 않습니다.
	이는 \clnref{exists} 의 \co{exists} 절이 발동될 수 있음을 의미합니다.
	\end{fcvref}

	\iffalse

	This litmus test is indeed a very interesting curiosity.
	Its ordering apparently occurs naturally given typical
	weakly ordered hardware design, which would normally be
	considered a great gift from the relevant laws of physics
	and cache-coherency-protocol mathematics.

	\begin{fcvref}[ln:formal:C-2+2W+o-wmb-o+o-wmb-o:whole]
	Unfortunately, no one has been able to come up with a software use
	case for this gift that does not have a much better alternative
	implementation.
	Therefore, neither the C11 nor the Linux kernel memory models
	provide any guarantee corresponding to
	\cref{lst:memorder:2+2W Litmus Test With Write Barriers}.
	This means that the \co{exists} clause on \clnref{exists} can
	trigger.
	\end{fcvref}

	\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-2+2W+o-o+o-o@whole.fcv}
\caption{2+2W Litmus Test (No Ordering)}
\label{lst:memorder:2+2W Litmus Test (No Ordering)}
\end{listing}

	물론, 배리어 없이는 순서 보장도 없는데
	\cref{lst:memorder:2+2W Litmus Test (No Ordering)}
	(\path{C-2+2W+o-o+o-o.litmus}) 에 보인 것처럼 실제 완화된 순서 규칙의
	하드웨어에서조차 그렇습니다.

	\iffalse

	Of course, without the barrier, there are no ordering
	guarantees, even on real weakly ordered hardware, as shown in
	\cref{lst:memorder:2+2W Litmus Test (No Ordering)}
	(\path{C-2+2W+o-o+o-o.litmus}).

	\fi

}\QuickQuizEnd

하지만 가끔 시간은 우리 편입니다.  계속 읽으세요!

\iffalse

But sometimes time really is on our side.  Read on!

\fi

\subsubsection{Happens-Before}
\label{sec:memorder:Happens-Before}

\begin{figure}[tbp]
\centering
\resizebox{\twocolumnwidth}{!}{\includegraphics{memorder/rf}}
\caption{Store-to-Load is Temporal}
\label{fig:memorder:Store-to-Load is Temporal}
\end{figure}

\Cref{fig:memorder:Store-to-Load is Temporal} 에 보인 것처럼, 사용자에게 보이는
예측이 없는 플랫폼에서 로드가 특정 스토어로부터의 값을 리턴하면 빛의 유한한
속도와 현대 컴퓨팅 시스템의 크기 존재 덕분에 그 스토어는 로드가 행해진 것보다
이른 시간에 수행되었어야만 합니다.
이는 주의 깊게 짜여진 프로그램은 시간의 흐름 자체를 메모리 순서 오퍼레이션으로
사용하여 의존할 수 있음을 의미합니다.

\iffalse

As shown in
\cref{fig:memorder:Store-to-Load is Temporal},
on platforms without user-visible speculation, if a load returns the value
from a particular store, then, courtesy of the finite speed of light and
the non-zero size of modern computing systems, the store absolutely has
to have executed at an earlier time than did the load.
This means that carefully constructed programs can rely on the
passage of time itself as an memory-ordering operation.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-LB+a-o+o-data-o+o-data-o@whole.fcv}
\caption{LB Litmus Test With One Acquire}
\label{lst:memorder:LB Litmus Test With One Acquire}
\end{listing}

물론, 스토어에서 로드로의 연결 외에는 아무것도 없는
page~\pageref{lst:memorder:Load-Buffering Litmus Test (No Ordering)} 의
\cref{lst:memorder:Load-Buffering Litmus Test (No Ordering)}
에서 보이는 것처럼 시간의 흐름 그자체만으로는 충분치 않은데, 이는 어떤 순서도
제공하지 않아서 여전히 \co{exists} 절을 발동시킬 수 있기 때문입니다.
그러나, 각 쓰레드가 가장 약한 순서만 제공할 때라도 \co{exists} 절은 발동될 수
없습니다.
예를 들어,
\cref{lst:memorder:LB Litmus Test With One Acquire}
(\path{C-LB+a-o+o-data-o+o-data-o.litmus})
는 \co{P0()} 가 \co{smp_load_acquire()} 로 순서잡히고 \co{P1()} 과 \co{P2()} 가
모두 데이터 종속성으로 순서잡힌 걸 보입니다.
\Cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet} 의 가장 위에 보인
것과 비슷한 이 순서 규칙들은 \co{exists} 절이 발동되는 걸 막기 충분합니다.

\iffalse

Of course, just the passage of time by itself is not enough, as
was seen in
\cref{lst:memorder:Load-Buffering Litmus Test (No Ordering)}
on
page~\pageref{lst:memorder:Load-Buffering Litmus Test (No Ordering)},
which has nothing but store-to-load links and, because it provides
absolutely no ordering, still can trigger its \co{exists} clause.
However, as long as each thread provides even the weakest possible
ordering, \co{exists} clause would not be able to trigger.
For example,
\cref{lst:memorder:LB Litmus Test With One Acquire}
(\path{C-LB+a-o+o-data-o+o-data-o.litmus})
shows \co{P0()} ordered with an \co{smp_load_acquire()} and
both \co{P1()} and \co{P2()} ordered with data dependencies.
These orderings, which are close to the top of
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet},
suffice to prevent the \co{exists} clause from triggering.

\fi

\QuickQuiz{
	\Cref{lst:memorder:LB Litmus Test With One Acquire}
	에 보인 것과 같은 종속성 \emph{만을} 사용하는 리트머스 테스트를 만들 수
	있습니까?

	\iffalse

	Can you construct a litmus test like that in
	\cref{lst:memorder:LB Litmus Test With One Acquire}
	that uses \emph{only} dependencies?

	\fi

}\QuickQuizAnswer{
	\Cref{lst:memorder:LB Litmus Test With No Acquires}
	는 무의미하지만 매우 실제적인 예입니다.
	더 유용한 (그러나 여전히 실제적인) 리트머스 테스트를 만드는 건 독자
	여러분의 몫으로 남겨둡니다.

	\iffalse

	\Cref{lst:memorder:LB Litmus Test With No Acquires}
	shows a somewhat nonsensical but very real example.
	Creating a more useful (but still real) litmus test is left
	as an exercise for the reader.

	\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-LB+o-data-o+o-data-o+o-data-o@whole.fcv}
\caption{LB Litmus Test With No Acquires}
\label{lst:memorder:LB Litmus Test With No Acquires}
\end{listing}
}\QuickQuizEnd

메모리 액세스를 순서잡기 위한 더 중요한 시간의 사용은 다음 섹션에서
다루어집니다.

\iffalse

An important use of time for ordering memory accesses is covered in the
next section.

\fi

\subsubsection{Release-Acquire Chains}
\label{sec:memorder:Release-Acquire Chains}

최소한의 release-acquire 연결이
page~\pageref{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test}
의
\cref{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test}
에 보여 있습니다만, 이 연결은
\cref{lst:memorder:Long LB Release-Acquire Chain}
(\path{C-LB+a-r+a-r+a-r+a-r.litmus})
에 보인 것처럼 훨씬 더 길어질 수 있습니다.
이 release-acquire 연결이 더 길어질수록, 시간의 흐름으로부터 더 많은 순서가
얻어져서 얼마나 많은 쓰레드가 연관되는지에 관계 없이 연관된 \co{exists} 절은
발동될 수 없습니다.

\iffalse

A minimal release-acquire chain was shown in
\cref{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test}
on
page~\pageref{lst:memorder:Enforcing Ordering of Load-Buffering Litmus Test},
but these chains can be much longer, as shown in
\cref{lst:memorder:Long LB Release-Acquire Chain}
(\path{C-LB+a-r+a-r+a-r+a-r.litmus}).
The longer the release-acquire chain, the more ordering is gained
from the passage of time, so that no matter how many threads are
involved, the corresponding \co{exists} clause cannot trigger.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-LB+a-r+a-r+a-r+a-r@whole.fcv}
\caption{Long LB Release-Acquire Chain}
\label{lst:memorder:Long LB Release-Acquire Chain}
\end{listing}

Release-acquire 연결은 본성적으로 스토어에서 로드로의 생성체이지만, 하나의
로드로부터 스토어로의 단계를 허용할 수 있음이, 그런 단계는 반-임시적이어야 하긴
하지만,
page~\pageref{fig:memorder:Load-to-Store is Counter-Temporal} 의
\cref{fig:memorder:Load-to-Store is Counter-Temporal}
에 보인 것처럼 드러났습니다.
예를 들어,
\cref{lst:memorder:Long ISA2 Release-Acquire Chain}
(\path{C-ISA2+o-r+a-r+a-r+a-o.litmus})
는 세 단계 release-acquire 연결을 보입니다만, \co{P3()} 의 마지막 액세스는
\co{x0} 로부터의 \co{READ_ONCE()} 인데, 이는 \co{P0()} 의 \co{WRITE_ONCE()} 에
의해 액세스되는 것이어서 반 임시적인 로드에서 스토어로의 연결을 이 두 프로세스
사이에 만듭니다.
\begin{fcvref}[ln:formal:litmus:C-ISA2+o-r+a-r+a-r+a-o:whole]
그러나, \co{P0()} 의 \co{smp_store_release()} (\clnref{P0:rel}) 은 cumulative
하므로, \co{P3()} 의 \co{READ_ONCE()} 가 0을 리턴했다면, 이 cumulativity 는
\co{READ_ONCE()} 가 \co{P0()} 의 \co{smp_store_release()} 전으로 순서 잡힐 것을
강제합니다.
더해서, 이 release-acquire 연결은
(\clnref{P0:rel,P1:acq,P1:rel,P2:acq,P2:rel,P3:acq})
\co{P3()} 의 \co{READ_ONCE()} 가 \co{P0()} 의 \co{smp_store_release()} 뒤로
순서잡히게 강제합니다.
\co{P3()} 의 \co{READ_ONCE()} 는 \co{P0()} 의 \co{smp_store_release()} 전후에
다 있을 수 는 없으므로, 둘 중 하나는 사실이어야 합니다:
\end{fcvref}

\iffalse

Although release-acquire chains are inherently store-to-load creatures,
it turns out that they can tolerate one load-to-store step, despite
such steps being counter-temporal, as shown in
\cref{fig:memorder:Load-to-Store is Counter-Temporal}
on
page~\pageref{fig:memorder:Load-to-Store is Counter-Temporal}.
For example,
\cref{lst:memorder:Long ISA2 Release-Acquire Chain}
(\path{C-ISA2+o-r+a-r+a-r+a-o.litmus})
shows a three-step release-acquire chain, but where \co{P3()}'s
final access is a \co{READ_ONCE()} from \co{x0}, which is
accessed via \co{WRITE_ONCE()} by \co{P0()}, forming a non-temporal
load-to-store link between these two processes.
\begin{fcvref}[ln:formal:litmus:C-ISA2+o-r+a-r+a-r+a-o:whole]
However, because \co{P0()}'s \co{smp_store_release()} (\clnref{P0:rel})
is cumulative, if \co{P3()}'s \co{READ_ONCE()} returns zero,
this cumulativity will force the \co{READ_ONCE()} to be ordered
before \co{P0()}'s \co{smp_store_release()}.
In addition, the release-acquire chain
(\clnref{P0:rel,P1:acq,P1:rel,P2:acq,P2:rel,P3:acq})
forces \co{P3()}'s \co{READ_ONCE()} to be ordered after \co{P0()}'s
\co{smp_store_release()}.
Because \co{P3()}'s \co{READ_ONCE()} cannot be both before and after
\co{P0()}'s \co{smp_store_release()}, either or both of two things must
be true:
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-ISA2+o-r+a-r+a-r+a-o@whole.fcv}
\caption{Long ISA2 Release-Acquire Chain}
\label{lst:memorder:Long ISA2 Release-Acquire Chain}
\end{listing}

\begin{enumerate}
\item	\co{P3()} 의 \co{READ_ONCE()} 는 \co{P0()} 의 \co{WRITE_ONCE()} 다음에
	왔어서, \co{READ_ONCE()} 는 값 2를 반환했어서, \co{exists} 절의
	\co{3:r2=0} 는 거짓입니다.
\item	이 release-acquire 연결은 이루어지지 않아서, 즉 \co{exists} 절의
	\co{1:r2=2}, \co{2:r2=2}, 또는 \co{3:r1=2} 는 거짓입니다.

\iffalse

\item	\co{P3()}'s \co{READ_ONCE()} came after \co{P0()}'s
	\co{WRITE_ONCE()}, so that the \co{READ_ONCE()} returned
	the value two, so that the \co{exists} clause's \co{3:r2=0}
	is false.
\item	The release-acquire chain did not form, that is, one or more
	of the \co{exists} clause's \co{1:r2=2}, \co{2:r2=2}, or \co{3:r1=2}
	is false.

\fi

\end{enumerate}

어느 쪽이든, \co{exists} 절은 발동될 수 없는데, 이 리트머스 테스트가 악명높은
로드에서 스토어로의 연결을 \co{P3()} 와 \co{P0()} 사이에 가지고 있음에도
그렇습니다.
그러나 release-acquire 연결은
\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)} 에 보인 것처럼
하나의 로드에서 스토어로의 연결만을 가질 수 있음을 결코 잊지 마십시오.

\iffalse

Either way, the \co{exists} clause cannot trigger, despite this litmus
test containing a notorious load-to-store link between
\co{P3()} and \co{P0()}.
But never forget that release-acquire chains can tolerate only one
load-to-store link, as was seen in
\cref{lst:memorder:W+RWC Litmus Test With Release (No Ordering)}.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-Z6.2+o-r+a-r+a-r+a-o@whole.fcv}
\caption{Long Z6.2 Release-Acquire Chain}
\label{lst:memorder:Long Z6.2 Release-Acquire Chain}
\end{listing}

Release-acquire 연결은 또한
\cref{lst:memorder:Long Z6.2 Release-Acquire Chain}
(\path{C-Z6.2+o-r+a-r+a-r+a-o.litmus}) 에 보인 것처럼 하나의 스토어에서
스토어로의 단계 하나를 허용할 수 있습니다.
\begin{fcvref}[ln:formal:C-Z6.2+o-r+a-r+a-r+a-o:whole]
앞의 예에서와 같이, \co{smp_store_release()} 의 cumulativity 가 release-acquire
연결이 임시적 본성과 결합되어 \clnref{exists} 의 \co{exists} 절이 발동되는 것을
막습니다.
하지만 주의하세요: 두번째 스토어에서 스토어로의 단계를 더하는 것은 연관된
업데이트된 \co{exists} 절이 발동되는 걸 허가할 수 있습니다.
\end{fcvref}

\iffalse

Release-acquire chains can also tolerate a single store-to-store step,
as shown in
\cref{lst:memorder:Long Z6.2 Release-Acquire Chain}
(\path{C-Z6.2+o-r+a-r+a-r+a-o.litmus}).
\begin{fcvref}[ln:formal:C-Z6.2+o-r+a-r+a-r+a-o:whole]
As with the previous example, \co{smp_store_release()}'s cumulativity
combined with the temporal nature of the release-acquire chain
prevents the \co{exists} clause on \clnref{exists} from triggering.
But beware: Adding a second store-to-store step would allow the correspondingly
updated \co{exists} clause to trigger.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-Z6.2+o-r+a-o+o-mb-o@whole.fcv}
\caption{Z6.0 Release-Acquire Chain (Ordering?)}
\label{lst:memorder:Z6.0 Release-Acquire Chain (Ordering?)}
\end{listing}

\QuickQuizSeries{%
\QuickQuizB{
	\Cref{lst:memorder:Z6.0 Release-Acquire Chain (Ordering?)}
	에 보인 것처럼 우리가 하나의 로드에서 스토어로의 연결과 하나의
	스토어에서 스토어로의 링크와 함께 짧은 release-acquire 연결을 갖는다고
	해봅시다.
	스토어에서 로드로의 연결이 아닌 종류의 것은 하나씩만 있으므로
	\co{exists} 는 발동될 수 없습니다, 맞죠?

	\iffalse

	Suppose we have a short release-acquire chain along with one
	load-to-store link and one store-to-store link, like that shown in
	\cref{lst:memorder:Z6.0 Release-Acquire Chain (Ordering?)}.
	Given that there is only one of each type of non-store-to-load
	link, the \co{exists} cannot trigger, right?

	\fi

}\QuickQuizAnswerB{
	틀렸습니다.
	중요한 건 스토어에서 로드로의 것이 아닌 연결들의 갯수입니다.
	단 하나의 스토어에서 로드로의 것이 아닌 연결이 있다면, release-acquire
	연결은 \co{exists} 절이 발동되는 걸 막을 수 있습니다.
	그러나, 두개 이상의 스토어에서 로드로의 것이 아닌 연결이 있다면 그게
	스토어에서 스토어로든 로드에서 스토어로든 또는 어떤 조합이든간에 각
	스토어에서 로드로의 것이 아닌 연결 사이에 완전한 배리어 (\co{smp_mb()}
	또는 그보다 나은 것) 가 필요합니다.
	\Cref{lst:memorder:Z6.0 Release-Acquire Chain (Ordering?)} 에서,
	\co{exists} 절이 발동되는 것을 막기 위해선 \co{P0()} 또는 \co{P1()}
	액세스 사이에 완전한 배리어를 추가할 것이 필요합니다.

	\iffalse

	Wrong.
	It is the number of non-store-to-load links that matters.
	If there is only one non-store-to-load link, a release-acquire
	chain can prevent the \co{exists} clause from triggering.
	However, if there is more than one non-store-to-load link,
	be they store-to-store, load-to-store, or any combination
	thereof, it is necessary to have at least one full barrier
	(\co{smp_mb()} or better) between each non-store-to-load link.
	In
	\cref{lst:memorder:Z6.0 Release-Acquire Chain (Ordering?)},
	preventing the \co{exists} clause from triggering therefore requires
	an additional full barrier between either \co{P0()}'s or
	\co{P1()}'s accesses.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	스토어에서 로드로의 연결, 로드에서 스토어로의 연결, 그리고 스토어에서
	스토어로의 연결이 있습니다.
	하지만 로드에서 로드로의 연결은 어떻습니까?

	\iffalse

	There are store-to-load links, load-to-store links, and
	store-to-store links.
	But what about load-to-load links?

	\fi

}\QuickQuizAnswerE{
	로드에서 로드로의 연결이라는 개념의 문제는 그 두개의 같은 변수로부터의
	로드가 같은 값을 반환한다면, 그것들 사이의 순서를 파악할 방법이 없다는
	겁니다.
	그것들의 순서를 파악할 유일한 방법은 그것들이 다른 값을 반환했을 때로,
	그 사이에 중간의 스토어가 있었을 때입니다.
	그리고 그 중간의 스토어는 로드에서 로드로의 연결이 아니라 로드에서
	스토어로의 연결 뒤에 스토어에서 로드로의 링크가 있었음을 의미합니다.

	\iffalse

	The problem with the concept of load-to-load links is that
	if the two loads from the same variable return the same
	value, there is no way to determine their ordering.
	The only way to determine their ordering is if they return
	different values, in which case there had to have been an
	intervening store.
	And that intervening store means that there is no load-to-load
	link, but rather a load-to-store link followed by a
	store-to-load link.

	\fi

}\QuickQuizEndE
}

요약하자면, 올바르게 구성된 release-acquire 연결은 더 복잡한 메모리 순서 규약의
상당히 반직관적인 바다에 의해 둘러싸인 직관적 행복의 평화로운 섬을 형성합니다.

\iffalse

In short, properly constructed release-acquire chains form a peaceful
island of intuitive bliss surrounded by a strongly counter-intuitive
sea of more complex memory-ordering constraints.

\fi

% @@@ Exercises?
% @@@ Hardware details from Appendix?

\section{Compile-Time Consternation}
\label{sec:memorder:Compile-Time Consternation}
%
\epigraph{Science increases our power in proportion as it lowers our pride.}
	 {\emph{Claude Bernard}}

C 를 포함해 대부분의 언어는 병렬 프로그래밍 경험이 없거나 조금만 있는
사람들에 의해 단일 프로세서 시스템에서 개발되었습니다.
그 결과, 명시적으로 달리 말해지지 않았다면 이 언어들은 현재 CPU 가 메모리를
읽고 쓰는 유일한 것이라고 가정합니다.
이는 결국 이 언어들의 컴파일러의 최적화기가 여러분의 프로그램이 수행하는 메모리
참조의 순서, 수, 그리고 크기에 극적인 변화를 만들 준비가 되어있고 하려 한다는
것을 의미합니다.
실제로, 하드웨어에 의해 수행되는 순서 재배치는 상대적으로 온순한 것입니다.

이 섹션은 여러분이 컴파일러를 길들여서 컴파일 시점의 놀람을 막는 것을 돕습니다.
\Cref{sec:memorder:Memory-Reference Restrictions}
는 컴파일러가 여러분의 코드의 메모리 참조를 파괴적으로 최적화 하는 걸 막는지
설명하고,
\cref{sec:memorder:Address- and Data-Dependency Difficulties}
는 주소와 데이터 종속성을 보호하는 법을 설명하며, 마지막으로
\cref{sec:memorder:Control-Dependency Calamities}
는 그 미묘한 제어 종속성을 보호하는 법을 설명합니다.

\iffalse

Most languages, including C, were developed on uniprocessor systems
by people with little or no parallel-programming experience.
As a results, unless explicitly told otherwise, these languages assume
that the current CPU is the only thing that is reading or writing memory.
This in turn means that these languages' compilers' optimizers
are ready, willing, and oh so able to make dramatic changes to the
order, number, and sizes of memory references that your program
executes.
In fact, the reordering carried out by hardware can seem quite tame
by comparison.

This section will help you tame your compiler, thus avoiding a great
deal of compile-time consternation.
\Cref{sec:memorder:Memory-Reference Restrictions}
describes how to keep the compiler from destructively optimizing
your code's memory references,
\cref{sec:memorder:Address- and Data-Dependency Difficulties}
describes how to protect address and data dependencies,
and finally,
\cref{sec:memorder:Control-Dependency Calamities}
describes how to protect those delicate control dependencies.

\fi

\subsection{Memory-Reference Restrictions}
\label{sec:memorder:Memory-Reference Restrictions}

\Cref{sec:toolsoftrade:Accessing Shared Variables} 에서 이야기 되었듯, 별달리
이야기 되지 않는다면 컴파일러는 그 코드가 접근하는 변수에 다른 것들은 영향을
끼치지 않는다고 가정합니다.
더 나아가서, 이 가정은 단순한 설계 오류가 아니라 여러 표준에서 소중히 간직되는
것입니다.\footnote{
	또는 어쩌면 이는 표준 설계 오류입니다.}
다음 섹션에 대한 준비로 이를 요약해 둘 가치가 있습니다.

C-언어에서의 \qco{r1 = a} 또는 \qco{b = 1} 과 같은 할당문으로 만들어지는 평범한
액세스는
\cref{sec:toolsoftrade:Shared-Variable Shenanigans} 에서 설명한 공유 변수에
대한 실수입니다.
이런 실수를 막는 방법들은
\cpageref{sec:toolsoftrade:A Volatile Solution}
에서 시작하는
\crefrange{sec:toolsoftrade:A Volatile Solution}{sec:toolsoftrade:Avoiding Data Races}
에 설명되어 있습니다:

\iffalse

As noted in \cref{sec:toolsoftrade:Accessing Shared Variables},
unless told otherwise, compilers assume that nothing else
is affecting the variables that the code is accessing.
Furthermore, this assumption is not simply some design error, but is
instead enshrined in various standards.\footnote{
	Or perhaps it is a standardized design error.}
It is worth summarizing this material in preparation for the following
sections.

Plain accesses, as in plain-access C-language assignment statements such
as \qco{r1 = a} or \qco{b = 1} are subject to the
shared-variable shenanigans described in
\cref{sec:toolsoftrade:Shared-Variable Shenanigans}.
Ways of avoiding these shenanigans are described in
\crefrange{sec:toolsoftrade:A Volatile Solution}{sec:toolsoftrade:Avoiding Data Races}
starting on
\cpageref{sec:toolsoftrade:A Volatile Solution}:

\fi

\begin{enumerate}
\item	평범한 액세스는 쪼개질 수 있는데, 예를 들어 컴파일러는 8 바이트
	포인터를 한번에 한 바이트씩 액세스할 수 있습니다.
	정렬된 기계 크기 액세스를 쪼개는 것은 \co{READ_ONCE()} 와
	\co{WRITE_ONCE()} 를 사용해 막아질 수 있습니다.
\item	평범한 로드는 융합될 수 있는데, 예를 들어 같은 객체로부터의 앞선 로드의
	결과가 여전히 기계 레지스터에 있다면, 컴파일러는 이를 메모리에서 다시
	로드하는 대신 이 레지스터 내의 값을 재사용하는 식으로 최적화를 할 수도
	있습니다.
	로드 융합은 \co{READ_ONCE()} 를 사용하거나 \co{barrier()},
	\co{smp_rmb()}, 또는
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
	에서 보인 다른 방법들을 이용해 순서를 강제함으로써 방지될 수 있습니다.
\item	평범한 스토어는 융합될 수 있어서 같은 변수로의 뒤따른 스토어가 있다면
	앞의 스토어는 완전히 제거될 수 있습니다.
	스토어 융합은 \co{WRITE_ONCE()} 를 사용하거나 \co{barrier()},
	\co{smp_wmb()}, 또는
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
	에서 보인 다른 방법들을 이용해 순서를 강제함으로써 방지될 수 있습니다.

\iffalse

\item	Plain accesses can tear, for example, the compiler could choose
	to access an eight-byte pointer one byte at a time.
	Tearing of aligned machine-sized accesses can be prevented by
	using \co{READ_ONCE()} and \co{WRITE_ONCE()}.
\item	Plain loads can fuse, for example, if the results of an earlier
	load from that same object are still in a machine register,
	the compiler might opt to reuse the value in that register
	instead of reloading from memory.
	Load fusing can be prevented by using \co{READ_ONCE()} or by
	enforcing ordering between the two loads using \co{barrier()},
	\co{smp_rmb()}, and other means shown in
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}.
\item	Plain stores can fuse, so that a store can be omitted entirely
	if there is a later store to that same variable.
	Store fusing can be prevented by using \co{WRITE_ONCE()} or by
	enforcing ordering between the two stores using \co{barrier()},
	\co{smp_wmb()}, and other means shown in
	\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}.

\fi

\item	평범한 액세스는 현대의 최적화 기능을 갖춘 컴파일러에 의해 놀라운
	방법으로 재배치될 수 있습니다.
	이 재배치는 앞에서 설명한 방법으로 순서를 강제해 막을 수 있습니다.
\item	평범한 로드는 만들어질 수 있는데, 예를 들어 레지스터 부족은 컴파일러가
	앞서 로드된 값을 레지스터에서 지우고 나중에 다시 로드하게 만들 수
	있습니다.
	만들어진 로드는 \co{READ_ONCE()} 를 사용하거나 해당 로드와 뒤따르는 그
	변수의 값 사이에 \co{barrier()} 를 사용해서 앞에 설명한 방법들로 순서를
	강제해 막을 수 있습니다.
\item	스토어는 평범한 스토어 앞에 만들어질 수 있는데, 예를 들어 써질 위치를
	임시 저장소로 사용하는 겁니다.
	이는 \co{WRITE_ONCE()} 의 사용으로 방지할 수 있습니다.

\iffalse

\item	Plain accesses can be reordered in surprising ways by modern
	optimizing compilers.
	This reordering can be prevented by enforcing ordering as
	called out above.
\item	Plain loads can be invented, for example, register pressure might
	cause the compiler to discard a previously loaded value from
	its register, and then reload it later on.
	Invented loads can be prevented by using \co{READ_ONCE()} or by
	enforcing ordering as called out above between the load and a
	later use of its value using \co{barrier()}.
\item	Stores can be invented before a plain store, for example, by
	using the stored-to location as temporary storage.
	This can be prevented by use of \co{WRITE_ONCE()}.

\fi

\end{enumerate}

\QuickQuiz{
	컴파일러가 스토어를 만들어내는 걸 막기 위해 \co{barrier()} 호출을
	평범한 스토어 직전에 위치시키는 건 어떤가요?

	\iffalse

	Why not place a \co{barrier()} call immediately before
	a plain store to prevent the compiler from inventing stores?

	\fi

}\QuickQuizAnswer{
	그건 동작하지 않을 겁니다.
	컴파일러가 \co{barrier()} 앞에 스토어를 만들어내는 건 막겠지만,
	\co{barrier()} 와 평범한 스토어 사이에 스토어를 만들어내는 건 막지
	않습니다.

	\iffalse

	Because it would not work.
	Although the compiler would be prevented from inventing a
	store prior to the \co{barrier()}, nothing would prevent
	it from inventing a store between that \co{barrier()} and
	the plain store.

	\fi

}\QuickQuizEnd

이 모든 공유 메모리 실수는
\cref{sec:toolsoftrade:Avoiding Data Races} 에서 설명한 것처럼 평범한 액세스
사이의 데이터 경주를 막음으로써 막아질 수 있습니다.
어쨌건, 데이터 경주가 없다면 앞서 이야기된 모든 컴파일러 최적화는 완전
안전합니다.
그러나 데이터 경주를 포함하는 코드에서 이 리스트는 컴파일러 최적화는 갈수록
적극적이 될 것이기 때문에 별다른 알림 없이 바뀔 수 있습니다.

요약해서, \co{READ_ONCE()}, \co{WRITE_ONCE()}, \co{barrier()}, \co{volatile},
그 외에 page~\pageref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet} 의
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
에서 이야기된 다른 기능들은 컴파일러가 여러분의 병렬 알고리즘을 존재치 않게
최적화 해버리는 걸 막는 가치있는 도구들입니다.
컴파일러는 로드와 스토어 쪼개기를 막는 다른 메커니즘도 지원하기 시작했는데,
예를 들면 \co{memory_order_relaxed} 어토믹 로드와 스토어인데, 그러나 여전히
작업이 필요합니다~\cite{JonathanCorbet2016C11atomics}.
또한, 컴파일러 이슈 외에도 \co{volatile} 은 C11 어토믹 액세스를 포함한 액세스의
합침과 만들어냄을 막기 위해 여전히 필요합니다.

\iffalse

Please note that all of these shared-memory shenanigans can instead be
avoided by avoiding data races on plain accesses, as described in
\cref{sec:toolsoftrade:Avoiding Data Races}.
After all, if there are no data races, then each and every one of the
compiler optimizations mentioned above is perfectly safe.
But for code containing data races, this list is subject to change
without notice as compiler optimizations continue becoming increasingly
aggressive.

In short, use of \co{READ_ONCE()}, \co{WRITE_ONCE()}, \co{barrier()},
\co{volatile}, and other primitives called out in
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
on
page~\pageref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
are valuable tools in preventing the compiler from
optimizing your parallel algorithm out of existence.
Compilers are starting to provide other mechanisms for avoiding
load and store tearing, for example, \co{memory_order_relaxed}
atomic loads and stores, however, work is still
needed~\cite{JonathanCorbet2016C11atomics}.
In addition, compiler issues aside, \co{volatile} is still needed
to avoid fusing and invention of accesses, including C11 atomic accesses.

\fi

\co{READ_ONCE()} 와 \co{WRITE_ONCE()} 를 과하게 사용하게 될 수 있음을
알아두십시오.
예를 들어, 여러분이 특정 변수가 변하는 걸 막았다면 (그 변수로의 모든 업데이트를
락으로 보호하는 식으로), \co{READ_ONCE()} 를 사용할 이유가 없습니다.
비슷하게, 다른 CPU 나 쓰레드가 특정 변수를 읽는 것을 막았다면 (그 변수를 다른
CPU 나 쓰레드가 그걸 액세스 하기 전에 최적화 한다거나 하는 식으로),
\co{WRITE_ONCE()} 를 사용할 이유가 없습니다.
그러나, 제 경험상 개발자들은 그들이 생각하는 것보다 더 자주 \co{READ_ONCE()} 와
\co{WRITE_ONCE()} 를 사용해야 하며, 불필요한 사용으로 인한 오버헤드는 매우
낮습니다.
반대로, 필요한 곳에 그것을 사용하지 않음에 따른 불이익은 매우 클 수 있습니다.

\iffalse

Please note that, it is possible to overdo use of \co{READ_ONCE()} and
\co{WRITE_ONCE()}.
For example, if you have prevented a given variable from changing
(perhaps by holding the lock guarding all updates to that
variable), there is no point in using \co{READ_ONCE()}.
Similarly, if you have prevented any other CPUs or threads from
reading a given variable (perhaps because you are initializing
that variable before any other CPU or thread has access to it),
there is no point in using \co{WRITE_ONCE()}.
However, in my experience, developers need to use things like
\co{READ_ONCE()} and \co{WRITE_ONCE()} more often than they think that
they do, and the overhead of unnecessary uses is quite low.
In contrast, the penalty for failing to use them when needed can be quite high.

\fi

\subsection{Address- and Data-Dependency Difficulties}
\label{sec:memorder:Address- and Data-Dependency Difficulties}
\OriginallyPublished{Section}{sec:memorder:Address- and Data-Dependency Difficulties}{Address- and Data-Dependency Difficulties}{the Linux kernel}{PaulEMcKenney2014rcu-dereference}

컴파일러는 주소나 데이터 종속성을 이해하지 못합니다만, 그걸 가르치려는, 또는
최소한 그걸 가르치는 방법을 표준화하려는 노력은 있긴
합니다~\cite{PaulEMcKennneyConsumeP0190R4,PaulEMcKenney2017markconsumeP0462R1}.
그 사이에는 여러분의 컴파일러가 여러분의 종속성을 깨버리는 걸 막기 위해 주의를
기울일 필요가 있습니다.

\iffalse

Compilers do not understand either address or data dependencies,
although there are efforts underway to teach them, or at the very
least, standardize the process of teaching
them~\cite{PaulEMcKennneyConsumeP0190R4,PaulEMcKenney2017markconsumeP0462R1}.
In the meantime, it is necessary to be very careful in order to prevent
your compiler from breaking your dependencies.

\fi

\subsubsection{Give your dependency chain a good start}
여러분의 종속성 연결을 시작하는 로드는 적절한 순서를 지켜야 하는데, 예를 들면
\co{rcu_dereference()} 나 \co{READ_ONCE()} 를 사용하는 겁니다.
이 규칙을 지키는데 실패하면 심각한 부작용이 있을 수 있습니다:

\iffalse

The load that heads your dependency chain must use proper
ordering, for example \co{rcu_dereference()} or \co{READ_ONCE()}.
Failure to follow this rule can have serious side effects:

\fi

\begin{enumerate}
\item	\Cref{sec:memorder:Alpha} 에서 이야기 되었듯, DEC Alpha 에서, 종속적
	로드는 종속성 연결을 시작하는 로드에 대해 순서잡히지 않을수도 있습니다.
\item	종속성 연결을 시작하는 로드가 C11 non-volatile
	\co{memory_order_relaxed} 로드라면, 컴파일러는 그 로드를 제거할 수
	있는데, 예를 들면 과거에 로드된 값을 사용하는 겁니다.
\item	종속성 연결을 시작하는 로드가 평범한 로드라면, 컴파일러는 이 로드를
	제거할 수 있는데, 앞에서와 마찬가지로 과거에 로드된 값을 사용하는
	식입니다.
	더 나쁜 것이, 로드를 한번이 아니라 두번 행할 수 있어서, 여러분의 코드의
	다른 부분이 다른 값을 보게 할 수 있습니다---그리고 컴파일러는 정말로 이
	일을 하는데, 특히 레지스터가 부족할 때 그렇습니다.
\item	종속성 연결의 시작에서 로드된 값은 포인터여야만 합니다.
	이론상으로는, 그렇습니다, 여러분은 정수형을 로드할 수 있는데, 아마도
	배열 인덱스로 이를 사용하기 위해서일 겁니다.
	현실에서는, 컴파일러는 정수형에 대해 너무 많은 걸 알아서, 여러분의
	종속성 연결을 깨부실 너무 많은 기회를 갖고
	있습니다~\cite{PaulEMcKennneyConsumeP0190R4}.

\iffalse

\item	On DEC Alpha, a dependent load might not be ordered with
	the load heading the dependency chain, as described in
	\cref{sec:memorder:Alpha}.
\item	If the load heading the dependency chain is a
	C11 non-volatile \co{memory_order_relaxed} load,
	the compiler could omit the load, for example, by using a value
	that it loaded in the past.
\item	If the load heading the dependency chain is a plain load,
	the compiler can omit the load, again by using a value
	that it loaded in the past.
	Worse yet, it could load twice instead of once, so that
	different parts of your code use different values---and
	compilers really do this, especially when under register
	pressure.
\item	The value loaded by the head of the dependency chain must
	be a pointer.
	In theory, yes, you could load an integer, perhaps to use
	it as an array index.
	In practice, the compiler knows too much about integers,
	and thus has way too many opportunities to break your
	dependency chain~\cite{PaulEMcKennneyConsumeP0190R4}.

\fi

\end{enumerate}

\subsubsection{Avoid arithmetic dependency breakage}
여러분의 종속성 연결 내에서 포인터에 대해 어떤 산술 오퍼레이션을 행하는게
괜찮긴 하지만, 컴파일러에게 너무 많은 정보를 주는 건 조심해서 막아야 합니다.
어쨌건, 컴파일러가 이 포인터의 정확한 값을 판단하기 충분하게 학습된다면,
컴파일러는 그 포인터 자체가 아니라 그 정확한 값을 대신 사용할 수 있습니다.
컴파일러가 그렇게 되자마자 종속성은 깨지고 모든 순서는 사라집니다.

\iffalse

Although it is just fine to do some arithmetic operations on a pointer in
your dependency chain, you need to be careful to avoid giving the
compiler too much information.
After all, if the compiler learns enough to determine the exact value
of the pointer, it can use that exact value instead of the pointer itself.
As soon as the compiler does that, the dependency is broken and all
ordering is lost.

\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Breakable Dependencies With Comparisons]
\begin{VerbatimL}[commandchars=\\\[\]]
int reserve_int;
int *gp;
int *p;

p = rcu_dereference(gp);
if (p == &reserve_int)		\lnlbl[cmp]
	handle_reserve(p);	\lnlbl[handle]
do_something_with(*p); /* buggy! */
\end{VerbatimL}
\end{fcvlabel}
\caption{Breakable Dependencies With Comparisons}
\label{lst:memorder:Breakable Dependencies With Comparisons}
\end{listing}

\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Broken Dependencies With Comparisons]
\begin{VerbatimL}[commandchars=\\\[\]]
int reserve_int;
int *gp;
int *p;

p = rcu_dereference(gp);	\lnlbl[deref1]
if (p == &reserve_int) {
	handle_reserve(&reserve_int);
	do_something_with(reserve_int); /* buggy! */ \lnlbl[deref2]
} else {
	do_something_with(*p); /* OK! */
}
\end{VerbatimL}
\end{fcvlabel}
\caption{Broken Dependencies With Comparisons}
\label{lst:memorder:Broken Dependencies With Comparisons}
\end{listing}

\begin{enumerate}
\item	포인터로부터 오프셋을 계산하는건 허용되지만 이 오프셋은 완전히 취소되지
	않아야만 합니다.
	예를 들어, 어떤 \co{char} 포인터 \co{cp} 가 있다면,
	\co{cp-(uintptr_t)cp} 는 오프셋을 취소시키고 컴파일러가 이 종속성
	연결을 깨게 할 수 있습니다.
	다른 한편, 오프셋 값을 서로와 함께 취소시키는 건 완전히 안전하고
	합법적입니다.
	예를 들어, \co{a} 와 \co{b} 가 동일하다면 \co{cp+a-b} 는 동일 함수로,
	종속성을 유지합니다.

\iffalse

\item	Although it is permissible to compute offsets from a
	pointer, these offsets must not result in total cancellation.
	For example, given a \co{char} pointer \co{cp},
	\co{cp-(uintptr_t)cp} will cancel and can allow the compiler
	to break your dependency chain.
	On the other hand, canceling offset values with each other
	is perfectly safe and legal.
	For example, if \co{a} and \co{b} are equal, \co{cp+a-b}
	is an identity function, including preserving the dependency.

\fi

\item	비교는 종속성을 깰 수 있습니다.
	\Cref{lst:memorder:Breakable Dependencies With Comparisons}
	이 이게 어떻게 일어날 수 있는지 보입니다.
	여기서 전역 포인터 \co{gp} 는 동적으로 할당된 정수를 가리키지만
	메모리가 부족하면 \co{reserve_int} 변수를 가리킬 수도 있습니다.
	\begin{fcvref}[ln:memorder:Breakable Dependencies With Comparisons]
	이 \co{reserve_int} 의 경우는 이 리스트의 \clnref{cmp,handle} 에서
	보이듯 특수한 처리가 필요할 수도 있습니다.
	\end{fcvref}
        \begin{fcvref}[ln:memorder:Broken Dependencies With Comparisons]
	하지만 컴파일러는 이 코드를
	\cref{lst:memorder:Broken Dependencies With Comparisons}
	에 보인 합리적인 형태로 변환할 수도 있는데, 절대 주소를 갖는 명령이
	레지스터를 통해 제공되는 주소를 사용하는 명령보다 빠른 시스템에서
	그렇습니다.
	그러나, \clnref{deref1} 와 \clnref{deref2} 의 역참조 사이에는 명확한
	순서 규칙이 없습니다.
	이는 단순한 하나의 예일 뿐임을 알아 두십시오: 비교를 통해 종속성 연결을
	깨는 수많은 방법이 존재합니다.
	\end{fcvref}

\iffalse

\item	Comparisons can break dependencies.
	\cref{lst:memorder:Breakable Dependencies With Comparisons}
	shows how this can happen.
	Here global pointer \co{gp} points to a dynamically allocated
	integer, but if memory is low, it might instead point to
	the \co{reserve_int} variable.
	\begin{fcvref}[ln:memorder:Breakable Dependencies With Comparisons]
	This \co{reserve_int} case might need special handling, as
	shown on \clnref{cmp,handle} of the listing.
	\end{fcvref}
        \begin{fcvref}[ln:memorder:Broken Dependencies With Comparisons]
	But the compiler could reasonably transform this code into
	the form shown in
	\cref{lst:memorder:Broken Dependencies With Comparisons},
	especially on systems where instructions with absolute
	addresses run faster than instructions using addresses
	supplied in registers.
	However, there is clearly no ordering between the pointer
	load on \clnref{deref1} and the dereference on \clnref{deref2}.
	Please note that this is simply an example: There are a great
	many other ways to break dependency chains with comparisons.
	\end{fcvref}

\fi

\end{enumerate}

\QuickQuizSeries{%
\QuickQuizB{
	\begin{fcvref}[ln:memorder:Breakable Dependencies With Comparisons]
	\Cref{lst:memorder:Breakable Dependencies With Comparisons}
	의 \clnref{cmp} 에서 \co{&reserve_int} 와 비교하기 전에 포인터를 그냥
	역참조하지 않는 이유가 뭐죠?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:memorder:Breakable Dependencies With Comparisons]
	Why can't you simply dereference the pointer before comparing it
	to \co{&reserve_int} on \clnref{cmp} of
	\cref{lst:memorder:Breakable Dependencies With Comparisons}?
	\end{fcvref}

	\fi

}\QuickQuizAnswerB{
	첫째로, \co{do_something_with()} 전에 \co{handle_reserve()} 를 호출해야
	합니다.

	하지만 메모리 순서에 더 밀접하게는, 컴파일러는 비교를 역참조 전으로
	옮길 권리를 가져서, 컴파일러가 하드웨어가 종속성을 표시해두는 변수
	\co{p} 대신 \co{&reserve_int} 를 사용할 수 있습니다.

	\iffalse

	For first, it might be necessary to invoke
	\co{handle_reserve()} before \co{do_something_with()}.

	But more relevant to memory ordering, the compiler is often within
	its rights to hoist the comparison ahead of the dereferences,
	which would allow the compiler to use \co{&reserve_int} instead
	of the variable \co{p} that the hardware has tagged with
	a dependency.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	하지만 두 포인터 변수를 비교하는건 안전합니다, 그렇죠?
	어쨌건, 컴파일러는 두 변수의 값을 모르는데 그 비교에서 뭘 알 수
	있겠습니까?

	\iffalse

	But it should be safe to compare two pointer variables,
	right?  After all, the compiler doesn't know the value
	of either, so how can it possibly learn anything from the
	comparison?

	\fi

}\QuickQuizAnswerE{
%
\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Breakable Dependencies With Non-Constant Comparisons]
\begin{VerbatimL}
int *gp1;
int *p;
int *q;

p = rcu_dereference(gp1);
q = get_a_pointer();
if (p == q)
	handle_equality(p);
do_something_with(*p);
\end{VerbatimL}
\end{fcvlabel}
\caption{Breakable Dependencies With Non-Constant Comparisons}
\label{lst:memorder:Breakable Dependencies With Non-Constant Comparisons}
\end{listing}%
%
\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Broken Dependencies With Non-Constant Comparisons]
\begin{VerbatimL}[commandchars=\\\[\]]
int *gp1;
int *p;
int *q;

p = rcu_dereference(gp1);		\lnlbl[p]
q = get_a_pointer();
if (p == q) {
	handle_equality(q);
	do_something_with(*q);		\lnlbl[q]
} else {
	do_something_with(*p);
}
\end{VerbatimL}
\end{fcvlabel}
\caption{Broken Dependencies With Non-Constant Comparisons}
\label{lst:memorder:Broken Dependencies With Non-Constant Comparisons}
\end{listing}%
%

	불행히도, 컴파일러는 여러분의 종속성 연결을 부수기 충분할 만큼 많은 걸
	알 수 있는데, 예를 들어
	\cref{lst:memorder:Breakable Dependencies With Non-Constant Comparisons}
	에 보인 것과 같습니다.
	컴파일러는 이 코드를
	\cref{lst:memorder:Broken Dependencies With Non-Constant Comparisons}
	에 보인 것과 같이 변환할 권리를 가지며, \co{handle_equality()} 가
	인라인화 되었으며 많은 레지스터를 필요로 한다면 레지스터 부족시에 이런
	변화를 만들 수 있습니다.
	\begin{fcvref}[ln:memorder:Broken Dependencies With Non-Constant Comparisons]
	이 변화된 코드의 \clnref{q} 는 \co{q} 를 사용하는데, 이는 \co{p} 와
	동일하지만 하드웨어에 의해 종속성을 가져오는 것으로 표시되지 않았을 수
	있습니다.
	따라서, 이 변화된 코드는 \clnref{q} 가 \clnref{p} 다음으로 순서잡힐
	것을 보장하지 않습니다.\footnote{
		이 예를 제공한 \ppl{Linus}{Torvalds} 에게 감사를 드립니다.}
	\end{fcvref}

	\iffalse

	Unfortunately, the compiler really can learn enough to
	break your dependency chain, for example, as shown in
	\cref{lst:memorder:Breakable Dependencies With Non-Constant Comparisons}.
	The compiler is within its rights to transform this code
	into that shown in
	\cref{lst:memorder:Broken Dependencies With Non-Constant Comparisons},
	and might well make this transformation due to register pressure
	if \co{handle_equality()} was inlined and needed a lot of registers.
	\begin{fcvref}[ln:memorder:Broken Dependencies With Non-Constant Comparisons]
	\Clnref{q} of this transformed code uses \co{q}, which although
	equal to \co{p}, is not necessarily tagged by the hardware as
	carrying a dependency.
	Therefore, this transformed code does not necessarily guarantee
	that \clnref{q} is ordered after \clnref{p}.\footnote{
		Kudos to \ppl{Linus}{Torvalds} for providing this example.}
	\end{fcvref}

	\fi

}\QuickQuizEndE
}

연속된 동일성 비교는 함께 취해졌을 경우 컴파일러에게 포인터의 정확한 값을
판단하기 충분한, 따라서 종속성을 깰 수 있는 정보를 줄 수도 있음을 명심하십시오.
더 나아가, 컴파일러는 하나의 동일성 비교로부터의 정보를 다른 정보와 결합해
정확한 값을 알아낼 수 있어서 또다시 종속성을 깰 수 있습니다.
배열의 원소로의 포인터는 특히 이 나중 부분의 종속성 깨짐에 취약합니다.

\iffalse

Note that a series of inequality comparisons might, when taken together,
give the compiler enough information to determine the exact value of
the pointer, at which point the dependency is broken.
Furthermore, the compiler might be able to combine information from
even a single inequality comparison with other information to learn
the exact value, again breaking the dependency.
Pointers to elements in arrays are especially susceptible to this latter
form of dependency breakage.

\fi

\subsubsection{Safe comparison of dependent pointers}
종속된 포인터들을 안전하게 비교하는 방법들이 있습니다:

\iffalse

It turns out that there are several safe ways to compare dependent
pointers:

\fi

\begin{enumerate}
\item	\co{NULL} 포인터에 대한 비교.
	이 경우, 컴파일러가 알 수 있는 모든 것은 포인터가 \co{NULL} 이라는
	것 뿐으로, 어차피 여러분은 이를 역참조할 수 없습니다.
\item	종속된 포인터가 비교 전이든 후든 결코 역참조되지 않는 경우.
\item	종속된 포인터가 매우 오래전에 변경된 객체를 참조하는 포인터와 비교되는
	경우로, 여기서 ``매우 오래 전'' 이라 하기 무조건적으로 안전한 값은
	``컴파일 시점'' 뿐.
	핵심은 주소나 데이터 종속성 이외의 무언가가 순서를 보장할 수 있다는 것.
\item	각각 적절한 종속성을 갖는 두개의 포인터 사이의 비교.
	예를 들어, 각자 락을 포함하는 데이터 구조로의 종속성을 갖는 한쌍의
	포인터가 있고 주소 순서대로 락을 잡아서 데드락을 회피하고자 하는 경우.
\item	비교가 같지 않고, 컴파일러는 종속성을 이끄는 포인터의 값을 추측할
	정보를 갖고 있지 않은 경우.

\iffalse

\item	Comparisons against the \co{NULL} pointer.
	In this case, all the compiler can learn is that the pointer
	is \co{NULL}, in which case you are not allowed to
	dereference it anyway.
\item	The dependent pointer is never dereferenced, whether before or
	after the comparison.
\item	The dependent pointer is compared to a pointer that references
	objects that were last modified a very long time ago, where
	the only unconditionally safe value of ``a very long time ago'' is
	``at compile time''.
	The key point is that something other than the address or data
	dependency guarantees ordering.
\item	Comparisons between two pointers, each of which carries
	an appropriate dependency.
	For example, you have a pair of pointers, each carrying a
	dependency, to data structures each containing a lock, and you
	want to avoid deadlock by acquiring the locks in address order.
\item	The comparison is not-equal, and the compiler does not have
	enough other information to deduce the value of the
	pointer carrying the dependency.

\fi

\end{enumerate}

\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Broken Dependencies With Pointer Comparisons]
\begin{VerbatimL}[commandchars=\\\[\]]
struct foo {		\lnlbl[foo:b]
	int a;
	int b;
	int c;
};                      \lnlbl[foo:e]
struct foo *gp1;	\lnlbl[gp1]
struct foo *gp2;	\lnlbl[gp2]

void updater(void)		\lnlbl[upd:b]
{
	struct foo *p;

	p = malloc(sizeo(*p));		\lnlbl[upd:alloc]
	BUG_ON(!p);			\lnlbl[upd:bug]
	p->a = 42;			\lnlbl[upd:init:a]
	p->b = 43;
	p->c = 44;			\lnlbl[upd:init:c]
	rcu_assign_pointer(gp1, p);	\lnlbl[upd:assign1]
	WRITE_ONCE(p->b, 143);		\lnlbl[upd:upd:b]
	WRITE_ONCE(p->c, 144);		\lnlbl[upd:upd:c]
	rcu_assign_pointer(gp2, p);	\lnlbl[upd:assign2]
}				\lnlbl[upd:e]

void reader(void)		\lnlbl[read:b]
{
	struct foo *p;
	struct foo *q;
	int r1, r2 = 0;

	p = rcu_dereference(gp2);	\lnlbl[read:gp2]
	if (p == NULL)			\lnlbl[read:nulchk]
		return;			\lnlbl[read:nulret]
	r1 = READ_ONCE(p->b);		\lnlbl[read:pb]
	q = rcu_dereference(gp1);	\lnlbl[read:gp1]
	if (p == q) {			\lnlbl[read:equ]
		r2 = READ_ONCE(p->c);	\lnlbl[read:pc]
	}
	do_something_with(r1, r2);
}				\lnlbl[read:e]
\end{VerbatimL}
\end{fcvlabel}
\caption{Broken Dependencies With Pointer Comparisons}
\label{lst:memorder:Broken Dependencies With Pointer Comparisons}
\end{listing}

포인터 비교는 상당히 복잡할 수 있으며, 따라서
\cref{lst:memorder:Broken Dependencies With Pointer Comparisons}
의 예를 따라가보는 게 좋겠습니다.
\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons]
이 예는 \clnrefrange{foo:b}{foo:e} 의 간단한 \co{struct foo} 와
\clnref{gp1,gp2} 에 각각 보인 두개의 전역 포인터 \co{gp1} 과 \co{gp2} 를
사용합니다.
이 예는 두 쓰레드를 사용하는데, \clnrefrange{upd:b}{upd:e} 의 \co{updater()} 와
\clnrefrange{read:b}{read:e} 의 \co{reader()} 입니다.
\end{fcvref}

\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons:upd]
\co{updater()} 쓰레드는 \clnref{alloc} 에서 메모리를 할당하고 할당에 실패하면
\clnref{bug} 에서 불만을 표합니다.
\Clnrefrange{init:a}{init:c} 는 새로 할당된 구조체를 초기화 하며, 이어서
\clnref{assign1} 에서 이 포인터를 \co{gp1} 에 할당합니다.
\Clnref{upd:b,upd:c} 는 이어서 이 구조체의 필드 중 두개를 업데이트 하는데,
\clnref{assign1} 이 그 필드들을 읽기 쓰레드에게 보이게 한 후입니다.
읽기 쓰레드에게 보이는 필드를 비동기적으로 업데이트 하는 것은 종종 버그임을
알아두세요.
그냥 이를 하는 합리적 사용처가 있지만, 그런 경우는 이 예에서보다 깊은 주의가
필요합니다.

마지막으로 \clnref{assign2} 는 이 포인터를 \co{gp2} 에 할당합니다.
\end{fcvref}

\iffalse

Pointer comparisons can be quite tricky, and so it is well worth working
through the example shown in
\cref{lst:memorder:Broken Dependencies With Pointer Comparisons}.
\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons]
This example uses a simple \co{struct foo} shown on \clnrefrange{foo:b}{foo:e}
and two global pointers, \co{gp1} and \co{gp2}, shown on \clnref{gp1,gp2},
respectively.
This example uses two threads, namely \co{updater()} on
\clnrefrange{upd:b}{upd:e} and \co{reader()} on \clnrefrange{read:b}{read:e}.
\end{fcvref}

\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons:upd]
The \co{updater()} thread allocates memory on \clnref{alloc}, and complains
bitterly on \clnref{bug} if none is available.
\Clnrefrange{init:a}{init:c} initialize the newly allocated structure,
and then \clnref{assign1} assigns the pointer to \co{gp1}.
\Clnref{upd:b,upd:c} then update two of the structure's fields, and does
so \co{after} \clnref{assign1} has made those fields visible to readers.
Please note that unsynchronized update of reader-visible fields
often constitutes a bug.
Although there are legitimate use cases doing just this, such use cases
require more care than is exercised in this example.

Finally, \clnref{assign2} assigns the pointer to \co{gp2}.
\end{fcvref}

\fi

\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons:read]
\co{reader()} 쓰레드는 먼저 \co{gp2} 를 \clnref{gp2} 에서 가져오고,
\clnref{nulchk,nulret} 에서 이를 \co{NULL} 과 비교한 후 동일하면 리턴합니다.
\Clnref{pb} 는 \co{->b} 필드를 가져오고 \clnref{gp2} 은 \co{gp2} 을 가져옵니다.
\Clnref{equ} 가 이 \clnref{gp2,gp2} 에서 가져온 포인터가 동일하다고 보게 되면,
\clnref{pc} 는 \co{p->c} 를 가져옵니다.
\Clnref{pc} 는 \clnref{gp2} 에서 가져온 포인터 \co{p} 를 사용하지 \clnref{gp1}
에서 가져온 포인터 \co{q} 를 사용하지 않음에 유의하세요.

그러나 이 차이는 문제가 되지 않을 수도 있습니다.
\Clnref{equ} 에서의 동일성 검사는 컴파일러가 (옳지 않게도) 두 포인터가
동일하다고 결론내리게 할 수 있습니다, 실제로는 이것들이 다른 종속성을 가짐에도
불구하고 말입니다.
이는 컴파일러가 \clnref{pc} 는 \co{r2 - q->c} 로 변환하게 할수도 있는데, 이는
예상된 값 144 가 아닌 값 44 를 로드되게 할 수 있습니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons:read]
The \co{reader()} thread first fetches \co{gp2} on \clnref{gp2}, with
\clnref{nulchk,nulret} checking for \co{NULL} and returning if so.
\Clnref{pb} fetches field \co{->b} and
\clnref{gp1} fetches \co{gp1}.
If \clnref{equ} sees that the pointers fetched on \clnref{gp2,gp1}
are equal, \clnref{pc} fetches \co{p->c}.
Note that \clnref{pc} uses pointer \co{p} fetched on \clnref{gp2}, not
pointer \co{q} fetched on \clnref{gp1}.

But this difference might not matter.
An equals comparison on \clnref{equ} might lead the compiler to (incorrectly)
conclude that both pointers are equivalent, when in fact they carry
different dependencies.
This means that the compiler might well transform \clnref{pc} to instead
be \co{r2 = q->c}, which might well cause the value 44 to be loaded
instead of the expected value 144.
\end{fcvref}

\fi

\QuickQuiz{
	\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons:read]
	하지만 \clnref{equ} 에서의 조건은 \clnref{pc} 를 \clnref{gp1} 다음으로
	순서짓는 제어 종속성을 제공하지 않나요?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons:read]
	But doesn't the condition in \clnref{equ} supply a control dependency
	that would keep \clnref{pc} ordered after \clnref{gp1}?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons:read]
	맞아요, 하지만 아닙니다.
	맞아요, 제어 종속성이 존재합니다, 그러나 제어 종속성은 나중의 로드가
	아니라 스토어만을 순서짓습니다.
	여러분이 정말 순서를필요로 한다면 \clnref{equ,pc} 사이에 \co{smp_rmb()}
	를 둘 수 있습니다.
	또는 더 낫게는 \co{update()} 가 그 구조체들을 재사용하는 대신 할당하게
	합니다.
	더 많은 정보를 위해선
	\cref{sec:memorder:Control-Dependency Calamities}
	를 참고하세요.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:memorder:Broken Dependencies With Pointer Comparisons:read]
	Yes, but no.
	Yes, there is a control dependency, but control dependencies do
	not order later loads, only later stores.
	If you really need ordering, you could place an \co{smp_rmb()}
	between \clnref{equ,pc}.
	Or better yet, have \co{update()}
	allocate two structures instead of reusing the structure.
	For more information, see
	\cref{sec:memorder:Control-Dependency Calamities}.
	\end{fcvref}

	\fi

}\QuickQuizEnd

요약하자면, 여러분의 소스코드의 종속성 연결이 여전히 컴파일러에 의해 생성된
어셈블리 코드에서도 종속성 연결이 되기 위해선 큰 주의가 필요합니다.

\iffalse

In short, great care is required to ensure that dependency
chains in your source code are still dependency chains in the
compiler-generated assembly code.

\fi

\subsection{Control-Dependency Calamities}
\label{sec:memorder:Control-Dependency Calamities}

제어 종속성은 특히 복잡한데, 현재의 컴파일러는 그걸 이해하지 못하고 쉽게 그걸
깨버릴 수 있기 때문입니다.
이 섹션의 규칙과 예제들은 여러분이 여러분의 컴파일러가 이를 무시하고 여러분의
코드를 깨부수는 것을 막는 것을 돕고자 작성되었습니다.

로드-로드 제어 종속성은 단순한 데이터 종속성 배리어가 아니라 완전한 읽기 메모리
배리어를 필요로 합니다.
다음 코드를 보세요:

\iffalse

Control dependencies are especially tricky because current compilers
do not understand them and can easily break them.
The rules and examples in this section are intended to help you
prevent your compiler's ignorance from breaking your code.

A load-load control dependency requires a full read memory barrier,
not simply a data dependency barrier.
Consider the following bit of code:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
if (q) {
	<data dependency barrier>
	q = READ_ONCE(y);
}
\end{VerbatimN}

이는 뜻한 효과를 내지 못하는데, 실제 데이터 종속성이 존재하지 않으며 CPU 는 그
결과를 먼저 예측해서 수행을 단축시킬 수 있는 제어 종속성을 가지고 있어서, 다른
CPU 는 \co{y} 로부터의 로드를 \co{x} 로드 전에 일어난 것으로 볼 수 있습니다.
그런 경우 정말로 필요한건 다음과 같습니다:

\iffalse

This will not have the desired effect because there is no actual data
dependency, but rather a control dependency that the CPU may short-circuit
by attempting to predict the outcome in advance, so that other CPUs see
the load from~\co{y} as having happened before the load from~\co{x}.
In such a case what's actually required is:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
if (q) {
	<read barrier>
	q = READ_ONCE(y);
}
\end{VerbatimN}

그러나, 스토어는 예측되지 않습니다.
이는 순서가 \emph{정말로} 로드-스토어 제어 종속성에는 다음 예와 같이 제공됨을
뜻합니다:

\iffalse

However, stores are not speculated.
This means that ordering \emph{is} provided for load-store control
dependencies, as in the following example:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
if (q)
	WRITE_ONCE(y, 1);
\end{VerbatimN}

제어 종속성은 일반적으로 다른 종류의 순서규칙 오퍼레이션과 짝을 이룹니다.
그러나, \co{READ_ONCE()} 도 \co{WRITE_ONCE()} 도 선택사항이 아님을 알아두세요!
\co{READ_ONCE()} 가 없다면 컴파일러는 \co{x} 로드를 다른 \co{x} 로드와 융합시킬
수도 있습니다.
\co{WRITE_ONCE()} 가 없다면 컴파일러는 \co{y} 로의 스토어를 다른 \co{y} 로의
스토어와 융합시킬 수도 있습니다.
둘 다 상당히 반직관적인 순서 효과를 낼 수 있습니다.

더 나쁜 것이, 컴파일러가 (예를 들어) 변수~\co{x} 의 값이 항상 0이 아님을 증명할
수 있다면, 원래의 예를 \qco{if} 문을 다음과 같이 제거할 권리를 갖습니다:

\iffalse

Control dependencies pair normally with other types of ordering operations.
That said, please note that neither \co{READ_ONCE()} nor \co{WRITE_ONCE()}
are optional!
Without the \co{READ_ONCE()}, the compiler might fuse the load
from~\co{x} with other loads from~\co{x}.
Without the \co{WRITE_ONCE()}, the compiler might fuse the store
to~\co{y} with other stores to~\co{y}.
Either can result in highly counter-intuitive effects on ordering.

Worse yet, if the compiler is able to prove (say) that the value of
variable~\co{x} is always non-zero, it would be well within its rights
to optimize the original example by eliminating the \qco{if} statement
as follows:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
WRITE_ONCE(y, 1); /* BUG: CPU can reorder!!! */
\end{VerbatimN}

다음과 같이 \qco{if} 문의 양 분기문의 동일한 스토어에 순서를 강제하고 싶을
겁니다:

It is tempting to try to enforce ordering on identical stores on both
branches of the \qco{if} statement as follows:

\begin{VerbatimN}
q = READ_ONCE(x);
if (q) {
	barrier();
	WRITE_ONCE(y, 1);
	do_something();
} else {
	barrier();
	WRITE_ONCE(y, 1);
	do_something_else();
}
\end{VerbatimN}

불행히도, 현재의 컴파일러는 높은 최적화 단계에서는 이를 다음과 같이 변환할 수
있습니다:

\iffalse

Unfortunately, current compilers will transform this as follows at high
optimization levels:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
barrier();
WRITE_ONCE(y, 1);  /* BUG: No ordering!!! */
if (q)
	do_something();
else
	do_something_else();
\end{VerbatimN}

이제 \co{x} 로부터의 로드와 \co{y} 로의 스토어 사이에는 조건이 없어지며, 이는
CPU 가 이들을 재배치할 권리를 가짐을 뜻합니다:
그 조건은 분명 필요하며, 모든 컴파일러 최적화가 적용된 뒤에도 어셈블리 코드
상에 존재해야만 합니다.
따라서, 이 예에서 순서가 필요하다면, 여러분은 명시적으로 메모리 순서
오퍼레이션을 추가해야 하는데, 예를 들면 release store 입니다:

\iffalse

Now there is no conditional between the load from~\co{x} and the store
to~\co{y}, which means that the CPU is within its rights to reorder them:
The conditional is absolutely required, and must be present in the
assembly code even after all compiler optimizations have been applied.
Therefore, if you need ordering in this example, you need explicit
memory-ordering operations, for example, a release store:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
if (q) {
	smp_store_release(&y, 1);
	do_something();
} else {
	smp_store_release(&y, 1);
	do_something_else();
}
\end{VerbatimN}

초기의 \co{READ_ONCE()} 는 컴파일러가 \co{x} 의 값을 추측하는 걸 막기 위해
여전히 필요합니다.
또한, 지역 변수 \co{q} 를 가지고 하는일에도 주의를 기울여야 하는데, 그러지
않으면 컴파일러는 그 값을 추측하고 다시 필요한 조건을 없애버릴 수 있습니다.
예를 들면:

\iffalse

The initial \co{READ_ONCE()} is still required to prevent the compiler from
guessing the value of~\co{x}.
In addition, you need to be careful what you do with the local variable~%
\co{q},
otherwise the compiler might be able to guess its value and again remove
the needed conditional.
For example:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
if (q % MAX) {
	WRITE_ONCE(y, 1);
	do_something();
} else {
	WRITE_ONCE(y, 2);
	do_something_else();
}
\end{VerbatimN}

만약 \co{MAX} 가 1로 정의되어 있다면, 컴파일러는 \co{(q\%MAX)} 가 0과 같다는 걸
알아서, 컴파일러는 앞의 코드를 다음과 같이 변환할 권리를 얻습니다:

\iffalse

If \co{MAX} is defined to be~1, then the compiler knows that \co{(q\%MAX)} is
equal to zero, in which case the compiler is within its rights to
transform the above code into the following:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
WRITE_ONCE(y, 2);
do_something_else();
\end{VerbatimN}

이 변환된 코드에서 CPU 는 \co{x} 로부터의 로드와 \co{y} 로의 스토어 사이에
순서를 지켜야 할 필요가 없습니다.
컴파일러를 제약하기 위해 \co{barrier()} 를 추가하고 싶겠지만 이는 도움이 되지
않습니다.
조건은 사라졌고 \co{barrier()} 는 이를 되돌리지 않습니다.
따라서, 여러분이 이 순서에 기대고 있다면, 아마도 다음과 같이 \co{MAX} 가 1보다
크다는 걸 보장해야 합니다:

\iffalse

Given this transformation, the CPU is not required to respect the ordering
between the load from variable~\co{x} and the store to variable~\co{y}.
It is tempting to add a \co{barrier()} to constrain the compiler,
but this does not help.
The conditional is gone, and the \co{barrier()} won't bring it back.
Therefore, if you are relying on this ordering, you should make sure
that \co{MAX} is greater than one, perhaps as follows:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
BUILD_BUG_ON(MAX <= 1);
if (q % MAX) {
	WRITE_ONCE(y, 1);
	do_something();
} else {
	WRITE_ONCE(y, 2);
	do_something_else();
}
\end{VerbatimN}

\co{y} 로의 스토어는 다름을 다시 주의하세요.
이것들이 동일하다면, 앞에서 언급한 바와 같이 컴파일러는 이 스토어들을 \qco{if}
문 바깥으로 가져올 수 있습니다.

여러분은 또한 이진 회로 평가에 지나치게 기대는 걸 막아야 합니다.
이 예를 생각해 보세요:

\iffalse

Please note once again that the stores to~\co{y} differ.
If they were identical, as noted earlier, the compiler could pull this
store outside of the \qco{if} statement.

You must also avoid excessive reliance on boolean short-circuit evaluation.
Consider this example:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
if (q || 1 > 0)
	WRITE_ONCE(y, 1);
\end{VerbatimN}

첫번째 조건은 두번째 조건이 항상 참인 관계로 거짓일 수 없으므로, 컴파일러는
이를 다음과 같이 변환시켜 제어 종속성을 제거할 수 있습니다:

\iffalse

Because the first condition cannot fault and the second condition is
always true, the compiler can transform this example as following,
defeating control dependency:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
WRITE_ONCE(y, 1);
\end{VerbatimN}

이 예는 컴파일러가 여러분의 코드를 추측할 수 없게 보장할 필요를 강조합니다.
더 일반적으로, \co{READ_ONCE()} 가 컴파일러에게 특정 로드를 위한 코드를 정말
생성하게 강제하지만, 컴파일러가 그 값을 로드하게끔 강제하지는 않습니다.

또한, 제어 종속성은 if 문의 then 절과 else 절에만 적용됩니다.
특히, if 문을 뒤따르는 코드에는 적용되지 않을 수 있습니다.

\iffalse

This example underscores the need to ensure that the compiler cannot
out-guess your code.
More generally, although \co{READ_ONCE()} does force
the compiler to actually emit code for a given load, it does not force
the compiler to use the value loaded.

In addition, control dependencies apply only to the then-clause and
else-clause of the if-statement in question.
In particular, it does
not necessarily apply to code following the if-statement:

\fi

\begin{VerbatimN}
q = READ_ONCE(x);
if (q)
	WRITE_ONCE(y, 1);
else
	WRITE_ONCE(y, 2);
WRITE_ONCE(z, 1);  /* BUG: No ordering. */
\end{VerbatimN}

컴파일러는 volatile 액세스를 재배치 할 수 없으며 조건 내의 \co{y} 로의 쓰기를
재배치할 수도 없다고 주장하고 싶을 겁니다.
불행히도 이 경우, 컴파일러는 \co{y} 로의 두개의 쓰기를 조건적 이동 명령으로
변환해서 다음과 같은 수도-어셈블리어를 만들어낼 수 있습니다:

\iffalse

It is tempting to argue that there in fact is ordering because the
compiler cannot reorder volatile accesses and also cannot reorder
the writes to~\co{y} with the condition.
Unfortunately for this line
of reasoning, the compiler might compile the two writes to~\co{y} as
conditional-move instructions, as in this fanciful pseudo-assembly
language:

\fi

\begin{VerbatimN}
ld r1,x
cmp r1,$0
cmov,ne r4,$1
cmov,eq r4,$2
st r4,y
st $1,z
\end{VerbatimN}

완화된 순서규칙의 CPU 는 \co{x} 로부터의 로드와 \co{z} 로의 스토어 사이에 어떤
종속성도 갖지 않습니다.
이 제어 종속성은 한쌍의 \co{cmov} 명령과 거기 종속된 스토어까지만 확장됩니다.
요약하면, 제어 종속성은 해당 \qco{if} 의 \qco{then} 과 \qco{else} 에만 (이 두
절에서 호출되는 함수 포함) 적용되지, \qco{if} 를 뒤따르는 코드까지는 아닙니다.

마지막으로, 제어 종속성은 cumulativity 를 제공하지 \emph{않습니다}.\footnote{
	Cumulativity 의 의미를 위해선
	\cref{sec:memorder:Cumulativity} 를 참고하세요.}
이는 두개의 연관된 리트머스 테스트, 즉 \co{x} 와 \co{y} 가 둘 다 0으로 초기화
되는
\cref{lst:memorder:LB Litmus Test With Control Dependency,%
lst:memorder:WWC Litmus Test With Control Dependency (Cumulativity?)}
를 통해 선보였습니다.

\iffalse

A weakly ordered CPU would have no dependency of any sort between the load
from~\co{x} and the store to~\co{z}.
The control dependencies would extend
only to the pair of \co{cmov} instructions and the store depending on them.
In short, control dependencies apply only to the stores in the \qco{then}
and \qco{else} of the \qco{if} in question (including functions invoked by
those two clauses), and not necessarily to code following that \qco{if}.

Finally, control dependencies do \emph{not} provide cumulativity.\footnote{
	Refer to \cref{sec:memorder:Cumulativity} for
	the meaning of cumulativity.}
This is demonstrated by two related litmus tests, namely
\cref{lst:memorder:LB Litmus Test With Control Dependency,%
lst:memorder:WWC Litmus Test With Control Dependency (Cumulativity?)}
with the initial values
of~\co{x} and~\co{y} both being zero.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/litmus/C-LB+o-cgt-o+o-cgt-o@whole.fcv}
\caption{LB Litmus Test With Control Dependency}
\label{lst:memorder:LB Litmus Test With Control Dependency}
\end{listing}

\Cref{lst:memorder:LB Litmus Test With Control Dependency}
(\path{C-LB+o-cgt-o+o-cgt-o.litmus})
의 두개 쓰레드 예에서의 \co{exists} 절은 결코 발동되지 않을 겁니다.
제어 종속성이 cumulativity 를 보장한다면 (사실은 보장하지 않음),
\cref{lst:memorder:WWC Litmus Test With Control Dependency (Cumulativity?)}
(\path{C-WWC+o-cgt-o+o-cgt-o+o.litmus})
처럼 쓰레드를 하나 더 추가하는 것이 연관된 \co{exists} 절이 발동되지 않게끔
보장할 겁니다.

\iffalse

The \co{exists} clause in the two-thread example of
\cref{lst:memorder:LB Litmus Test With Control Dependency}
(\path{C-LB+o-cgt-o+o-cgt-o.litmus})
will never trigger.
If control dependencies guaranteed cumulativity (which they do
not), then adding a thread to the example as in
\cref{lst:memorder:WWC Litmus Test With Control Dependency (Cumulativity?)}
(\path{C-WWC+o-cgt-o+o-cgt-o+o.litmus})
would guarantee the related \co{exists} clause never to trigger.

\fi

\begin{listing}
\input{CodeSamples/formal/litmus/C-WWC+o-cgt-o+o-cgt-o+o@whole.fcv}
\caption{WWC Litmus Test With Control Dependency (Cumulativity?)}
\label{lst:memorder:WWC Litmus Test With Control Dependency (Cumulativity?)}
\end{listing}

그러나 제어 종속성은 cumulativity 를 제공하지 \emph{않으므로}, 세개 쓰레드
리트머스 테스트의 \co{exists} 절은 발동될 수 있습니다.
세개 쓰레드 예가 순서를 제공해야 한다면, 여러분은 \co{P0()} 의 로드와 스토어
사이, 즉 \qco{if} 문 직전 또는 직후에에 \co{smp_mb()} 를 추가해야 합니다.
더 나아가서, 원래의 두개 쓰레드 예는 잘못되기 쉬우니 사용되지 않아야 합니다.

\iffalse

But because control dependencies do \emph{not} provide cumulativity, the
\co{exists} clause in the three-thread litmus test can trigger.
If you need the three-thread example to provide ordering, you will need
\co{smp_mb()} between the load and store in \co{P0()},
that is, just before or just after the \qco{if} statements.
Furthermore, the original two-thread example is very fragile and should be avoided.

\fi

\QuickQuiz{
	\cref{lst:memorder:WWC Litmus Test With Control Dependency (Cumulativity?)}
	의 \co{P1()} 에 \co{smp_mb()} 를 대신 추가할 순 없나요?

	\iffalse

	Can't you instead add an \co{smp_mb()} to \co{P1()} in
	\cref{lst:memorder:WWC Litmus Test With Control Dependency (Cumulativity?)}?

	\fi

}\QuickQuizAnswer{
	리눅스 커널 메모리 모델에서라면 안됩니다.
	(시도해 보세요!)
	그러나, 여러분은 대신 \co{P0()} 의 \co{WRITE_ONCE()} 를
	일반적으로 \co{smp_mb()} 를 더하는 것보단 적은 오버헤드를 갖는
	\co{smp_store_release()} 로 대체할 수 있습니다.

	\iffalse

	Not given the Linux kernel memory model.
	(Try it!)
	However, you can instead replace \co{P0()}'s
	\co{WRITE_ONCE()} with \co{smp_store_release()},
	which usually has less overhead than does adding an \co{smp_mb()}.

	\fi

}\QuickQuizEnd

다음 규칙들의 리스트가 이 섹션의 교훈들을 요약합니다:

\iffalse

The following list of rules summarizes the lessons of this section:

\fi

\begin{enumerate}
\item	컴파일러는 제어 종속성을 이해하지 못하며, 따라서 컴파일러가 여러분의
	코드를 망가뜨리지 못하게 하는건 여러분의 일입니다.

\item	제어 종속성은 앞의 로드를 뒤의 스토어에 대해 순서잡습니다.
	그러나, 그것은 어떤 다른 종류의 순서도 보장하지 \emph{않습니다}.
	앞의 로드를 뒤의 로드에 대해서도, 앞의 스토어를 뒤의 어떤 것에 대해서도
	순서잡지 않습니다.
	이런 다른 형태의 순서가 필요하다면, \co{smp_rmb()}, \co{smp_wmb()},
	또는 앞의 스토어와 뒤의 로드 사이에의 순서라면 \co{smp_mb()} 를
	사용하십시오.

\item	\qco{if} 문의 양쪽 분기가 동일한 변수로의 같은 스토어로 시작한다면 제어
	종속성은 그 스토어들을 순서잡지 않을 겁니다.
	순서가 필요하다면, 그것들 앞에 \co{smp_mb()} 를 두거나
	\co{smp_store_release()} 를 사용하세요.
	\qco{if} 문의 양 분기의 시작에 \co{barrier()} 를 두는 것은 충분치
	\emph{않은데}, 앞의 예에서 보인바와 같이 컴파일러의 최적화는
	\co{barrier()} 의 규칙을 지키면서도 제어 종속성을 파괴할 수 있기
	때문임을 유의하십시오.

\iffalse

\item	Compilers do not understand control dependencies, so it is
	your job to make sure that the compiler cannot break your code.

\item	Control dependencies can order prior loads against later stores.
	However, they do \emph{not} guarantee any other sort of ordering:
	Not prior loads against later loads, nor prior stores against
	later anything.
	If you need these other forms of ordering, use \co{smp_rmb()},
	\co{smp_wmb()}, or, in the case of prior stores and later loads,
	\co{smp_mb()}.

\item	If both legs of the \qco{if} statement begin with identical stores
	to the same variable, then the control dependency will not order
	those stores.
	If ordering is needed, precede both of them with \co{smp_mb()} or
	use \co{smp_store_release()}.
	Please note that it is \emph{not} sufficient to use \co{barrier()}
	at beginning of each leg of the \qco{if} statement because, as shown
	by the example above, optimizing compilers can destroy the control
	dependency while respecting the letter of the \co{barrier()} law.

\fi

\item	제어 종속성은 앞의 로드와 뒤의 스토어 사이에 최소 하나의 수행 시간
	조건을 필요로 하며, 이 조건은 앞의 로드와 연관되어야만 합니다.
	컴파일러가 조건을 최적화 해서 없앨 수 있다면, 이는 순서 역시 최적화
	해서 없앨 겁니다.
	주의 깊은 \co{READ_ONCE()} 와 \co{WRITE_ONCE()} 의 사용은 필요한 조건을
	지키는 걸 도울 수 있습니다.

\item	제어 종속성은 컴파일러가 종속성을 존재치 않게 재배치 하는 걸 막을
	필요를 갖습니다.
	주의 깊은 \co{READ_ONCE()}, \co{atomic_read()}, 또는
	\co{atomic64_read()} 의 사용은 여러분의 제어 종속성을 지키는 걸 도울 수
	있습니다.

\iffalse

\item	Control dependencies require at least one run-time conditional
	between the prior load and the subsequent store, and this
	conditional must involve the prior load.
	If the compiler is able to optimize the conditional away, it
	will have also optimized away the ordering.
	Careful use of \co{READ_ONCE()} and \co{WRITE_ONCE()} can help
	to preserve the needed conditional.

\item	Control dependencies require that the compiler avoid reordering
	the dependency into nonexistence.
	Careful use of \co{READ_ONCE()}, \co{atomic_read()}, or
	\co{atomic64_read()} can help to preserve your control
	dependency.

\fi

\item	제어 종속성은 이 종속성을 포함한 \qco{if} 문의 \qco{then} 과 \qco{else}
	절과 이 두 절에서 호출하는 함수들에까지만 적용됩니다.
	제어 종속성은 \qco{if} 문의 끝을 뒤따르는 코드에는 적용되지
	\emph{않습니다}.

\item	제어 종속성은 일반적으로 다른 종류의 메모리 순서 오퍼레이션과 짝을
	이룹니다.

\item	제어 종속성은 cumulativity 를 제공하지 \emph{않습니다}.
	Cumulativity 가 필요하다면, 이를 제공하는 무언가,
	\co{smp_store_release()} 또는 \co{smp_mb()} 같은 걸 사용하십시오.

\iffalse

\item	Control dependencies apply only to the \qco{then} and
	\qco{else} of the \qco{if} containing the control
	dependency, including any functions that these two clauses call.
	Control dependencies do \emph{not} apply to code following the
	end of the \qco{if} statement containing the control dependency.

\item	Control dependencies pair normally with other types of
	memory-ordering operations.

\item	Control dependencies do \emph{not} provide cumulativity.
	If you need cumulativity, use something that provides it,
	such as \co{smp_store_release()} or \co{smp_mb()}.

\fi

\end{enumerate}

다시 말하지만, 많은 대중적 언어들이 싱글쓰레드 기반으로 설계되었습니다.
이 언어들을 멀티쓰레드 기반으로 성공적으로 사용하기 위해선 여러분이 메모리
참조와 종속성에 특별한 주의를 기울일 것을 요합니다.

\iffalse

Again, many popular languages were designed with single-threaded use
in mind.  Successful multithreaded use of these languages requires you
to pay special attention to your memory references and dependencies.

\fi

\section{Higher-Level Primitives}
\label{sec:memorder:Higher-Level Primitives}
%
\epigraph{Method will teach you to win time.}
	 {\emph{Johann Wolfgang von Goethe}}

\Cref{sec:formal:Axiomatic Approaches and Locking}
의 quick quiz 중 하나의 답은 높은 단계의 추상화로 모델링된 프로그램의 검증으로
인한 폭발적 속도 향상을 보였습니다.
이 섹션은 얼마나 더 높은 단계의 추상화가 동기화 기능 자체에 대한 더 깊은 이해를
제공할 수 있는지 알아봅니다.
\Cref{sec:memorder:Memory Allocation}
는 메모리 할당을 알아보고
\cref{sec:memorder:RCU}
는 RCU 까지 더 깊이 파고듭니다.

\iffalse

The answer to one of the quick quizzes in
\cref{sec:formal:Axiomatic Approaches and Locking}
demonstrated exponential speedups due to verifying programs
modeled at higher levels of abstraction.
This section will look into how higher levels of abstraction can
also provide a deeper understanding of the synchronization primitives
themselves.
\Cref{sec:memorder:Memory Allocation}
takes a look at memory allocation and
\cref{sec:memorder:RCU}
digs more deeply into RCU\@.

\fi

\subsection{Memory Allocation}
\label{sec:memorder:Memory Allocation}

\Cref{sec:SMPdesign:Parallel Fastpath for Resource Allocation}
는 메모리 할당을 다루었고, 이 섹션은 연관된 메모리 순서 문제까지 이를
확장합니다.

핵심 요구사항은 어떤 메모리 블록이 할당 해제되기 전까지 해당 블록에 수행된 모든
액세스는 그 블록이 재할당 된 후에 수행된 모든 액세스보다 앞으로 순서잡혀야
한다는 겁니다.
할당 해제 전에 수행된 스토어가 재할당을 뒤따르는 스토어 다음으로 재배치 된다면
그건 어쨌건 잔인하고 비상식적인 메모리 할당기 버그일 겁니다.
그러나, 개발자에게 동적으로 할당된 메모리를 접근하는데 \co{READ_ONCE()} 와
\co{WRITE_ONCE()} 를 사용하도록 요구하는 것 역시 잔인하고 비상식적일 겁니다.
따라서
\cref{sec:toolsoftrade:Shared-Variable Shenanigans}
에서 이야기된 공유 변수 비극에도 불구하고 완전한 순서는 평범한 액세스에도
제공되어야 합니다.

\iffalse

\Cref{sec:SMPdesign:Parallel Fastpath for Resource Allocation}
touched upon memory allocation, and this section expands upon the relevant
memory-ordering issues.

The key requirement is that any access executed on a given block of
memory before freeing that block must be ordered before any access
executed after that same block is reallocated.
It would after all be a cruel and unusual memory-allocator bug if a store
preceding the free were to be reordered after another store following
the reallocation!
However, it would also be cruel and unusual to require developers to use
\co{READ_ONCE()} and \co{WRITE_ONCE()} to access dynamically allocated
memory.
Full ordering must therefore be provided for plain accesses, in spite of
all the shared-variable shenanigans called out in
\cref{sec:toolsoftrade:Shared-Variable Shenanigans}.

\fi

물론, 각 CPU 는 자신의 액세스는 순서대로 보고 컴파일러는 항상 CPU 간 비극을
일으킵니다.
이 사실들은
\cref{lst:SMPdesign:Allocator-Cache Allocator Function,%
lst:SMPdesign:Allocator-Cache Free Function} 에 각각 보인 \co{memblock_alloc()}
과 \co{memblock_free()} 의 락 없는 빠른 수행경로를 가능하게 합니다.
그러나, 이는 또한 개발자가 새로 할당된 메모리 블록으로의 포인터를 공개할 때
적절한 순서를 제공해야 할 (예를 들면, \co{smp_store_release()} 를 이용해서)
책임이 있는 이유입니다.

그러나, 할당기는 쓰레드별 풀을 밸런스 맞출 때 순서를 제공해야만 합니다.
이 순서 잡기는 \co{memblock_alloc()} 과 \co{memblock_free()} 에서의
\co{spin_lock()} 과 \co{spin_unlock()} 을 통해 제공됩니다.
한 쓰레드에서 다른 쓰레드로 옮겨진 모든 블록에 대해, 기존 쓰레드는 해당 블록을
\co{globalmem} 풀에 위치시킨 후 \co{spin_unlock(&globalmem.mutex)} 를 수행할
것이고, 새 쓰레드는 해당 블록을 자신의 쓰레드별 풀에 옮기기 전에
\co{spin_lock(&globalmem.mutex)} 를 수행했을 겁니다.
이 \co{spin_unlock()} 과 \co{spin_lock()} 은 기존 쓰레드와 새 쓰레드 둘 다 기존
쓰레드의 액세스가 새 쓰레드의 것들 전에 일어난 것으로 볼 것을 보장할 겁니다.

\iffalse

Of course, each CPU sees its own accesses in order and the compiler
always has fully accounted for intra-CPU shenanigans.
These facts are what enables the lockless fastpaths in
\co{memblock_alloc()} and \co{memblock_free()}, which are shown in
\cref{lst:SMPdesign:Allocator-Cache Allocator Function,%
lst:SMPdesign:Allocator-Cache Free Function},
respectively.
However, this also why the developer is responsible for providing
appropriate ordering (for example, by using \co{smp_store_release()})
when publishing a pointer to a newly allocated block of memory.
After all, in the CPU-local case, the allocator has not necessarily
provided any ordering.

However, the allocator must provide ordering when rebalancing its
per-thread pools.
This ordering is provided by the calls to \co{spin_lock()} and
\co{spin_unlock()} from \co{memblock_alloc()} and \co{memblock_free()}.
For any block that has migrated from one thread to another, the old
thread will have executed \co{spin_unlock(&globalmem.mutex)} after
placing the block in the \co{globalmem} pool, and the new thread will
have executed \co{spin_lock(&globalmem.mutex)} before moving that
block to its per-thread pool.
This \co{spin_unlock()} and \co{spin_lock()} ensures that both the
old and new threads see the old thread's accesses as having happened
before those of the new thread.

\fi

\QuickQuiz{
	하지만 PowerPC 는 리눅스 커널에서 완화된 unlock-lock 순서 속성을 가져서
	unlock 전의 쓰기가 lock 뒤의 읽기와 재배치될 수 있게 하지 않나요?

	\iffalse

	But doesn't PowerPC have weak unlock-lock ordering properties
	within the Linux kernel, allowing a write before the unlock to
	be reordered with a read after the lock?

	\fi

}\QuickQuizAnswer{
	맞습니다, 그러나 그 락을 잡지 않은 세번째 쓰레드의 관점에만 그렇습니다.
	반대로, 메모리 할당자는 이 메모리를 옮기는 두 쓰레드에 대해서만
	걱정하면 됩니다.
	새로 옮겨진 메모리 블록으로의 액세스를 해야 하는 다른 쓰레드와의 올바른
	동기화는 개발자의 책임입니다.

	\iffalse

	Yes, but only from the perspective of a third thread not holding
	that lock.
	In contrast, memory allocators need only concern themselves with
	the two threads migrating the memory.
	It is after all the developer's responsibility to properly
	synchronize with any other threads that need access to the newly
	migrated block of memory.

	\fi

}\QuickQuizEnd

따라서, 일반적인 메모리 할당의 사용에 필요한 순서는 빠르지 않은 수행경로의
locking 을 통해 제공되어, 빠른 수행경로는 여전히 동기화로부터 자유롭게 합니다.

\iffalse

Therefore, the ordering required by conventional uses of memory allocation
can be provided solely by non-fastpath locking, allowing the fastpath to
remain synchronization-free.

\fi

% \subsection{Detailed Locking Semantics}
% \label{sec:memorder:Detailed Locking Semantics}
% % Awaiting LWN article.

% Locking is a well-known synchronization primitive with which the
% parallel-programming community has had decades of experience with
% in a great many situations.
% As such, locking's semantics are quite simple.

% However, they remain quite simple only until you start thinking about
% them rigorously enough to mathematically model them.

% The simple part is that any CPU or thread holding a given lock is
% guaranteed to see accesses executed when other CPUs or threads
% were previously holding that lock.
% In addition, any CPU or thread holding a given lock is guaranteed not
% to see accesses executed when other CPUs or threads will be
% subsequently holding that lock.

% Existence of mathematical modeling, as called out in
% Section~\ref{sec:formal:Axiomatic Approaches and Locking}.
% Pull in performance from LKMM effort.

% Ordering for holders of same lock.
% For holders of different locks?

% Memory-ordering constraints for lock and unlock.
% When augmented by \co{smp_mb__after_spinlock()} or
% \co{smp_mb__after_spinlock()}.

% Memory-ordering constraints for unlock followed by lock.
% When augmented \co{smp_mb__after_unlock_lock()}.

\subsection{RCU}
\label{sec:memorder:RCU}

\Cref{sec:defer:RCU Fundamentals} 에서 이야기된 바와 같이, RCU grace period 의
기본적 속성은 이 간단한 두 부분의 보장입니다:
(1)~특정 RCU read-side 크리티컬 섹션의 어떤 부분이 어떤 grace period 의 시작을
앞선다면 이 크리티컬 섹션의 모든 부분이 그 grace period 의 끝을 앞섭니다.
(2)~특정 RCU read-side 크리티컬 섹션의 어떤 부분이 어떤 grace period 의 끝을
뒤따른다면, 이 크리티컬 섹션의 모든 부분이 이 grace period 의 시작을
뒤따릅니다.
이 보장들은 grace period 가 우상단의 \co{call_rcu()} 호출과 좌하단의 연관된 RCU
콜백 수행 사이의 점선 화살표로 표시된
\cref{fig:memorder:RCU Grace-Period Ordering Guarantees}
가 이를 요약합니다.\footnote{
	보다 자세한 사항을 위해선
	page~\pageref{fig:defer:RCU Reader and Later Grace Period} 에서
	시작하는
	\crefrange{fig:defer:RCU Reader and Later Grace Period}{fig:defer:RCU Reader Within Grace Period}
	를 참고해 주시기 바랍니다.}

\iffalse

As described in
\cref{sec:defer:RCU Fundamentals},
the fundamental property of RCU grace periods is this straightforward
two-part guarantee:
(1)~If any part of a given RCU read-side critical section precedes
the beginning of a given grace period, then the entirety of that
critical section precedes the end of that grace period.
(2)~If any part of a given RCU read-side critical section follows
the end of a given grace period, then the entirety of that
critical section follows the beginning of that grace period.
These guarantees are summarized in
\cref{fig:memorder:RCU Grace-Period Ordering Guarantees},
where the grace period is denoted by the dashed arrow between the
\co{call_rcu()} invocation in the upper right and the corresponding
RCU callback invocation in the lower left.\footnote{
	For more detail, please see
	\crefrange{fig:defer:RCU Reader and Later Grace Period}{fig:defer:RCU Reader Within Grace Period}
	starting on
	page~\pageref{fig:defer:RCU Reader and Later Grace Period}.}

\fi

\begin{figure}[tbp]
\centering
\resizebox{3in}{!}{\includegraphics{memorder/RCUGPordering}}
\caption{RCU Grace-Period Ordering Guarantees}
\label{fig:memorder:RCU Grace-Period Ordering Guarantees}
\end{figure}

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+rl-o-o-rul@whole.fcv}
\caption{RCU Fundamental Property}
\label{lst:memorder:RCU Fundamental Property}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+i-rl-o-o-rul@whole.fcv}
\caption{RCU Fundamental Property and Reordering}
\label{lst:memorder:RCU Fundamental Property and Reordering}
\end{listing}

요약하자면, RCU read-side 크리티컬 섹션은
\cref{lst:memorder:RCU Fundamental Property}
(\path{C-SB+o-rcusync-o+rl-o-o-rul.litmus}) 에 보인 바와 같이 RCU grace period
와 겹치지 않을 것이 보장되어 있습니다.
\co{r2} 레지스터들은 둘 다 마지막 값으로 0을 가지거나 가지지 않을 수 있으나 그
중 최소 하나는 0이 아니어야만 하는데 (즉, \co{exists} 절에 의해 파악되는
사이클이 금지됩니다), RCU 의 기본적인 grace-period 보장 덕분으로, 이 리트머스
테스트를 \co{herd} 로 수행해서 볼 수 있습니다.
이 보장은 \co{P1()} 의 크리티컬 섹션 내에서의 액세스 순서에 민감하지 않으며,
따라서
\cref{lst:memorder:RCU Fundamental Property and Reordering}\footnote{
	물론 종속성은 RCU read-side 크리티컬 섹션 내에서의 액세스 재배치를
	제한할 수 있습니다.}
또한 같은 사이클을 막습니다.

그러나, 이 정의는 불완전한데, 다음 질문들의 리스트에서 볼 수
있습니다:\footnote{
	이 중 일부는 LKMM 초기 작업 중 \ppl{Jade}{Alglave} 에 의해, 다른
	여러가지는 다른 LKMM
	참여자로부터~\cite{Alglave:2018:FSC:3173162.3177156} Paul 에게
	소개되었습니다.}

\iffalse

In short, an RCU read-side critical section is guaranteed never to
completely overlap an RCU grace period, as demonstrated by
\cref{lst:memorder:RCU Fundamental Property}
(\path{C-SB+o-rcusync-o+rl-o-o-rul.litmus}).
Either or neither of the \co{r2} registers can have the final value of zero,
but at least one of them must be non-zero (that is, the cycle identified
by the \co{exists} clause is prohibited), courtesy of RCU's fundamental
grace-period guarantee, as can be seen by running \co{herd} on this litmus test.
Note that this guarantee is insensitive to the ordering of the accesses
within \co{P1()}'s critical section, so the litmus test shown in
\cref{lst:memorder:RCU Fundamental Property and Reordering}\footnote{
	Dependencies can of course limit the ability to reorder accesses
	within RCU read-side critical sections.}
also forbids this same cycle.

However, this definition is incomplete, as can be seen from the following
list of questions:\footnote{
	Several of which were introduced to Paul by \ppl{Jade}{Alglave} during
	early work on LKMM, and a few more of which came from other
	LKMM participants~\cite{Alglave:2018:FSC:3173162.3177156}.}

\fi

\begin{enumerate}
\item	RCU grace period 무관하게 \co{rcu_read_lock()} 과
	\co{rcu_read_unlock()} 에 의해 어떤 순서가 제공되는가?
\item	RCU read-side 크리티컬 섹션과 무관하게 \co{synchronize_rcu()} 와
	\co{synchronize_rcu_expedited()} 에 의해 어떤 순서가 제공되는가?
\item	만약 특정 RCU read-side 크리티컬 섹션의 모든 부분이 어떤 RCU grace
	period 의 끝을 앞선다면, 이 크리티컬 섹션을 앞서는 액세스는 어떤가?
\item	만약 어떤 RCU read-side 크리티컬 섹션의 모든 부분이 어떤 RCU grace
	period 의 시작을 뒤따른다면, 이 크리티컬 섹션을 뒤따르는 액세스는
	어떤가?
\item	두개 이상의 RCU read-side 크리티컬 섹션 그리고/또는 두개 이상의 RCU
	grace period가 연관된 상황에서는 무슨 일이 벌어지느가?
\item	RCU 가 다른 메모리 순서 메커니즘과 결합되면 무슨 일이 벌어지는가?

\iffalse

\item	What ordering is provided by \co{rcu_read_lock()}
	and \co{rcu_read_unlock()}, independent of RCU grace periods?
\item	What ordering is provided by \co{synchronize_rcu()}
	and \co{synchronize_rcu_expedited()}, independent of RCU read-side
	critical sections?
\item	If the entirety of a given RCU read-side critical section
	precedes the end of a given RCU grace period, what about
	accesses preceding that critical section?
\item	If the entirety of a given RCU read-side critical section
	follows the beginning of a given RCU grace period, what about
	accesses following that critical section?
\item	What happens in situations involving more than one RCU read-side
	critical section and/or more than one RCU grace period?
\item	What happens when RCU is mixed with other memory-ordering
	mechanisms?

\fi

\end{enumerate}

이 질문들은 다음 섹션에서 다루어집니다.

\iffalse

These questions are addressed in the following sections.

\fi

\subsubsection{RCU Read-Side Ordering}
\label{sec:memorder:RCU Read-Side Ordering}

그것 자체로, RCU 의 read-side 기능인 \co{rcu_read_lock()} 과
\co{rcu_read_unlock()} 은 어떤 순서 규칙도 제공하지 않습니다.
특히, 그 이름에도 불구하고
\cref{lst:memorder:RCU Readers Provide No Lock-Like Ordering}
(\path{C-LB+rl-o-o-rul+rl-o-o-rul.litmus}) 에 보인 것처럼 이것들은 락처럼
동작하지 않습니다.
이 리트머스 테스트의 사이클은 허용되어 있습니다: \co{r1} 레지스터의 두
인스턴스가 모두 마지막 값 1을 가질 수 있습니다.

\iffalse

On their own, RCU's read-side primitives \co{rcu_read_lock()} and
\co{rcu_read_unlock()} provide no ordering whatsoever.
In particular, despite their names, they do not act like locks, as can
be seen in
\cref{lst:memorder:RCU Readers Provide No Lock-Like Ordering}
(\path{C-LB+rl-o-o-rul+rl-o-o-rul.litmus}).
This litmus test's cycle is allowed: Both instances of the \co{r1}
register can have final values of 1.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-LB+rl-o-o-rul+rl-o-o-rul@whole.fcv}
\caption{RCU Readers Provide No Lock-Like Ordering}
\label{lst:memorder:RCU Readers Provide No Lock-Like Ordering}
\end{listing}

이 기능들 중 어떤 것도 배리어 같은 순서 속성을 갖지 않는데,
at least not unless there is a grace period in the mix, as can be seen in
\cref{lst:memorder:RCU Readers Provide No Barrier-Like Ordering}
(\path{C-LB+o-rl-rul-o+o-rl-rul-o.litmus}) 에 보인 것처럼 어떤 grace period 가
섞여 있지 않은 한은 그렇습니다.
이 리트머스 테스트의 사이클은 허용되어 있습니다.
(시도해 보세요!)

\iffalse

Nor do these primitives have barrier-like ordering properties,
at least not unless there is a grace period in the mix, as can be seen in
\cref{lst:memorder:RCU Readers Provide No Barrier-Like Ordering}
(\path{C-LB+o-rl-rul-o+o-rl-rul-o.litmus}).
This litmus test's cycle is also allowed.
(Try it!)

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-LB+o-rl-rul-o+o-rl-rul-o@whole.fcv}
\caption{RCU Readers Provide No Barrier-Like Ordering}
\label{lst:memorder:RCU Readers Provide No Barrier-Like Ordering}
\end{listing}

물론, 이 두 리트머스 테스트에서의 순서의 부재는 \co{rcu_read_lock()} 와
\co{rcu_read_unlock()} 이 모두 RCU 의 QSBR 구현에서는 no-op 이라는 점을
생각하면 결코 놀랍지 않을 겁니다.

\iffalse

Of course, lack of ordering in both these litmus tests should be absolutely
no surprise, given that both \co{rcu_read_lock()} and \co{rcu_read_unlock()}
are no-ops in the QSBR implementation of RCU\@.

\fi

\subsubsection{RCU Update-Side Ordering}
\label{sec:memorder:RCU Update-Side Ordering}

RCU 읽기 쪽 것들과 달리, RCU update-side 기능들인 \co{synchronize_rcu()} 와
\co{synchronize_rcu_expedited()} 는 최소 \co{smp_mb()} 만큼은 강력한 메모리
순서를 제공하며
\cref{lst:memorder:RCU Updaters Provide Full Ordering} 에 보인 리트머스
테스트를 \co{herd} 로 돌려봄으로써 볼 수 있습니다.
이 테스트의 사이클은 \co{smp_mb()} 를 놓는 것처럼 금지되어 있습니다.
이는
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet} 에 보인 정보를
놓고 보면 놀라운 일은 아닐 겁니다.

\iffalse

In contrast with RCU readers, the RCU update-side functions
\co{synchronize_rcu()} and \co{synchronize_rcu_expedited()}
provide memory ordering at least as strong as \co{smp_mb()},
as can be seen by running \co{herd} on the litmus test shown in
\cref{lst:memorder:RCU Updaters Provide Full Ordering}.
This test's cycle is prohibited, just as it would with \co{smp_mb()}.
This should be no surprise given the information presented in
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+o-rcusync-o@whole.fcv}
\caption{RCU Updaters Provide Full Ordering}
\label{lst:memorder:RCU Updaters Provide Full Ordering}
\end{listing}

\subsubsection{RCU Readers: Before and After}
\label{sec:memorder:RCU Readers: Before and After}

이 섹션을 읽기 전에, 사용 가능한 보장과 지속 관리되어야 하는 소프트웨어가 기댈
수 있는 보장의 다름을 생각하는게 좋을 겁니다.
이를 분명히 명심해 두고, 이 섹션은 보다 신기한 RCU 보장들을 보입니다.

\iffalse

Before reading this section, it would be well to reflect on the distinction
between guarantees that are available and guarantees that maintainable
software should rely on.
Keeping that firmly in mind, this section presents a few of the
more exotic RCU guarantees.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+o-rl-o-rul@whole.fcv}
\caption{What Happens Before RCU Readers?}
\label{lst:memorder:What Happens Before RCU Readers?}
\end{listing}

\Cref{lst:memorder:What Happens Before RCU Readers?}
(\path{C-SB+o-rcusync-o+o-rl-o-rul.litmus})
는
\cref{lst:memorder:RCU Fundamental Property} 에 보인 것과 유사하지만 RCU 읽기
쓰레드의 첫번째 액세스가 RCU read-side 크리티컬 섹션을 앞서는데, 보다 전통적인
(그리고 유지보수 가능한!) 방법 역시 안에 내포되어 있습니다.
어쩌면 놀랍게도, 이 리트머스 테스트를 \co{herd} 로 돌리는 것은
\cref{lst:memorder:RCU Fundamental Property} 에서와 같은 결과를 냈습니다:
사이클이 금지되었습니다.

왜 그런 걸까요?

\iffalse

\Cref{lst:memorder:What Happens Before RCU Readers?}
(\path{C-SB+o-rcusync-o+o-rl-o-rul.litmus})
shows a litmus test similar to that in
\cref{lst:memorder:RCU Fundamental Property},
but with the RCU reader's first access preceding the RCU read-side critical
section, rather than the more conventional (and maintainable!) approach of
being contained within it.
Perhaps surprisingly, running \co{herd} on this litmus test gives the
same result as for that in
\cref{lst:memorder:RCU Fundamental Property}:
The cycle is forbidden.

Why would this be the case?

\fi

\co{P1()} 의 액세스들은 모두 volatile 이어서,
\cref{sec:toolsoftrade:A Volatile Solution} 에서 이야기한 바와 같이 이
컴파일러는 이것들을 재배치 하지 못합니다.
이 말은 \co{P1()} 의 \co{WRITE_ONCE()} 에 의해 생성된 코드는 \co{P1()} 의
\co{READ_ONCE()} 를 앞서게 됩니다.
따라서, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 안에 메모리 배리어
명령을 넣는 RCU 구현은 \co{P1()} 의 두 액세스의 순서를 하드웨어 단계까지
유지시킬 겁니다.
다른 한편, 인터럽트 기반의 상태 기계에 기반하는 RCU 구현 역시 이 순서를
\emph{grace period 에 상대적으로} 지킬 것인데 인터럽트가 인터럽트된 코드의
정확한 수행 위치에서 이뤄진다는 사실 때문입니다.

이는 결국 \co{WRITE_ONCE()} 가 특정 RCU grace period 의 끝을 뒤따른다면, 그 RCU
read-side 크리티컬 섹션 내의 \emph{그리고 뒤따르는} 액세스들은 같은 grace
period 의 시작을 뒤따르게 된다는 것입니다.
비슷하게, \co{READ_ONCE()} 가 grace period 의 시작을 앞선다면 그 크리티컬 섹션
내의 그리고 \emph{앞서는} 모든 것은 같은 grace period 의 끝을 앞서야만 합니다.

\iffalse

Because both of \co{P1()}'s accesses are volatile,
as discussed in
\cref{sec:toolsoftrade:A Volatile Solution},
the compiler is not permitted to reorder them.
This means that the code emitted for \co{P1()}'s \co{WRITE_ONCE()} will
precede that of \co{P1()}'s \co{READ_ONCE()}.
Therefore, RCU implementations that place memory-barrier instructions in
\co{rcu_read_lock()} and \co{rcu_read_unlock()} will preserve the ordering
of \co{P1()}'s two accesses all the way down to the hardware level.
On the other hand, RCU implementations that rely on interrupt-based
state machines will also fully preserve this ordering
\emph{relative to the grace period} due to the fact that interrupts take
place at a precise location in the execution of the interrupted code.

This in turn means that if the \co{WRITE_ONCE()} follows the end of a
given RCU grace period, then the accesses within \emph{and following}
that RCU read-side critical section must follow the beginning of that
same grace period.
Similarly, if the \co{READ_ONCE()} precedes the beginning of the grace
period, everything within \emph{and preceding} that critical section
must precede the end of that same grace period.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+rl-o-rul-o@whole.fcv}
\caption{What Happens After RCU Readers?}
\label{lst:memorder:What Happens After RCU Readers?}
\end{listing}

\Cref{lst:memorder:What Happens After RCU Readers?}
(\path{C-SB+o-rcusync-o+rl-o-rul-o.litmus})
도 비슷하지만 RCU read-side 크리티컬 섹션 뒤의 액세스를 알아봅니다.
이 테스트의 사이클 역시 금지되어 있으며, \co{herd} 를 통해 검사할 수 있습니다.
그 이유는
\cref{lst:memorder:What Happens Before RCU Readers?}
의 것과 비슷하며 독자 여러분의 연습을 위해 놔두겠습니다.

\iffalse

\Cref{lst:memorder:What Happens After RCU Readers?}
(\path{C-SB+o-rcusync-o+rl-o-rul-o.litmus})
is similar, but instead looks at accesses after the RCU read-side
critical section.
This test's cycle is also forbidden, as can be checked with the \co{herd}
tool.
The reasoning is similar to that for
\cref{lst:memorder:What Happens Before RCU Readers?},
and is left as an exercise for the reader.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+o-rl-rul-o@whole.fcv}
\caption{What Happens With Empty RCU Readers?}
\label{lst:memorder:What Happens With Empty RCU Readers?}
\end{listing}

\Cref{lst:memorder:What Happens With Empty RCU Readers?}
(\path{C-SB+o-rcusync-o+o-rl-rul-o.litmus})
는 이를 한단계 더 나아가서 \co{P1()} 의 \co{WRITE_ONCE()} 를 RCU read-side
크리티컬 섹션 앞으로 두고 \co{P1()} 의 \co{READ_ONCE()} 는 그를 뒤따르게 해서
텅 빈 RCU read-side 크리티컬 섹션을 만듭니다.

어쩌면 놀랍게도, 텅 빈 크리티컬 섹션에도 불구하고 RCU 는 여전히 사이클의 형성을
막습니다.
이는 다시 한번 \co{herd} 를 통해 검사될 수 있습니다.
더 나아가, 그 이유는 다시 한번
\cref{lst:memorder:What Happens Before RCU Readers?} 의 것과 비슷합니다.
요약해 보자면, \co{P1()} 의 \co{WRITE_ONCE()} 가 특정 grace period 의 끝을
뒤따른다면, \co{P1()} 의 RCU read-side 크리티컬 섹션---그리고 그를 뒤따르는
모든 것---은 그 grace period 의 시작을 뒤따라야만 합니다.
비슷하게, \co{P1()} 의 \co{READ_ONCE()} 가 특정 grace period 의 시작을
앞선다면, \co{P1()} 의 RCU read-side 크리티컬 섹션---그리고 이를 앞서는
모든것---은 이 grace period 의 뒤를 앞서야만 합니다.
두 경우 모두, 크리티컬 섹션의 비어있음은 관계 없습니다.

\iffalse

\Cref{lst:memorder:What Happens With Empty RCU Readers?}
(\path{C-SB+o-rcusync-o+o-rl-rul-o.litmus})
takes things one step farther, moving \co{P1()}'s \co{WRITE_ONCE()}
to precede the RCU read-side critical section and moving
\co{P1()}'s \co{READ_ONCE()} to follow it, resulting in an
empty RCU read-side critical section.

Perhaps surprisingly, despite the empty critical section, RCU nevertheless
still manages to forbid the cycle.
This can again be checked using the \co{herd} tool.
Furthermore, the reasoning is once again similar to that for
\cref{lst:memorder:What Happens Before RCU Readers?}.
Recapping, if \co{P1()}'s \co{WRITE_ONCE()} follows the end of a given
grace period, then \co{P1()}'s RCU read-side critical section---and
everything following it---must follow the beginning of that same grace
period.
Similarly, if \co{P1()}'s \co{READ_ONCE()} precedes the beginning of a
given grace period, then \co{P1()}'s RCU read-side critical section---and
everything preceding it---must precede the end of that same grace period.
In both cases, the critical section's emptiness is irrelevant.

\fi

\QuickQuiz{
	잠깐만요!
	RCU 의 QSBR 구현에서는 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()}
	에 어떤 코드도 만들어지지 않습니다.
	이 말은
	\cref{lst:memorder:What Happens With Empty RCU Readers?}
	의 RCU read-side 크리티컬 섹션은 그저 비어있음을, 완전히 존재하지
	않음을 의미합니다!!!
	그런데 어떻게 존재하지도 않는 무언가가 순서에 대해 뭔가 효과를 낼 수
	있죠???

	\iffalse

	Wait a minute!
	In QSBR implementations of RCU, no code is emitted for
	\co{rcu_read_lock()} and \co{rcu_read_unlock()}.
	This means that the RCU read-side critical section in
	\cref{lst:memorder:What Happens With Empty RCU Readers?}
	isn't just empty, it is completely nonexistent!!!
	So how can something that doesn't exist at all possibly have
	any effect whatsoever on ordering???

	\fi

}\QuickQuizAnswer{
	QSBR 에서 RCU read-side 크리티컬 섹션은 정말로 사라지지는 않습니다.
	대신, 그것들은 quiescent state 가 만나지는 지점까지 양방향으로
	확장됩니다.
	예를 들어, 리눅스 커널에서 이 크리티컬 섹션은 최근의 \co{schedule()}
	호출부터 다음 \co{schedule()} 호출까지로 확장될 수 있습니다.
	물론, 비 QSBR 구현에서, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()}
	은 순서를 제공하는 코드를 실제로 만듭니다.
	그리고 리눅스 커널에서는 QSBR 구현조차도 컴파일러 \co{barrier()} 를
	\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 에 내포하는데, 이는
	컴파일러가 page fault 를 일으킬 수도 있는 메모리 액세스를 RCU read-side
	크리티컬 섹션 내로 옮기는 것을 막기 위해 필요합니다.

	따라서, 이상하게 보일 수 있겠으나, 텅 빈 RCU read-side 크리티컬 섹션은
	정말로 어떤 정도의 순서 규칙을 제공할 수 있고 제공합니다.

	\iffalse

	Because in QSBR, RCU read-side critical sections don't
	actually disappear.
	Instead, they are extended in both directions until a quiescent
	state is encountered.
	For example, in the Linux kernel, the critical section might
	be extended back to the most recent \co{schedule()} call and
	ahead to the next \co{schedule()} call.
	Of course, in non-QSBR implementations, \co{rcu_read_lock()}
	and \co{rcu_read_unlock()} really do emit code, which can clearly
	provide ordering.
	And within the Linux kernel, even the QSBR implementation
	has a compiler \co{barrier()} in \co{rcu_read_lock()} and
	\co{rcu_read_unlock()}, which is necessary to prevent
	the compiler from moving memory accesses that might result
	in page faults into the RCU read-side critical section.

	Therefore, strange though it might seem, empty RCU read-side
	critical sections really can and do provide some degree of
	ordering.

	\fi

}\QuickQuizEnd

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+o-o@whole.fcv}
\caption{What Happens With No RCU Readers?}
\label{lst:memorder:What Happens With No RCU Readers?}
\end{listing}

이 상황은
\cref{lst:memorder:What Happens With No RCU Readers?}
(\path{C-SB+o-rcusync-o+o-o.litmus})
에 보인 것처럼 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 이 발생하면 무슨
일이 벌어지는지에 대한 질문을 이끕니다.
\co{herd} 로 볼 수 있듯 이 리트머스 테스트의 사이클은 허용되는데, 즉 \co{r2} 의
두 인스턴스가 마지막 값으로 0을 가질 수 있습니다.

이는 텅 빈 RCU read-side 크리티컬 섹션이 순서를 제공한다는 사실을 놓고 볼 때
이상해 보입니다.
그리고 RCU 의 QSBR 구현은 실제로 이 결과를 허용치 않는다는 건 사실인데
\co{P1()} 의 함수 몸체 전체가 preemption 을 금지하고 있어서 \co{P1()} 은 암묵적
RCU read-side 크리티컬 섹션 내에서 수행된다는 사실 때문입니다.
그러나, RCU 는 비 QSBR 구현도 가지며, 이 구현을 사용하는 커널은 preemption
가능한데, 이는 암묵적 RCU read-side 크리티컬 섹션이 존재치 않으며, 그 결과 RCU
가 순서를 강제할 방법이 없다는 겁니다.
따라서, 이 리트머스 테스트의 사이클이 허용됩니다.

\iffalse

This situation leads to the question of what happens if
\co{rcu_read_lock()} and \co{rcu_read_unlock()} are omitted
entirely, as shown in
\cref{lst:memorder:What Happens With No RCU Readers?}
(\path{C-SB+o-rcusync-o+o-o.litmus}).
As can be checked with \co{herd}, this litmus test's cycle is allowed,
that is, both instances of \co{r2} can have final values of zero.

This might seem strange in light of the fact that empty RCU
read-side critical sections can provide ordering.
And it is true that QSBR implementations of RCU would in fact forbid
this outcome, due to the fact that preemption would be disabled across
the entirety of \co{P1()}'s function body, so that \co{P1()} would run
within an implicit RCU read-side critical section.
However, RCU also has non-QSBR implementations, and the kernels running
these implementations are preemptible, which means there is no implied
RCU read-side critical section, and in turn no way for RCU to enforce
ordering.
Therefore, this litmus test's cycle is allowed.

\fi

\QuickQuiz{
	\Cref{lst:memorder:What Happens Before RCU Readers?,%
	lst:memorder:What Happens After RCU Readers?,%
	lst:memorder:What Happens With Empty RCU Readers?} 의 리트머스
	테스트들에 보인 \co{P1()} 의 액세스들은 그것들이
	\cref{lst:memorder:RCU Fundamental Property} 부터
	\cref{lst:memorder:RCU Fundamental Property and Reordering}
	까지에서와 같은 방식으로 재배치 될 수 있나요?

	\iffalse

	Can \co{P1()}'s accesses be reordered in the litmus tests shown in
	\cref{lst:memorder:What Happens Before RCU Readers?,%
	lst:memorder:What Happens After RCU Readers?,%
	lst:memorder:What Happens With Empty RCU Readers?}
	in the same way that they were reordered going from
	\cref{lst:memorder:RCU Fundamental Property}
	to
	\cref{lst:memorder:RCU Fundamental Property and Reordering}?

	\fi

}\QuickQuizAnswer{
	안됩니다, 이 나중의 리트머스 테스트들 중 어느 것도 RCU read-side
	크리티컬 섹션 내에 두개 이상의 액세스를 갖지 않기 때문입니다.
	하지만 예를 들면
	\cref{lst:memorder:What Happens Before RCU Readers?}
	에서 \co{P1()} 의 \co{WRITE_ONCE()} 를 그 크리티컬 섹션 내로, 그리고
	\co{READ_ONCE()} 를 크리티컬 섹션 전으로 놓는 식으로 액세스를 교체하면
	어떻게 될까요?

	이 액세스들을 교체하는 건 \co{r2} 의 두 인스턴스가 마지막 값 0을 갖는
	걸 허용하는데, 달리 말하자면 RCU read-side 크리티컬 섹션의 순서 속성은
	크리티컬 섹션 바깥으로 확장될 수 있으나 그것들의 재배치 속성에 대해서는
	같지 않다는 말입니다.
	이를 \co{herd} 로 검사하고 그 이유를 설명하는 건 독자 여러분의 몫으로
	남겨 둡니다.

	\iffalse

	No, because none of these later litmus tests have more than one
	access within their RCU read-side critical sections.
	But what about swapping the accesses, for example, in
	\cref{lst:memorder:What Happens Before RCU Readers?},
	placing \co{P1()}'s \co{WRITE_ONCE()} within its critical
	section and the \co{READ_ONCE()} before its critical section?

	Swapping the accesses allows both instances of \co{r2} to
	have a final value of zero, in other words, although RCU read-side
	critical sections' ordering properties can extend outside of
	those critical sections, the same is not true of their
	reordering properties.
	Checking this with \co{herd} and explaining why is left as an
	exercise for the reader.

	\fi

}\QuickQuizEnd

\subsubsection{Multiple RCU Readers and Updaters}
\label{sec:memorder:Multiple RCU Readers and Updaters}

\co{synchronize_rcu()} 는 \co{smp_mb()} 보다 강력한 순서 규칙을 가지므로, SB
리트머스 테스트에 얼마나 많은 프로세스들이 있는가에
(\cref{lst:memorder:RCU Updaters Provide Full Ordering} 에서처럼), 관계 없이
\co{synchronize_rcu()} 를 각 프로세스의 액세스 사이에 \co{synchronize_rcu()} 를
두는 것은 사이클을 금지시킵니다.
또한,
\cref{lst:memorder:RCU Fundamental Property}
에 보인 것처럼 한 프로세스는 \co{synchronize_rcu()} 를 사용하고 다른 프로세스는
\co{rcu_read_lock()} 을 사용할 때에도 사이클이 금지됩니다.
그러나, 두 프로세스가
\cref{lst:memorder:RCU Readers Provide No Lock-Like Ordering} 처럼
\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 을 사용한다면 사이클은
허용됩니다.

어떤 RCU 로 보호되는 리트머스 테스트가 금지되고 어떤건 허용될지에 대한 일반적
규칙 같은게 있을까요?
이 섹션은 그 질문에 답해봅니다.

\iffalse

Because \co{synchronize_rcu()} has stronger ordering semantics than does
\co{smp_mb()}, no matter how many processes there are in an SB
litmus test (such as \cref{lst:memorder:RCU Updaters Provide Full Ordering}),
placing \co{synchronize_rcu()} between each process's
accesses prohibits the cycle.
In addition, the cycle is prohibited in an SB test where one process
uses \co{synchronize_rcu()} and the other uses \co{rcu_read_lock()} and
\co{rcu_read_unlock()}, as shown by
\cref{lst:memorder:RCU Fundamental Property}.
However, if both processes use \co{rcu_read_lock()} and
\co{rcu_read_unlock()}, the cycle will be allowed, as shown by
\cref{lst:memorder:RCU Readers Provide No Lock-Like Ordering}.

Is it possible to say anything general about which RCU-protected
litmus tests will be prohibited and which will be allowed?
This section takes up that question.

\fi

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+rl-o-o-rul+rl-o-o-rul@whole.fcv}
\caption{One RCU Grace Period and Two Readers}
\label{lst:memorder:One RCU Grace Period and Two Readers}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/formal/herd/C-SB+o-rcusync-o+o-rcusync-o+rl-o-o-rul+rl-o-o-rul@whole.fcv}
\caption{Two RCU Grace Periods and Two Readers}
\label{lst:memorder:Two RCU Grace Periods and Two Readers}
\end{listing}

더 구체적으로,
\cref{lst:memorder:One RCU Grace Period and Two Readers} 에 보인 것처럼
리트머스 테스트가 하나의 RCU grace period 와 두개의 RCU 읽기 쓰레드가 있다면
어떻게 될까요?
\co{herd} 는 이 사이클이 허용되었다 이야기 합니다만, \emph{왜} 그런지 아는게
좋을 겁니다.\footnote{
	특히 Paul 이 \ppl{Jade}{Alglave} 와 RCU 순서 규칙을 범용화 하기 위해
	일할 때 이 특별한 리트머스 테스트에 대한 생각을 여러번 바꿨다는 것을
	놓고 보면요.}

\iffalse

More specifically, what if the litmus test has one RCU grace
period and two RCU readers, as shown in
\cref{lst:memorder:One RCU Grace Period and Two Readers}?
The \co{herd} tool says that this cycle is allowed, but it would be
good to know \emph{why}.\footnote{
	Especially given that Paul changed his mind several times about
	this particular litmus test when working with \ppl{Jade}{Alglave} to
	generalize RCU ordering semantics.}

\fi

\begin{figure*}[tbp]
\centering
\resizebox{0.75\onecolumntextwidth}{!}{\includegraphics{memorder/RCU1G2R}}
\caption{Cycle for One RCU Grace Period and Two RCU Readers}
\label{fig:memorder:Cycle for One RCU Grace Period and Two RCU Readers}
\end{figure*}

\begin{figure*}[tbp]
\centering
\resizebox{\onecolumntextwidth}{!}{\includegraphics{memorder/RCU2G2R}}
\caption{No Cycle for Two RCU Grace Periods and Two RCU Readers}
\label{fig:memorder:No Cycle for Two RCU Grace Periods and Two RCU Readers}
\end{figure*}

요점은 CPU 가 \co{P1()} 과 \co{P2()} 의 \co{WRITE_ONCE()} 와 \co{READ_ONCE()}
를 재배치 할 수 있다는 겁니다.
그 재배치가 있다면,
\cref{fig:memorder:Cycle for One RCU Grace Period and Two RCU Readers}
가 어떻게 이 사이클이 생성되는지 보입니다:

\iffalse

The key point is that the CPU is free to reorder \co{P1()}'s and \co{P2()}'s
\co{WRITE_ONCE()} and \co{READ_ONCE()}.
With that reordering,
\cref{fig:memorder:Cycle for One RCU Grace Period and Two RCU Readers}
shows how the cycle forms:

\fi

\begin{enumerate}
\item	이 다이어그램의 바닥 근처 점선 화살표로 그려진 것처럼 \co{P0()} 의
	\co{x1} 읽기가 \co{P1()} 의 쓰기를 앞지릅니다.
\item	\co{P1()} 의 쓰기는 \co{P0()} 의 grace period 의 종료를 뒤따르므로,
	\co{P1()} 의 \co{x2} 읽기는 \co{P0()} 의 grace period 의 시작을 앞설 수
	없습니다.
\item	\co{P1()} 의 \co{x2} 읽기가 \co{P2()} 의 쓰기를 앞지릅니다.
\item	\co{P2()} 의 \co{x2} 쓰기가 \co{P0()} 의 grace period 의 종료를
	앞지르므로, \co{P2()} 의 \co{x0} 읽기가 \co{P0()} 의 grace period 의
	시작을 앞지르는 건 완전히 합법적입니다.
\item	따라서, \co{P2()} 의 \co{x0} 읽기는 \co{P0()} 의 쓰기를 앞지를 수
	있어서 사이클이 형성됩니다.

\iffalse

\item	\co{P0()}'s read from \co{x1} precedes \co{P1()}'s write, as
	depicted by the dashed arrow near the bottom of the diagram.
\item	Because \co{P1()}'s write follows the end of \co{P0()}'s grace period,
	\co{P1()}'s read from \co{x2} cannot precede the beginning of
	\co{P0()}'s grace period.
\item	\co{P1()}'s read from \co{x2} precedes \co{P2()}'s write.
\item	Because \co{P2()}'s write to \co{x2} precedes the end of
	\co{P0()}'s grace period, it is completely legal for \co{P2()}'s
	read from \co{x0} to precede the beginning of \co{P0()}'s grace period.
\item	Therefore, \co{P2()}'s read from \co{x0} can precede \co{P0()}'s
	write, thus allowing the cycle to form.

\fi

\end{enumerate}

하지만 grace period 가 하나 더 추가되면 어떤 일이 벌어질까요?
이 상황이
\cref{lst:memorder:Two RCU Grace Periods and Two Readers} 에 그려져 있는데,
하나의 SB 리트머스 테스트로 \co{P0()} 와 \co{P1()} 의 RCU grace period 를
가지고 \co{P2()} 와 \co{P3()} 는 RCU 읽기 쓰레드입니다.
다시 말하지만, CPU 는 RCU read-side 크리티컬 섹션 내에서의 액세스들을 재배치 할
수 있습니다,
\cref{fig:memorder:No Cycle for Two RCU Grace Periods and Two RCU Readers} 에
보인 것과 같이요.
이 사이클이 생성되려면 \co{P2()} 의 크리티컬 섹션은 \co{P1()} 의 grace period
후에 끝나야 하고 \co{P3()} 의 크리티컬 섹션은 같은 grace period 의 시작 뒤에
끝나야 하는데, 이는 또한 \co{P0()} 의 grace period 의 종료 후에 일어날 겁니다.
따라서, \co{P3()} 의 크리티컬 섹션은 \co{P0()} 의 grace period 시작 후에
시작되어야만 하는데, 이는 결국 \co{P3()} 의 \co{x0} 읽기가 \co{P0()} 의 쓰기를
앞설 수 없음을 의미합니다.
따라서, RCU read-side 크리티컬 섹션이 전체 RCU grace period 로 확장될 수
없으므로 사이클이 금지됩니다.

\iffalse

But what happens when another grace period is added?
This situation is shown in
\cref{lst:memorder:Two RCU Grace Periods and Two Readers},
an SB litmus test in which \co{P0()} and \co{P1()} have RCU grace periods
and \co{P2()} and \co{P3()} have RCU readers.
Again, the CPUs can reorder the accesses within RCU read-side critical
sections, as shown in
\cref{fig:memorder:No Cycle for Two RCU Grace Periods and Two RCU Readers}.
For this cycle to form, \co{P2()}'s critical section must
end after \co{P1()}'s grace period and \co{P3()}'s must end after the
beginning of that same grace period, which happens to also be after the
end of \co{P0()}'s grace period.
Therefore, \co{P3()}'s critical section must start after the beginning
of \co{P0()}'s grace period, which in turn means that \co{P3()}'s
read from \co{x0} cannot possibly precede \co{P0()}'s write.
Therefore, the cycle is forbidden because RCU read-side critical sections
cannot span full RCU grace periods.

\fi

그러나,
\cref{fig:memorder:No Cycle for Two RCU Grace Periods and Two RCU Readers}
를 깊이 들여다보면 세번째 읽기 쓰레드를 추가하면 사이클이 허용됨을 알 수
있습니다.
이는 이 세번째 읽기 쓰레드가 \co{P0()} 의 grace period 전에 끝나서 같은 grace
period 의 시작 전에 시작될 수 있기 때문입니다.
이는 결국 일반적인 규칙을 제안하는데, 그것은:  이런 종류의 RCU 만 있는 리트머스
테스트에서, RCU read-side 크리티컬 섹션의 갯수만큼의 RCU grace period 가
존재한다면 사이클은 금지된다.\footnote{
	흥미롭게도, Alan Stern 은 LKMM 의 맥락에서
	\cref{sec:defer:RCU Fundamentals} 에 보인 RCU 의 기본적 속성 두 부분이
	실제로 RCU 공리~\cite{Alglave:2018:FSC:3173162.3177156} 라 불리는 이
	보다 일반적 결과로 보이는 것을 암시함을 증명했습니다.}

\iffalse

However, a closer look at
\cref{fig:memorder:No Cycle for Two RCU Grace Periods and Two RCU Readers}
makes it clear that adding a third reader would allow the cycle.
This is because this third reader could end before the end of \co{P0()}'s
grace period, and thus start before the beginning of that same grace
period.
This in turn suggests the general rule, which is:  In these sorts of RCU-only
litmus tests, if there are at least as many RCU grace periods as there
are RCU read-side critical sections, the cycle is forbidden.\footnote{
	Interestingly enough, Alan Stern proved that within the context
	of LKMM, the two-part fundamental property of RCU expressed
	in \cref{sec:defer:RCU Fundamentals} actually implies
	this seemingly more general result, which is called the RCU
	axiom~\cite{Alglave:2018:FSC:3173162.3177156}.}

\fi

\subsubsection{RCU and Other Ordering Mechanisms}
\label{sec:memorder:RCU and Other Ordering Mechanisms}

하지만 RCU 를 다른 순서 규칙 메커니즘과 결합한 리트머스 테스트는 어떨까요?

일반적 규칙은 사이클을 막는데에는 하나의 메커니즘만 사용된다는 겁니다.

예를 들어,
\cref{lst:memorder:RCU Readers Provide No Lock-Like Ordering} 로 되돌아 가
봅시다.
앞의 섹션에서의 일반적 규칙을 적용하면, 이 리트머스 테스트는 두개의 RCU
read-side 크리티컬 섹션이 있고 어느 RCU grace period 도 없으므로, 사이클이
형성됩니다.
그러나 \co{P0()} 의 \co{WRITE_ONCE()} 가 \co{smp_store_release()} 로 대체되고
\co{P1()} 의 \co{READ_ONCE()} 가 \co{smp_load_acquire()} 로 대체된다면 어떻게
될까요?

RCU 는 여전히 사이클을 허용할 겁니다만, release-acquire 쌍은 금지합니다.
사이클을 금지하는데에 하나의 메커니즘만 사용되므로, 이 release-acquire 쌍이
이겨서 사이클이 금지되게 합니다.

\iffalse

But what about litmus tests that combine RCU with other ordering
mechanisms?

The general rule is that it takes only one mechanism to forbid a cycle.

For example, refer back to
\cref{lst:memorder:RCU Readers Provide No Lock-Like Ordering}.
Applying the general rule from the previous section, because this litmus
test has two RCU read-side critical sections and no RCU grace periods,
the cycle is allowed.
But what if \co{P0()}'s \co{WRITE_ONCE()} is replaced by an
\co{smp_store_release()} and \co{P1()}'s \co{READ_ONCE()} is replaced
by an \co{smp_load_acquire()}?

RCU would still allow the cycle, but the release-acquire pair would
forbid it.
Because it only takes one mechanism to forbid a cycle, the
release-acquire pair would prevail so that the cycle would be
forbidden.

\fi

\begin{figure*}[tbp]
\centering
\resizebox{0.75\onecolumntextwidth}{!}{\includegraphics{memorder/RCU1G2Rmb}}
\caption{Cycle for One RCU Grace Period, Two RCU Readers, and Memory Barrier}
\label{fig:memorder:Cycle for One RCU Grace Period; Two RCU Readers; and Memory Barrier}
\end{figure*}

또다른 예로,
\cref{lst:memorder:One RCU Grace Period and Two Readers}
로 돌아가 봅시다.
이 리트머스 테스트는 두개의 RCU 읽기 쓰레드가 있지만 하나의 grace period 만
있기에, 이 사이클은 허용되지 않습니다.
하지만 \co{smp_mb()} 가 \co{P1()} 의 액세스 쌍 사이에 있다고 해봅시다.
이 새 리트머스 테스트에서는 \co{smp_mb()} 의 추가 때문에 \co{P2()} 와 \co{P1()}
의 크리티컬 섹션 모두 \co{P0()} 의 grace period 의 끝 너머로 확장되는데, 이는
결국 \co{P2()} 의 \co{x0} 읽기가 \co{P0()} 의 쓰기를 앞서지 못하게 하며, 이는
\cref{fig:memorder:Cycle for One RCU Grace Period; Two RCU Readers; and Memory Barrier}
의 빨간 점선 화살표로 그려져 있습니다.
이 경우, RCU 와 완전한 메모리 배리어는 사이클을 금지하기 위해 함께 동작하는데,
RCU 는 \co{P0()}, \co{P1()} 그리고 \co{P2()} 사이의 순서를 유지하고
\co{smp_mb()} 는 \co{P1()} 과 \co{P2()} 사이의 순서를 유지합니다.

\iffalse

For another example, refer back to
\cref{lst:memorder:One RCU Grace Period and Two Readers}.
Because this litmus test has two RCU readers but only one grace period,
its cycle is allowed.
But suppose that an \co{smp_mb()} was placed between \co{P1()}'s
pair of accesses.
In this new litmus test, because of the addition of the \co{smp_mb()},
\co{P2()}'s as well as \co{P1()}'s critical sections would extend beyond the
end of \co{P0()}'s grace period, which in turn would prevent \co{P2()}'s
read from \co{x0} from preceding \co{P0()}'s write, as depicted by the
red dashed arrow in
\cref{fig:memorder:Cycle for One RCU Grace Period; Two RCU Readers; and Memory Barrier}.
In this case, RCU and the full memory barrier work together to forbid
the cycle, with RCU preserving ordering between \co{P0()} and both
\co{P1()} and \co{P2()}, and with the \co{smp_mb()} preserving
ordering between \co{P1()} and \co{P2()}.

\fi

\QuickQuiz{
	\Cref{lst:memorder:One RCU Grace Period and Two Readers}
	의 \co{P2()} 의 액세스 사이에 \co{smp_mb()} 가 위치되면 어떻게 될까요?

	\iffalse

	What would happen if the \co{smp_mb()} was instead added between
	\co{P2()}'s accesses in
	\cref{lst:memorder:One RCU Grace Period and Two Readers}?

	\fi

}\QuickQuizAnswer{
	또다시 사이클은 금지됩니다.
	이에 대한 추가적 분석은 독자 여러분의 몫으로 남겨둡니다.

	\iffalse

	The cycle would again be forbidden.
	Further analysis is left as an exercise for the reader.

	\fi

}\QuickQuizEnd

요약하자면, RCU 의 규칙이 실용적인 곳이라면 그것들은 이제 완전히 정형화
되었습니다~\cite{PaulMcKenney2005RCUSemantics,MathieuDesnoyers2012URCU,AlexeyGotsman2013ESOPRCU,Alglave:2018:FSC:3173162.3177156}.

\iffalse

In short, where RCU's semantics were once purely pragmatic, they are
now fully
formalized~\cite{PaulMcKenney2005RCUSemantics,MathieuDesnoyers2012URCU,AlexeyGotsman2013ESOPRCU,Alglave:2018:FSC:3173162.3177156}.

\fi

% \subsection{SRCU}
% \label{sec:memorder:SRCU}
% @@@ After LWN article

% Nesting vs. value passed from \co{srcu_read_lock()} to
% \co{srcu_read_unlock()}.

% When augmented by \co{smp_mb__after_srcu_read_unlock()}.

더 높은 수준의 기능에 대한 자세한 의미가 보다 많은 정적 분석과 모델 검사를
가능하게 할 것을 희망합니다.

\iffalse

It is hoped that detailed semantics for higher-level primitives will
enable more capable static analysis and model checking.

\fi

\section{Hardware Specifics}
\label{sec:memorder:Hardware Specifics}
\OriginallyPublished{Section}{sec:memorder:Hardware Specifics}{Memory-Barrier Instructions For Specific CPUs}{Linux Journal}{PaulMcKenney2005i,PaulMcKenney2005j}
%
\epigraph{Rock beats paper!}{\emph{Derek Williams}}

\begin{table*}[tb] % @@@ Omitting 'p' prevents unordered floats in 2c builds
\rowcolors{4}{}{lightgray}
\small
\centering
\newcommand{\cpufml}[1]{\begin{picture}(6,50)(0,0)\rotatebox{90}{#1}\end{picture}}
\renewcommand*{\arraystretch}{1.2}\OneColumnHSpace{-.35in}
\begin{tabular}{llccccccccc}
	\toprule
	\multicolumn{2}{l}{~} & \multicolumn{9}{c}{CPU Family} \\
	\cmidrule{3-11}
	\multicolumn{2}{c}{\raisebox{.5ex}{Property}}
	& \cpufml{Alpha}
	& \cpufml{\ARMv7-A/R}
	& \cpufml{\ARMv8}
	& \cpufml{Itanium}
	& \cpufml{MIPS}
	& \cpufml{\Power{}}
	& \cpufml{SPARC TSO}
	& \cpufml{x86}
	& \cpufml{z~Systems}
	\\
	\cmidrule(r){1-2} \cmidrule{3-11}
%		 Alpha ARMv8 ARMv7 Itanium MIPS PPC SPARC x86 z Systems
\cellcolor{white}
	Memory Ordering
	& Loads Reordered After Loads or Stores?
		 & Y   & Y   & Y   & Y     & Y  & Y & ~   & ~ & ~ \\
	& Stores Reordered After Stores?
		 & Y   & Y   & Y   & Y     & Y  & Y & ~   & ~ & ~ \\
\cellcolor{white}
	& Stores Reordered After Loads?
		 & Y   & Y   & Y   & Y     & Y  & Y & Y   & Y & Y \\
	& \parbox[c][6ex]{2in}{\raggedright Atomic Instructions Reordered With\par Loads or Stores?}
		 & Y   & Y   & Y   & ~     & Y  & Y & ~   & ~ & ~ \\
\cellcolor{white}
	& Dependent Loads Reordered?
		 & Y   & ~   & ~   & ~     & ~  & ~ & ~   & ~ & ~ \\
	& Dependent Stores Reordered?
		 & ~   & ~   & ~   & ~     & ~  & ~ & ~   & ~ & ~ \\
\cellcolor{white}
	& Non-Sequentially Consistent?
		 & Y   & Y   & Y   & Y     & Y  & Y & Y   & Y & Y \\
	& Non-Multicopy Atomic?
		 & Y   & Y   & Y   & Y     & Y  & Y & Y   & Y & ~ \\
\cellcolor{white}
	& Non-Other-Multicopy Atomic?
		 & Y   & Y   & ~   & Y     & Y  & Y & ~   & ~ & ~ \\
	& Non-Cache Coherent?
		 & ~   & ~   & ~   & Y     & ~  & ~ & ~   & ~ & ~ \\
	\cmidrule(r){1-2} \cmidrule{3-11}
\cellcolor{white}
	Instructions
	& Load-Acquire/Store-Release?
		 & F   & F   & i   & I     & F  & b & ~   & ~ & ~ \\
	& Atomic RMW Instruction Type?
		 & L   & L   & L   & C     & L  & L & C   & C & C \\
\cellcolor{white}
	& Incoherent Instruction Cache/Pipeline?
		 & Y   & Y   & Y   & Y     & Y  & Y & Y   & Y & Y \\
	\bottomrule
\end{tabular}

\vspace{5pt}\hfill
\framebox[\width]{\footnotesize\setlength{\tabcolsep}{3pt}
\rowcolors{1}{}{}
\renewcommand*{\arraystretch}{1}
\begin{tabular}{llcl}
	{ \bf Key: }
	  & \multicolumn{3}{l}{Load-Acquire/Store-Release?} \\
	~ & ~ & b: & Lightweight memory barrier \\
	~ & ~ & F: & Full memory barrier \\
	~ & ~ & i: & Instruction with lightweight ordering \\
	~ & ~ & I: & Instruction with heavyweight ordering \\
	~ &\multicolumn{3}{l}{Atomic RMW Instruction Type?} \\
	~ & ~ & C: & Compare-and-exchange instruction \\
	~ & ~ & L: & Load-linked/store-conditional instruction \\
\end{tabular}
}\OneColumnHSpace{-0.4in}
\caption{Summary of Memory Ordering}
\label{tab:memorder:Summary of Memory Ordering}
\end{table*}

각 CPU 제품군은 각자만의 메모리 순서규칙에 대한 기묘한 접근법을 취하는데, 이는
\cref{tab:memorder:Summary of Memory Ordering} 에서 이야기된 바와 같이 이식성을
어렵게 할 수 있습니다.
실제로, 일부 소프트웨어 환경은 메모리 순서 오퍼레이션의 사용을 단순히
금지시켜서 프로그래머가 필요한 정도까지는 사용할 수 있는 상호배제 기능까지만
사용할 수 있도록 제약시킵니다.
이 섹션은 각 CPU 제품군의 모든 (또는 심지어 대부분의) 부분을 다루는 레퍼런스
매뉴얼이 되려기보다는 대략적 비교를 제공하는 높은 단계의 개론으로 의도되었음을
명심해 주십시오.
전체 세부사항을 위해선 관심 있는 CPU 의 레퍼런스 매뉴얼을 들여다 보시기
바랍니다.

\iffalse

Each CPU family has its own peculiar approach to memory ordering, which
can make portability a challenge, as indicated by
\cref{tab:memorder:Summary of Memory Ordering}.
In fact, some software environments simply prohibit
direct use of memory-ordering operations, restricting the programmer
to mutual-exclusion primitives that incorporate them to the extent that
they are required.  Please note that this section is not intended to be
a reference manual
covering all (or even most) aspects of each CPU family, but rather
a high-level overview providing a rough comparison.
For full details, see the reference manual for the CPU of interest.

\fi

\Cref{tab:memorder:Summary of Memory Ordering} 로 돌아가서, 열들의 첫번째
그룹은 메모리 순서 속성을 보이고 두번째 그룹은 명령 속성을 보입니다.

첫번째 세 열은 특정 CPU 가
\cref{sec:memorder:Ordering: Why and How?} 와
\crefrange{sec:memorder:Load Followed By Load}{sec:memorder:Store Followed By Store}
에서 이야기된 것처럼 네개의 가능한 로드와 스토어 조합을 재배치 할 수 있는지
보입니다.
다음 열 (``Atomic Instructions Reordered With Loads or Stores?'') 은 특정 CPU
가 어토믹 인스트럭션을 사용하는 로드와 스토어가 재배치 될 수 있는지 보입니다.

다섯번째와 여섯번째 열은 재배치와 의존성을 다루는데, 이는
\crefrange{sec:memorder:Address Dependencies}{sec:memorder:Control Dependencies}
에서 다루어졌고
\cref{sec:memorder:Alpha} 에서 보다 자세한 내용이 설명되었습니다.
간략한 버전으로는 Alpha 가 연결된 데이터 구조에 대한 읽기 쓰레드는 물론
업데이트 쓰레드에도 메모리 배리어를 필요로 하지만, 이 메모리 배리어는 v4.15
이후 리눅스 커널에서의 Alpha 아키텍쳐 전용 코드에 의해 제공된다는 겁니다.

\iffalse

Getting back to
\cref{tab:memorder:Summary of Memory Ordering},
the first group of rows look at memory-ordering
properties and the second group looks at instruction properties.

The first three rows indicate whether a given CPU allows the four
possible combinations of loads and stores to be reordered, as discussed
in
\cref{sec:memorder:Ordering: Why and How?} and
\crefrange{sec:memorder:Load Followed By Load}{sec:memorder:Store Followed By Store}.
The next row (``Atomic Instructions Reordered With Loads or Stores?'')
indicates whether a given CPU allows loads and stores
to be reordered with atomic instructions.

The fifth and sixth rows cover reordering and dependencies,
which was covered in
\crefrange{sec:memorder:Address Dependencies}{sec:memorder:Control Dependencies}
and which is explained in more detail in
\cref{sec:memorder:Alpha}.
The short version is that Alpha requires memory barriers for readers
as well as updaters of linked data structures, however, these memory
barriers are provided by the Alpha architecture-specific code in
v4.15 and later Linux kernels.

\fi

다음 열, ``Non-Sequentially Consistent'' 은 CPU 의 평범한 로드와 스토어 명령이
sequential consistency 에 의해 제약되는지 보입니다.
거의 모두가 성능상 이유로 이 방법으로는 제약되지 않습니다.

다음 두 열은 multicopy atomicity 를 다루는데,
\cref{sec:memorder:Multicopy Atomicity} 에서 정의되었습니다.
첫번째는 완전한 (그리고 드문) multicopy atomicity 이고, 두번째 것은 완화된
다른것들에 대한 multicopy atomicity 입니다.

다음 열, ``Non-Cache Coherent'' 는
\cref{sec:memorder:Cache Coherence} 에서 다루었던 여러 쓰레드의 단일 변수로의
액세스를 다룹니다.

마지막 세개의 열은 명령 수준의 선택과 문제를 다룹니다.
첫번째 열은 각 CPU 가 load-acquire 와 store-release 를 어떻게 구현하는지
알리고, 두번째 열은 CPU 들을 atomic-instruction 종류로 구분하며, 마지막 세번째
열은 특정 CPU 가 일관적이지 않은 명령 캐쉬와 파이프라인을 갖는지 보입니다.
그런 CPU 는 스스로를 수정하는 코드를 위해 특별한 명령을 수행해야 합니다.

\iffalse

The next row, ``Non-Sequentially Consistent'', indicates whether
the CPU's normal load and store instructions are constrained by
sequential consistency.
Almost all are not constrained in this way for performance reasons.

The next two rows cover multicopy atomicity, which was defined in
\cref{sec:memorder:Multicopy Atomicity}.
The first is full-up (and rare) multicopy atomicity, and the second is the
weaker other-multicopy atomicity.

The next row, ``Non-Cache Coherent'', covers accesses from multiple
threads to a single variable, which was discussed in
\cref{sec:memorder:Cache Coherence}.

The final three rows cover instruction-level choices and issues.
The first row indicates how each CPU implements load-acquire
and store-release, the second row classifies CPUs by atomic-instruction
type, and the third and final row
indicates whether a given CPU has an incoherent
instruction cache and pipeline.
Such CPUs require special instructions be executed for self-modifying
code.

\fi

%Parenthesized CPU names indicate modes that are architecturally allowed,
%but rarely used in practice.

메모리 순서 오퍼레이션에 ``그냥 안된다고 하기'' 라는 흔한 방법은 적용되는
곳에서는 탁월하게 합리적입니다만, 리눅스 커널과 같이 직접적인 메모리 순서
오퍼레이션이 필요한 환경도 있습니다.
따라서, 리눅스는 주의깊게 선택된 최소 공통 분모 메모리 순서 기능 집합을
제공하는데, 다음과 같습니다:

\iffalse

The common ``just say no'' approach to memory-ordering operations
can be eminently reasonable where it applies,
but there are environments, such as the Linux kernel, where direct
use of memory-ordering operations is required.
Therefore,
Linux provides a carefully chosen least-common-denominator
set of memory-ordering primitives, which are as follows:

\fi

\begin{description}
\item	[\tco{smp_bm()}] (완전한 메모리 배리어) 는 로드와 스토어를 모두
	순서잡습니다.
	이는 메모리 배리어를 앞서는 로드와 스토어가 메모리 배리어를 뒤따르는
	로드와 스토어보다 먼저 메모리에 가해질 것을 의미합니다.
\item	[\tco{smp_rmb()}] (읽기 메모리 배리어) 는 로드만을 순서잡습니다.
\item	[\tco{smp_wmb()}] (쓰기 메모리 배리어) 는 스토어만을 순서잡습니다.
\item	[\tco{smp_mb__before_atomic()}] 은 \co{smp_mb__before_atomic()} 을
	앞서는 액세스들을 뒤의 RMW 어토믹 오퍼레이션을 뒤따르는 액세스에 대해
	순서잡습니다.
	완전히 순서잡힌 어토믹 RMW 오퍼레이션을 제공하는 시스템에서 이는 noop
	입니다.
\item	[\tco{smp_mb__after_atomic()}] 은 앞의 RMW 어토믹 오퍼레이션을 앞서는
	액세스들을 \co{smp_mb__after_atomic()} 을 뒤따르는 액세스에 대해
	순서잡습니다.
	완전히 순서잡힌 어토믹 RMW 오퍼레이션을 제공하는 시스템에서는 이것 역시
	noop 입니다.
\item	[\tco{smp_mb__after_spinlock()}] 은 락 획득을 앞서는 액세스들을
	\co{smp_mb__after_atomic()} 을 뒤따르는 것들에 대해 순서잡습니다.
	완전히 순서 잡힌 락 획득을 제공하는 시스템에서는 이것 역시 noop 입니다.
\item	[\tco{mmiowb()}] 는 전역 스핀락으로 보호되는 MMIO 쓰기를 순서잡으며,
	2016년의 MMIO 에 대한 LWN 기사에서 더 자세히
	설명되었습니다~\cite{PaulEMcKenney2016LinuxKernelMMIO}.

\iffalse

\item	[\tco{smp_mb()}] (full memory barrier) that orders both loads and
	stores.
	This means that loads and stores preceding the memory barrier
	will be committed to memory before any loads and stores
	following the memory barrier.
\item	[\tco{smp_rmb()}] (read memory barrier) that orders only loads.
\item	[\tco{smp_wmb()}] (write memory barrier) that orders only stores.
\item	[\tco{smp_mb__before_atomic()}] that forces ordering of accesses
	preceding the \co{smp_mb__before_atomic()} against accesses following
	a later RMW atomic operation.
	This is a noop on systems that fully order atomic RMW operations.
\item	[\tco{smp_mb__after_atomic()}] that forces ordering of accesses
	preceding an earlier RMW atomic operation against accesses
	following the \co{smp_mb__after_atomic()}.
	This is also a noop on systems that fully order atomic RMW operations.
\item	[\tco{smp_mb__after_spinlock()}] that forces ordering of accesses
	preceding a lock acquisition against accesses
	following the \co{smp_mb__after_spinlock()}.
	This is also a noop on systems that fully order lock acquisitions.
\item	[\tco{mmiowb()}] that forces ordering on MMIO writes that are guarded
	by global spinlocks, and is more thoroughly described
	in a 2016 LWN article on MMIO~\cite{PaulEMcKenney2016LinuxKernelMMIO}.

\fi

\end{description}

\co{smp_mb()}, \co{smp_rmb()}, 그리고 \co{smp_wmb()} 기능들은 또한 컴파일러가
배리어 앞뒤로 메모리 재배치를 할 수 있는 최적화를 금지하게 합니다.

\iffalse

The \co{smp_mb()}, \co{smp_rmb()}, and \co{smp_wmb()}
primitives also force
the compiler to eschew any optimizations that would have the effect
of reordering memory optimizations across the barriers.

\fi

\QuickQuiz{
	어토믹 오퍼레이션과 \co{smp_mb__after_atomic()} 사이의 코드엔 무슨 일이
	벌어지나요?

	\iffalse

	What happens to code between an atomic operation and an
	\co{smp_mb__after_atomic()}?

	\fi

}\QuickQuizAnswer{
	일단, 그런 일을 벌이지 마세요!

	하지만 만약 그런다면, 이 중간의 코드는 \co{smp_mb__after_atomic()}
	전이나 후로 순서잡히는데, 아키텍쳐에 의존적이나, 둘 다에 배치될 수는
	없습니다.
	이는 또한 \co{smp_mb__before_atomic()} 과 \co{smp_mb__after_spinlock()}
	에 적용되는데, 즉, 중간의 코드에는 불명확한 순서가 지어지며 그런 코드는
	막아야 합니다.

	\iffalse

	First, please don't do this!

	But if you do, this intervening code will either be ordered
	after the atomic operation or before the
	\co{smp_mb__after_atomic()}, depending on the architecture,
	but not both.
	This also applies to \co{smp_mb__before_atomic()} and
	\co{smp_mb__after_spinlock()}, that is, both the uncertain
	ordering of the intervening code and the plea to avoid such code.

	\fi

}\QuickQuizEnd

이 기능들은 SMP 커널에서만 코드를 생성합니다만, UP (Uni Processor) 커널에서도
메모리 배리어를 생성하는 몇몇 UP 버전이 (\co{mb()}, \co{rmb()}, 그리고
\co{wmb()}) 존재합니다.
대부분의 상황에서는 \co{smp_} 버전들이 사용되어야 합니다.
그러나, 이 뒤의 기능들은 드라이버를 작성할 때 유용한데, MMIO 액세스는 UP
커널에서도 순서를 지켜야 하기 때문입니다.
메모리 순서 오퍼레이션의 부재 시에, CPU 와 컴파일러는 모두 액세스를 재배치할 수
있는데, 이는 최선의 경우에도 기기가 이상하게 동작하게 하며, 커널을 깨지게
하거나 여러분의 하드웨어를 손상시킬 수조차 있습니다.

따라서 대부분의 커널 프로그래머는 이 인터페이스를 사용하는 이상 각 CPU 의
이상한 메모리 순서 규칙에 걱정하지 않아도 됩니다.
여러분이 특정 CPU 의 아키텍쳐 특수 코드에 깊이 관여하고 있다면, 물론 마음대로
해도 됩니다.

\iffalse

These primitives generate code only in SMP kernels, however, several
have UP versions (\co{mb()}, \co{rmb()}, and \co{wmb()},
respectively) that generate a memory barrier even in UP kernels.
The \co{smp_} versions should be used in most cases.
However, these latter primitives are useful when writing drivers,
because MMIO accesses must remain ordered even in UP kernels.
In absence of memory-ordering operations, both CPUs and compilers would
happily rearrange these accesses, which at best would make the device
act strangely, and could crash your kernel or even damage your hardware.

So most kernel programmers need not worry about the memory-ordering
peculiarities of each and every CPU, as long as they stick to these
interfaces.
If you are working deep in a given CPU's architecture-specific code,
of course, all bets are off.

\fi

더 나아가서, 리눅스의 락킹 기능 (spinlock, reader-writer 락, semaphore, RCU,
\ldots) 은 모든 필요한 순서 기능을 내포합니다.
따라서 이 기능들을 올바르게 사용한 코드를 가지고 작업한다면 리눅스의 메모리
순서 기능들에 대해 염려하지 않아도 됩니다.

그렇다고는 하나, 각 CPU 의 메모리 일관성 모델에 대한 깊은 지식은 아키텍쳐 특수
코드나 동기화 기능을 작성할 때 디버깅에 매우 도움될 수 있습니다.

곁다리로, 어떤 사람들은 얕은 지식은 매우 위험하다고 합니다.
많은 지식을 가지고 여러분이 입힐 수 있는 피해들을 생각해 보세요!
각 CPU 의 메모리 일관성 모델에 대해 이해하길 원하는 분들을 위해, 다음 섹션은
일부 유명하고 대중적인 CPU 들을 알아봅니다.
실제로 해당 CPU 의 문서를 읽는 것을 대체할 방법은 없지만, 이 섹션들은 좋은
개요를 제공합니다.

\iffalse

Furthermore,
all of Linux's locking primitives (spinlocks, reader-writer locks,
semaphores, RCU, \ldots) include any needed ordering primitives.
So if you are working with code that uses these primitives properly,
you need not worry about Linux's memory-ordering primitives.

That said, deep knowledge of each CPU's memory-consistency model
can be very helpful when debugging, to say nothing of when writing
architecture-specific code or synchronization primitives.

Besides, they say that a little knowledge is a very dangerous thing.
Just imagine the damage you could do with a lot of knowledge!
For those who wish to understand more about individual CPUs'
memory consistency models, the next sections describe those of a few
popular and prominent CPUs.
Although there is no substitute for actually reading a given CPU's
documentation, these sections do give a good overview.

\fi

\subsection{Alpha}
\label{sec:memorder:Alpha}

수명이 한참 전에 끝난 CPU 에 대해 무언가 이야기하는 건 이상하게 보일 수 있지만,
Alpha 는 종속적 로드를 재배치하는 유일한 주류 CPU 라서 흥미로운 경우이며,
따라서 리눅스 커널을 포함해 동시성 API 에 두드러지는 영향을 끼쳤습니다.
핵심 리눅스 커널 코드에서 Alpha 를 위해 필요했던 코드는 리눅스 커널 v4.15 을
끝으로 사라졌으며, 이 모든 지원을 위한 기록은 \co{smp_read_barrier_depends()}
와 \co{read_barrier_depends()} API 의 제거와 함께 사라졌습니다.
이 섹션은 2021년 초 기준으로 여전히 v4.15 전 버전의 리눅스 커널을 가지고 일하는
리눅스 커널 해커들이 꽤 존재하기 때문에 Second Edition 까지는 유지됩니다.
또한, 이 API 들이 제거될 수 있게 한 \co{READ_ONCE()} 의 변경은 여전히 Alpha 를
지원하는 유저스페이스 프로젝트들에 전파되지 않았을 수 있습니다.

\iffalse

It may seem strange to say much of anything about a CPU whose end of life
has long since passed, but Alpha is interesting because it is the only
mainstream CPU that reorders dependent loads, and has thus had outsized
influence on concurrency APIs, including within the Linux kernel.
The need for core Linux-kernel code to accommodate Alpha ended
with version v4.15 of the Linux kernel, and all traces of this
accommodation were removed in v5.9 with the removal of the
\co{smp_read_barrier_depends()} and \co{read_barrier_depends()} APIs.
This section is nevertheless retained in the Second Edition
% @@@ Update after release of Second Edition.
because here in early 2021 there are quite a few Linux kernel hackers
still working on pre-v4.15 versions of the Linux kernel.
In addition, the modifications to \co{READ_ONCE()} that permitted
these APIs to be removed have not necessarily propagated to all
userspace projects that might still support Alpha.

\fi

\begin{fcvref}[ln:memorder:Insert and Lock-Free Search (No Ordering)]
Alpha 와 다른 CPU 사이의 종속적 로드에 대한 차이가
\cref{lst:memorder:Insert and Lock-Free Search (No Ordering)}
의 코드에 보여져 있습니다.
이 \co{smp_store_release()} 는 \clnrefrange{init:b}{init:e} 의 원소 초기화가 그
원소가 \clnref{add} 에서 리스트에 추가되기 전에 행해지게끔 보장해서 lock-free
탐색이 올바르게 동작하게끔 합니다.
즉, 이 보장이 Alpha 를 {\em 제외한} 모든 CPU 에서 보장되게 합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:memorder:Insert and Lock-Free Search (No Ordering)]
The dependent-load difference between Alpha and the other CPUs is
illustrated by the code shown in
\cref{lst:memorder:Insert and Lock-Free Search (No Ordering)}.
This \co{smp_store_release()}
guarantees that the element initialization
in \clnrefrange{init:b}{init:e} is executed before the element is added to the
list on \clnref{add}, so that the lock-free search will work correctly.
That is, it makes this guarantee on all CPUs {\em except} Alpha.
\end{fcvref}

\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Insert and Lock-Free Search (No Ordering)]
\begin{VerbatimL}[commandchars=\\\[\]]
struct el *insert(long key, long data)
{
	struct el *p;
	p = kmalloc(sizeof(*p), GFP_ATOMIC);
	spin_lock(&mutex);
	p->next = head.next;		\lnlbl[init:b]
	p->key = key;
	p->data = data;			\lnlbl[init:e]
	smp_store_release(&head.next, p); \lnlbl[add]
	spin_unlock(&mutex);
}

struct el *search(long searchkey)
{
	struct el *p;
	p = READ_ONCE_OLD(head.next);	\lnlbl[h:next]
	while (p != &head) {
		/* Prior to v4.15, BUG ON ALPHA!!! */ \lnlbl[BUG]
		if (p->key == searchkey) {	\lnlbl[key]
			return (p);
		}
		p = READ_ONCE_OLD(p->next);	\lnlbl[next]
	};
	return (NULL);
}
\end{VerbatimL}
\end{fcvlabel}
\caption{Insert and Lock-Free Search (No Ordering)}
\label{lst:memorder:Insert and Lock-Free Search (No Ordering)}
\end{listing}

\begin{fcvref}[ln:memorder:Insert and Lock-Free Search (No Ordering)]
이 코드에서 \co{READ_ONCE_OLD()} 라고 표시된 v4.15 이전 버전에서의
\co{READ_ONCE()} 구현이 사용되면, Alpha 는 실제로
\cref{lst:memorder:Insert and Lock-Free Search (No Ordering)}
의 \clnref{key} 의 코드가 \clnrefrange{init:b}{init:e} 에서의 초기화 전의
오래된 쓰레기 값을 볼 수 있게 합니다.

\iffalse

\begin{fcvref}[ln:memorder:Insert and Lock-Free Search (No Ordering)]
Given the pre-v4.15 implementation of \co{READ_ONCE()}, indicated by
\co{READ_ONCE_OLD()} in the listing, Alpha actually allows the code on
\clnref{key} of
\cref{lst:memorder:Insert and Lock-Free Search (No Ordering)}
to see the old garbage values that were present before the initialization
on \clnrefrange{init:b}{init:e}.

\fi

\Cref{fig:memorder:fig:memorder:Why smp-read-barrier-depends() is Required in Pre-v4.15 Linux Kernels}
는 분할된 캐쉬를 가져서 캐쉬 라인을 교체하는 것이 캐쉬의 다른 파티션에서 수행될
수 있으며 공격적인 병렬 기계에서 이게 어떻게 일어날 수 있는지 보입니다.
예를 들어,
\cref{lst:memorder:Insert and Lock-Free Search (No Ordering)} 의
\clnref{h:next} 에서의 \co{head.next} 로드는 캐쉬 뱅크~0 을 액세스 했을 수도
있고, \clnref{key} 에서의 \co{p->key} 로드와 \clnref{next} 에서의 \co{p->next}
로드는 캐쉬 뱅크~1 을 액세스 했을 수도 있습니다.
Alpha 에서, \co{smp_store_release()} 는
\cref{lst:memorder:Insert and Lock-Free Search (No Ordering)}
의 \clnrefrange{init:b}{init:e} 에서 수행된 (\co{p->next}, \co{p->key}, 그리고
\co{p->data} 에 대한) 캐쉬 무효화가 \clnref{add} 의 (\co{head.next} 를 위한)
것보다 먼저 중간 연결부에 도달하게 하지만, 읽는 CPU 의 캐쉬 뱅크로의 전파
순서에 대해선 어떤 보장도 하지 않습니다.
예를 들면, 읽는 CPU 의 캐쉬 뱅크~1 이 매우 바쁜 사이 뱅크~0 은 한가할 수
있습니다.
이는 새 원소를 위한 (\co{p->next}, \co{p->key}, 그리고 \co{p->data} 의) 캐쉬
무효화가 지연되게 하여서 읽는 CPU 는 \co{head.next} 의 새 값을 로드하지만
\co{p->key} 와 \co{p->next} 의 과거에 캐쉬된 값을 로드하게 할 수 있습니다.
그렇습니다, 이는 Alpha 가 실제로 가리켜진 데이터를 그 포인터 자체보다 {\em
먼저} 읽어올 수 있는데, 이는 이상하지만 사실입니다.
\end{fcvref}
더 많은 정보를 위해선, 또는 제가 뭔가 잘못 이야기하고 있다고 느끼신다면 앞에서
이야기된 문서를~\cite{Compaq01,WilliamPugh2000Gharachorloo} 읽어
보세요.\footnote{
	물론, 영리한 독자 여러분은
	\cref{sec:app:whymb:Ordering-Hostile Architecture}
	의 상상속 아키텍쳐의 경우처럼 (감사하게도) 이미 Alpha 가 주변에 없음을
	알아차렸을 겁니다.}
이 일반적이지 않은 순서 규칙의 이익은 Alpha 가 더 간단한 캐쉬 하드웨어를 가질
수 있어서 결국 Alpha 의 전성기에는 더 높은 클락 주파수를 가능하게 했다는
겁니다.

\iffalse

\Cref{fig:memorder:fig:memorder:Why smp-read-barrier-depends() is Required in Pre-v4.15 Linux Kernels}
shows how this can happen on
an aggressively parallel machine with partitioned caches, so that
alternating cache lines are processed by the different partitions
of the caches.
For example, the load of \co{head.next} on \clnref{h:next} of
\cref{lst:memorder:Insert and Lock-Free Search (No Ordering)}
might access cache bank~0,
and the load of \co{p->key} on \clnref{key} and of \co{p->next} on \clnref{next}
might access cache bank~1.
On Alpha, the \co{smp_store_release()} will guarantee that the cache
invalidations performed by \clnrefrange{init:b}{init:e} of
\cref{lst:memorder:Insert and Lock-Free Search (No Ordering)}
(for \co{p->next}, \co{p->key}, and \co{p->data}) will reach
the interconnect before that of \clnref{add} (for \co{head.next}), but
makes absolutely no guarantee about the order of
propagation through the reading CPU's cache banks.
For example, it is possible that the reading CPU's cache bank~1 is very
busy, but cache bank~0 is idle.
This could result in the cache invalidations for the new element
(\co{p->next}, \co{p->key}, and \co{p->data}) being
delayed, so that the reading CPU loads the new value for \co{head.next},
but loads the old cached values for \co{p->key} and \co{p->next}.
Yes, this does mean that Alpha can in effect fetch
the data pointed to {\em before} it fetches the pointer itself, strange
but true.
\end{fcvref}
See the documentation~\cite{Compaq01,WilliamPugh2000Gharachorloo}
called out earlier for more information,
or if you think that I am just making all this up.\footnote{
	Of course, the astute reader will have already recognized that
	Alpha is nowhere near as mean and nasty as it could be,
	the (thankfully) mythical architecture in
	\cref{sec:app:whymb:Ordering-Hostile Architecture}
	being a case in point.}
The benefit of this unusual approach to ordering is that Alpha can use
simpler cache hardware, which in turn permitted higher clock frequencies
in Alpha's heyday.

\fi

\begin{figure}[tbp]
\centering
\resizebox{\twocolumnwidth}{!}{\includegraphics{memorder/Alpha}}
\caption{Why \tco{smp_read_barrier_depends()} is Required in Pre-v4.15 Linux Kernels}
\label{fig:memorder:fig:memorder:Why smp-read-barrier-depends() is Required in Pre-v4.15 Linux Kernels}
\end{figure}

어떤 사람은 Alpha 가 이 포인터 읽기와 뒤따르는 종속적 로드 사이에 순서를 지키게
하기 위해 \co{smp_rmb()} 를 포인터 읽기와 그 역참조 사이에 위치시킬 수 있을
겁니다.
그러나, 이는 읽기 쪽의 데이터 종속성을 지켜주는 시스템에서는 (\ARM, Itanium,
PPC, 그리고 SPARC 등) 불필요한 오버헤드를 일으킬 겁니다.
그래서 이런 시스템에서의 오버헤드를 제거하기 위해
\co{smp_read_barrier_depends()} 기능이 리눅스 커널에 추가되었습니다만, Alpha 의
\co{READ_ONCE()} 정의의 강화 덕에 v5.9 리눅스 커널에서는 사라졌습니다.
따라서, v5.9 기준으로, 코어 커널 코드는 더이상 DEC Alpha 때문에 걱정할 필요가
없습니다.
\begin{fcvref}[ln:memorder:Safe Insert and Lock-Free Search]
하지만,
\cref{lst:memorder:Safe Insert and Lock-Free Search}
의 \clnref{deref1,deref2} 에서 보이듯 모든 최근의 커널 버전에서 안전하고
효율적으로 동작하는 \co{rcu_dereference()} 를 사용하는게 낫습니다.
\end{fcvref}

\iffalse

One could place an \co{smp_rmb()} primitive
between the pointer fetch and dereference in order to force Alpha
to order the pointer fetch with the later dependent load.
However, this imposes unneeded overhead on systems (such as \ARM,
Itanium, PPC, and SPARC) that respect data dependencies on the read side.
A \co{smp_read_barrier_depends()} primitive was therefore added to the
Linux kernel to eliminate overhead on these systems, but was removed
in v5.9 of the Linux kernel in favor of augmenting Alpha's definition
of \co{READ_ONCE()}.
Thus, as of v5.9, core kernel code no longer needs to concern itself
with this aspect of DEC Alpha.
\begin{fcvref}[ln:memorder:Safe Insert and Lock-Free Search]
However, it is better to use \co{rcu_dereference()}
as shown on \clnref{deref1,deref2} of
\cref{lst:memorder:Safe Insert and Lock-Free Search},
which works safely and efficiently for all recent kernel versions.
\end{fcvref}

\fi

또한 모든 읽기를 하는 CPU 가 쓰기를 하는 CPU 의 쓰기를 순서대로 보게 하게끔
\co{smp_store_release()} 자리에 소프트웨어 메커니즘을 구현할 수도 있습니다.
이 소프트웨어 배리어는 inter-processor interrupt (IPI) 들을 모든 다른 CPU 에게
보냄으로써 구현될 수 있습니다.
그런 IPI 를 받으면, CPU 는 메모리 배리어 명령을 수행하므로, 리눅스 커널의
\co{sys_membarrier()} 시스템콜이 제공하는 것과 비슷한 시스템 범위 메모리
배리어를 구현합니다.
데드락을 막기 위해 추가적 로직이 필요합니다.
물론, 데이터 종속성을 지키는 CPU 는 그런 배리어를 간단히
\co{smp_store_release()} 로 정의할 겁니다.
하지만, 리눅스 커뮤니티는 이 방법은 지나친 오버헤드를
발생시키며~\cite{McKenney01f}, 그들의 시점에서는 이는 공격적인 리얼타임 응답
요구가 있는 상황에서는 완전히 부적절하다고 여깁니다.

\iffalse

It is also possible to implement a software mechanism
that could be used in place of \co{smp_store_release()} to force
all reading CPUs to see the writing CPU's writes in order.
This software barrier could be implemented by sending inter-processor
interrupts (IPIs) to all other CPUs.
Upon receipt of such an IPI, a CPU would execute a memory-barrier
instruction, implementing a system-wide memory barrier similar to that
provided by the Linux kernel's \co{sys_membarrier()} system call.
Additional logic is required to avoid deadlocks.
Of course, CPUs that respect data dependencies would define such a barrier
to simply be \co{smp_store_release()}.
However, this approach was deemed by the Linux community
to impose excessive overhead~\cite{McKenney01f}, and to their point would
be completely inappropriate for systems having
aggressive real-time response requirements.

\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:Safe Insert and Lock-Free Search]
\begin{VerbatimL}[commandchars=\\\[\]]
struct el *insert(long key, long data)
{
	struct el *p;
	p = kmalloc(sizeof(*p), GFP_ATOMIC);
	spin_lock(&mutex);
	p->next = head.next;
	p->key = key;
	p->data = data;
	smp_store_release(&head.next, p);
	spin_unlock(&mutex);
}

struct el *search(long searchkey)
{
	struct el *p;
	p = rcu_dereference(head.next);		\lnlbl[deref1]
	while (p != &head) {
		if (p->key == searchkey) {
			return (p);
		}
		p = rcu_dereference(p->next);	\lnlbl[deref2]
	};
	return (NULL);
}
\end{VerbatimL}
\end{fcvlabel}
\caption{Safe Insert and Lock-Free Search}
\label{lst:memorder:Safe Insert and Lock-Free Search}
\end{listing}

리눅스 메모리 배리어 기능들은 그들의 이름을 Alpha 명령들에서 따와서
\co{smp_mb()} 는 \co{mb} 이고 \co{smp_rmb()} 는 \co{rmb} 이며 \co{smp_wmb()} 는
\co{wmb} 입니다.
Alpha 는 \co{READ_ONCE()} 가 \co{smp_mb()} 를 내포하는 유일한 CPU 입니다.

\iffalse

The Linux memory-barrier primitives took their names from the Alpha
instructions, so \co{smp_mb()} is \co{mb}, \co{smp_rmb()} is \co{rmb},
and \co{smp_wmb()} is \co{wmb}.
Alpha is the only CPU whose \co{READ_ONCE()} includes an \co{smp_mb()}.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	Alpha 의 \co{READ_ONCE()} 는 왜 \co{rmb} 가 아니라 \co{mb} 명령을
	내포하나요?

	\iffalse

	Why does Alpha's \co{READ_ONCE()} include an
	\co{mb} instruction rather than a \co{rmb}?

	\fi

}\QuickQuizAnswerB{
	Alpha 는 \co{mb} 와 \co{wmb} 명령만을 가져서, 어떻게 하든
	\co{smp_rmb()} 는 Alpha 의 \co{mb} 명령으로 구현될 겁니다.
	또한, 리눅스 커널이 종속성 순서에 기대기 시작했던 시점에서는 Alpha 가
	종속된 스토어의 순서를 지켜주는지 분명치 않았고, 따라서 \co{smp_mb()}
	가 안전한 선택이었습니다.

	그러나, 앞서 설명한 v5.9 의 \co{READ_ONCE()} 변경과 일부 Alpha 의
	어토믹 read-modify-write 오퍼레이션들을 놓고 생각하면, 어떤 리눅스 커널
	핵심 코드도 DEC Alpha 에 대해 걱정할 필요가 없으며, 따라서 커널에서
	Alpha 지원을 제거하기 위한 Paul E.~McKenney 의 동기를 크게 줄여줍니다.

	\iffalse

	Alpha has only \co{mb} and \co{wmb} instructions,
	so \co{smp_rmb()} would be implemented by the Alpha \co{mb}
	instruction in either case.
	In addition, at the time that the Linux kernel started relying on
	dependency ordering, it was not clear that Alpha ordered dependent
	stores, and thus \co{smp_mb()} was therefore the safe choice.

	However, given the aforementioned v5.9 changes to \co{READ_ONCE()}
	and a few of Alpha's atomic read-modify-write operations,
	no Linux-kernel core code need concern itself with DEC Alpha,
	thus greatly reducing Paul E.~McKenney's incentive to remove
	Alpha support from the kernel.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	DEC Alpha 는 가능한 메모리 순서 규칙 중 가장 약한 것을 가지니 중요하지
	않나요?

	\iffalse

	Isn't DEC Alpha significant as having the weakest possible
	memory ordering?

	\fi

}\QuickQuizAnswerE{
	DEC Alpha 가 상당한 비난을 받기는 하나, 같은 CPU 에서 같은 변수로의
	읽기들에 대한 재배치는 막습니다.
	또한 Java 와 C11 메모리 모델을 괴롭히는 out-of-thin-air 문제도
	막습니다~\cite{Boehm:2014:OGA:2618128.2618134,conf/esop/BattyMNPS15,MarkBatty2013OOTA-WorkingNote,HansBoehm2020ConcurrentUB,DavidGoldblatt2019NoElegantOOTAfix,AlanJeffrey2014JavaDRF,PaulEMcKenney2020RelaxedGuideRelaxed,PaulEMcKenney2016OOTA,Sevcik:2011:SOS:1993316.1993534,Vafeiadis:2015:CCO:2775051.2676995}.

	\iffalse

	Although DEC Alpha does take considerable flak, it does avoid
	reordering reads from the same CPU to the same variable.
	It also avoids the out-of-thin-air problem that plagues
	the Java and C11 memory
	models~\cite{Boehm:2014:OGA:2618128.2618134,conf/esop/BattyMNPS15,MarkBatty2013OOTA-WorkingNote,HansBoehm2020ConcurrentUB,DavidGoldblatt2019NoElegantOOTAfix,AlanJeffrey2014JavaDRF,PaulEMcKenney2020RelaxedGuideRelaxed,PaulEMcKenney2016OOTA,Sevcik:2011:SOS:1993316.1993534,Vafeiadis:2015:CCO:2775051.2676995}.

	\fi

}\QuickQuizEndE
}

Alpha 에 대한 더 많은 내용을 위해선 레퍼런스 매뉴얼을~\cite{ALPHA2002} 보시기
바랍니다.

\iffalse

For more on Alpha, see its reference manual~\cite{ALPHA2002}.

\fi

\subsection{\ARMv7-A/R}
\label{sec:memorder:ARMv7-A/R}

\ARM\ 제품군 CPU 는 임베디드 어플리케이션에서, 특히 휴대폰과 같이 전력이 제한된
어플리케이션에서 굉장히 인기있습니다.
이것의 메모리 모델은 \Power{} 와 유사합니다만
(\cref{sec:memorder:POWER / PowerPC} 를 참고하세요), \ARM\ 은 다른 메모리
배리어 명령 집합을 사용합니다~\cite{ARMv7A:2010}:

\iffalse

The \ARM\ family of CPUs is extremely popular in embedded applications,
particularly for power-constrained applications such as cellphones.
Its memory model is similar to that of \Power{}
(see \cref{sec:memorder:POWER / PowerPC}), but \ARM\ uses a
different set of memory-barrier instructions~\cite{ARMv7A:2010}:

\fi

\begin{description}
\item	[\tco{DMB}] (data memory barrier) 는 명시된 종류의 오퍼레이션이 같은
	타입의 뒤따르는 모든 오퍼레이션보다 앞서 완료된 것으로 \emph{보이게}
	합니다.
	오퍼레이션의 ``타입'' 은 모든 오퍼레이션이거나 쓰기만으로 제한될 수
	있습니다 (Alpha 의 \co{wmb} 와 \Power{} \co{eieio} 인스트럭션과
	유사합니다).
	또한, \ARM\ 은 캐쉬 일관성이 세개의 범위를 가질 수 있게 합니다: 단일
	프로세서, 프로세서의 부분집합 (``inner'') 그리고 전역 (``outer'').
\item	[\tco{DSB}] (data synchronization barrier) 는 명시된 타입의
	오퍼레이션이 뒤따르는 (모든 타입의) 오퍼레이션이 수행되기 전에 정말로
	완료되게 합니다.
	오퍼레이션의 ``타입'' 은 \co{DMB} 의 것과 같습니다.
	\co{DSB} 명령은 \ARM\ 아키텍쳐의 초기에는 \co{DWB} (drain write buffer
	또는 data write barrier) 라고 불렸습니다.
\item	[\tco{ISB}] (instruction synchronization barrier) 는 CPU 파이프라인을
	비워서, \co{ISB} 를 뒤따르는 모든 명령이 \co{ISB} 의 완료 후에만
	읽어지게 만듭니다.
	예를 들어, 스스로를 수정하는 프로그램 (JIT 같은) 을 작성한다면,
	여러분은 코드의 생성과 그것의 수행 사이에 \co{ISB} 를 수행해야 합니다.

\iffalse

\item	[\tco{DMB}] (data memory barrier) causes the specified type of
	operations to \emph{appear} to have completed before any
	subsequent operations of the same type.
	The ``type'' of operations can be all operations or can be
	restricted to only writes (similar to the Alpha \co{wmb}
	and the \Power{} \co{eieio} instructions).
	In addition, \ARM\ allows cache coherence to have one of three
	scopes: single processor, a subset of the processors
	(``inner'') and global (``outer'').
\item	[\tco{DSB}] (data synchronization barrier) causes the specified
	type of operations to actually complete before any subsequent
	operations (of any type) are executed.
	The ``type'' of operations is the same as that of \co{DMB}.
	The \co{DSB} instruction was called \co{DWB} (drain write buffer
	or data write barrier, your choice) in early versions of the
	\ARM\ architecture.
\item	[\tco{ISB}] (instruction synchronization barrier) flushes the CPU
	pipeline, so that all instructions following the \co{ISB}
	are fetched only after the \co{ISB} completes.
	For example, if you are writing a self-modifying program
	(such as a JIT), you should execute an \co{ISB} between
	generating the code and executing it.

\fi

\end{description}

이 명령들 중 어느 것도 리눅스의 \co{rmb()} 기능의 명세에 정확히 들어맞지
않으며, 따라서 완전한 \co{DMB} 로 구현됩니다.
\co{DMB} 와 \co{DSB} 명령은 이 배리어 전후로 순서잡힌 액세스들에 대한 회귀적
정의를 갖는데, \Power{} 의 cumulativity 와 유사한 효과를 내며, 이는 둘 다
\cref{sec:memorder:Cumulativity} 에서 설명된 LKMM 의 cumulativity 보다 더
강력한 것입니다.

\ARM\ 은 또한 제어 종속성을 구현하여서 어떤 조건적 분기가 어떤 로드에
종속적이라면, 그 조건적 분기 뒤에 수행되는 모든 스토어는 그 로드 뒤로
순서잡힙니다.
그러나, 조건적 분기를 뒤따르는 로드는 그 분기와 로드 사이에 \co{ISB} 명령이
있지 않은 한 순서잡힐 것으로 보장되지 \emph{않습니다}.
다음 예를 생각해 봅시다:

\iffalse

None of these instructions exactly match the semantics of Linux's
\co{rmb()} primitive, which must therefore be implemented as a full
\co{DMB}.
The \co{DMB} and \co{DSB} instructions have a recursive definition
of accesses ordered before and after the barrier, which has an effect
similar to that of \Power{}'s cumulativity, both of which are
stronger than LKMM's cumulativity described in
\cref{sec:memorder:Cumulativity}.

\ARM\ also implements control dependencies, so that if a conditional
branch depends on a load, then any store executed after that conditional
branch will be ordered after the load.
However, loads following the conditional branch will \emph{not}
be guaranteed to be ordered unless there is an \co{ISB}
instruction between the branch and the load.
Consider the following example:

\fi

\begin{fcvlabel}[ln:memorder:ARM:load-store control dependency]
\begin{VerbatimN}[commandchars=\\\[\]]
r1 = x;			\lnlbl[x]
if (r1 == 0)		\lnlbl[if]
	nop();		\lnlbl[nop]
y = 1;			\lnlbl[y]
r2 = z;			\lnlbl[z1]
ISB();			\lnlbl[isb]
r3 = z;			\lnlbl[z2]
\end{VerbatimN}
\end{fcvlabel}

\begin{fcvref}[ln:memorder:ARM:load-store control dependency]
이 예에서, 로드-스토어 제어종속성 순서규칙은 \clnref{x} 에서의 \co{x} 로드를
\clnref{y} 에서의 \co{y} 로의 스토어 전으로 순서잡습니다.
하지만, \ARM\ 은 로드-로드 제어 종속성을 지키지 않으므로, \clnref{x} 에서의
로드는 \clnref{z1} 의 로드 \emph{뒤에} 벌어질 수도 있습니다.
다른 한편, \clnref{if} 에서의 조건적 분기와 \clnref{isb} 의 \co{ISB} 명령은
\clnref{z2} 의 로드가 \clnref{x} 의 로드 뒤에 일어날 것을 보장합니다.
추가적인 \co{ISB} 명령을 \clnref{if,z1} 사이 어딘가에 배치하는 것은
\clnref{x,z1} 사이의 순서를 강제함을 알아 두시기 바랍니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:memorder:ARM:load-store control dependency]
In this example, load-store control dependency ordering causes
the load from \co{x} on \clnref{x} to be ordered before the store to
\co{y} on \clnref{y}.
However, \ARM\ does not respect load-load control dependencies, so that
the load on \clnref{x} might well happen \emph{after} the
load on \clnref{z1}.
On the other hand, the combination of the conditional branch on \clnref{if}
and the \co{ISB} instruction on \clnref{isb} ensures that
the load on \clnref{z2} happens after the load on \clnref{x}.
Note that inserting an additional \co{ISB} instruction somewhere between
\clnref{if,z1} would enforce ordering between \clnref{x,z1}.
\end{fcvref}

\fi

\subsection{\ARMv8}
\label{sec:memorder:ARMv8}

\begin{figure}[tb]
\centering
\resizebox{2in}{!}{\includegraphics{cartoons/r-2014-LDLAR}}
\caption{Half Memory Barrier}
\ContributedBy{Figure}{fig:memorder:Half Memory Barrier}{Melissa Brossard}
\end{figure}

\ARM\ 의 \ARMv8 CPU 제품군은~\cite{ARMv8A:2017}
\cref{sec:memorder:ARMv7-A/R} 에 설명된 32비트만 지원하는 CPU 와 달리 64비트
기능을 갖습니다.
\ARMv8 의 메모리 모델은 그것의 \ARMv7 쪽 것들을 상당히 닮아있습니다만
load-acquire (\co{LDLARB}, \co{LDLARH}, 그리고 \co{LDLAR}) 와 store-release
(\co{STLLRB}, \co{STLLRH}, 그리고 \co{STLLR}) 명령을 추가했습니다.
이 명령들은 ``반쪽 메모리 배리어'' 로 동작해서 \ARMv8 CPU 는 앞의 액세스를 뒤의
\co{LDLAR} 명령과 재배치할 수 있지만 앞의 \co{LDLAR} 명령을 뒤의 액세스와는
재배치 할 수 없는데,
\cref{fig:memorder:Half Memory Barrier} 에 이게 그려져 있습니다.
비슷하게, \ARMv8 CPU 는 앞의 \co{STLLR} 명령을 뒤따르는 액세스와 재배치 할 수
있지만, 뒤의 \co{STLLR} 과 앞의 액세스는 재배치 할 수 없습니다.
예상할 수 있듯, 이는 이 명령들은 C11 의 load-acquire 와 store-release 노선을
직접적으로 지원합니다.

\iffalse

\ARM's \ARMv8 CPU family~\cite{ARMv8A:2017}
includes 64-bit capabilities,
in contrast to their 32-bit-only CPU described in
\cref{sec:memorder:ARMv7-A/R}.
\ARMv8's memory model closely resembles its \ARMv7 counterpart,
but adds load-acquire (\co{LDLARB}, \co{LDLARH}, and \co{LDLAR})
and store-release (\co{STLLRB}, \co{STLLRH}, and \co{STLLR})
instructions.
These instructions act as ``half memory barriers'', so that
\ARMv8 CPUs can reorder previous accesses with a later \co{LDLAR}
instruction, but are prohibited from reordering an earlier \co{LDLAR}
instruction with later accesses, as fancifully depicted in
\cref{fig:memorder:Half Memory Barrier}.
Similarly, \ARMv8 CPUs can reorder an earlier \co{STLLR} instruction with
a subsequent access, but are prohibited from reordering
previous accesses with a later \co{STLLR} instruction.
As one might expect, this means that these instructions directly support
the C11 notion of load-acquire and store-release.

\fi

그러나, \ARMv8 은 store-release 와 load-acquire 의 조합이 특정 상황에서는
완전한 배리어로 동작할 것을 강제함으로써 C11 메모리 모델보다 더한 것을
제공합니다.
예를 들어, \ARMv8 에서 어떤 스토어 뒤에 store-release 가 있고 그 뒤에
load-acquire, 그리고 로드가 있다면, 그리고 그것들이 모두 다른 변수를 향한
것이라면 모두 하나의 CPU 에서 행해진다면, 모든 CPU 는 처음의 스토어가 마지막의
로드를 앞선다고 보게 됩니다.
흥미롭게도, 대부분의 TSO 구조들은 (x86 과 mainframe 포함) 이 보장을 내지
않는데, 여기서의 두 로드는 두 스토어 앞으로 재배치 될 수 있기 때문입니다.

\ARMv8 은 \co{smp_mb__after_spinlock()} 이 완전체 배리어가 되어야 하는 두 구조
중 하나인데, 리눅스 커널 내에서의 상대적으로 약한 lock-acquisition 구현
때문입니다.

\ARMv8 은 또한 제조사가 공개적으로 수행 가능한 정식 모델과 함께 메모리 규칙을
정의한~\cite{ARMv8A:2017} 최초의 CPU 로 차별화 됩니다.

\iffalse

However, \ARMv8 goes well beyond the C11 memory model by mandating that
the combination of a store-release and load-acquire act as a full
barrier under certain circumstances.
For example, in \ARMv8, given a store followed by a store-release followed
a load-acquire followed by a load, all to different variables and all from
a single CPU, all CPUs
would agree that the initial store preceded the final load.
Interestingly enough, most TSO architectures (including x86 and the
mainframe) do not make this guarantee, as the two loads could be
reordered before the two stores.

\ARMv8 is one of only two architectures that needs the
\co{smp_mb__after_spinlock()} primitive to be a full barrier,
due to its relatively weak lock-acquisition implementation in
the Linux kernel.

\ARMv8 also has the distinction of being the first CPU whose vendor publicly
defined its memory ordering with an executable formal model~\cite{ARMv8A:2017}.

\fi

\subsection{Itanium}
\label{sec:memorder:Itanium}

Itanium 은 완화된 일관성 모델을 제공해서 명시적 메모리 배리어 명령이나 종속성이
없으면 Itanium 은 임의적으로 메모리 참조를 재배치 할 수
있습니다~\cite{IntelItanium02v2}.
Itanium 은 \co{mf} 라는 이름의 메모리 장벽 명령을 제공합니다만 로드, 스토어,
그리고 일부 어토믹 인스트럭션을 위한 ``반쪽 메모리 장벽'' 변화기 또한
제공합니다~\cite{IntelItanium02v3}.
\co{acq} 변화기는 뒤따르는 메모리 참조 명령이 \co{acq} 전으로 재배치 되는 것을
막습니다만 앞의 메모리 참조 명령이 \co{acq} 뒤로 재배치 되는 것은 허용하는데,
\ARMv8 load-acquire 명령과 비슷합니다.
비슷하게 \co{rel} 변화기는 앞의 메모리 참조 명령이 \co{rel} 뒤로 재배치 되는
것은 막지만 뒤따르는 메모리 참조 명령이 \co{rel} 앞으로 재배치 되는 것은
허용합니다.

\iffalse

Itanium offers a weak consistency model, so that in absence of explicit
memory-barrier instructions or dependencies, Itanium is within its rights
to arbitrarily reorder memory references~\cite{IntelItanium02v2}.
Itanium has a memory-fence instruction named \co{mf}, but also has
``half-memory fence'' modifiers to loads, stores, and to some of its atomic
instructions~\cite{IntelItanium02v3}.
The \co{acq} modifier prevents subsequent memory-reference instructions
from being reordered before the \co{acq}, but permits
prior memory-reference instructions to be reordered after the \co{acq},
similar to the \ARMv8 load-acquire instructions.
Similarly, the \co{rel} modifier prevents prior memory-reference
instructions from being reordered after the \co{rel}, but allows
subsequent memory-reference instructions to be reordered before
the \co{rel}.

\fi

이 반쪽 메모리 장벽들은 크리티컬 섹션에 유용한데, 크리티컬 섹션은 오퍼레이션을
크리티컬 섹션에 밀어넣는 건 안전하지만 그것들이 밖으로 새어나가면 치명적이기
때문입니다.
그러나, 이 속성을 갖는 몇몇 CPU 중 하나로써 Itanium 은 한때 리눅스의 락 획득과
해제에 연관된 메모리 순서 규칙을 정의했습니다.\footnote{
	지금은 PowerPC 가 이 모호한 혜택을 갖는 아키텍쳐입니다.}
이상하겠지만, 실제 Itanium 하드웨어는 load-acquire 와 store-release 명령을
완전한 배리어로 구현할 것이라는 소문을 가졌습니다.
그러나, Itanium 은 명령어 집합에 load-acquire 와 store-release 의 (실제가
아니라면) 컨셉을 소개한 최초의 주류 CPU 였습니다.

\iffalse

These half-memory fences are useful for critical sections, since
it is safe to push operations into a critical section, but can be
fatal to allow them to bleed out.
However, as one of the few CPUs with this property, Itanium at one
time defined Linux's semantics of memory ordering associated with lock
acquisition and release.\footnote{
	PowerPC is now the architecture with this dubious privilege.}
Oddly enough, actual Itanium hardware is rumored to implement
both load-acquire and store-release instructions as full barriers.
Nevertheless, Itanium was the first mainstream CPU to introduce the concept
(if not the reality) of load-acquire and store-release into its
instruction set.

\fi

\QuickQuiz{
	하드웨어가 반쪽 메모리 배리어를 가질 수 있다면, 락킹 기능은 왜
	컴파일러가 메모리 참조 명령을 락 기반 크리티컬 섹션 안으로 옮길 수 있게
	하지 않죠?

	\iffalse

	Given that hardware can have a half memory barrier, why don't
	locking primitives allow the compiler to move memory-reference
	instructions into lock-based critical sections?

	\fi

}\QuickQuizAnswer{
	사실, \cref{sec:memorder:ARMv8} 에서 보았고
	\cref{sec:memorder:POWER / PowerPC} 에서 보게 될 것이지만, 하드웨어는
	정말로 부분적 메모리 순서 인스트럭션을 구현하며 이것들이 실제로 락킹
	기능을 구축하는데 사용되었습니다.
	그러나, 이 락킹 기능들은 완전한 컴파일러 배리어를 사용하며, 따라서
	컴파일러가 메모리 참조 명령을 연관된 크리티컬 섹션의 안밖으로
	재배치하는 것을 막습니다.

	\iffalse

	In fact, as we saw in \cref{sec:memorder:ARMv8} and will
	see in \cref{sec:memorder:POWER / PowerPC}, hardware really does
	implement partial memory-ordering instructions and it also turns
	out that these really are used to construct locking primitives.
	However, these locking primitives use full compiler barriers,
	thus preventing the compiler from reordering memory-reference
	instructions both out of and into the corresponding critical
	section.

	\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:memorder:synchronize-rcu]
\begin{VerbatimL}[commandchars=\@\[\]]
static inline int rcu_gp_ongoing(unsigned long *ctr)
{
	unsigned long v;

	v = LOAD_SHARED(*ctr);@lnlbl[load]
	return v && (v != rcu_gp_ctr);
}

static void update_counter_and_wait(void)
{
	struct rcu_reader *index;

	STORE_SHARED(rcu_gp_ctr, rcu_gp_ctr + RCU_GP_CTR);
	barrier();
	list_for_each_entry(index, &registry, node) {@lnlbl[loop]
		while (rcu_gp_ongoing(&index->ctr))@lnlbl[call2]
			msleep(10);
	}
}

void synchronize_rcu(void)
{
	unsigned long was_online;

	was_online = rcu_reader.ctr;
	smp_mb();
	if (was_online)@lnlbl[if]
		STORE_SHARED(rcu_reader.ctr, 0);@lnlbl[store]
	mutex_lock(&rcu_gp_lock);@lnlbl[acqmutex]
	update_counter_and_wait();@lnlbl[call1]
	mutex_unlock(&rcu_gp_lock);
	if (was_online)
		STORE_SHARED(rcu_reader.ctr, LOAD_SHARED(rcu_gp_ctr));
	smp_mb();
}
\end{VerbatimL}
\end{fcvlabel}
\caption{Userspace RCU Code Reordering}
\label{lst:memorder:Userspace RCU Code Reordering}
\end{listing}

	왜 컴파일러가 하드웨어에 의해 허용된 재배치를 하지 못하게 했는지 알기
	위해
	\cref{lst:memorder:Userspace RCU Code Reordering} 의 예제 코드를
	보십시오.
	이 코드는 userspace RCU update-side
	코드~\cite[Supplementary Materials Figure 5]{MathieuDesnoyers2012URCU}
	에 기반합니다.

	\iffalse

	To see why the compiler is forbidden from doing reordering that
	is permitted by hardware, consider the following sample code
	in \cref{lst:memorder:Userspace RCU Code Reordering}.
	This code is based on the userspace RCU update-side
	code~\cite[Supplementary Materials Figure 5]{MathieuDesnoyers2012URCU}.

	\fi

\begin{fcvref}[ln:memorder:synchronize-rcu]
	컴파일러가 \clnref{if,store} 를 \clnref{acqmutex} 에서 시작하는
	크리티컬 섹션 내로 재배치했다고 해봅시다.
	이제 두 업데이트 쓰레드가 거의 같은 시간에 \co{synchronize_rcu()} 를
	시작한다고 해봅시다.
	그럼 다음과 같은 이벤트들이 가능할 겁니다:

	\iffalse

	Suppose that the compiler reordered \clnref{if,store} into
	the critical section starting at \clnref{acqmutex}.
	Now suppose that two updaters start executing \co{synchronize_rcu()}
	at about the same time.
	Then consider the following sequence of events:

	\fi

	\begin{enumerate}
	\item	CPU~0 이 \clnref{acqmutex} 에서 락을 획득합니다.
	\item	\Clnref{if} 가 CPU~0 이 온라인임을 알게 되고, 따라서
		\clnref{store} 에서 자신의 카운터를 비웁니다.
		(\clnref{if,store} 가 컴파일러에 의해 \clnref{acqmutex} 뒤로
		재배치 되었음을 기억하세요).
	\item	CPU~0 이 \lnref{call1} 에서 \co{update_counter_and_wait()} 를
		호출합니다.
	\item	CPU~0 이 \clnref{call2} 에서 스스로 \co{rcu_gp_ongoing()} 을
		호출하고 \clnref{load} 가 CPU~0 이 quiescent state 에 있음을
		봅니다.
		따라서 수행은 \co{update_counter_and_wait()} 로 돌아가고
		\clnref{loop} 는 CPU~1 로 넘어갑니다.
	\item	CPU~1 이 \co{synchronize_rcu()} 를 수행하지만 CPU~0 이 이미
		락을 잡고 있으므로, CPU~1 은 이 락이 사용 가능해지길
		기다립니다.
		컴파일러는 \clnref{if,store} 를 \lnref{acqmutex} 뒤로
		재배치했으므로 CPU~1 은 온라인이면서도 자신의 카운터를 지우지
		않습니다.
	\item	CPU~0 이 \clnref{call2} 에서 CPU~1 위에서 \co{rcu_gp_ongoing()}
		을 호출하고 \clnref{load} 는 CPU~1 이 quiescent state 에 있지
		않음을 보게 됩니다.
		따라서 \clnref{call2} 의 \co{while} 반복문은 결코 종료되지
		않습니다.

	\iffalse

	\item	CPU~0 acquires the lock at \clnref{acqmutex}.
	\item	\Clnref{if} determines that CPU~0 was online, so it clears
		its own counter at \clnref{store}.
		(Recall that \clnref{if,store} have been reordered by the
		compiler to follow \clnref{acqmutex}).
	\item	CPU~0 invokes \co{update_counter_and_wait()} from
		\lnref{call1}.
	\item	CPU~0 invokes \co{rcu_gp_ongoing()} on itself at
		\clnref{call2}, and \clnref{load} sees that CPU~0 is
		in a quiescent state.
		Control therefore returns to \co{update_counter_and_wait()},
		and \clnref{loop} advances to CPU~1.
	\item	CPU~1 invokes \co{synchronize_rcu()}, but because CPU~0
		already holds the lock, CPU~1 blocks waiting for this
		lock to become available.
		Because the compiler reordered \clnref{if,store} to follow
		\lnref{acqmutex}, CPU~1 does not clear its own counter,
		despite having been online.
	\item	CPU~0 invokes \co{rcu_gp_ongoing()} on CPU~1 at
		\clnref{call2}, and \clnref{load} sees that CPU~1 is
		not in a quiescent state.
		The \co{while} loop at \clnref{call2} therefore never
		exits.

	\fi

	\end{enumerate}

	그러므로 컴파일러의 재배치가 deadlock 을 초래합니다.
	반면, 하드웨어 재배치는 일시적이어서 CPU~1 은 \clnref{acqmutex} 에서의
	mutex 획득 시도를 \clnref{if,store} 수행 전에 착수할 수 있지만, 결국은
	\clnref{if,store} 를 수행할 겁니다.
	하드웨어 재배치는 짧은 지연을 초래할 뿐이므로, 견뎌질 수 있습니다.
	다른 한편, 컴파일러 재배치는 deadlock 을 초래하므로 반드시 막아져야
	합니다.

	어떤 연구 노력은 컴파일러가 더 적극적인 재배치를 안전하게 할 수 있도록
	하드웨어 transactinal memory 를 사용했습니다만, 하드웨어 transaction 의
	오버헤드는 아직까지는 그런 최적화를 충분히 매력적이진 못하게 했습니다.

	\iffalse

	So the compiler's reordering results in a deadlock.
	In contrast, hardware reordering is temporary, so that CPU~1
	might undertake its first attempt to acquire the mutex on
	\clnref{acqmutex} before executing \clnref{if,store}, but it
	will eventually execute \clnref{if,store}.
	Because hardware reordering only results in a short delay, it
	can be tolerated.
	On the other hand, because compiler reordering results in a
	deadlock, it must be prohibited.

	Some research efforts have used hardware transactional memory
	to allow compilers to safely reorder more aggressively, but
	the overhead of hardware transactions has thus far made
	such optimizations unattractive.
	% @@@ Citation for compilers use of HTM in this manner?

	\fi

\end{fcvref}
}\QuickQuizEnd

Itanium \co{mf} 명령은 리눅스 커널의 \co{smp_rmb()}, \co{smp_mb()}, 그리고
\co{smp_wmb()} 기능에 사용되었습니다.
반대의 지속적인 루머에도 불구하고 \qco{mf} 라는 이름은 ``memory fence'' 의
약자라고 합니다.

Itanium 은 또한 \co{mf} 명령을 포함한 release 오퍼레이션을 위한 전역적 완전
순서를 제공합니다.
이는 transitivity 의 노선을 제공하는데, 이는 특정 코드 조각이 어떤 액세스가
일어났음을 보게 된다면 모든 뒤의 코드 조각은 또한 이 앞의 액세스가 일어난
것으로 본다는 겁니다.
모든 관여된 코드 조각이 올바르게 메모리 배리어를 사용한다는 가정 하입니다.

마지막으로, Itanium 은 리눅스 커널을 지원하며 같은 변수로의 평범한 로드를
재배치 할 수 있는 유일한 아키텍쳐입니다.
리눅스 커널은 \co{READ_ONCE()} 가 특정 CPU 에 의한 같은 변수로의 것을 포함한
모든 \co{READ_ONCE()} 순서를 강제하는, \co{ld,acq} 명령으로 번역되는
\co{volatile} 로드를 만들어내기 때문에 이 문제를 막습니다.

\iffalse

The Itanium \co{mf} instruction is used for the \co{smp_rmb()},
\co{smp_mb()}, and \co{smp_wmb()} primitives in the Linux kernel.
Despite persistent rumors to the contrary, the \qco{mf} mnemonic stands
for ``memory fence''.

Itanium also offers a global total order for release operations,
including the \co{mf} instruction.
This provides the notion of transitivity, where if a given code fragment
sees a given access as having happened, any later code fragment will
also see that earlier access as having happened.
Assuming, that is, that all the code fragments involved correctly use
memory barriers.

Finally, Itanium is the only architecture supporting the Linux kernel
that can reorder normal loads to the same variable.
The Linux kernel avoids this issue because \co{READ_ONCE()} emits
a \co{volatile} load, which is compiled as a \co{ld,acq} instruction,
which forces ordering of all \co{READ_ONCE()} invocations by a given
CPU, including those to the same variable.

\fi

\subsection{MIPS}

MIPS 메모리 모델~\cite[page~479]{MIPSvII-A-2016} 은 \ARM, Itanium, 그리고
\Power{} 의 것을 닮았는데, 기본적으로는 완화된 순서규칙을 가지지만 종속성은
지킵니다.
MIPS 는 다양한 종류의 메모리 배리어 명령을 갖지만 그것들을 하드웨어 주의사항과
연결하지 않고, 그대신 리눅스 커널과 C++11 표준~\cite{RichardSmith2019N4800} 에
의해 제공되는 사용처에 연결하는데 \ARMv8 추가사항과 비슷한 방법입니다:

\iffalse

The MIPS memory model~\cite[page~479]{MIPSvII-A-2016}
appears to resemble that of \ARM, Itanium, and \Power{},
being weakly ordered by default, but respecting dependencies.
MIPS has a wide variety of memory-barrier instructions, but ties them
not to hardware considerations, but rather to the use cases provided
by the Linux kernel and the C++11 standard~\cite{RichardSmith2019N4800}
in a manner similar to the \ARMv8 additions:

\fi

\begin{description}[style=nextline]
\item[\tco{SYNC}]
	OCTEON 시스템을 위한 v4.13 리눅스 커널의 \co{smp_mb()} 구현에 사용된,
	메모리 참조를 포함해 여러 하드웨어 오퍼레이션을 위한 완전한 배리어.
\item[\tco{SYNC_WMB}]
	OCTECON 시스템에서 \co{syncw} 를 통해 v4.13 리눅스 커널의
	\co{smp_wmb()} 구현을 위해 사용될 수 있는 쓰기 메모리 배리어.
	다른 시스템은 평범한 \co{sync} 를 사용합니다.
\item[\tco{SYNC_MB}]
	전체 메모리 배리어이나 메모리 오퍼레이션만을 위해 작동함.
	이는 C++ \co{atomic_thread_fence(memory_order_seq_cst)} 를 구현하는데
	사용될 수 있습니다.
\item[\tco{SYNC_ACQUIRE}]
	C++ 의 \co{atomic_thread_fence(memory_order_acquire)} 를 구현하는데
	사용될 수 있는 acquire 메모리 배리어.
	이론상, 이는 v4.13 리눅스 커널의 \co{smp_load_acquire()} 를 구현하는
	데에 사용될 수 있는데, 실전에서는 \co{sync} 가 대신 사용됩니다.

\iffalse

\item[\tco{SYNC}]
	Full barrier for a number of hardware operations in addition
	to memory references, which is used to implement the v4.13
	Linux kernel's \co{smp_mb()} for OCTEON systems.
\item[\tco{SYNC_WMB}]
	Write memory barrier, which can be used on OCTEON systems
	to implement the
	\co{smp_wmb()} primitive in the v4.13 Linux kernel via the
	\co{syncw} mnemonic.
	Other systems use plain \co{sync}.
\item[\tco{SYNC_MB}]
	Full memory barrier, but only for memory operations.
	This may be used to implement the
	C++ \co{atomic_thread_fence(memory_order_seq_cst)}.
\item[\tco{SYNC_ACQUIRE}]
	Acquire memory barrier, which could be used to implement
	C++'s \co{atomic_thread_fence(memory_order_acquire)}.
	In theory, it could also be used to implement the v4.13 Linux-kernel
	\co{smp_load_acquire()} primitive, but in practice
	\co{sync} is used instead.

\fi

\item[\tco{SYNC_RELEASE}]
	C++ 의 \co{atomic_thread_fence(memory_order_release)} 를 구현하는데에
	사용될 수 있는 release 메모리 배리어.
	이론상, v4.13 리눅스 커널의 \co{smp_store_release()} 기능을 구현하는
	데에 사용될 수 있으나, 실제로는 \co{sync} 가 사용됩니다.
\item[\tco{SYNC_RMB}]
	v4.13 리눅스 커널에 의해 지원되는 현재 MIPS 구현들은 순서를 강제하기
	위한 명시적 명령을 필요로 하지 않는다는 점을 제외하면 이론상 리눅스
	커널의 \co{smp_rmb()} 구현에 사용될 수 있는 읽기 메모리 배리어.
\item[\tco{SYNCI}]
	Just-in-time (JIT) 컴파일러에 의해 생성되는 것과 같은 스스로를 수정하는
	코드를 허용하기 위해 다른 명령들과 함께 사용되는 명령 캐쉬 동기화 기능.

\iffalse

\item[\tco{SYNC_RELEASE}]
	Release memory barrier, which may be used to implement
	C++'s \co{atomic_thread_fence(memory_order_release)}.
	In theory, it could also be used to implement the v4.13 Linux-kernel
	\co{smp_store_release()} primitive, but in practice
	\co{sync} is used instead.
\item[\tco{SYNC_RMB}]
	Read memory barrier, which could in theory be used to implement the
	\co{smp_rmb()} primitive in the Linux kernel, except that current
	MIPS implementations supported by the v4.13 Linux kernel do not
	need an explicit instruction to force ordering.
	Therefore, \co{smp_rmb()} instead simply constrains the compiler.
\item[\tco{SYNCI}]
	Instruction-cache synchronization, which is used in conjunction with
	other instructions to allow self-modifying code, such as that produced
	by just-in-time (JIT) compilers.

\fi

\end{description}

MIPS 아키텍쳐를 위한 비정형적 논의는 MIPS 가 \ARM\ 과 \Power{} 의 그것과 유사한
transitivity 와 cumulativity 정의를 가짐을 알게 합니다.
그러나, 다른 MIPS 구현은 다른 메모리 순서 속성을 가질 수 있는 것으로 보이므로
여러분이 사용하는 특정 MIPS 구현을 위한 문서를 보는게 중요합니다.

\iffalse

Informal discussions with MIPS architects indicates that MIPS has a
definition of transitivity or cumulativity similar to that of
\ARM\ and \Power{}\@.
However, it appears that different MIPS implementations can have
different memory-ordering properties, so it is important to consult
the documentation for the specific MIPS implementation you are using.

\fi

\subsection{\Power{} / PowerPC}
\label{sec:memorder:POWER / PowerPC}

\Power{} 와 PowerPC CPU 제품군은 다양한 메모리 배리어
명령을~\cite{PowerPC94,MichaelLyons05a} 갖습니다:

\iffalse

The \Power{} and PowerPC CPU families have a wide variety of memory-barrier
instructions~\cite{PowerPC94,MichaelLyons05a}:

\fi

\begin{description}
\item	[\tco{sync}] 는 모든 앞의 오퍼레이션이 모든 뒤따르는 오퍼레이션이
	시작하기 전에 완료된 것으로 {\em 보이게} 만듭니다.
	따라서 이 명령은 매우 비용이 높습니다.
\item	[\tco{lwsync}] (lightweight sync) 는 로드를 뒤따르는 로드와
	스토어에 대해 순서 잡으며, 스토어에 대해서도 순서를 잡습니다.
	그러나, 이는 스토어를 뒤따르는 로드에 대해 순서잡지는 {\em 않습니다}.
	\co{lwsync} 명령은 load-acquire 와 store-release 오퍼레이션을
	구현하는데 사용될 수 있습니다.
	흥미롭게도, \co{lwsync} 명령은 x86, z~System, 그리고 우연히도 SPARC TSO
	에서의 것과 동일한 CPU 내 순서를 강제합니다.
	그러나, \co{lwsync} 명령을 각 메모리 참조 명령 사이에 위치시키는 것은
	x86, z~System, 또는 SPARC TSO 메모리 순서 규칙을 만들지는 \emph{않을}
	겁니다.
	이 시스템들에서는 한쌍의 CPU 가 개별적으로 다른 변수에 스토어를
	수행하면 모든 다른 CPU 가 이 스토어들의 순서에 동의합니다.
	PowerPC 에서는 \co{lwsync} 명령이 각 메모리 참조 명령 쌍 사이에 있다고
	해도 그렇지 않은데, PowerPC 는 multicopy atomic 하지 않기 때문입니다.

\iffalse

\item	[\tco{sync}] causes all preceding operations to {\em appear to have}
	completed before any subsequent operations are started.
	This instruction is therefore quite expensive.
\item	[\tco{lwsync}] (lightweight sync) orders loads with respect to
	subsequent loads and stores, and also orders stores.
	However, it does {\em not} order stores with respect to subsequent
	loads.
	The \co{lwsync} instruction may be used to implement
	load-acquire and store-release operations.
	Interestingly enough, the \co{lwsync} instruction enforces
	the same within-CPU ordering as does x86, z~Systems, and coincidentally,
	SPARC TSO\@.
	However, placing the \co{lwsync} instruction between each
	pair of memory-reference instructions will \emph{not}
	result in x86, z~Systems, or SPARC TSO memory ordering.
	On these other systems, if a pair of CPUs independently execute
	stores to different variables, all other CPUs will agree on the
	order of these stores.
	Not so on PowerPC, even with an \co{lwsync} instruction between each
	pair of memory-reference instructions, because PowerPC is
	non-multicopy atomic.

\fi

\item	[\tco{eieio}] (뭐의 약자인지 궁금하시다면, enforce in-order execution
	of I/O) 는 모든 앞의 캐쉬될 수 있는 스토어가 모든 뒤따르는 스토어보다
	먼저 완료된 것으로 나타나게 합니다.
	그러나, 캐쉬될 수 있는 메모리로의 스토어는 캐쉬될 수 없는 메모리로의
	스토어와 별개로 순서지어지는데, 이는 \co{eieio} 가 MMIO 스토어가 스핀락
	해제를 앞서는 걸 강제하지 않음을 의미합니다.
\item	[\tco{isync}] 는 모든 앞의 명령들이 모든 뒤따르는 명령이 수행을
	시작하기 전에 완료된 것으로 나타나게 합니다.
	이는 앞의 명령들이 그것들이 생성할 수 있는 모든 trap 이 일어났거나
	일어나지 않을 것이 보장되었을 정도로, 그리고 이 명령의 모든 부가작용
	(예를 들면, page-table 변경) 뒤따르는 명령에 의해 보일 정도로 충분히
	진행되었어야만 함을 의미합니다.
	그러나, 이는 모든 메모리 참조가 순서잡힐 것을 강제하지 \emph{않고},
	오로지 그 명령 자체의 실제 수행만을 강제합니다.
	따라서, 로드는 여전히 캐쉬되어 있는 오래된 값을 반환할 수 있으며
	\co{isync} 명령은 앞서 저장된 값을 스토어 버퍼로부터 비워지게 강제하지
	않습니다.

\iffalse

\item	[\tco{eieio}] (enforce in-order execution of I/O, in case you
	were wondering) causes all preceding cacheable stores to appear
	to have completed before all subsequent stores.
	However, stores to cacheable memory are ordered separately from
	stores to non-cacheable memory, which means that \co{eieio}
	will not force an MMIO store to precede a spinlock release.
\item	[\tco{isync}] forces all preceding instructions to appear to have
	completed before any subsequent instructions start execution.
	This means that the preceding instructions must have progressed
	far enough that any traps they might generate have either happened
	or are guaranteed not to happen, and that any side-effects of
	these instructions (for example, page-table changes) are seen by the
	subsequent instructions.
	However, it does \emph{not} force all memory references to be
	ordered, only the actual execution of the instruction itself.
	Thus, the loads might return old still-cached values and the
	\co{isync} instruction does not force values previously stored
	to be flushed from the store buffers.

\fi

\end{description}

불행히도, 이 명령들 중 어느 것도 {\em 모든} 스토어가 순서지어져야 하지만
\co{sync} 명령의 높은 오버헤드를 요구하지는 않는 리눅스의 \co{wmb()} 명령에
정확히 맞아떨어지지 않습니다.
그러나 다른 선택지는 없습니다: ppc64 버전의 \co{wmb()} 와 \co{mb()} 는 비용이
높은 \co{sync} 명령으로 정의되었습니다.
그러나, 리눅스의 \co{smp_wmb()} 명령은 MMIO 에 결코 쓰이지 않아서 (드라이버가
MMIO 들을 UP 는 물론 SMP 커널에서도 순서 잡아야 하기 때문), 더 가벼운
\co{eieio} 나 \co{lwsync} 명령으로
정의되었습니다~\cite{PaulEMcKenney2016LinuxKernelMMIO}.
이 명령은 다섯개 모음으로 구성된 이름으로 독특합니다.
\co{smp_mb()} 명령 또한 \co{sync} 명령으로 정의되었습니다만, \co{smp_mrb()} 와
\co{rmb()} 는 모두 더 가벼운 \co{lwsync} 명령으로 정의되었습니다.

\iffalse

Unfortunately, none of these instructions line up exactly with Linux's
\co{wmb()} primitive, which requires {\em all} stores to be ordered,
but does not require the other high-overhead actions of the \co{sync}
instruction.
But there is no choice: ppc64 versions of \co{wmb()} and \co{mb()} are
defined to be the heavyweight \co{sync} instruction.
However, Linux's \co{smp_wmb()} instruction is never used for MMIO
(since a driver must carefully order MMIOs in UP as well as
SMP kernels, after all), so it is defined to be the lighter weight
\co{eieio} or \co{lwsync} instruction~\cite{PaulEMcKenney2016LinuxKernelMMIO}.
This instruction may well be unique in having a five-vowel mnemonic.
The \co{smp_mb()} instruction is also defined to be the \co{sync}
instruction, but both \co{smp_rmb()} and \co{rmb()} are defined to
be the lighter-weight \co{lwsync} instruction.

\fi

\Power{} 는 transitivity 를 관측하는데 사용될 수 있는 ``cumulativity'' 를
제공합니다.
올바르게 사용되면 앞의 코드 조각의 결과를 보는 모든 코드는 이 앞의 코드 조각
그자체가 본 것들에 대한 액세스도 보게 됩니다.
훨씬 많은 세부사항이 McKenney 와 Silvera 에 의해~\cite{PaulEMcKenneyN2745r2009}
정리되어 있습니다.

\Power{} 는 \ARM\ 과 거의 같은 방식으로 제어 종속성을 지킵니다만 \Power{}
\co{isync} 명령은 \ARM\ \co{ISB} 명령으로 대체되어야 합니다.

\iffalse

\Power{} features ``cumulativity'', which can be used to obtain
transitivity.
When used properly, any code seeing the results of an earlier
code fragment will also see the accesses that this earlier code
fragment itself saw.
Much more detail is available from
McKenney and Silvera~\cite{PaulEMcKenneyN2745r2009}.

\Power{} respects control dependencies in much the same way that \ARM\
does, with the exception that the \Power{} \co{isync} instruction
is substituted for the \ARM\ \co{ISB} instruction.

\fi

\ARMv8 과 같이, \Power{} 는 \co{smp_mb__after_spinlock()} 이 완전한 메모리
배리어가 될 것을 필요로 합니다.
또한, \Power{} 는 \co{smp_mb__after_unlock_lock()} 이 완전한 메모리 배리어가 될
것을 필요로 하는 유일한 아키텍쳐입니다.
두 경우 모두, 이는 \Power{} 의 락킹 기능의 완화된 순서 속성 때문이며
\co{lwsync} 명령의 사용이 획득과 해제 둘 다에 순서를 제공해야 하기 때문입니다.

\Power{} 제품군의 많은 제품들이 비일관적 인스트럭션 캐쉬를 가져서 메모리로의
스토어는 인스트럭션 캐쉬에 반영되지 않을 수 있습니다.
고맙게도 몇몇 사람들이 스스로를 수정하는 코드를 요즘 작성하지만, JIT 와
컴파일러는 항상 그러지는 않습니다.
더 나아가, 최근에 수행된 프로그램을 다시 컴파일하는 건 CPU 의 시점에서는
스스로를 수정하는 코드처럼 보입니다.
\co{icbi} 명령 (instruction cache block invalidate) 은 인스트럭션 캐쉬로부터
특정 캐쉬 라인을 무효화 시키며 이 상황에 쓰일 수 있을 겁니다.

\iffalse

Like \ARMv8, \Power{} requires \co{smp_mb__after_spinlock()} to be
a full memory barrier.
In addition, \Power{} is the only architecture requiring
\co{smp_mb__after_unlock_lock()} to be a full memory barrier.
In both cases, this is because of the weak ordering properties
of \Power{}'s locking primitives, due to the use of the \co{lwsync}
instruction to provide ordering for both acquisition and release.

Many members of the \Power{} architecture have incoherent instruction
caches, so that a store to memory will not necessarily be reflected
in the instruction cache.
Thankfully, few people write self-modifying code these days, but JITs
and compilers do it all the time.
Furthermore, recompiling a recently run program looks just like
self-modifying code from the CPU's viewpoint.
The \co{icbi} instruction (instruction cache block invalidate)
invalidates a specified cache line from
the instruction cache, and may be used in these situations.

\fi

\subsection{SPARC TSO}

SPARC 의 TSO (total-store order) 가 리눅스와 Solaris 양쪽에서 사용되지만, 이
아키텍쳐는 PSO (partial store order) 와 RMO (relaxed-memory order) 또한
정의합니다.
RMO 에서 수행되는 모든 프로그램은 PSO 나 TSO 에서도 수행될 것이며, 비슷하게,
PSO 에서 수행되는 프로그램은 TSO 에서도 수행될 겁니다.
공유 메모리 병렬 프로그램을 이와 다른 방향으로 옮기는 것은 주의 깊은 메모리
배리어 삽입을 필요로 할 겁니다.

\iffalse

Although SPARC's TSO (total-store order) is used by both Linux and
Solaris, the architecture also defines PSO (partial store order) and RMO
(relaxed-memory order).
Any program that runs in RMO will also run in either PSO or TSO, and similarly,
a program that runs in PSO will also run in TSO\@.
Moving a shared-memory parallel program in the other direction may
require careful insertion of memory barriers.

\fi

SPARC 의 PSO 와 RMO 모드는 오늘날 그렇게 널리 사용되지는 않지만 그것들은 세밀한
순서 제어를 가능하게 하는 매우 유연한 메모리 배리어 명령을 크게 늘렸습니다:
\begin{description}
\item	[\tco{StoreStore}] 는 앞의 스토어를 뒤의 스토어에 대해 순서 잡습니다.
	(이는 리눅스 \co{smp_wmb()} 기능에서 사용됩니다.)
\item	[\tco{LoadStore}] 는 앞의 로드를 뒤의 스토어에 대해 순서 잡습니다.
\item	[\tco{StoreLoad}] 는 앞의 스토어를 뒤의 로드에 대해 순서 잡습니다.
\item	[\tco{LoadLoad}] 는 앞의 로드를 뒤의 로드에 대해 순서 잡습니다.
	(이는 리눅스 \co{smp_rmb()} 기능에서 사용됩니다.)
\item	[\tco{Sync}] 는 모든 앞의 오퍼레이션을 뒤의 오퍼레이션 전에
	완료시킵니다.
\item	[\tco{MemIssue}] 는 앞의 메모리 오퍼레이션을 뒤의 메모리 오퍼레이션
	전에 완료시키는데, 일부 memory-mapped I/O 에 중요합니다.
\item	[\tco{Lookaside}] 는 MemIssue 와 같은 일을 하지만 앞의 스토어와
	뒤따르는 로드에만 적용되며 거기서도 같은 메모리 위치에 대해 액세스하는
	스토어와 로드에 대해서만입니다.
\end{description}

\iffalse

Although SPARC's PSO and RMO modes are not used much these days, they
did give rise to a very flexible memory-barrier instruction~\cite{SPARC94}
that permits fine-grained control of ordering:
\begin{description}
\item	[\tco{StoreStore}] orders preceding stores before subsequent stores.
	(This option is used by the Linux \co{smp_wmb()} primitive.)
\item	[\tco{LoadStore}] orders preceding loads before subsequent stores.
\item	[\tco{StoreLoad}] orders preceding stores before subsequent loads.
\item	[\tco{LoadLoad}] orders preceding loads before subsequent loads.
	(This option is used by the Linux \co{smp_rmb()} primitive.)
\item	[\tco{Sync}] fully completes all preceding operations before starting
	any subsequent operations.
\item	[\tco{MemIssue}] completes preceding memory operations before subsequent
	memory operations, important for some instances of memory-mapped
	I/O.
\item	[\tco{Lookaside}] does the same as MemIssue,
	but only applies to preceding stores
	and subsequent loads, and even then only for stores and loads that
	access the same memory location.
\end{description}

\fi

그래서, 왜 \qco{membar #MemIssue} 가 필요할까요?
\qco{membar #StoreLoad} 는 뒤의 로드가 그 값을 스토어 버퍼로부터 가져올 수
있어서 그 쓰기가 MMIO 레지스터로의 것이었다면 읽일 값에 부가작용을 일으킬 수
있는 경우라면 문제가 될 수 있기 때문입니다.
반대로, \qco{membar #MemIssue} 는 이 로드가 수행되기 전에 스토어 버퍼가
비워지길 기다리고, 따라서 이 로드는 그 값을 MMIO 레지스터에서 정말로 읽어오게
합니다.
드라이버는 \qco{membar #Sync} 를 대신 사용할 수 있으나, 보다 비용이 높은
\qco{membar #Sync} 의 추가적 기능이 필요치 않을 때에는 더 저렴한 \qco{membar
#MemIssue} 가 선호됩니다.

\qco{membar #Lookaside} 는 \qco{membar #MemIssue} 의 저렴한 버전으로, 특정 MMIO
레지스터로의 쓰기가 그 레지스터로부터 다음에 읽혀질 값에 영향을 끼치는 경우
유용합니다.
그러나, 특정 MMIO 레지스터로의 쓰기가 {\em 다른} MMIO 레지스터로부터 다음에
읽을 값에 영향을 끼치는 경우엔 더 비용이 높은 \qco{membar #MemIssue} 가 반드시
사용되어야 합니다.

\iffalse

So, why is \qco{membar #MemIssue} needed?
Because a \qco{membar #StoreLoad} could permit a subsequent
load to get its value from a store buffer, which would be
disastrous if the write was to an MMIO register that induced side effects
on the value to be read.
In contrast, \qco{membar #MemIssue} would wait until the store buffers
were flushed before permitting the loads to execute,
thereby ensuring that the load actually gets its value from the MMIO register.
Drivers could instead use \qco{membar #Sync}, but the lighter-weight
\qco{membar #MemIssue} is preferred in cases where the additional function
of the more-expensive \qco{membar #Sync} are not required.

The \qco{membar #Lookaside} is a lighter-weight version of
\qco{membar #MemIssue}, which is useful when writing to a given MMIO register
affects the value that will next be read from that register.
However, the heavier-weight \qco{membar #MemIssue} must be used when
a write to a given MMIO register affects the value that will next be
read from {\em some other} MMIO register.

\fi

SPARC 는 인스트럭션 흐름이 수정되었을 때와 이 인스트럭션 중 무언가가 수행되는
시점 사이에 \co{flush} 명령이 사용될 것을 필요로 합니다~\cite{SPARC94}.
이는 해당 위치의 이전 값을 SPARC 의 인스트럭션 캐쉬로부터 비워내기 위해
필요합니다.
\co{flush} 는 주소를 취하며, 인스트럭션 캐쉬로부터 그 주소만을 비움을
주의하십시오.
SMP 시스템에서는 모든 CPU 의 캐쉬가 비워지나 언제 CPU 밖의 비우기가
완료되는지를 아는 편리한 방법이 없으나, 구현 메모에 참고사항이 있긴 합니다.

그러나 다시 말하지만, 리눅스 커널은 TSO 모드에서 SPARC 를 수행하므로, 앞의 모든
\co{membar} 변종은 역사적 흥미거리일 뿐입니다.
특히, \co{smp_mb()} 기능은 다른 세개의 재배치가 TSO 에 의해 금지되므로
\co{#StoreLoad} 만을 필요로 합니다.

\iffalse

SPARC requires a \co{flush} instruction be used between the time that
the instruction stream is modified and the time that any of these
instructions are executed~\cite{SPARC94}.
This is needed to flush any prior value for that location from
the SPARC's instruction cache.
Note that \co{flush} takes an address, and will flush only that address
from the instruction cache.
On SMP systems, all CPUs' caches are flushed, but there is no
convenient way to determine when the off-CPU flushes complete,
though there is a reference to an implementation note.

But again, the Linux kernel runs SPARC in TSO mode, so
all of the above \co{membar} variants are strictly of historical
interest.
In particular, the \co{smp_mb()} primitive only needs to use \co{#StoreLoad}
because the other three reorderings are prohibited by TSO\@.

\fi

\subsection{x86}

역사적으로, x86 CPU 는 모든 CPU 가 특정 CPU 의 메모리 쓰기 순서에 동의하게끔
``process ordering'' 을 제공했습니다.
이는 \co{smp_wmb()} 기능이 no-op 이 될 수 있게 했습니다~\cite{IntelXeonV3-96a}.
물론, \co{smp_wmb()} 기능 전후로 재배치 될 수 있는 최적화를 막기 위한 컴파일러
지시어는 필요했습니다.
아주 옛날에는, 특정 x86 CPU 는 로드를 위한 순서 보장을 제공하지 않아서
\co{smp_mb()} 와 \co{smp_rmb()} 기능이 \co{lock;addl} 로 확장되었습니다.
이 어토믹 인스트럭션은 로드와 스토어 둘 다에 대한 배리어로 동작합니다.

\iffalse

Historically, the x86 CPUs provided ``process ordering'' so that all CPUs
agreed on the order of a given CPU's writes to memory.
This allowed the \co{smp_wmb()}
primitive to be a no-op for the CPU~\cite{IntelXeonV3-96a}.
Of course, a compiler directive was also required to prevent optimizations
that would reorder across the \co{smp_wmb()} primitive.
In ancient times, certain x86 CPUs gave no ordering guarantees for loads, so
the \co{smp_mb()} and \co{smp_rmb()} primitives expanded to \co{lock;addl}.
This atomic instruction acts as a barrier to both loads and stores.

\fi

하지만 그건 과거의 일입니다.
최근에 Intel 은 x86 을 위한 메모리 모델을
출판했습니다~\cite{Intelx86MemoryOrdering2007}.
Intel 의 현대 CPU 는 이전의 명세서에서 이야기된 것보다 더 강화된 순서를
제공하는 것으로 드러났으며, 따라서 이 모델은 이 현대 동작만을 요합니다.
더 최근에는 Intel 이 x86 을 위한 업데이트된 메모리 모델~\cite[Section
8.2]{Intel64IA32v3A2011} 을 출판했는데, 여기선 스토어에 대한 전체 전역 순서를
강요합니다만, 개별 CPU 는 여전히 스스로의 스토어가 전체 전역 순서가 파악하는
것보다 일찍 볼 수 있게 합니다.
이 전체 순서에 대한 예외는 스토어 버퍼와 연관된 중요한 하드웨어 최적화를
허용하기 위해 필요합니다.
또한, x86 은 다른 multicopy 원자성을 제공하는데, 예를 들면 CPU~0 이 CPU~1 의
스토어를 봤다면 CPU~0 은 CPU~1 이 그 스토어 전에 봤던 모든 스토어를 볼 것이
보장됩니다.
소프트웨어는 이 하드웨어 최적화를 덮기 위해 어토믹 오퍼레이션을 사용할 수
있는데, 어토믹 오퍼레이션이 비 어토믹 버전의 그것들에 비해 비용이 높은 이유 중
하나입니다.

\iffalse


But those were ancient times.
More recently, Intel has published a memory model for
x86~\cite{Intelx86MemoryOrdering2007}.
It turns out that Intel's modern CPUs enforce tighter ordering than was
claimed in the previous specifications, so this model simply mandates
this modern behavior.
Even more recently, Intel published an updated memory model for
x86~\cite[Section 8.2]{Intel64IA32v3A2011}, which mandates a total global order
for stores, although individual CPUs are still permitted to see their
own stores as having happened earlier than this total global order
would indicate.
This exception to the total ordering is needed to allow important
hardware optimizations involving store buffers.
In addition, x86 provides other-multicopy atomicity, for example,
so that if CPU~0 sees a store by CPU~1, then CPU~0 is guaranteed to see
all stores that CPU~1 saw prior to its store.
Software may use atomic operations to override these hardware optimizations,
which is one reason that atomic operations tend to be more expensive
than their non-atomic counterparts.

\fi

특정 메모리 위치에 가해지는 어토믹 명령들은 모두 같은 크기여야 한다는
것을~\cite[Section 8.1.2.2]{Intel64IA32v3A2016} 알아두는게 중요합니다.
예를 들어, 한 CPU 가 원자적으로 한 바이트를 증가시키는 사이 다른 CPU 는 같은
위치에 4-바이트 원자적 값 증가를 수행하는 프로그램을 작성한다면, 알아서 하세요.

어떤 SSE 명령은 완화된 순서를 갖습니다 (\co{clflush} 와 비임시적 이동
명령~\cite{IntelXeonV2b-96a}).
이 비임시적 이동 명령을 사용하는 코드는 \co{smp_mb()} 를 위해 \co{mfence} 를,
\co{smp_rmb()} 를 위해 \co{lfence} 를, 그리고 \co{smp_wmb()} 를 위해
\co{sfence} 를 사용할 수 있습니다.
x86 CPU 의 일부 오래된 변종들은 비순차적 스토어를 가능하게 하기 위핸 모드 bit
를 가지며 이런 CPU 에서 \co{smp_wmb()} 는 \co{lock;addl} 로 정의되어야만
합니다.

최근의 x86 구현이 특별한 명령 없이 스스로를 수정하는 코드를 수용하지만, 과거와
잠재적 미래 x86 구현에 완전히 호환되려면, CPU 는 jump 명령이나 순차화 명령 (예:
\co{cpuid}) 을 코드 수정과 수행 사이에 수행해야만 합니다~\cite[Section
8.1.3]{Intel64IA32v3A2011}.

\iffalse

It is also important to note that atomic instructions operating
on a given memory location should all be of the same
size~\cite[Section 8.1.2.2]{Intel64IA32v3A2016}.
For example, if you write a program where one CPU atomically increments
a byte while another CPU executes a 4-byte atomic increment on
that same location, you are on your own.

Some SSE instructions are weakly ordered (\co{clflush}
and non-temporal move instructions~\cite{IntelXeonV2b-96a}).
Code that uses these non-temporal move instructions
can also use \co{mfence} for \co{smp_mb()},
\co{lfence} for \co{smp_rmb()}, and \co{sfence} for \co{smp_wmb()}.
A few older variants of the x86 CPU have a mode bit that enables out-of-order
stores, and for these CPUs, \co{smp_wmb()} must also be defined to
be \co{lock;addl}.

Although newer x86 implementations accommodate self-modifying code
without any special instructions, to be fully compatible with
past and potential future x86 implementations, a given CPU must
execute a jump instruction or a serializing instruction (e.g., \co{cpuid})
between modifying the code and executing
it~\cite[Section 8.1.3]{Intel64IA32v3A2011}.

\fi

\subsection{z Systems}

z~Systems 기계는 앞서 360, 370, 390 그리고 Zseries~\cite{IBMzSeries04a} 라
알려진 IBM mainframe 제품군을 만드는데 쓰입니다.
병렬성은 z~Systems 에 뒤늦게 도입되었습니다만 이 mainframe 들이 1960년대 중반에
처음 선적되었음을 생각하면 그렇게 늦은 건 아닙니다.
\qco{bcr 15,0} 명령이 리눅스 \co{smp_mb()} 기능을 위해 사용됩니다만
\co{smp_rmb()} 와 \co{smp_wmb()} 기능들을 위해선 컴파일러 제약만으로
충분합니다.
이 제품군은 또한
\cref{tab:memorder:Summary of Memory Ordering} 에 보인 것과 같이 강력한 메모리
순서 규칙을 제공합니다.
특히, 모든 CPU 가 다른 CPU 들로부터의 관계없는 스토어들의 순서에 대해 동의하게
되어 있는데, 즉, z~Systems CPU 제품군은 완전히 multicopy atomic 하며, 이 속성을
제공하는 유일한 상용의 사용가능한 시스템입니다.

\iffalse

The z~Systems machines make up the IBM mainframe family, previously
known as the 360, 370, 390 and zSeries~\cite{IBMzSeries04a}.
Parallelism came late to z~Systems, but given that these mainframes first
shipped in the mid 1960s, this is not saying much.
The \qco{bcr 15,0} instruction is used for the Linux \co{smp_mb()} primitives,
but compiler constraints suffices for both the
\co{smp_rmb()} and \co{smp_wmb()} primitives.
It also has strong memory-ordering semantics, as shown in
\cref{tab:memorder:Summary of Memory Ordering}.
In particular, all CPUs will agree on the order of unrelated stores from
different CPUs, that is, the z~Systems CPU family is fully multicopy
atomic, and is the only commercially available system with this property.

\fi

다른 대부분의 CPU 와 같이 z~Systems 아키텍쳐는 캐쉬 일관성 인스트럭션 흐름을
보장하지 않으며, 따라서 스스로를 수정하는 코드는 인스트럭션의 업데이트와 수행
사이에 인스트럭션 직렬화 명령을 수행해야 합니다.
그렇다고는 하나, 많은 실제 z~Systems 기계들이 인스트럭션 직렬화 없이 스스로를
수정하는 코드를 받아들이고 있습니다.
z~Systems 명령 집합은 compare-and-swap, 일부 종류의 분기문 (예를 들어, 앞서
이야기 된 \qco{bcr 15,0} 명령), 그리고 test-and-set 같은 많은 직렬화 명령
집합을 제공합니다.

\iffalse

As with most CPUs, the z~Systems architecture does not guarantee a
cache-coherent instruction stream, hence,
self-modifying code must execute a serializing instruction between updating
the instructions and executing them.
That said, many actual z~Systems machines do in fact accommodate self-modifying
code without serializing instructions.
The z~Systems instruction set provides a large set of serializing instructions,
including compare-and-swap, some types of branches (for example, the
aforementioned \qco{bcr 15,0} instruction), and test-and-set.

\fi

\section{Where is Memory Ordering Needed?}
\label{sec:memorder:Where is Memory Ordering Needed?}
%
\epigraph{Almost all people are intelligent.
	  It is method that they lack.}
	 {\emph{F. W. Nichol}}

이 섹션은
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
와 \cref{sec:memorder:Basic Rules of Thumb} 를 다시 방문해 더 정교한 경험적
법칙과 함께 그 사이의 논의를 요약합니다.

그 첫번째 경헙적 규칙은 메모리 순서 오퍼레이션들이 최소 두개의 쓰레드에서 최소
두개의 공유변수 사이의 상호작용을 가질 가능성이 있을 때에만 필요하다는 겁니다.
그 사이의 것들에 의해, 이 단일 문장은
\cref{sec:memorder:Basic Rules of Thumb} 의 기본적 경험적 법칙의 만흔 것을
담아내는데, 예를 들어 ``memory-barrier pairing'' 은 ``사이클'' 의 두개
쓰레드에서의 특수 경우임을 명심하십시오.
또한, 항상 그렇듯 싱글쓰레드 프로그램이 충분한 성능을 제공한다면, 왜 병렬성을
고려하겠습니까?\footnote{
	취미가들과 연구자들은 물론 여러 이유로 이를 무시하셔도 무방하겠습니다.}
어쨌건, 병렬성을 막는 것은 메모리 순서 오퍼레이션의 추가 비용을 막습니다.

\iffalse

This section revisits
\cref{tab:memorder:Linux-Kernel Memory-Ordering Cheat Sheet}
and \cref{sec:memorder:Basic Rules of Thumb},
summarizing the intervening discussion with a more sophisticated
set of rules of thumb.

The first rule of thumb is that memory-ordering operations are only
required where there is a possibility of interaction between at least
two variables shared among at least two threads.
In light of the intervening material, this single sentence encapsulates much of
\cref{sec:memorder:Basic Rules of Thumb}'s basic rules of thumb,
for example, keeping in mind that ``memory-barrier pairing'' is a
two-thread special case of ``cycle''.
And, as always, if a single-threaded program will provide sufficient
performance, why bother with parallelism?\footnote{
	Hobbyists and researchers should of course feel free to ignore
	this and many other cautions.}
After all, avoiding parallelism also avoids the added cost of
memory-ordering operations.

\fi

그 두번째 경험적 법칙은 로드-버퍼링 상황에 연관됩니다:
특정 사이클에서의 모든 쓰레드간 통신이 store-to-load 연결을 사용한다면 (즉,
다음 쓰레드의 로드는 앞의 쓰레드가 저장한 값을 반환한다면), 최소한의 순서
짓기로 충분합니다.
최소한의 순서 짓기는 종속성과 acquire 는 물론 더 강한 순서 오퍼레이션들도
포함합니다.

\iffalse

The second rule of thumb involves load-buffering situations:
If all thread-to-thread communication in a given cycle use store-to-load
links (that is, the next thread's load returns the value stored by
the previous thread), minimal ordering suffices.
Minimal ordering includes dependencies and acquires as well as all stronger
ordering operations.

\fi

그 세번째 경험적 법칙은 release-acquire 연결에 연관됩니다:
주어진 사이클의 모든 링크가 하나만 제외하고는 모두 store-to-load 연결이라면,
\cref{lst:memorder:Long ISA2 Release-Acquire Chain,%
lst:memorder:Long Z6.2 Release-Acquire Chain} 에 보인 것처럼 그 store-to-load
연결의 각 짝에 release-acquire 짝을 사용하는 것으로 충분합니다.
여러분은 이 acquire 를 허용되는 환경에서는 종속성으로 대체할 수 있는데, C11
표준의 메모리 모델은 종속성을 완전히 존중하지 \emph{않음} 을 명심하시기
바랍니다.
따라서, 로드를 앞서는 종속성은 \co{READ_ONCE()} 나 \co{rcu_dereference()} 를
통해 이루어져야 합니다: 평범한 C 언어 로드는 충분치 않습니다.
또한, 여러분의 컴파일러에 의해 부서진 종속성은 어떤 것도 순서잡지 않을테니
\cref{sec:memorder:Address- and Data-Dependency Difficulties,%
sec:memorder:Control-Dependency Calamities} 을 주의 깊게 다시 보세요.
하나의 store-to-load 가 아닌 링크를 공유하는 두개의 쓰레드는 보통
\co{WRITE_ONCE()} 더하기 \co{smp_wmb()} 를 \co{smp_store_release()} 로,
\co{READ_ONCE()} 더하기 \co{smp_rmb()} 는 \co{smp_load_acquire()} 로 교체할 수
있습니다.
그러나, 현명한 개발자는 그런 교체를 주의 깊게 검사할 텐데, 예를 들면
\cref{sec:formal:Axiomatic Approaches} 에 설명된 것처럼 \co{herd} 도구를
사용하는 겁니다.

\iffalse

The third rule of thumb involves release-acquire chains:
If all but one of the links in a given cycle is a store-to-load
link, it is sufficient to use release-acquire pairs for each of
those store-to-load links, as illustrated by
\cref{lst:memorder:Long ISA2 Release-Acquire Chain,%
lst:memorder:Long Z6.2 Release-Acquire Chain}.
You can replace a given acquire with a dependency in environments permitting
this, keeping in mind that the C11 standard's memory model does \emph{not}
fully respect dependencies.
Therefore, a dependency leading to a load must be headed by
a \co{READ_ONCE()} or an \co{rcu_dereference()}:
a plain C-language load is not sufficient.
In addition, carefully review
\cref{sec:memorder:Address- and Data-Dependency Difficulties,%
sec:memorder:Control-Dependency Calamities}, because
a dependency broken by your compiler will not order anything.
The two threads sharing the sole non-store-to-load link can
usually substitute \co{WRITE_ONCE()} plus \co{smp_wmb()} for
\co{smp_store_release()} on the one hand,
and \co{READ_ONCE()} plus \co{smp_rmb()} for \co{smp_load_acquire()}
on the other.
However, the wise developer will check such substitutions carefully,
for example, using the \co{herd} tool as described in
\cref{sec:formal:Axiomatic Approaches}.

\fi

\QuickQuiz{
	왜 store-to-load 가 아닌 load-to-store 와 store-to-store 링크에는 보다
	무거운 순서 오퍼레이션을 사용해야만 하죠?
	대체 무엇이 store-to-load 링크를 그렇게 특별하게 합니까???

	\iffalse

	Why is it necessary to use heavier-weight ordering for
	load-to-store and store-to-store links, but not for
	store-to-load links?
	What on earth makes store-to-load links so special???

	\fi

}\QuickQuizAnswer{
	Load-to-store 와 store-to-store 링크는
	\cref{sec:memorder:Propagation} 의
	\cref{fig:memorder:Load-to-Store is Counter-Temporal,%
	fig:memorder:Store-to-Store is Counter-Temporal} 에서 설명된 것처럼
	임시적이지 않을 수 있음을 기억하십시오.
	이 load-to-store 와 store-to-store 링크의 반 임시성은 강력한 순서
	규칙을 필요로 합니다.

	대조적으로, store-to-load 링크는
	\cref{lst:memorder:Load-Buffering Data-Dependency Litmus Test,%
	lst:memorder:Load-Buffering Control-Dependency Litmus Test} 에 보인
	것처럼 임시적입니다.
	이 store-to-load 링크의 임시성이 최소한의 순서 규칙만 지키는 것을
	허용합니다.

	\iffalse

	Recall that load-to-store and store-to-store links can be
	counter-temporal, as illustrated by
	\cref{fig:memorder:Load-to-Store is Counter-Temporal,%
	fig:memorder:Store-to-Store is Counter-Temporal} in
	\cref{sec:memorder:Propagation}.
	This counter-temporal nature of load-to-store and store-to-store
	links necessitates strong ordering.

	In constrast, store-to-load links are temporal, as illustrated by
	\cref{lst:memorder:Load-Buffering Data-Dependency Litmus Test,%
	lst:memorder:Load-Buffering Control-Dependency Litmus Test}.
	This temporal nature of store-to-load links permits use of
	minimal ordering.

	\fi

}\QuickQuizEnd

마지막인 그 네번째 경험적 규칙은 어디에 전체 메모리 배리어가 (또는 그보다
강력한 것이) 필요한지 정의합니다:
주어진 사이클이 두개 이상의 store-to-load 링크가 아닌 링크를 갖는다면 (즉, 총
두개 이상의 링크가 load-to-store 나 store-to-store 링크라면), 여러분은 이
사이클의 각 store-to-load 가 아닌 링크들 사이에 최소 하나의 전체 메모리
배리어를 필요로 하며, 이는
\cref{lst:memorder:W+WRC Litmus Test With More Barriers} 와
\QuickQuizARef{\MemorderQQLitmusTestR} 의 답변에 설명되어 있습니다.
전체 배리어는 \co{smp_mb()}, 성공한 전체 강력도의 \co{void} 가 아닌 atomic RMW
오퍼레이션, 그리고 \co{smp_mb__before_atomic()} 또는
\co{smp_mb__after_atomic()} 와 함께 사용된 다른 tomic RMW 오퍼레이션들을
포함합니다.
모든 RCU 의 grace-period 대기 기능 (\co{synchronize_rcu()} 와 그 친구들) 또한
전체 배리어로 동작합니다만 \co{smp_mb()} 보다 훨씬 비용이 높습니다.
전체 배리어가 확장성을 손상시키는 것보다는 성능을 보통 덜 손상시키긴 합니다만
힘은 비용과 함께 옵니다.

이 규칙들을 다시 정리해 봅니다:

\iffalse

The fourth and final rule of thumb identifies where full memory barriers
(or stronger) are required:
If a given cycle contains two or more non-store-to-load links (that is, a
total of two or more links that are either load-to-store or store-to-store
links), you will need at least one full barrier between each pair of
non-store-to-load links in that cycle, as illustrated by
\cref{lst:memorder:W+WRC Litmus Test With More Barriers}
as well as in the answer to
\QuickQuizARef{\MemorderQQLitmusTestR}.
Full barriers include \co{smp_mb()}, successful full-strength non-\co{void}
atomic RMW operations, and other atomic RMW operations in conjunction with
either \co{smp_mb__before_atomic()} or \co{smp_mb__after_atomic()}.
Any of RCU's grace-period-wait primitives (\co{synchronize_rcu()} and
friends) also act as full barriers, but at far greater expense than
\co{smp_mb()}.
With strength comes expense, though full barriers
usually hurt performance more than they hurt scalability.

Recapping the rules:

\fi

\begin{enumerate}
\item	메모리 순서 오퍼레이션들은 최소한 두개의 변수들이 최소 두개의 쓰레드에
	의해 공유될 때에만 필요합니다.
\item	사이클의 모든 링크가 store-to-load 링크라면, 최소한의 순서 보장으로
	충분합니다.
\item	만약 사이클의 링크들 중 하나를 제외한 모두가 store-to-load 링크라면, 각
	store-to-load 링크는 release-acquire 쌍을 사용할 수 있습니다.
\item	그렇지 않다면, 최소 하나의 전체 배리어가 store-to-load 가 아닌 각 쌍
	사이에 필요합니다.

\iffalse

\item	Memory-ordering operations are required only if at least
	two variables are shared by at least two threads.
\item	If all links in a cycle are store-to-load links, then
	minimal ordering suffices.
\item	If all but one of the links in a cycle are store-to-load links,
	then each store-to-load link may use a release-acquire pair.
\item	Otherwise, at least one full barrier is required between
	each pair of non-store-to-load links.

\fi

\end{enumerate}

이 네개의 경험적 규칙은 \emph{최소한의} 보장을 다룸을 명심하세요.
특정 아키텍쳐는 \cref{sec:memorder:Hardware Specifics} 에서 설명한 것처럼 보다
상당한 보장을 제공할 수도 있습니다만 이 보장은 그 아키텍쳐에서만 수행되는
코드에만 의존할 수도 있습니다.
또한, 더 연관된 메모리 모델은 보다 높은 복잡도를 대가로 더 강한 보장을 제공할
수도 있습니다~\cite{Alglave:2018:FSC:3173162.3177156}.
이 보다 정형적인 메모리 순서 논문에서, store-to-load 링크는 readers-from (rf)
링크의 예이고, load-to-store 링크는 from-reads (fr) 링크의 예이며,
store-to-store 링크는 coherence (co) 링크의 예입니다.

마지막 조언입니다: 날것의 메모리 순서 기능을 사용하는 것은 최후의 수단입니다.
거의 항상 이미 존재하는 락킹이나 RCU 같은 기능을 사용해서 그 기능들이 여러분을
위한 메모리 순서 보장을 하게 하는 것이 더 낫습니다.

\iffalse

Note that these four rules of thumb encapsulate \emph{minimum} guarantees.
A given architecture may give more substantial guarantees, as discussed
in \cref{sec:memorder:Hardware Specifics}, but these guarantees may only
be relied upon in code that runs only for that architecture.
In addition, more involved memory models may give stronger
guarantees~\cite{Alglave:2018:FSC:3173162.3177156}, at the
expense of somewhat greater complexity.
In these more formal memory-ordering papers, a store-to-load link is an
example of a reads-from (rf) link, a load-to-store link is an example
of a from-reads (fr) link, and a store-to-store link is an example of
a coherence (co) link.

One final word of advice: Use of raw memory-ordering primitives is
a last resort.
It is almost always better to use existing primitives, such as locking
or RCU, thus letting those primitives do the memory ordering for you.

\fi

\QuickQuizAnswersChp{qqzmemorder}
