% toolsoftrade/toolsoftrade.tex

\QuickQuizChapter{chp:Tools of the Trade}{Tools of the Trade}

이 챕터에서는 리눅스와 유사한 운영체제에서 돌아가는 어플리케이션에 집중해서
몇몇 기본적인 병렬 프로그래밍 도구를 소개합니다.
Section~\ref{sec:toolsoftrade:Scripting Languages} 는 스크립트 언어로 시작을
하고,
Section~\ref{sec:toolsoftrade:POSIX Multiprocessing} 에서는 POSIX API 로
지원되는 멀티 프로세스 병렬성을 설명하고 POSIX 쓰레드를 다뤄봅니다.
Section~\ref{sec:toolsoftrade:Atomic Operations} 는 어토믹 오퍼레이션들을
설명하며,
Section~\ref{sec:toolsoftrade:Linux-Kernel Equivalents to POSIX Operations}
에서는 리눅스 커널에서의 유사한 오퍼레이션들을 알아봅니다. 그리고 마지막으로,
Section~\ref{sec:toolsoftrade:The Right Tool for the Job: How to Choose?}
에서는 해당 일을 완료하기 위해 어떤 도구를 골라야 할지 선택을 도와드립니다.

이 챕터는 간략한 소개만을 제공한다는 점을 기억해 두세요.
더 자세한 내용은 인용된 참조 목록들에서 볼 수 있으며, 이 도구들을 어떻게
사용하는게 최선인지는 뒤의 챕터들에서 설명합니다.

\iffalse
This chapter provides a brief introduction to some basic tools of the
parallel-programming trade, focusing mainly on those available to
user applications running on operating systems similar to Linux.
Section~\ref{sec:toolsoftrade:Scripting Languages} begins with
scripting languages,
Section~\ref{sec:toolsoftrade:POSIX Multiprocessing}
describes the multi-process parallelism supported by the POSIX API and
touches on POSIX threads,
Section~\ref{sec:toolsoftrade:Atomic Operations}
describes atomic operations,
Section~\ref{sec:toolsoftrade:Linux-Kernel Equivalents to POSIX Operations}
presents the analogous operations within the Linux kernel, and finally,
Section~\ref{sec:toolsoftrade:The Right Tool for the Job: How to Choose?}
helps to choose the tool that will get the job done.

Please note that this chapter provides but a brief introduction.
More detail is available from the references cited, and more information
on how best to use these tools will be provided in later chapters.
\fi

\section{Scripting Languages}
\label{sec:toolsoftrade:Scripting Languages}

리눅스 셸 스크립트 언어들은 병렬성을 관리하는 간단하지만 효과적인 방법들을
제공합니다.
예를 들어, 당신이 \co{compute_it} 이라는 이름의 프로그램을 가지고 있는데 두개의
다른 인자들로 두번 수행해야 한다고 생각해 봅시다.
유닉스 셸 스크립트를 사용하면 다음과 같이 수행을 할 수 있습니다:

\iffalse
The Linux shell scripting languages provide simple but effective ways
of managing parallelism.
For example, suppose that you had a program \co{compute_it}
that you needed to run twice with two different sets of arguments.
This can be accomplished using UNIX shell scripting as follows:
\fi

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\scriptsize
\begin{verbatim}
  1 compute_it 1 > compute_it.1.out &
  2 compute_it 2 > compute_it.2.out &
  3 wait
  4 cat compute_it.1.out
  5 cat compute_it.2.out
\end{verbatim}
\end{minipage}
\vspace{5pt}

\begin{figure}[tb]
\begin{center}
\resizebox{3in}{!}{\includegraphics{toolsoftrade/shellparallel}}
\end{center}
\caption{Execution Diagram for Parallel Shell Execution}
\label{fig:intro:Execution Diagram for Parallel Shell Execution}
\end{figure}

라인~1 과 2 는 이 프로그램의 인스턴스를 두개 실행시키고, 각 인스턴스의 결과물을 두개의 별개의 파일에 집어넣는데, \co{&} 문자는 셸이 그 두 프로그램 인스턴스를 백그라운드에서 실행하도록 합니다.
라인~3 은 두개의 인스턴스 모두가 종료되길 기다리고, 라인~4 와 5 에서는 그들의 결과값을 화면에 출력합니다.
실행 흐름은 Figure~\ref{fig:intro:Execution Diagram for Parallel Shell Execution} 에 나타난 대로입니다:
\co{compute_it} 의 두개의 인스턴스는 병렬적으로 수행되고, \co{wait} 은 두개 인스턴스 모두가 완료된 뒤에 실행 완료되며, 그 뒤에 \co{cat}의 두개의 인스턴스가 순차적으로 수행됩니다.

\iffalse
Lines~1 and 2 launch two instances of this program, redirecting their
output to two separate files, with the \co{&} character directing the
shell to run the two instances of the program in the background.
Line~3 waits for both instances to complete, and lines~4 and 5
display their output.
The resulting execution is as shown in
Figure~\ref{fig:intro:Execution Diagram for Parallel Shell Execution}:
the two instances of \co{compute_it} execute in parallel,
\co{wait} completes after both of them do, and then the two instances
of \co{cat} execute sequentially.
% @@@ Maui scheduler, load balancing, BOINC, and so on.
% @@@ Diagram showing parallel execution.
\fi

\QuickQuiz{}
	하지만 이 간단한 셸 스크립트는 \emph{진짜} 병렬 프로그램이 아니잖아요!
	왜 이런 별거아닌 걸 신경쓰는거죠???

	\iffalse
	But this silly shell script isn't a \emph{real} parallel program!
	Why bother with such trivia???
	\fi
\QuickQuizAnswer{
	당신은 \emph{결코} 이 간단한 것을 잊을 수 없을 것이기 때문입니다!

	이 책의 제목이 ``Is Parallel Programming Hard, And, If So, What Can You
	Do About It?'' 이란 걸 마음에 새겨 두십시오.
	당신이 할 수 있는 가장 효과적인 일은 그 간단한 것을 잊지 않도록 하는
	것입니다!
	무엇보다, 당신이 병렬 프로그래밍을 어려운 방법으로 하기로 선택했다면,
	당신의 선택이니, 당신은 당신 자신 외의 누구에게도 불평 할 수 없습니다.

	\iffalse
	Because you should \emph{never} forget the simple stuff!

	Please keep in mind that the title of this book is
	``Is Parallel Programming Hard, And, If So, What Can You Do About It?''.
	One of the most effective things you can do about it is to
	avoid forgetting the simple stuff!
	After all, if you choose to do parallel programming the hard
	way, you have no one but yourself to blame.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	병렬 셸 스크립트를 작성하는 좀 더 간단한 방법은 없나요?
	만약 있다면, 어떻게 하나요? 없다면, 왜 없죠?

	\iffalse
	Is there a simpler way to create a parallel shell script?
	If so, how?  If not, why not?
	\fi
\QuickQuizAnswer{
	가장 직관적인 방법은 셸 파이프라인입니다:

	\iffalse
	One straightforward approach is the shell pipeline:
	\fi
\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\small
\begin{verbatim}
grep $pattern1 | sed -e 's/a/b/' | sort
\end{verbatim}
\end{minipage}
\vspace{5pt}
	충분히 커다란 입력 파일에 대해서, \co{grep} 의 패턴 매칭, \co{sed} 의
	수정과 \co{sort} 의 입력물 처리는 병렬적으로 수행될 겁니다.
	\co{parallel.sh} 파일에 셸 스크립트 병렬성과 파이프라인에 대한 데모가
	있습니다.

	\iffalse
	For a sufficiently large input file,
	\co{grep} will pattern-match in parallel with \co{sed}
	editing and with the input processing of \co{sort}.
	See the file \co{parallel.sh} for a demonstration of
	shell-script parallelism and pipelining.
	\fi
} \QuickQuizEnd

다른 예로, \co{make} 소프트웨어 빌드 스크립트 언어는 얼마나 많은 병렬성이 해당
빌드 작업에 주어져야 하는지 결정하는 \co{-j} 옵션을 제공합니다.
예를 들어, \co{make -j4} 명령을 리눅스 커널 빌드를 위해 내리게 되면 최대 4개의
병렬 컴파일이 동시에 수행될 수 있습니다.

이런 간단한 예가 병렬 프로그래밍은 항상 복잡하거나 어려울 필요는 없음을
당신에게 납득시켜 주길 바랍니다.

\iffalse
For another example, the \co{make} software-build scripting language
provides a \co{-j} option that specifies how much parallelism should be
introduced into the build process.
For example, typing \co{make -j4} when building a Linux kernel
specifies that up to four parallel compiles be carried out concurrently.

It is hoped that these simple examples convince you that parallel
programming need not always be complex or difficult.
\fi

\QuickQuiz{}
	하지만 스크립트 기반 병렬 프로그래밍이 그렇게 쉽다면, 왜 다른 것들을
	신경쓰는거죠?

	\iffalse
	But if script-based parallel programming is so easy, why
	bother with anything else?
	\fi
\QuickQuizAnswer{
	사실 오늘날 사용되는 병렬 프로그램들의 매우 많은 부분들이 스크립트에
	기반합니다.
	하지만, 스크립트 기반 병렬성은 한계점도 지니고 있습니다:
	\begin{enumerate}
	\item	새 프로세스의 생성은 보통 비싼 시스템콜인 \co{fork()} 와
		\co{exec()} 를 포함하기 때문에 상당히 무거운 작업입니다.
	\item	파이프라이닝을 포함해서 데이터의 공유는 일반적으로 비싼 file
		I/O 를 포함합니다.
	\item	스크립트에서 믿고 쓸 수 있는 사용 가능한 동기화 기본 도구들
		역시 일반적으로 비싼 file I/O 를 포함합니다.
	\end{enumerate}
	이런 제한점들은 스크립트 기반 병렬성이 coarse-grained 병렬성을 사용하고
	각 일의 단위들은 최소 수십 밀리세컨드, 그리고 가능하다면 그보다도 훨씬
	긴 시간을 가질 것을 요구합니다.

	\iffalse
	In fact, it is quite likely that a very large fraction of
	parallel programs in use today are script-based.
	However, script-based parallelism does have its limitations:
	\begin{enumerate}
	\item	Creation of new processes is usually quite heavyweight,
		involving the expensive \co{fork()} and \co{exec()}
		system calls.
	\item	Sharing of data, including pipelining, typically involves
		expensive file I/O.
	\item	The reliable synchronization primitives available to
		scripts also typically involve expensive file I/O.
	\end{enumerate}
	These limitations require that script-based parallelism use
	coarse-grained parallelism, with each unit of work having
	execution time of at least tens of milliseconds, and preferably
	much longer.
	\fi

	finer-grained 병렬성을 필요로 하는 작업들은 그 작업의 문제가
	coarse-grained 형태로 표현될 수는 없을지 좀 고민해 보도록 추천됩니다.
	만약 불가능하다면, Section~\ref{sec:toolsoftrade:POSIX Multiprocessing}
	에서 다루는 것과 같은 다른 병렬 프로그래밍 환경을 고려해 봐야 합니다.

	\iffalse
	Those requiring finer-grained parallelism are well advised to
	think hard about their problem to see if it can be expressed
	in a coarse-grained form.
	If not, they should consider using other parallel-programming
	environments, such as those discussed in
	Section~\ref{sec:toolsoftrade:POSIX Multiprocessing}.
	\fi
} \QuickQuizEnd

\section{POSIX Multiprocessing}
\label{sec:toolsoftrade:POSIX Multiprocessing}

이 섹션에서는 이미 사용 가능하고 여러 구현체가 존재하는 POSIX 환경에 대해,
pthread~\cite{OpenGroup1997pthreads} 를 포함해 알아봅니다.
Section~\ref{sec:toolsoftrade:POSIX Process Creation and Destruction}
에서는 POSIX \co{fork()} 와 관련된 것들을 살짝 훑어보고,
Section~\ref{sec:toolsoftrade:POSIX Thread Creation and Destruction}
에서는 쓰레드 생성과 소멸에 대해 간단히 알아본 후,
Section~\ref{sec:toolsoftrade:POSIX Locking} 에서는 POSIX 락킹에 대한 짧은
개요를 제공할 예정입니다. 그리고, 마지막으로,
Section~\ref{sec:toolsoftrade:POSIX Reader-Writer Locking} 에서 여러 쓰레드에
의해 읽히고 가끔만 갱신되는 데이터에 대해 사용되곤 하는 특정한 락에 대해
설명합니다.

\iffalse
This section scratches the surface of the
POSIX environment, including pthreads~\cite{OpenGroup1997pthreads},
as this environment is readily available and widely implemented.
Section~\ref{sec:toolsoftrade:POSIX Process Creation and Destruction}
provides a glimpse of the POSIX \co{fork()} and related primitives,
Section~\ref{sec:toolsoftrade:POSIX Thread Creation and Destruction}
touches on thread creation and destruction,
Section~\ref{sec:toolsoftrade:POSIX Locking} gives a brief overview
of POSIX locking, and, finally,
Section~\ref{sec:toolsoftrade:POSIX Reader-Writer Locking} describes a
specific lock which can be used for data that is read by many threads and only
occasionally updated.
\fi

\subsection{POSIX Process Creation and Destruction}
\label{sec:toolsoftrade:POSIX Process Creation and Destruction}

프로세스는 \co{fork()} 를 통해 생성되고, \co{kill()} 를 통해 소멸될 수도,
스스로 \co{exit()} 를 통해 소멸될 수도 있습니다.
\co{fork()} 를 실행하는 프로세스는 새로 생성되는 프로세스의 ``부모'' 라고
불리웁니다.
부모는 자신의 자식을 \co{wait()} 를 통해 기다릴 수도 있습니다.

\iffalse
Processes are created using the \co{fork()} primitive, they may
be destroyed using the \co{kill()} primitive, they may destroy
themselves using the \co{exit()} primitive.
A process executing a \co{fork()} primitive is said to be the ``parent''
of the newly created process.
A parent may wait on its children using the \co{wait()} primitive.
\fi

이 섹션의 예제들은 상당히 간단한 것들이란 점을 기억해 두시기 바랍니다.
이 간단한 도구들을 사용하는 실제 어플리케이션들은 시그널, 파일 디스크립터,
공유된 메모리 조각, 그리고 또다른 많은 자원들을 사용해야만 할 수도 있을 겁니다.
또한, 어떤 어플리케이션은 어떤 자식 프로세스가 종료되었을 때 특별한 행동을
취해야 할 수도 있고, 또한 자식 프로세스가 어떤 이유로 종료되었는지에 대해서도
신경써야 할 수 있습니다.
이렇게 신경써야 하는 부분들은 물론 코드에 상당한 복잡도를 추가할 수 있습니다.
더 많은 내용을 위해서는, 해당 주제에 대한
교재들~\cite{WRichardStevens1992,StewartWeiss2013UNIX} 을 보시기 바랍니다.

\iffalse
Please note that the examples in this section are quite simple.
Real-world applications using these primitives might need to manipulate
signals, file descriptors, shared memory segments, and any number of
other resources.
In addition, some applications need to take specific actions if a given
child terminates, and might also need to be concerned with the reason
that the child terminated.
These concerns can of course add substantial complexity to the code.
For more information, see any of a number of textbooks on the
subject~\cite{WRichardStevens1992,StewartWeiss2013UNIX}.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 pid = fork();
  2 if (pid == 0) {
  3   /* child */
  4 } else if (pid < 0) {
  5   /* parent, upon error */
  6   perror("fork");
  7   exit(-1);
  8 } else {
  9   /* parent, pid == child ID */
 10 }
\end{verbatim}
}
\caption{Using the fork() Primitive}
\label{fig:toolsoftrade:Using the fork() Primitive}
\end{figure}

\co{fork()} 가 성공하면, \co{fork()}는 한번은 부모에게, 또한번은 자식에게 두번
리턴합니다.
\co{fork()} 가 리턴하는 값은 Figure~\ref{fig:toolsoftrade:Using the fork()
Primitive}(\co{forkjoin.c}) 에 보여진 것처럼 콜러가 그 차이를 알 수 있게
합니다.
라인~1 은 \co{fork()} 함수를 실행하고, 그 리턴값을 지역 변수 \co{pid} 에
저장합니다.
라인~2 에서는 \co{pid} 가 0인지 체크하는데, 만약 맞다면 자신은 자식
프로세스라는 뜻이며, 이 경우 코드 실행은 라인~3으로 이어집니다.
앞서 이야기 했듯, 자식 프로세스는 \co{exit()} 함수를 통해 종료될 수 있습니다.
만약 \co{fork()} 리턴값이 0이 아니어서 자신이 부모 프로세스라면, 라인~4 에서
얻은 \co{fork()} 리턴값을 가지고 라인~5-7 에서 에러가 있었는지 확인하고 에러가
있었다면 에러를 화면에 출력하고 종료합니다.
그렇지 않고 \co{fork()} 가 성공적으로 수행되었다면, 자식 프로세스의 프로세스 ID
값을 가지고 있는 변수 \co{pid} 와 함께 라인~9로 넘어갑니다.

\iffalse
If \co{fork()} succeeds, it returns twice, once for the parent
and again for the child.
The value returned from \co{fork()} allows the caller to tell
the difference, as shown in
Figure~\ref{fig:toolsoftrade:Using the fork() Primitive}
(\co{forkjoin.c}).
Line~1 executes the \co{fork()} primitive, and saves its return value
in local variable \co{pid}.
Line~2 checks to see if \co{pid} is zero, in which case, this is the
child, which continues on to execute line~3.
As noted earlier, the child may terminate via the \co{exit()} primitive.
Otherwise, this is the parent, which checks for an error return from
the \co{fork()} primitive on line~4, and prints an error and exits
on lines~5-7 if so.
Otherwise, the \co{fork()} has executed successfully, and the parent
therefore executes line 9 with the variable \co{pid} containing the
process ID of the child.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 void waitall(void)
  2 {
  3   int pid;
  4   int status;
  5 
  6   for (;;) {
  7     pid = wait(&status);
  8     if (pid == -1) {
  9       if (errno == ECHILD)
 10         break;
 11       perror("wait");
 12       exit(-1);
 13     }
 14   }
 15 }
\end{verbatim}
}
\caption{Using the wait() Primitive}
\label{fig:toolsoftrade:Using the wait() Primitive}
\end{figure}

부모 프로세스는 자식 프로세스가 완료될 때까지 \co{wait()} 함수를 이용해 기다릴
수도 있습니다.
하지만, 각 \co{wait()} 호출은 오로지 한개 자식 프로세스만 기다리기 때문에, 이
함수의 사용은 셸 스크립트에서 사용할 때보다 좀 더 복잡합니다.
그래서 Figure~\ref{fig:toolsoftrade:Using the wait()
Primitive}(\co{api-pthread.h}) 에서 보여진, 셸 스크립트 에서의 \co{wait} 명령과
유사한 의미를 가진, \co{waitall()} 함수와 비슷한 함수로 \co{wait()} 를 감싸는게
일반적입니다.
라인~6-15 에서의 루프의 각 패스에서는 한개 자식 프로세스를 기다립니다.
라인~7 에서는 \co{wait()} 함수를 호출하는데, 이로 인해 부모 프로세스는 자식
프로세스 하나가 종료할 때까지 블록되어 있고, 자식 프로세스가 종료된 후 자식
프로세스의 프로세스 ID 를 리턴합니다.
만약 프로세스 ID 가 아니라 -1 이 리턴된다면, 이는 \co{wait()} 함수가 자식
프로세스를 기다릴 수 없었음을 의미합니다.
만약 그렇다면, 라인~9 에서 errno 가 \co{ECHILD} 로 되었는지 여부를 체크하는데,
만약 그렇다면 더이상 자식 프로세스가 존재하지 않았다는 의미로, 이 때엔 라인~10
에서 루프를 빠져나옵니다.
그렇지 않다면, 라인~11 과 12 에서 에러를 출력하고 종료합니다.

\iffalse
The parent process may use the \co{wait()} primitive to wait for its children
to complete.
However, use of this primitive is a bit more complicated than its shell-script
counterpart, as each invocation of \co{wait()} waits for but one child
process.
It is therefore customary to wrap \co{wait()} into a function similar
to the \co{waitall()} function shown in
Figure~\ref{fig:toolsoftrade:Using the wait() Primitive}
(\co{api-pthread.h}),
with this \co{waitall()} function having semantics similar to the
shell-script \co{wait} command.
Each pass through the loop spanning lines~6-15 waits on one child process.
Line~7 invokes the \co{wait()} primitive, which blocks until a child process
exits, and returns that child's process ID.
If the process ID is instead -1, this indicates that the \co{wait()}
primitive was unable to wait on a child.
If so, line~9 checks for the \co{ECHILD} errno, which indicates that there
are no more child processes, so that line~10 exits the loop.
Otherwise, lines~11 and 12 print an error and exit.
\fi

\QuickQuiz{}
	왜 이 \co{wait()} 함수는 그렇게 복잡해야만 하는거죠?
	왜 그냥 셸 스크립트의 \co{wait} 같이 동작하도록 만들지 않는 거예요?

	\iffalse
	Why does this \co{wait()} primitive need to be so complicated?
	Why not just make it work like the shell-script \co{wait} does?
	\fi
\QuickQuizAnswer{
	일부 병렬 어플리케이션은 특정 자식 프로세스가 끝났을 때 특별한 행동을
	취해야 할 수 있고, 그 때문에 각 자식 프로세스에 대해 개별적으로 대기를
	할 필요가 있습니다.
	또한, 일부 병렬 어플리케이션들은 자식 프로세스가 종료된 이유를 알
	필요도 있습니다.
	Figure~\ref{fig:toolsoftrade:Using the wait() Primitive} 에서 본
	것처럼, \co{wait()} 함수를 가지고 \co{waitall()} 함수를 만드는 건
	어렵지 않습니다만 그 반대는 불가능하겠지요.
	한번 특정 자식 프로세스에 대한 정보를 잃어버리면, 그건 복구될 수
	없습니다.

	\iffalse
	Some parallel applications need to take special action when
	specific children exit, and therefore need to wait for each
	child individually.
	In addition, some parallel applications need to detect the
	reason that the child died.
	As we saw in Figure~\ref{fig:toolsoftrade:Using the wait() Primitive},
	it is not hard to build a \co{waitall()} function out of
	the \co{wait()} function, but it would be impossible to
	do the reverse.
	Once the information about a specific child is lost, it is lost.
	\fi
} \QuickQuizEnd

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 int x = 0;
  2 int pid;
  3 
  4 pid = fork();
  5 if (pid == 0) { /* child */
  6   x = 1;
  7   printf("Child process set x=1\n");
  8   exit(0);
  9 }
 10 if (pid < 0) { /* parent, upon error */
 11   perror("fork");
 12   exit(-1);
 13 }
 14 waitall();
 15 printf("Parent process sees x=%d\n", x);
\end{verbatim}
}
\caption{Processes Created Via fork() Do Not Share Memory}
\label{fig:toolsoftrade:Processes Created Via fork() Do Not Share Memory}
\end{figure}

부모와 자식 프로세스가 메모리를 공유하지 \emph{않는}다는 점은 매우 중요하므로
반드시 기억해야 합니다.
이는 Figure~\ref{fig:toolsoftrade:Processes Created Via fork() Do Not Share Memory}
(\co{forkjoinvar.c}) 에 나타난 프로그램에 보여지는데, 자식 프로세스는 라인~6
에서 전역 변수 \co{x} 를 1로 만들고 라인~7 에서 메세지를 프린트한 후, 라인~8
에서 종료합니다.
부모는 라인~14에서 실행 흐름을 이어서 자식 프로세스를 기다리고 라인~15 에서
변수 \co{x} 의 값을 보지만 여전히 그 값은 0입니다.
따라서 이 프로그램의 출력은 다음과 같습니다:

\iffalse
It is critically important to note that the parent and child do \emph{not}
share memory.
This is illustrated by the program shown in
Figure~\ref{fig:toolsoftrade:Processes Created Via fork() Do Not Share Memory}
(\co{forkjoinvar.c}),
in which the child sets a global variable \co{x} to 1 on line~6,
prints a message on line~7, and exits on line~8.
The parent continues at line~14, where it waits on the child,
and on line~15 finds that its copy of the variable \co{x} is still zero.
The output is thus as follows:
\fi

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\scriptsize
\begin{verbatim}
Child process set x=1
Parent process sees x=0
\end{verbatim}
\end{minipage}
\vspace{5pt}

\QuickQuiz{}
	여기서 이야기한 것 외에도 \co{fork()} 와 \co{wait()} 에 대해 이야기할
	것들이 많지 않나요?

	\iffalse
	Isn't there a lot more to \co{fork()} and \co{wait()}
	than discussed here?
	\fi
\QuickQuizAnswer{
	맞습니다, 그리고 그리고 이 섹션은 나중에 메세징 기능 (UNIX 파이프,
	TCP/IP, 그리고 공유 파일 I/O 같은) 과 메모리 매핑 (\co{mmap()} 과
	\co{shmget()} 같은) 기능을 포함하도록 확장될 수도 있을 겁니다.
	그 전까지는, 이런 기능들에 대해 훨씬 자세하게 설명하는 다른 교재들이
	많이 있고, 정말 잘 알고 싶다면 man 페이지(역주: UNIX 커맨드
	\co{man})나, 이런 기능을 사용하며 현존하는 병렬 어플리케이션들, 또는
	리눅스 커널 구현의 소스 코드를 참고해도 될 것입니다.

	Figure~\ref{fig:toolsoftrade:Processes Created Via fork() Do Not Share
	Memory} 의 부모 프로세스는 자식 프로세스가 종료될 때까지 자신의
	\co{printf()} 를 위해 기다리고 있다는 것을 기억해 둘 필요가 있습니다.
	\co{printf()} 의 buffered I/O 를 같은 파일에 대해 여러 프로세스에서
	동시적으로 사용하는 것은 일반적이지 않고, 그러지 않는게 최선입니다.
	정말로 동시적으로 buffered I/O 를 해야만 한다면, 당신의 OS 의 문서를
	보세요.
	UNIX/Linux 시스템에서는 Stewart Weiss 의 강의 노트가
	예제~\cite{StewartWeiss2013UNIX} 와 함께 좋은 소개를 제공합니다.

	\iffalse
	Indeed there is, and
	it is quite possible that this section will be expanded in
	future versions to include messaging features (such as UNIX
	pipes, TCP/IP, and shared file I/O) and memory mapping
	(such as \co{mmap()} and \co{shmget()}).
	In the meantime, there are any number of textbooks that cover
	these primitives in great detail,
	and the truly motivated can read manpages, existing parallel
	applications using these primitives, as well as the
	source code of the Linux-kernel implementations themselves.

	It is important to note that the parent process in
	Figure~\ref{fig:toolsoftrade:Processes Created Via fork() Do Not Share Memory}
	waits until after the child terminates to do its \co{printf()}.
	Using \co{printf()}'s buffered I/O concurrently to the same file
	from multiple processes is non-trivial, and is best avoided.
	If you really need to do concurrent buffered I/O,
	consult the documentation for your OS.
	For UNIX/Linux systems, Stewart Weiss's lecture notes provide
	a good introduction with informative
	examples~\cite{StewartWeiss2013UNIX}.
	\fi
} \QuickQuizEnd

가장 잘게 크리티컬 섹션을 쪼갠 병렬성은 공유 메모리를 필요로 하며, 이는
Section~\ref{sec:toolsoftrade:POSIX Thread Creation and Destruction} 에서
다룹니다.
참고로, 공유 메모리 병렬성은 fork-join 병렬성에 비해 상당히 복잡할 수 있습니다.

\iffalse
The finest-grained parallelism requires shared memory, and
this is covered in
Section~\ref{sec:toolsoftrade:POSIX Thread Creation and Destruction}.
That said, shared-memory parallelism can be significantly more complex
than fork-join parallelism.
\fi

\subsection{POSIX Thread Creation and Destruction}
\label{sec:toolsoftrade:POSIX Thread Creation and Destruction}

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 int x = 0;
  2 
  3 void *mythread(void *arg)
  4 {
  5   x = 1;
  6   printf("Child process set x=1\n");
  7   return NULL;
  8 }
  9 
 10 int main(int argc, char *argv[])
 11 {
 12   pthread_t tid;
 13   void *vp;
 14 
 15   if (pthread_create(&tid, NULL,
 16                      mythread, NULL) != 0) {
 17     perror("pthread_create");
 18     exit(-1);
 19   }
 20   if (pthread_join(tid, &vp) != 0) {
 21     perror("pthread_join");
 22     exit(-1);
 23   }
 24   printf("Parent process sees x=%d\n", x);
 25   return 0;
 26 }
\end{verbatim}
}
\caption{Threads Created Via {\tt pthread\_create()} Share Memory}
\label{fig:toolsoftrade:Threads Created Via pthread-create() Share Memory}
\end{figure}

프로세스 내에서 쓰레드를 생성하려면 Figure~\ref{fig:toolsoftrade:Threads
Created Via pthread-create() Share Memory}(\co{pcreate.c}) 의 라인~15 와 16 에
보인 것처럼 \co{pthread_create()} 함수를 호출해야 합니다.
첫번째 인자는 \co{pthread_t} 타입 변수로의 포인터로, 해당 쓰레드의 ID 를
저장하게 되며, 두번째로 예제에서는 \co{NULL} 값을 준 인자는 필요하면 추가하게
되는 \co{pthread_attr_t} 타입 변수로의 포인터이며, 세번째 인자는 새로 생성된
쓰레드에 의해 호출될 함수(이 경우, \co{mythread()}) 이고, 마지막으로 여기선
\co{NULL} 을 준 인자는 \co{mythread} 에게 전달될 인자입니다.

이 예제에서, \co{mythread()} 는 단순히 리턴하지만, 대신 \co{pthread_exit()} 를
사용할 수도 있습니다.

\iffalse
To create a thread within an existing process, invoke the
\co{pthread_create()} primitive, for example, as shown on lines~15
and~16 of
Figure~\ref{fig:toolsoftrade:Threads Created Via pthread-create() Share Memory}
(\co{pcreate.c}).
The first argument is a pointer to a \co{pthread_t} in which to store the
ID of the thread to be created, the second \co{NULL} argument is a pointer
to an optional \co{pthread_attr_t}, the third argument is the function
(in this case, \co{mythread()}
that is to be invoked by the new thread, and the last \co{NULL} argument
is the argument that will be passed to \co{mythread}.

In this example, \co{mythread()} simply returns, but it could instead
call \co{pthread_exit()}.
\fi

\QuickQuiz{}
	Figure~\ref{fig:toolsoftrade:Threads Created Via pthread-create() Share
	Memory} 의 \co{mythread()} 함수가 그냥 리턴해도 된다면, 왜
	\co{pthread_exit()} 를 신경써야하죠?

	\iffalse
	If the \co{mythread()} function in
	Figure~\ref{fig:toolsoftrade:Threads Created Via pthread-create() Share Memory}
	can simply return, why bother with \co{pthread_exit()}?
	\fi
\QuickQuizAnswer{
	이 간단한 예제에서는 \co{pthread_exit()} 를 신경 쓸 이유가 없는게
	맞습니다.
	하지만, \co{mythread()} 가 별도로 컴파일된 다른 함수를 호출하는 경우를
	생각해 봅시다.
	그런 경우, \co{pthread_exit()} 는 이런 다른 함수들에서도 별도의 다른
	에러들을 리턴하거나 해서 실행 흐름을 \co{mythread()} 에 되돌리거나 할
	필요 없이 곧바로 쓰레드의 실행을 종료시킬 수 있게 합니다.

	\iffalse
	In this simple example, there is no reason whatsoever.
	However, imagine a more complex example, where \co{mythread()}
	invokes other functions, possibly separately compiled.
	In such a case, \co{pthread_exit()} allows these other functions
	to end the thread's execution without having to pass some sort
	of error return all the way back up to \co{mythread()}.
	\fi
} \QuickQuizEnd

라인~20 에 있는 \co{pthread_join()} 함수는 fork-join 에서의 \co{wait()} 함수와
유사합니다.
이 함수는 \co{tid} 변수로 이야기된 쓰레드가 \co{pthread_exit()} 함수를 통해서나
쓰레드의 탑 레벨 함수가 리턴을 하거나 해서 실행을 완료할 때까지 기다립니다.
쓰레드의 종료 값은 \co{pthread_join()} 함수에 두번째 인자로 넘겨진 포인터를
통해 저장됩니다.
쓰레드의 종료 값은 쓰레드가 어떻게 종료되었는지에 따라 다른데,
\co{pthread_exit()} 함수에 넘겨진 값이거나 쓰레드의 탑 레벨 함수에서 리턴한
값입니다.

Figure~\ref{fig:toolsoftrade:Threads Created Via pthread-create() Share Memory}
에 보여진 프로그램은 다음과 같이 결과를 내놓게 되는데, 이 결과는 메모리가 두개
쓰레드간에 공유됨을 보여줍니다:

\iffalse
The \co{pthread_join()} primitive, shown on line~20,  is analogous to
the fork-join \co{wait()} primitive.
It blocks until the thread specified by the \co{tid} variable completes
execution, either by invoking \co{pthread_exit()} or by returning from
the thread's top-level function.
The thread's exit value will be stored through the pointer passed as the
second argument to \co{pthread_join()}.
The thread's exit value is either the value passed to \co{pthread_exit()}
or the value returned by the thread's top-level function, depending on
how the thread in question exits.

The program shown in
Figure~\ref{fig:toolsoftrade:Threads Created Via pthread-create() Share Memory}
produces output as follows, demonstrating that memory is in fact
shared between the two threads:
\fi

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\scriptsize
\begin{verbatim}
Child process set x=1
Parent process sees x=1
\end{verbatim}
\end{minipage}
\vspace{5pt}

이 프로그램은 변수 \co{x} 에 값을 저장하는 쓰레드가 한번에 하나 뿐임을 확실히
하기 위해 많은 신경을 쓰고 있음을 알아 두십시오.
한 쓰레드가 어떤 변수에 값을 저장하는 동안 다른 쓰레드가 그 변수의 값을 읽거나
쓰려 하는 상황을 가리켜 ``data race(데이터 레이스)'' 라 합니다.
C 언어는 데이터 레이스의 결과에 대해 어떤 보장도 하지 않기 때문에, 우리는 다음
섹션에서 이야기할 락킹 도구들과 같이 데이터에의 동시적 접근과 수정을 안전하게
할 수 있는 방법이 필요합니다.

\iffalse
Note that this program carefully makes sure that only one of the threads
stores a value to variable \co{x} at a time.
Any situation in which one thread might be storing a value to a given
variable while some other thread either loads from or stores to that
same variable is termed a ``data race''.
Because the C language makes no guarantee that the results of a data race
will be in any way reasonable, we need some way of safely accessing
and modifying data concurrently, such as the locking primitives discussed
in the following section.
\fi

\QuickQuiz{}
	C 언어가 데이터 레이스에 대해 어떤 보장도 하지 않는다면, 왜 리눅스
	커널은 그렇게 많은 데이터 레이스들을 가지고 있는거죠?
	지금 리눅스 커널이 완전 엉망이라고 이야기 하려는 거예요???

	\iffalse
	If the C language makes no guarantees in presence of a data
	race, then why does the Linux kernel have so many data races?
	Are you trying to tell me that the Linux kernel is completely
	broken???
	\fi
\QuickQuizAnswer{
	아, 하지만 리눅스 커널은 조심스럽게 선택된, 데이터 레이스 상황에서도
	안전한 실행을 가능하게 하는 asm 과 같은 gcc 의 특수한 확장 기능을
	포함하는 C 언어의 슈퍼셋으로 작성되었습니다.
	또한, 리눅스 커널은 데이터 레이스가 특히나 문제가 되는 플랫폼들
	위에서는 동작하지 않습니다.
	예를 들어, 32 비트 포인터와 16 비트 버스를 갖는 임베디드 시스템을
	생각해 보세요.
	그런 시스템에서는 하나의 포인터에 값을 저장하고 읽어오는 데이터
	레이스에서 읽기는 아래쪽 16 비트는 예전 값이고 위쪽 16 비트는 새 값인
	값을 읽어올 수도 있을 겁니다.

	\iffalse
	Ah, but the Linux kernel is written in a carefully selected
	superset of the C language that includes special gcc
	extensions, such as asms, that permit safe execution even
	in presence of data races.
	In addition, the Linux kernel does not run on a number of
	platforms where data races would be especially problematic.
	For an example, consider embedded systems with 32-bit pointers
	and 16-bit busses.
	On such a system, a data race involving a store to and a load
	from a given pointer might well result in the load returning the
	low-order 16 bits of the old value of the pointer concatenated
	with the high-order 16 bits of the new value of the pointer.
	\fi
} \QuickQuizEnd

\subsection{POSIX Locking}
\label{sec:toolsoftrade:POSIX Locking}

POSIX 표준은 프로그래머가 ``POSIX 락킹'' 을 이용해 데이터 레이스 상황을 회피할
수 있게 합니다.
POSIX 락킹은 여러개의 기본 기능을 제공하는데, 가장 기본적인 것들은
\co{pthread_mutex_lock()} 과 \co{pthread_mutex_unlock()} 입니다.
이 기본 기능들은 \co{pthread_mutex_t} 타입인 락에 대해 동작합니다.
이 락들은 정적으로 선언되고 \co{PTHREAD_MUTEX_INITIALIZER} 를 통해 초기화
될수도, 동적으로 할당된 후 \co{pthread_mutex_init()} 를 통해 초기화 될 수도
있습니다.
이 섹션의 예제 코드는 앞의 경우들을 취할 것입니다.

\iffalse
The POSIX standard allows the programmer to avoid data races via
``POSIX locking''.
POSIX locking features a number of primitives, the most fundamental
of which are \co{pthread_mutex_lock()} and \co{pthread_mutex_unlock()}.
These primitives operate on locks, which are of type \co{pthread_mutex_t}.
These locks may be declared statically and initialized with
\co{PTHREAD_MUTEX_INITIALIZER}, or they may be allocated dynamically
and initialized using the \co{pthread_mutex_init()} primitive.
The demonstration code in this section will take the former course.
\fi

\co{pthread_mutex_lock()} 함수는 특정 락을 ``획득'' 하고,
\co{pthread_mutex_unlock()} 함수는 특정 락을 ``해제'' 합니다.
이것들은 ``명시적'' 락킹 함수들이기 때문에, 한 순간에 하나의 쓰레드만이 특정
락을 ``가질'' 수 있습니다.
예를 들어, 두개의 쓰레드들이 같은 락을 동시에 획득하려 하면, 그 중 하나만이
먼저 락을 얻을 수 있도록 ``허락'' 되고, 다른 쓰레드는 첫번째 쓰레드가 락을
해제할 때까지 기다려야 합니다.

\iffalse
The \co{pthread_mutex_lock()} primitive ``acquires'' the specified lock,
and the \co{pthread_mutex_unlock()} ``releases'' the specified lock.
Because these are ``exclusive'' locking primitives,
only one thread at a time may ``hold'' a given lock at a given time.
For example, if a pair of threads attempt to acquire the same lock
concurrently, one of the pair will be ``granted'' the lock first, and
the other will wait until the first thread releases the lock.
\fi

\QuickQuiz{}
	제가 여러 쓰레드들이 한번에 같은 락을 쥐고 있게 하고 싶으면 어떻게
	하죠?

	\iffalse
	What if I want several threads to hold the same lock at the
	same time?
	\fi
\QuickQuizAnswer{
	가장 먼저 당신이 해야할 일은 왜 그러길 원하는지 스스로에게 물어보는
	겁니다.
	만약 답이 ``나는 많은 쓰레드에 의해 읽혀지고 아주 가끔 수정되는 많은
	데이터를 가지고 있기 때문'' 이라면, POSIX 리더-라이터 락이 당신이 찾고
	있는 것일 수 있습니다.
	이것들은 Section~\ref{sec:toolsoftrade:POSIX Reader-Writer Locking} 에
	소개되어 있습니다.

	여러 쓰레드가 같은 락을 잡고 있는 것과 같은 효과를 얻는 또다른 방법은
	한 쓰레드가 락을 획득하고 나서 \co{pthread_create()} 함수를 이용해 다른
	쓰레드들을 생성하는 것입니다.
	왜 이게 좋은 방법인지는 독자 여러분께서 생각해 보시기 바랍니다.

	\iffalse
	The first thing you should do is to ask yourself why you would
	want to do such a thing.
	If the answer is ``because I have a lot of data that is read
	by many threads, and only occasionally updated'', then
	POSIX reader-writer locks might be what you are looking for.
	These are introduced in
	Section~\ref{sec:toolsoftrade:POSIX Reader-Writer Locking}.

	Another way to get the effect of multiple threads holding
	the same lock is for one thread to acquire the lock, and
	then use \co{pthread_create()} to create the other threads.
	The question of why this would ever be a good idea is left
	to the reader.
	\fi
} \QuickQuizEnd

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 pthread_mutex_t lock_a = PTHREAD_MUTEX_INITIALIZER;
  2 pthread_mutex_t lock_b = PTHREAD_MUTEX_INITIALIZER;
  3 int x = 0;
  4 
  5 void *lock_reader(void *arg)
  6 {
  7   int i;
  8   int newx = -1;
  9   int oldx = -1;
 10   pthread_mutex_t *pmlp = (pthread_mutex_t *)arg;
 11 
 12   if (pthread_mutex_lock(pmlp) != 0) {
 13     perror("lock_reader:pthread_mutex_lock");
 14     exit(-1);
 15   }
 16   for (i = 0; i < 100; i++) {
 17     newx = ACCESS_ONCE(x);
 18     if (newx != oldx) {
 19       printf("lock_reader(): x = %d\n", newx);
 20     }
 21     oldx = newx;
 22     poll(NULL, 0, 1);
 23   }
 24   if (pthread_mutex_unlock(pmlp) != 0) {
 25     perror("lock_reader:pthread_mutex_unlock");
 26     exit(-1);
 27   }
 28   return NULL;
 29 }
 30 
 31 void *lock_writer(void *arg)
 32 {
 33   int i;
 34   pthread_mutex_t *pmlp = (pthread_mutex_t *)arg;
 35 
 36   if (pthread_mutex_lock(pmlp) != 0) {
 37     perror("lock_writer:pthread_mutex_lock");
 38     exit(-1);
 39   }
 40   for (i = 0; i < 3; i++) {
 41     ACCESS_ONCE(x)++;
 42     poll(NULL, 0, 5);
 43   }
 44   if (pthread_mutex_unlock(pmlp) != 0) {
 45     perror("lock_writer:pthread_mutex_unlock");
 46     exit(-1);
 47   }
 48   return NULL;
 49 }
\end{verbatim}
}
\caption{Demonstration of Exclusive Locks}
\label{fig:toolsoftrade:Demonstration of Exclusive Locks}
\end{figure}

Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks}
(\co{lock.c}) 에 명시적 락킹의 사용 예가 있습니다.
라인~1 은 \co{lock_a} 라는 이름의 POSIX 락을 정의와 함께 초기화 하고,
라인~2 에서는 비슷하게 \co{lock_b} 라는 이름의 락을 정의하고 초기화 합니다.
라인~3 에서는 공유 변수 ~\co{x} 를 정의와 함께 초기화 합니다.

라인~5-28 은 \co{arg} 로 가리켜진 락을 잡고서 공유 변수 \co{x} 를 반복적으로
읽는 \co{lock_reader()} 함수를 정의합니다.
라인~10 은 \co{arg} 를 \co{pthread_mutex_lock()} 과 \co{pthread_mutex_unlock()}
함수에 사용하기 위해 \co{pthread_mutex_t} 포인터로 캐스팅 합니다.

\iffalse
This exclusive-locking property is demonstrated using the code shown in
Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks}
(\co{lock.c}).
Line~1 defines and initializes a POSIX lock named \co{lock_a}, while
line~2 similarly defines and initializes a lock named \co{lock_b}.
Line~3 defines and initializes a shared variable ~\co{x}.

Lines~5-28 defines a function \co{lock_reader()} which repeatedly
reads the shared variable \co{x} while holding
the lock specified by \co{arg}.
Line~10 casts \co{arg} to a pointer to a \co{pthread_mutex_t}, as
required by the \co{pthread_mutex_lock()} and \co{pthread_mutex_unlock()}
primitives.
\fi

\QuickQuiz{}
	왜 그냥 Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks}
	라인~5 에서 \co{lock_reader()} 가 곧바로 \co{pthread_mutex_t} 포인터를
	받도록 하지 않는거죠?

	\iffalse
	Why not simply make the argument to \co{lock_reader()}
	on line~5 of
	Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks}
	be a pointer to a \co{pthread_mutex_t}?
	\fi
\QuickQuizAnswer{
	\co{lock_reader()} 를 \co{pthread_create()} 에 넘겨야 하기 때문이죠.
	물론 함수를 \co{pthread_create()} 에 넘길 때 캐스팅을 해서 넘길 수도
	있지만, 함수 캐스팅은 좀 보기도 안좋고 간단한 포인터 캐스팅에 비해
	잘 하기가 어렵습니다.

	\iffalse
	Because we will need to pass \co{lock_reader()} to
	\co{pthread_create()}.
	Although we could cast the function when passing it to
	\co{pthread_create()}, function casts are quite a bit
	uglier and harder to get right than are simple pointer casts.
	\fi
} \QuickQuizEnd

라인~12-15 는 특정 \co{pthread_mutex_t} 를 획득하고, 에러를 체크한 후 만약
에러가 있었다면 프로그램을 종료합니다.
라인~16-23 은 반복적으로 \co{x} 의 값을 체크하고, 그 값이 바뀔 때마다 새로운
값을 화면에 출력합니다.
라인~22 는 예제가 싱글 프로세서 머신에서도 잘 돌아가도록 1 밀리세컨드씩 잠을
잡니다.
라인~24-27 에서는 \co{pthread_mutex_t} 를 해제하고, 에러를 체크한 후 에러가
났다면 프로그램을 종료합니다.
마지막으로, 라인~28 에서는 \co{pthread_create()} 에서 요구된 함수 타입을
맞춰주기 위해 \co{NULL} 을 리턴합니다.

\iffalse
Lines~12-15 acquire the specified \co{pthread_mutex_t}, checking
for errors and exiting the program if any occur.
Lines~16-23 repeatedly check the value of \co{x}, printing the new value
each time that it changes.
Line~22 sleeps for one millisecond, which allows this demonstration
to run nicely on a uniprocessor machine.
Line~24-27 release the \co{pthread_mutex_t}, again checking for
errors and exiting the program if any occur.
Finally, line~28 returns \co{NULL}, again to match the function type
required by \co{pthread_create()}.
\fi

\QuickQuiz{}
	\co{pthread_mutex_t} 의 획득과 해제에 매번 4줄이나 써야한다니 좀
	고통스러울 것 같군요!
	더 나은 방법은 없나요?

	\iffalse
	Writing four lines of code for each acquisition and release
	of a \co{pthread_mutex_t} sure seems painful!
	Isn't there a better way?
	\fi
\QuickQuizAnswer{
	실로 그렇습니다!
	그리고 그런 이유로, \co{pthread_mutex_lock()} 과
	\co{pthread_mutex_unlock()} 함수들은 보통 이 에러 체킹을 해주는 함수로
	감싸져서 사용되곤 합니다.
	뒤에서, 우리는 이들을 리눅스 커널의 \co{spin_lock()} 과
	\co{spin_unlock()} API 들로 감싸서 사용할 겁니다.

	\iffalse
	Indeed!
	And for that reason, the \co{pthread_mutex_lock()} and
	\co{pthread_mutex_unlock()} primitives are normally wrapped
	in functions that do this error checking.
	Later on, we will wrapper them with the Linux kernel
	\co{spin_lock()} and \co{spin_unlock()} APIs.
	\fi
} \QuickQuizEnd

Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks} 의 라인~31-49 는
주기적으로 공유 변수 \co{x} 를 특정 \co{pthread_mutex_t} 를 잡은 채로 업데이트
하는 \co{lock_writer()} 함수를 보여줍니다.
\co{lock_reader()} 에서처럼 라인~34 에서는 \co{arg} 를 \co{pthread_mutex_t}
포인터로 캐스팅 하고 라인~36-39 에서 해당 락을 얻어오고, 라인~44-47 에서 락을
놓아줍니다.
락을 잡고 있는 동안, 라인~40-43 에서는 공유 변수 \co{x} 를 5 밀리세컨드 씩
자면서 증가시킵니다.
마지막으로 라인~44-47 에서는 락을 놓아줍니다.

\iffalse
Lines~31-49 of
Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks}
shows \co{lock_writer()}, which
periodically update the shared variable \co{x} while holding the
specified \co{pthread_mutex_t}.
As with \co{lock_reader()}, line~34 casts \co{arg} to a pointer
to \co{pthread_mutex_t}, lines~36-39 acquires the specified lock,
and lines~44-47 releases it.
While holding the lock, lines~40-43 increment the shared variable \co{x},
sleeping for five milliseconds between each increment.
Finally, lines~44-47 release the lock.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1   printf("Creating two threads using same lock:\n");
  2   if (pthread_create(&tid1, NULL,
  3                      lock_reader, &lock_a) != 0) {
  4     perror("pthread_create");
  5     exit(-1);
  6   }
  7   if (pthread_create(&tid2, NULL,
  8                      lock_writer, &lock_a) != 0) {
  9     perror("pthread_create");
 10     exit(-1);
 11   }
 12   if (pthread_join(tid1, &vp) != 0) {
 13     perror("pthread_join");
 14     exit(-1);
 15   }
 16   if (pthread_join(tid2, &vp) != 0) {
 17     perror("pthread_join");
 18     exit(-1);
 19   }
\end{verbatim}
}
\caption{Demonstration of Same Exclusive Lock}
\label{fig:toolsoftrade:Demonstration of Same Exclusive Lock}
\end{figure}

Figure~\ref{fig:toolsoftrade:Demonstration of Same Exclusive Lock}
는 \co{lock_reader()} 와 \co{lock_writer()} 를 같은 \co{lock_a} 락을 사용하도록
하면서 쓰레드로 실행시키는 코드를 보여줍니다.
라인~2-6 은 \co{lock_reader()} 를 실행하는 쓰레드를 생성하고, 라인~7-11 에서는
\co{lock_writer()} 를 실행하는 쓰레드를 생성합니다.
라인~12-19 에서는 두 쓰레드가 완료되기를 기다립니다.
이 코드가 내놓는 결과는 다음과 같습니다:

\iffalse
Figure~\ref{fig:toolsoftrade:Demonstration of Same Exclusive Lock}
shows a code fragment that runs \co{lock_reader()} and
\co{lock_writer()} as thread using the same lock, namely, \co{lock_a}.
Lines~2-6 create a thread running \co{lock_reader()}, and then
Lines~7-11 create a thread running \co{lock_writer()}.
Lines~12-19 wait for both threads to complete.
The output of this code fragment is as follows:
\fi

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\scriptsize
\begin{verbatim}
Creating two threads using same lock:
lock_reader(): x = 0
\end{verbatim}
\end{minipage}
\vspace{5pt}

두 쓰레드가 모두 같은 락을 사용하기 때문에, \co{lock_reader()} 쓰레드는
\co{lock_writer()} 가 락을 잡고서 만들어내는 \co{x} 의 중간 값들을 볼 수
없습니다.

\iffalse
Because both threads are using the same lock, the \co{lock_reader()}
thread cannot see any of the intermediate values of \co{x} produced
by \co{lock_writer()} while holding the lock.
\fi

\QuickQuiz{}
	``x = 0'' 만이 Figure~\ref{fig:toolsoftrade:Demonstration of Same
	Exclusive Lock} 의 코드에서 발생 가능한 오로지 하나의 결과인가요?
	만약 그렇다면, 왜죠?
	아니라면, 어떤 다른 결과가 가능할까요, 그리고 왜일까요?

	\iffalse
	Is ``x = 0'' the only possible output from the code fragment
	shown in
	Figure~\ref{fig:toolsoftrade:Demonstration of Same Exclusive Lock}?
	If so, why?
	If not, what other output could appear, and why?
	\fi
\QuickQuizAnswer{
	아닙니다.
	``x = 0'' 가 나온 이유는 \co{lock_reader()} 가 락을 먼저 잡았기
	때문입니다.
	\co{lock_writer()} 가 먼저 락을 잡았다면, 결과는 ``x = 3'' 가 되었을
	것입니다.
	하지만, 해당 코드에서는 \co{lock_reader()} 를 먼저 시작시키고 이 실행은
	멀티프로세서에서 이루어졌기 때문에, 대부분은 일반적으로
	\co{lock_reader()} 가 락을 먼저 잡을 것으로 예상할 수 있을 겁니다.
	하지만, 보장된 건 아니지요, 특히나 바쁜 시스템에서는요.

	\iffalse
	No.
	The reason that ``x = 0'' was output was that \co{lock_reader()}
	acquired the lock first.
	Had \co{lock_writer()} instead acquired the lock first, then
	the output would have been ``x = 3''.
	However, because the code fragment started \co{lock_reader()} first
	and because this run was performed on a multiprocessor,
	one would normally expect \co{lock_reader()} to acquire the
	lock first.
	However, there are no guarantees, especially on a busy system.
	\fi
} \QuickQuizEnd

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1   printf("Creating two threads w/different locks:\n");
  2   x = 0;
  3   if (pthread_create(&tid1, NULL,
  4                      lock_reader, &lock_a) != 0) {
  5     perror("pthread_create");
  6     exit(-1);
  7   }
  8   if (pthread_create(&tid2, NULL,
  9                      lock_writer, &lock_b) != 0) {
 10     perror("pthread_create");
 11     exit(-1);
 12   }
 13   if (pthread_join(tid1, &vp) != 0) {
 14     perror("pthread_join");
 15     exit(-1);
 16   }
 17   if (pthread_join(tid2, &vp) != 0) {
 18     perror("pthread_join");
 19     exit(-1);
 20   }
\end{verbatim}
}
\caption{Demonstration of Different Exclusive Locks}
\label{fig:toolsoftrade:Demonstration of Different Exclusive Locks}
\end{figure}

Figure~\ref{fig:toolsoftrade:Demonstration of Different Exclusive Locks}
에서 비슷한, 하지만 이번엔 다른 락을 사용하는 코드를 보여줍니다:
\co{lock_reader()} 를 위해선 \co{lock_a}를, \co{lock_wirter()} 를 위해선
\co{lock_b} 를 사용합니다.
이 코드의 수행 결과는 다음과 같습니다:

\iffalse
Figure~\ref{fig:toolsoftrade:Demonstration of Different Exclusive Locks}
shows a similar code fragment, but this time using different locks:
\co{lock_a} for \co{lock_reader()} and \co{lock_b} for
\co{lock_writer()}.
The output of this code fragment is as follows:
\fi

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\scriptsize
\begin{verbatim}
Creating two threads w/different locks:
lock_reader(): x = 0
lock_reader(): x = 1
lock_reader(): x = 2
lock_reader(): x = 3
\end{verbatim}
\end{minipage}
\vspace{5pt}

두 쓰레드가 다른 락을 사용하기 때문에, 서로를 배제하지 않고, 동시에 수행됩니다.
그래서 \co{lock_reader()} 함수는 \co{lock_writer()} 가 저장한 \co{x} 중간값을
볼 수 있습니다.

\iffalse
Because the two threads are using different locks, they do not exclude
each other, and can run concurrently.
The \co{lock_reader()} function can therefore see the intermediate
values of \co{x} stored by \co{lock_writer()}.
\fi

\QuickQuiz{}
	서로 다른 락을 사용하는건 쓰레드가 서로 상대의 중간 상태를 볼 수 있는등
	혼란스럽게 할 수 있는 것같은데요.
	잘 짜여진 병렬 프로그램은 이런 혼란을 막기 위해서는 하나의 락만을
	사용해야만 하는 건가요?

	\iffalse
	Using different locks could cause quite a bit of confusion,
	what with threads seeing each others' intermediate states.
	So should well-written parallel programs restrict themselves
	to using a single lock in order to avoid this kind of confusion?
	\fi
\QuickQuizAnswer{
	가끔은 프로그램을 하나의 전역적인 락만을 사용하면서 잘 동작하고
	확장성도 좋게 작성하는 것도 가능하지만, 그런 프로그램은 좀 예외적인
	경우입니다.
	당신은 좋은 성능과 확장성을 위해선 보통은 여러개의 락을 사용해야
	할겁니다.

	이 규칙에 대해 하나의 가능한 예외는 아직은 연구 단계에 머물러 있는,
	``트랜잭셔널 메모리'' 입니다.
	트랜잭셔널 메모리는 하나의 전역 락을 사용하면서 허용된 최적화를
	사용하고, 추가적으로 롤백을 지원하는 케이스~\cite{HansJBoehm2009HOTPAR}
	로 간략히 생각할 수 있습니다.

	\iffalse
	Although it is sometimes possible to write a program using a
	single global lock that both performs and scales well, such
	programs are exceptions to the rule.
	You will normally need to use multiple locks to attain good
	performance and scalability.

	One possible exception to this rule is ``transactional memory'',
	which is currently a research topic.
	Transactional-memory semantics can be loosely thought of as those
	of a single global lock with optimizations permitted and
	with the addition of rollback~\cite{HansJBoehm2009HOTPAR}.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	Figure~\ref{fig:toolsoftrade:Demonstration of Different Exclusive
	Locks} 에 보여진 코드에서, \co{lock_reader()} 는 \co{lock_writer()} 가
	생성하는 값 모두를 보도록 보장되어 있나요?
	그렇다면, 또 그렇지 않다면, 왜죠?

	\iffalse
	In the code shown in
	Figure~\ref{fig:toolsoftrade:Demonstration of Different Exclusive Locks},
	is \co{lock_reader()} guaranteed to see all the values produced
	by \co{lock_writer()}?
	Why or why not?
	\fi
\QuickQuizAnswer{
	아닙니다.
	바쁜 시스템에서라면, \co{lock_reader()} 는 \co{lock_writer()} 의 실행이
	완료될 때까지 CPU 를 선점당해 \co{lock_writer()} 의 \co{x} 중간 값을
	\emph{전혀} 볼 수 없을 수도 있습니다.

	\iffalse
	No.
	On a busy system, \co{lock_reader()} might be preempted
	for the entire duration of \co{lock_writer()}'s execution,
	in which case it would not see \emph{any} of \co{lock_writer()}'s
	intermediate states for \co{x}.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	잠깐만요!!!
	Figure~\ref{fig:toolsoftrade:Demonstration of Same Exclusive Lock}
	에서는 공유 변수 \co{x} 를 초기화 하지 않았는데, 
	Figure~\ref{fig:toolsoftrade:Demonstration of Different Exclusive
	Locks} 에서는 왜 초기화 해야 했던거죠?

	\iffalse
	Wait a minute here!!!
	Figure~\ref{fig:toolsoftrade:Demonstration of Same Exclusive Lock}
	didn't initialize shared variable \co{x},
	so why does it need to be initialized in
	Figure~\ref{fig:toolsoftrade:Demonstration of Different Exclusive Locks}?
	\fi
\QuickQuizAnswer{
	Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks} 의
	라인~3 을 보세요.
	Figure~\ref{fig:toolsoftrade:Demonstration of Same Exclusive Lock} 의
	코드는 먼저 수행되었기 때문에, \co{x} 의 컴파일 타임 초기화에 의존할
	수도 있었습니다.
	Figure~\ref{fig:toolsoftrade:Demonstration of Different Exclusive
	Locks} 는 그 다음에 돌았기 때문에, \co{x} 를 다시 초기화 해야 합니다.

	\iffalse
	See line~3 of
	Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks}.
	Because the code in
	Figure~\ref{fig:toolsoftrade:Demonstration of Same Exclusive Lock}
	ran first, it could rely on the compile-time initialization of
	\co{x}.
	The code in
	Figure~\ref{fig:toolsoftrade:Demonstration of Different Exclusive Locks}
	ran next, so it had to re-initialize \co{x}.
	\fi
} \QuickQuizEnd

이외에도 몇가지 더 POSIX 명시적 락킹이 있지만, 여기 소개한 것만으로도 좋은
시작이 될 수 있고, 많은 상황에는 이것만으로도 충분할 겁니다.
다음 섹션에서는 POSIX 리더-라이터 락킹에 대해 간략히 알아봅니다.

\iffalse
Although there is quite a bit more to POSIX exclusive locking, these
primitives provide a good start and are in fact sufficient in a great
many situations.
The next section takes a brief look at POSIX reader-writer locking.
\fi

\subsection{POSIX Reader-Writer Locking}
\label{sec:toolsoftrade:POSIX Reader-Writer Locking}

The POSIX API provides a reader-writer lock, which is represented by
a \co{pthread_rwlock_t}.
As with \co{pthread_mutex_t}, \co{pthread_rwlock_t} may be statically
initialized via \co{PTHREAD_RWLOCK_INITIALIZER} or dynamically
initialized via the \co{pthread_rwlock_init()} primitive.
The \co{pthread_rwlock_rdlock()} primitive read-acquires the
specified \co{pthread_rwlock_t}, the \co{pthread_rwlock_wrlock()}
primitive write-acquires it, and the \co{pthread_rwlock_unlock()}
primitive releases it.
Only a single thread may write-hold a given \co{pthread_rwlock_t}
at any given time, but multiple threads may read-hold a given
\co{pthread_rwlock_t}, at least while there is no thread
currently write-holding it.

As you might expect, reader-writer locks are designed for read-mostly
situations.
In these situations, a reader-writer lock can provide greater scalability
than can an exclusive lock because the exclusive lock is by definition
limited to a single thread holding the lock at any given time, while
the reader-writer lock permits
an arbitrarily large number of readers to concurrently hold the lock.
However, in practice, we need to know how much additional scalability is
provided by reader-writer locks.

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 pthread_rwlock_t rwl = PTHREAD_RWLOCK_INITIALIZER;
  2 int holdtime = 0;
  3 int thinktime = 0;
  4 long long *readcounts;
  5 int nreadersrunning = 0;
  6 
  7 #define GOFLAG_INIT 0
  8 #define GOFLAG_RUN  1
  9 #define GOFLAG_STOP 2
 10 char goflag = GOFLAG_INIT;
 11 
 12 void *reader(void *arg)
 13 {
 14   int i;
 15   long long loopcnt = 0;
 16   long me = (long)arg;
 17 
 18   __sync_fetch_and_add(&nreadersrunning, 1);
 19   while (ACCESS_ONCE(goflag) == GOFLAG_INIT) {
 20     continue;
 21   }
 22   while (ACCESS_ONCE(goflag) == GOFLAG_RUN) {
 23     if (pthread_rwlock_rdlock(&rwl) != 0) {
 24       perror("pthread_rwlock_rdlock");
 25       exit(-1);
 26     }
 27     for (i = 1; i < holdtime; i++) {
 28       barrier();
 29     }
 30     if (pthread_rwlock_unlock(&rwl) != 0) {
 31       perror("pthread_rwlock_unlock");
 32       exit(-1);
 33     }
 34     for (i = 1; i < thinktime; i++) {
 35       barrier();
 36     }
 37     loopcnt++;
 38   }
 39   readcounts[me] = loopcnt;
 40   return NULL;
 41 }
\end{verbatim}
}
\caption{Measuring Reader-Writer Lock Scalability}
\label{fig:toolsoftrade:Measuring Reader-Writer Lock Scalability}
\end{figure}

Figure~\ref{fig:toolsoftrade:Measuring Reader-Writer Lock Scalability}
(\co{rwlockscale.c})
shows one way of measuring reader-writer lock scalability.
Line~1 shows the definition and initialization of the reader-writer
lock, line~2 shows the \co{holdtime} argument controlling the
time each thread holds the reader-writer lock,
line~3 shows the \co{thinktime} argument controlling the time between
the release of the reader-writer lock and the next acquisition,
line~4 defines the \co{readcounts} array into which each reader thread
places the number of times it acquired the lock, and
line~5 defines the \co{nreadersrunning} variable, which
determines when all reader threads have started running.

Lines~7-10 define \co{goflag}, which synchronizes the start and the
end of the test.
This variable is initially set to \co{GOFLAG_INIT}, then set to
\co{GOFLAG_RUN} after all the reader threads have started, and finally
set to \co{GOFLAG_STOP} to terminate the test run.

Lines~12-41 define \co{reader()}, which is the reader thread.
Line~18 atomically increments the \co{nreadersrunning} variable
to indicate that this thread is now running, and
lines~19-21 wait for the test to start.
The \co{ACCESS_ONCE()} primitive forces the compiler to fetch \co{goflag}
on each pass through the loop---the compiler would otherwise be within its
rights to assume that the value of \co{goflag} would never change.

\QuickQuiz{}
	Instead of using \co{ACCESS_ONCE()} everywhere, why not just
	declare \co{goflag} as \co{volatile} on line~10 of
	Figure~\ref{fig:toolsoftrade:Measuring Reader-Writer Lock Scalability}?
\QuickQuizAnswer{
	A \co{volatile} declaration is in fact a reasonable alternative in
	this particular case.
	However, use of \co{ACCESS_ONCE()} has the benefit of clearly
	flagging to the reader that \co{goflag} is subject to concurrent
	reads and updates.
	However, \co{ACCESS_ONCE()} is especially useful in cases where
	most of the accesses are protected by a lock (and thus \emph{not}
	subject to change), but where a few of the accesses are made outside
	of the lock.
	Using a volatile declaration in this case would make it harder
	for the reader to note the special accesses outside of the lock,
	and would also make it harder for the compiler to generate good
	code under the lock.
} \QuickQuizEnd

\QuickQuiz{}
	\co{ACCESS_ONCE()} only affects the compiler, not the CPU.
	Don't we also need memory barriers to make sure
	that the change in \co{goflag}'s value propagates to the
	CPU in a timely fashion in
	Figure~\ref{fig:toolsoftrade:Measuring Reader-Writer Lock Scalability}?
\QuickQuizAnswer{
	No, memory barriers are not needed and won't help here.
	Memory barriers only enforce ordering among multiple
	memory references:  They do absolutely nothing to expedite
	the propagation of data from one part of the system to
	another.
	This leads to a quick rule of thumb:  You do not need
	memory barriers unless you are using more than one
	variable to communicate between multiple threads.

	But what about \co{nreadersrunning}?
	Isn't that a second variable used for communication?
	Indeed it is, and there really are the needed memory-barrier
	instructions buried in \co{__sync_fetch_and_add()},
	which make sure that the thread proclaims its presence
	before checking to see if it should start.
} \QuickQuizEnd

\QuickQuiz{}
	Would it ever be necessary to use \co{ACCESS_ONCE()} when accessing
	a per-thread variable, for example, a variable declared using
	the \co{gcc} \co{__thread} storage class?
\QuickQuizAnswer{
	It depends.
	If the per-thread variable was accessed only from its thread,
	and never from a signal handler, then no.
	Otherwise, it is quite possible that \co{ACCESS_ONCE()} is needed.
	We will see examples of both situations in
	Section~\ref{sec:count:Signal-Theft Limit Counter Implementation}.

	This leads to the question of how one thread can gain access to
	another thread's \co{__thread} variable, and the answer is that
	the second thread must store a pointer to its \co{__thread}
	pointer somewhere that the first thread has access to.
	One common approach is to maintain a linked list with one 
	element per thread, and to store the address of each thread's
	\co{__thread} variable in the corresponding element.
} \QuickQuizEnd

The loop spanning lines~22-38 carries out the performance test.
Lines~23-26 acquire the lock, lines~27-29 hold the lock for the specified
duration (and the \co{barrier()} directive prevents the compiler from
optimizing the loop out of existence), lines~30-33 release the lock,
and lines~34-36 wait for the specified duration before re-acquiring the
lock.
Line~37 counts this lock acquisition.

Line~39 moves the lock-acquisition count to this thread's element of the
\co{readcounts[]} array, and line~40 returns, terminating this thread.

\begin{figure}[tb]
\begin{center}
\resizebox{3in}{!}{\includegraphics{CodeSamples/toolsoftrade/rwlockscale}}
\end{center}
\caption{Reader-Writer Lock Scalability}
\label{fig:intro:Reader-Writer Lock Scalability}
\end{figure}

Figure~\ref{fig:intro:Reader-Writer Lock Scalability}
shows the results of running this test on a 64-core Power-5 system
with two hardware threads per core for a total of 128 software-visible
CPUs.
The \co{thinktime} parameter was zero for all these tests, and the
\co{holdtime} parameter set to values ranging from one thousand (``1K''
on the graph) to 100 million (``100M'' on the graph).
The actual value plotted is:
\begin{equation}
	\frac{L_N}{N L_1}
\end{equation}
where $N$ is the number of threads,
$L_N$ is the number of lock acquisitions by $N$ threads, and
$L_1$ is the number of lock acquisitions by a single thread.
Given ideal hardware and software scalability, this value will always
be 1.0.

As can be seen in the figure, reader-writer locking scalability is
decidedly non-ideal, especially for smaller sizes of critical
sections.
To see why read-acquisition can be so slow, consider
that all the acquiring threads must update the \co{pthread_rwlock_t}
data structure.
Therefore, if all 128 executing threads attempt to
read-acquire the reader-writer lock concurrently, they must update
this underlying \co{pthread_rwlock_t} one at a time.
One lucky thread might do so almost immediately, but the least-lucky
thread must wait for all the other 127 threads to do their updates.
This situation will only get worse as you add CPUs.

\QuickQuiz{}
	Isn't comparing against single-CPU throughput a bit harsh?
\QuickQuizAnswer{
	Not at all.
	In fact, this comparison was, if anything, overly lenient.
	A more balanced comparison would be against single-CPU
	throughput with the locking primitives commented out.
} \QuickQuizEnd

\QuickQuiz{}
	But 1,000 instructions is not a particularly small size for
	a critical section.
	What do I do if I need a much smaller critical section, for
	example, one containing only a few tens of instructions?
\QuickQuizAnswer{
	If the data being read \emph{never} changes, then you do not
	need to hold any locks while accessing it.
	If the data changes sufficiently infrequently, you might be
	able to checkpoint execution, terminate all threads, change
	the data, then restart at the checkpoint.

	Another approach is to keep a single exclusive lock per
	thread, so that a thread read-acquires the larger aggregate
	reader-writer lock by acquiring its own lock, and write-acquires
	by acquiring all the per-thread locks~\cite{WilsonCHsieh92a}.
	This can work quite well for readers, but causes writers
	to incur increasingly large overheads as the number of threads
	increases.

	Some other ways of handling very small critical sections are
	described in Section~\ref{sec:defer:Read-Copy Update (RCU)}.
} \QuickQuizEnd

\QuickQuiz{}
	In
	Figure~\ref{fig:intro:Reader-Writer Lock Scalability},
	all of the traces other than the 100M trace deviate gently
	from the ideal line.
	In contrast, the 100M trace breaks sharply from the ideal
	line at 64 CPUs.
	In addition, the spacing between the 100M trace and the 10M
	trace is much smaller than that between the 10M trace and the
	1M trace.
	Why does the 100M trace behave so much differently than the
	other traces?
\QuickQuizAnswer{
	Your first clue is that 64 CPUs is exactly half of the 128
	CPUs on the machine.
	The difference is an artifact of hardware threading.
	This system has 64 cores with two hardware threads per core.
	As long as fewer than 64 threads are running, each can run
	in its own core.
	But as soon as there are more than 64 threads, some of the threads
	must share cores.
	Because the pair of threads in any given core share some hardware
	resources, the throughput of two threads sharing a core is not
	quite as high as that of two threads each in their own core.
	So the performance of the 100M trace is limited not by the
	reader-writer lock, but rather by the sharing of hardware resources
	between hardware threads in a single core.

	This can also be seen in the 10M trace, which deviates gently from
	the ideal line up to 64 threads, then breaks sharply down, parallel
	to the 100M trace.
	Up to 64 threads, the 10M trace is limited primarily by reader-writer
	lock scalability, and beyond that, also by sharing of hardware
	resources between hardware threads in a single core.
} \QuickQuizEnd

\QuickQuiz{}
	Power-5 is several years old, and new hardware should
	be faster.
	So why should anyone worry about reader-writer locks being slow?
\QuickQuizAnswer{
	In general, newer hardware is improving.
	However, it will need to improve more than two orders of magnitude
	to permit reader-writer lock to achieve ideal performance on
	128 CPUs.
	Worse yet, the greater the number of CPUs, the larger the
	required performance improvement.
	The performance problems of reader-writer locking are therefore
	very likely to be with us for quite some time to come.
} \QuickQuizEnd

Despite these limitations, reader-writer locking is quite useful in many
cases, for example when the readers must do high-latency file or network I/O.
There are alternatives, some of which will be presented in
Chapters~\ref{chp:Counting} and \ref{chp:Deferred Processing}.

\section{Atomic Operations}
\label{sec:toolsoftrade:Atomic Operations}

Given that
Figure~\ref{fig:intro:Reader-Writer Lock Scalability}
shows that the overhead of reader-writer locking is most severe for the
smallest critical sections, it would be nice to have some other way
to protect the tiniest of critical sections.
One such way are atomic operations.
We have seen one atomic operations already, in the form of the
\co{__sync_fetch_and_add()} primitive on line~18 of
Figure~\ref{fig:toolsoftrade:Measuring Reader-Writer Lock Scalability}.
This primitive atomically adds the value of its second argument to
the value referenced by its first argument, returning the old value
(which was ignored in this case).
If a pair of threads concurrently execute \co{__sync_fetch_and_add()} on
the same variable, the resulting value of the variable will include
the result of both additions.

The {\sf gcc} compiler offers a number of additional atomic operations,
including \co{__sync_fetch_and_sub()},
\co{__sync_fetch_and_or()},
\co{__sync_fetch_and_and()},
\co{__sync_fetch_and_xor()}, and
\co{__sync_fetch_and_nand()}, all of which return the old value.
If you instead need the new value, you can instead use the
\co{__sync_add_and_fetch()},
\co{__sync_sub_and_fetch()},
\co{__sync_or_and_fetch()},
\co{__sync_and_and_fetch()},
\co{__sync_xor_and_fetch()}, and
\co{__sync_nand_and_fetch()} primitives.

\QuickQuiz{}
	Is it really necessary to have both sets of primitives?
\QuickQuizAnswer{
	Strictly speaking, no.
	One could implement any member of the second set using the
	corresponding member of the first set.
	For example, one could implement \co{__sync_nand_and_fetch()}
	in terms of \co{__sync_fetch_and_nand()} as follows:

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\scriptsize
\begin{verbatim}
tmp = v;
ret = __sync_fetch_and_nand(p, tmp);
ret = ~ret & tmp;
\end{verbatim}
\end{minipage}
\vspace{5pt}

	It is similarly possible to implement \co{__sync_fetch_and_add()},
	\co{__sync_fetch_and_sub()}, and \co{__sync_fetch_and_xor()}
	in terms of their post-value counterparts.

	However, the alternative forms can be quite convenient, both
	for the programmer and for the compiler/library implementor.
} \QuickQuizEnd

The classic compare-and-swap operation is provided by a pair of
primitives, \co{__sync_bool_compare_and_swap()} and
\co{__sync_val_compare_and_swap()}.
Both of these primitive atomically update a location to a new value,
but only if its prior value was equal to the specified old value.
The first variant returns 1 if the operation succeeded and 0 if it
failed, for example, if the prior value was not equal to the specified
old value.
The second variant returns the prior value of the location, which, if
equal to the specified old value, indicates that the operation succeeded.
Either of the compare-and-swap operation is ``universal'' in the sense
that any atomic operation on a single location can be implemented in
terms of compare-and-swap, though the earlier operations are often
more efficient where they apply.
The compare-and-swap operation is also capable of serving as the basis
for a wider set of atomic operations, though the more elaborate of
these often suffer from complexity, scalability, and performance
problems~\cite{MauriceHerlihy90a}.

The \co{__sync_synchronize()} primitive issues a ``memory barrier'',
which constrains both the compiler's and the CPU's ability to reorder
operations, as discussed in Section~\ref{sec:advsync:Memory Barriers}.
In some cases, it is sufficient to constrain the compiler's ability
to reorder operations, while allowing the CPU free rein, in which
case the \co{barrier()} primitive may be used, as it in fact was
on line~28 of
Figure~\ref{fig:toolsoftrade:Measuring Reader-Writer Lock Scalability}.
In some cases, it is only necessary to ensure that the compiler
avoids optimizing away a given memory access, in which case the
\co{ACCESS_ONCE()} primitive may be used, as it was on line~17 of
Figure~\ref{fig:toolsoftrade:Demonstration of Exclusive Locks}.
These last two primitives are not provided directly by gcc,
but may be implemented straightforwardly as follows:

\vspace{5pt}
{
\scriptsize
\begin{verbatim}
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
#define barrier() __asm__ __volatile__("": : :"memory")
\end{verbatim}
}
\vspace{5pt}

\QuickQuiz{}
	Given that these atomic operations will often be able to
	generate single atomic instructions that are directly
	supported by the underlying instruction set, shouldn't
	they be the fastest possible way to get things done?
\QuickQuizAnswer{
	Unfortunately, no.
	See Chapter~\ref{chp:Counting} for some stark counterexamples.
} \QuickQuizEnd

\section{Linux-Kernel Equivalents to POSIX Operations}
\label{sec:toolsoftrade:Linux-Kernel Equivalents to POSIX Operations}

\begin{table*}
\scriptsize
\begin{center}
\begin{tabular}{l|l|l}
	Category & POSIX & Linux Kernel \\
	\hline
	\hline
	Thread Management
		& \co{pthread_t}
			& \co{struct task_struct} \\
	\cline{2-3}
		& \co{pthread_create()}
			& \co{kthread_create} \\
	\cline{2-3}
		& \co{pthread_exit()}
			& \co{kthread_should_stop()}~~~~~(rough) \\
	\cline{2-3}
		& \co{pthread_join()}
			& \co{kthread_stop()}~~~(rough) \\
	\cline{2-3}
		& \co{poll(NULL, 0, 5)}
			& \co{schedule_timeout_interruptible()} ~~~ \\
	\hline
	\hline
	POSIX Locking
		& \co{pthread_mutex_t}
			& \co{spinlock_t}~~~(rough) \\
		&	& \co{struct mutex} \\
	\cline{2-3}
		& \co{PTHREAD_MUTEX_INITIALIZER}
			& \co{DEFINE_SPINLOCK()} \\
		&	& \co{DEFINE_MUTEX()} \\
	\cline{2-3}
		& \co{pthread_mutex_lock()}
			& \co{spin_lock()}~~~(and friends) \\
		&	& \co{mutex_lock()}~~~(and friends) \\
	\cline{2-3}
		& \co{pthread_mutex_unlock()}
			& \co{spin_unlock()}~~~(and friends) \\
		&	& \co{mutex_unlock()} \\
	\hline
	\hline
	POSIX Reader-Writer
		& \co{pthread_rwlock_t}
			& \co{rwlock_t}~~~(rough) \\
	Locking	&	& \co{struct rw_semaphore} \\
	\cline{2-3}
		& \co{PTHREAD_RWLOCK_INITIALIZER}
			& \co{DEFINE_RWLOCK()} \\
		&	& \co{DECLARE_RWSEM()} \\
	\cline{2-3}
		& \co{pthread_rwlock_rdlock()}
			& \co{read_lock()}~~~(and friends) \\
		&	& \co{down_read()}~~~(and friends) \\
	\cline{2-3}
		& \co{pthread_rwlock_unlock()}
			& \co{read_unlock()}~~~(and friends) \\
		&	& \co{up_read()} \\
	\cline{2-3}
		& \co{pthread_rwlock_wrlock()}
			& \co{write_lock()}~~~(and friends) \\
		&	& \co{down_write()}~~~(and friends) \\
	\cline{2-3}
		& \co{pthread_rwlock_unlock()}
			& \co{write_unlock()}~~~(and friends) \\
		&	& \co{up_write()} \\
	\hline
	\hline
	Atomic Operations
		& C Scalar Types
			& \co{atomic_t} \\
		&	& \co{atomic64_t} \\
	\cline{2-3}
		& \co{__sync_fetch_and_add()}
			& \co{atomic_add_return()} \\
		&	& \co{atomic64_add_return()} \\
	\cline{2-3}
		& \co{__sync_fetch_and_sub()}
			& \co{atomic_sub_return()} \\
		&	& \co{atomic64_sub_return()} \\
	\cline{2-3}
		& \co{__sync_val_compare_and_swap()} ~~~~~~~~~~
			& \co{cmpxchg()} \\
	\cline{2-3}
		& \co{__sync_lock_test_and_set()}
			& \co{xchg()}~~~(rough) \\
	\cline{2-3}
		& \co{__sync_synchronize()}
			& \co{smp_mb()} \\
\end{tabular}
\end{center}
\caption{Mapping from POSIX to Linux-Kernel Primitives}
\label{tab:advsync:Mapping from POSIX to Linux-Kernel Primitives}
\end{table*}

Unfortunately, threading operations, locking primitives, and atomic
operations were in reasonably wide use long before the various standards
committees got around to them.
As a result, there is considerable variation in how these operations
are supported.
It is still quite common to find these operations implemented in
assembly language, either for historical reasons or to obtain better
performance in specialized circumstances.
For example, the gcc \co{__sync_} family of primitives all
provide memory-ordering semantics, motivating many developers to
create their own implementations for situations where the memory
ordering semantics are not required.

Therefore,
Table~\ref{tab:advsync:Mapping from POSIX to Linux-Kernel Primitives} on
page~\pageref{tab:advsync:Mapping from POSIX to Linux-Kernel Primitives}
provides a rough mapping between the POSIX and
gcc primitives to those used in the Linux kernel.
Exact mappings are not always available, for example, the Linux kernel
has a wide variety of locking primitives, while gcc has a number
of atomic operations that are not directly available in the Linux kernel.
Of course, on the one hand, user-level code does not need the Linux
kernel's wide array of locking primitives, while on the other hand,
gcc's atomic operations can be emulated reasonably straightforwardly
using \co{cmpxchg()}.

\QuickQuiz{}
	What happened to the Linux-kernel equivalents to \co{fork()}
	and \co{wait()}?
\QuickQuizAnswer{
	They don't really exist.
	All tasks executing within the Linux kernel share memory,
	at least unless you want to do a huge amount of memory-mapping
	work by hand.
} \QuickQuizEnd

\section{The Right Tool for the Job: How to Choose?}
\label{sec:toolsoftrade:The Right Tool for the Job: How to Choose?}

As a rough rule of thumb, use the simplest tool that will get the job done.
If you can, simply program sequentially.
If that is insufficient, try using a shell script to mediate parallelism.
If the resulting shell-script \co{fork()}/\co{exec()} overhead
(about 480 microseconds for a minimal C program on an Intel Core Duo
laptop) is too
large, try using the C-language \co{fork()} and \co{wait()} primitives.
If the overhead of these primitives (about 80 microseconds for a minimal
child process) is still too large, then you
might need to use the POSIX threading primitives, choosing the appropriate
locking and/or atomic-operation primitives.
If the overhead of the POSIX threading primitives (typically sub-microsecond)
is too great, then the primitives introduced in
Chapter~\ref{chp:Deferred Processing} may be required.
Always remember that inter-process communication and message-passing
can be good alternatives to shared-memory multithreaded execution.

\QuickQuiz{}
	Wouldn't the shell normally use \co{vfork()} rather than
	\co{fork()}?
\QuickQuizAnswer{
	It might well do that, however, checking is left as an exercise
	for the reader.
	But in the meantime, I hope that we can agree that \co{vfork()}
	is a variant of \co{fork()}, so that we can use \co{fork()}
	as a generic term covering both.
} \QuickQuizEnd

Of course, the actual overheads will depend not only on your hardware,
but most critically on the manner in which you use the primitives.
Therefore, it is necessary to make the right design choices as well as
the correct choice of individual primitives,
as is discussed at length in subsequent chapters.
