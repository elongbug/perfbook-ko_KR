% formal/formal.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\QuickQuizChapter{chp:Formal Verification}{Formal Verification}
%
\Epigraph{Beware of bugs in the above code; I have only proved it correct,
	  not tried it.}{\emph{Donald Knuth}}

\OriginallyPublished{Chapter}{chp:Formal Verification}{Formal Verification}{Linux Weekly News}{PaulEMcKenney2007QRCUspin,PaulEMcKenney2008dynticksRCU,PaulEMcKenney2011ppcmem}

병렬 알고리즘들은 작성하기 어렵고, 디버깅 하기는 그보다도 더 어렵습니다.
테스트는 필수이긴 하지만 race condition 은 극단적으로 낮은 발현 확률을 가질 수
있기 때문에, 그것만으로는 충분하지 않습니다.
올바름의 증명은 가치있을 수 있습니다만, 그것도 결국은 원래의 알고리즘이
그렇듯이 사람에 의한 에러에 취약합니다.
또한, 올바름의 증명은 가정 자체에 있는 에러, 요구사항의 한계, 아래에 있는
소프트웨어나 하드웨어 기능들에 대한 잘못된 이해, 또는 증명을 할 생각을 하지
못한 에러들은 찾지 못할 것입니다.
이는 정형적 방법들은 테스트를 대체할 수는 없음을 의미합니다만, 정형적 방법들은
검증 도구상자의 또하나의 가치있는 한가지 이상도 이하도 아닙니다.
\iffalse

Parallel algorithms can be hard to write, and even harder to debug.
Testing, though essential, is insufficient, as fatal race conditions
can have extremely low probabilities of occurrence.
Proofs of correctness can be valuable, but in the end are just as
prone to human error as is the original algorithm.
In addition, a proof of correctness cannot be expected to find errors
in your assumptions, shortcomings in the requirements,
misunderstandings of the underlying software or hardware primitives,
or errors that you did not think to construct a proof for.
This means that formal methods can never replace testing, however,
formal methods are nevertheless a valuable addition to your validation toolbox.
\fi

어떻게든 모든 race condition 들을 찾아낼 수 있는 도구를 갖는다면 매우 도움이
될겁니다.
그런 도구들이 여럿 존재하는데, 예를 들어서
Section~\ref{sec:formal:General-Purpose State-Space Search}
는 범용 상태 공간 탐색 도구들인 Promela 와 Spin 을 소개하고,
Section~\ref{sec:formal:Special-Purpose State-Space Search}
는 비슷하게 특수 목적의 ppcmem 와 cppmem 도구들을 소개하며,
Section~\ref{sec:formal:Axiomatic Approaches}
는 자명한 방법의 예를 보고,
Section~\ref{sec:formal:SAT Solvers}
에서는 간단히 SAT solver 들을 살펴보며, 마지막으로
Section~\ref{sec:formal:Stateless Model Checkers}
에서는 stateless model checker 에 대한 간단한 개괄을 제공하고,
Section~\ref{sec:formal:Summary}
에서는 병렬 알고리즘을 검증하기 위해 정형 검증을 사용하는 것에 대해 요약합니다.
\iffalse

It would be very helpful to have a tool that could somehow locate
all race conditions.
A number of such tools exist, for example,
Section~\ref{sec:formal:State-Space Search} provides an
introduction to the general-purpose state-space search tools Promela and Spin,
Section~\ref{sec:formal:Special-Purpose State-Space Search}
similarly introduces the special-purpose ppcmem and cppmem tools,
Section~\ref{sec:formal:Axiomatic Approaches}
looks at an example axiomatic approach,
Section~\ref{sec:formal:SAT Solvers}
briefly overviews SAT solvers,
Section~\ref{sec:formal:Stateless Model Checkers}
briefly overviews stateless model checkers,
and finally
Section~\ref{sec:formal:Summary}
sums up use of formal-verification tools for verifying parallel algorithms.
\fi

\input{formal/spinhint}
\input{formal/dyntickrcu}
\input{formal/ppcmem}
\input{formal/axiomatic}
\input{formal/sat}
\input{formal/stateless}

\section{Summary}
\label{sec:formal:Summary}
%
\epigraph{Western thought has focused on True-False;
	  it is high time to shift to Robust-Fragile.}
	 {\emph{summarized from Nassim Nicholas Taleb}}
% Full quote:
% Since Plato, Western thought and the theory of knowledge has focused on
% the notions of True-False; as commendable as that was, it is high time
% to shift the concern to Robust-Fragile, and social epistemology to the
% more serious problem of Sucker-Nonsucker.

이 챕터에서 설명한 형식적 검증 테크닉은 작은 병렬 알고리즘들을 검증하는데에는
매우 강력한 도구입니다만, 당신의 도구상자에 그것들만 있어선 안됩니다.
지난 수십년간의 형식적 검증에 대한 집중에도 불구하고, 테스트는 커다란 병렬
소프트웨어 시스템을 위한 대표적 검증 도구로
남아있습니다~\cite{JonathanCorbet2006lockdep,DaveJones2011Trinity,PaulEMcKenney2016Formal}.
\iffalse

The formal-verification techniques described in this chapter
are very powerful tools for validating small
parallel algorithms, but they should not be the only tools in your toolbox.
Despite decades of focus on formal verification, testing remains the
validation workhorse for large parallel software
systems~\cite{JonathanCorbet2006lockdep,DaveJones2011Trinity,PaulEMcKenney2016Formal}.
\fi

물론 이는 항상 그렇지는 않을 수도 있는 것이 사실입니다.
이를 확실히 하기 위해, 2017년 기준으로 200억개가 넘는 리눅스 커널의
인스턴스가 존재한다고 추정된다는 점을 생각해 보세요.
리눅스 커널에 평균적으로 백만년의 수행 중 한번 발생할 수 있는 버그가 있다고
생각해 봅시다.
앞의 챕터의 마지막에서 설명했다시피, 이 버그는 이 전체 설치된 환경에서
\emph{하루에} 50 번씩 나타날 겁니다.
하지만 대부분의 형식적 검증 테크닉은 매우 작은 코드에 대해서만 사용될 수 있다는
사실도 여전합니다.
그런 상황에서 동시적 코드를 짜는 사람들은 뭘 해야 할까요?
\iffalse

It is nevertheless quite possible that this will not always be the case.
To see this, consider that there is estimated to be more than twenty
billion instances of the Linux kernel as of 2017.
Suppose that the Linux kernel has a bug that manifests on average every million
years of runtime.
As noted at the end of the preceding chapter, this bug will be appearing
more than 50 times \emph{per day} across the installed base.
But the fact remains that most formal validation techniques can be used
only on very small code bases.
So what is a concurrency coder to do?
\fi

한가지 방법은 첫번째 버그, 첫번째로 관련있는 버그, 마지막으로 관련있는 버그,
그리고 마지막 버그를 찾는 것에 대해 생각해 보는 겁니다.

첫번째 버그는 코드 검사난 컴파일러의 조사를 통해 발견되어집니다.
최신의 컴파일러에 의해 제공되는, 지속적으로 세련되어지는 진단 기능이 가벼운
형태의 형식적 검증으로 여겨질 수도 있긴 하지만, 그것들을 그런 용어로 부르는건
흔하지 않습니다.
이는 부분적으로는 ``내가 그걸 사용하고 있다면, 그것은 형식적 검증일 수 없다''
라고 말하는, 이상한 실무자의 선입견 때문이기도 하고, 컴파일러 진단기능과 검증에
대한 연구 사이의 서로 다른 철학 때문이기도 합니다.
\iffalse

One approach is to think in terms of finding the first bug, the first
relevant bug, the last relevant bug, and the last bug.

The first bug is normally found via inspection or compiler diagnostics.
Although the increasingly sophisticated diagnostics provided by modern
compilers might be considered to be a lightweight sort of formal
verification, it is not common to think of them in those terms.
This is in part due to an odd practitioner prejudice which says
``If I am using it, it cannot be formal verification'' on the one
hand, and the large difference in sophistication between compiler
diagnostics and verification research on the other.
\fi

첫번째로 관련있는 버그는 코드 검사나 컴파일러 진단 기능으로 발견되어질 수도
있지만, 이 두 단계가 오타와 거짓 양성 반응만을 찾게 되는 것도 흔하지 않은 일은
아닙니다.
어떤 방식으로든, 실제 제품에서마주하게 될 버그들인 관련된 많은 버그들은 많은
경우 테스트를 통해 발견되어질 겁니다.

테스트가 예측된 사용 예에서 만들어졌든 진짜 사용 예에서 만들어졌든, 마지막
연관된 버그가 테스트를 통해 발견되어지는 것은 흔치 않은 일이 아닙니다.
이 상황은 형식적 검증에 대한 완전한 거부의 동기가 될 수도 있겠습니다만,
관계없는 버그들은 black-hat 공격의 덕에 최소한의 알맞은 사이즈에 있어서는
갑자기 관계있는 것이 되어버리는 안좋은 습관을 가지고 있습니다.
전체 소프트웨어 가운데 그 분포도를 지속적으로 높여가는 보안에 관련된
소프트웨어에 있어서는 마지막 버그를 찾아내고 고쳐내려는 강한 동기가 존재할 수
있습니다.
테스트는 마지막 버그를 찾아내는 것은 명백히 불가능하므로 형식적 검증에게만
가능한 역할이 존재합니다.
형식적 검증이 그 안으로 적용될 수 있다고만 하면 그런 역할이 있다는
이야기입니다.
이 챕터에서 보였듯이, 현재의 형식적 검증 시스템들은 상당히 제한적입니다.
\iffalse

Although the first relevant bug might be located via inspection or
compiler diagnostics, it is not unusual for these two steps to find
only typos and false positives.
Either way, the bulk of the relevant bugs, that is, those bugs that
might actually be encountered in production, will often be found via testing.

When testing is driven by anticipated or real use cases, it is not
uncommon for the last relevant bug to be located by testing.
This situation might motivate a complete rejection of formal verification,
however, irrelevant bugs have an annoying habit of suddenly becoming relevant
at the least convenient moment possible, courtesy of black-hat attacks.
For security-critical software, which appears to be a continually
increasing fraction of the total, there can thus be strong motivation
to find and fix the last bug.
Testing is demonstrably unable to find the last bug, so there is a
possible role for formal verification.
That is, there is such a role if and only if formal verification
proves capable of growing into it.
As this chapter has shown, current formal verification systems are
extremely limited.
\fi

\QuickQuiz{}
	하지만 충분히 낮은 단계의 소프트웨어는 모든 의도와 목적에 있어
	블랙햇으로부터의 공격에 내성이 있지 않나요?
	\iffalse

	But shouldn't sufficiently low-level software be for all intents
	and purposes immune to being exploited by black hats?
	\fi
\QuickQuizAnswer{
	불행히도, 그렇지 않습니다.

	한번은, Paul E. McKenney 는 리눅스 커널 RCU 가 그런 공격에 대해 내성이
	있다고 생각했는데, Row Hanner 의 발전은 그렇지 않음을 보였습니다.
	무엇보다도, 그 블랙햇들이 시스템의 DRAM 을 건들 수 있다면, RCU 를 건들
	수 있습니다.
	\iffalse

	Unfortunately, no.

	At one time, Paul E. McKenney felt that Linux-kernel RCU
	was immune to such exploits, but the advent of Row Hammer
	showed him otherwise.
	After all, if the black hats can hit the system's DRAM,
	they can hit RCU.
	\fi
} \QuickQuizEnd

또다른 방법은 형식적 검증이 많은 경우 테스트보다 적용하기가 어렵다는 점을
고려하는 겁니다.
물론 이는 문화적인 측면에서의 이야기일 수 있고, 형식적 검증이 더 많은
사람들에게 친숙해 질수록 더 쉽게 전파될 것이라는 희망을 가져볼 수도 있습니다.
그렇다고는 하나, 매우 간단한 테스트 사용은 임의의 거대한 소프트웨어 시스템에서
심각한 버그들을 찾아낼 수 있습니다.
반면에, 형식적 검증을 적용하기 위해 필요한 노력은 시스템의 크기가 증가할수록
극적으로 증가합니다.

전 20년이 넘도록 형식적 검증을 형식적 검증이 효력을 발휘하는 곳에서 필요할
때에만 사용했을 뿐인데, 설계 시점에서의, 무엇보다 중요한 소프트웨어 구성물의
작고 복잡한 부분의 검증에 있어 그랬습니다.
무엇보다 중요하지만 더 커다란 소프트웨어 구성물들은 물론 테스트로 검증했습니다.
\iffalse

Another approach is to consider that
formal verification is often much harder to use than is testing.
This is of course in part a cultural statement, and there is every reason
to hope that formal verification will be perceived to be easier as more
people become familiar with it.
That said, very simple test harnesses can find significant bugs in arbitrarily
large software systems.
In contrast, the effort required to apply formal verification seems to
increase dramatically as the system size increases.

I have nevertheless made occasional use of formal verification
for more than 20 years, playing to formal verification's strengths,
namely design-time verification of small complex portions of the overarching
software construct.
The larger overarching software construct is of course validated by testing.
\fi

\QuickQuiz{}
	L4 마이크로커널의 전체 검증을 생각해 보면, 이런 형식적 검증에 대한
	제한적인 시각은 약간 시대에 뒤쳐진 것 아닌가요?
	\iffalse

	In light of the full verification of the L4 microkernel,
	isn't this limited view of formal verification just a little
	bit obsolete?
	\fi
\QuickQuizAnswer{
	안타깝지만, 그렇지 않습니다.

	L4 마이크로커널의 첫번째 전체 검증은 많은 수의 Ph.D.~학생들 학생마다
	매우 느린 속도로 진행한, 손으로 하는 코드 검증으로 이루어진
	역작이었습니다.
	이런 수준의 노력은 대부분의 소프트웨어 프로젝트들에는 적용될 수가
	없는데, 변화의 비율이 너무 거대하기 때문입니다.
	더 나아가서, 비록 L4 마이크로커널이 형식적 검증의 시점에서 보기에는
	커다란 소프트웨어 작품이긴 합니다만, LLVM, \GCC, 리눅스 커널, Hadoop,
	MongoDB, 그 외의 커다란 많은 것들 등과 같은 많은 수의 프로젝트들에
	비교하면 매우 작은 것입니다.
	또한, 이 검증은 일부 연구자들이 인정했듯이, 한계를 가지고 있습니다:
	\url{https://wiki.sel4.systems/FrequentlyAskedQuestions#Does_seL4_have_zero_bugs.3F}.
	\iffalse

	Unfortunately, no.

	The first full verification of the L4 microkernel was a tour de force,
	with a large number of Ph.D.~students hand-verifying code at a
	very slow per-student rate.
	This level of effort could not be applied to most software projects
	because the rate of change is just too great.
	Furthermore, although the L4 microkernel is a large software
	artifact from the viewpoint of formal verification, it is tiny
	compared to a great number of projects, including LLVM,
	\GCC, the Linux kernel, Hadoop, MongoDB, and a great many others.
	In addition, this verification did have limits, as the researchers
	freely admit, to their credit:
	\url{https://wiki.sel4.systems/FrequentlyAskedQuestions#Does_seL4_have_zero_bugs.3F}.
	\fi

	형식적 검증이 마침내 더 최근의, 커다란 수준의 자동화에 관련된 L4 검증을
	포함해서 어떤 전망을 내놓기 시작하고 있기는 하지만, 전망 가능한 미래에
	테스트를 완전히 대체할 기회는 현재로써는 보이지 않습니다.
	그리고 이 점에 있어서 제가 틀렸다고 증명되면 전 좋아할 겁니다만, 그런
	증명은 실제 소프트웨어를 검증하는 실제 도구를 통한 형태여야 하지,
	자극적인 미사여구를 통한 형태가 되어선 안될 겁니다.

	언젠가는 형식적 검증이 지금은 회귀 검증으로 알려진 영역을 포함해 많은
	검증에 사용될 수도 있을겁니다.
	Section~\ref{sec:future:Formal Regression Testing?} 에서는 이 가능성이
	현실이 되기 위해 무엇이 필요한지 알아봅니다.

	\iffalse

	Although formal verification is finally starting to show some
	promise, including more-recent L4 verifications involving greater
	levels of automation, it currently has no chance of completely
	displacing testing in the foreseeable future.
	And although I would dearly love to be proven wrong on this point,
	please note that such a proof will be in the form of a real tool
	that verifies real software, not in the form of a large body of
	rousing rhetoric.

	Perhaps someday formal verification will be used heavily for
	validation, including for what is now known as regression testing.
	Section~\ref{sec:future:Formal Regression Testing?} looks at
	what would be required to make this possibility a reality.
	\fi
} \QuickQuizEnd

마지막 방법은 다음의 두개의 정의와 그것들이 암시하는 결론에 대해서 고려해 보는
것입니다:
\iffalse

One final approach is to consider the following two definitions and the
consequence that they imply:
\fi

\begin{description}[itemsep=0pt,labelindent=1em]
\item[정의:]	버그가 없는 프로그램들은 사소한 프로그램들이다.
\item[정의:]	신뢰할 수 있는 프로그램은 알려진 버그가 없다.
\item[결론:]	모든 사소하지 않으며 신뢰할 수 있는 프로그램에는 최소 하나의
		아직 알려지지 않은 버그가 있다.
\iffalse

\item[Definition:]	Bug-free programs are trivial programs.
\item[Definition:]	Reliable programs have no known bugs.
\item[Consequence:]	Any non-trivial reliable program contains at least
			one as-yet-unknown bug.
\fi
\end{description}

이 시점에서 보면, 모든 검증 영역에서의 진보는 두가지 영향을 가질 수밖에 없을
겁니다: (1)~사소한 프로그램들의 갯수의 증가 또는 (2)~신뢰할 수 있는
프로그램들의 수의 감소.
물론, 인류의 멀티코어 시스템과 소프트웨어에 대한 증가하는 의존도는 사소한
프로그램들의 갯수의 가파른 증가에 대한 커다란 동기가 될겁니다!
\iffalse

From this viewpoint, any advances in validation and verification can
have but two effects: (1)~An increase in the number of trivial programs or
(2)~A decrease in the number of reliable programs.
Of course, the human race's increasing reliance on multicore systems and
software provides extreme motivation for a very sharp increase in the
number of trivial programs!
\fi

하지만, 만약 여러분의 코드가 너무 복잡해서 여러분이 형식적 검증 도구에 너무
과하게 의존하고 있다는 점을 알게 된다면, 여러분은 여러분의 설계를 다시 세심하게
생각해 봐야 하는데, 당신의 형식적 검증 도구들이 당신의 코드가 특정 목적 언어로
손으로 변환해야 하게 되는 상황이라면 특히 그렇습니다.
예를 들어,
Section~\ref{sec:formal:Promela Parable: dynticks and Preemptible RCU}
에서 보인 preemption 가능한 RCU 의 복잡한 dynticks 인터페이스 구현에 있어서는
Section~\ref{sec:formal:Simplicity Avoids Formal Verification} 에서
이야기한대로 훨씬 간단한 대안적 구현이 존재함이 드러났습니다.
다른게 모두 동일하다면, 복잡한 구현을 위한 올바름의 증명보다 간단한 구현이 훨씬
낫습니다!

그리고 형식적 검증 테크닉들과 시스템들에 대한 열려있는 도전은 이 요약 내용이
틀리다고 증명하는 것입니다!
이 일을 돕기 위해, Verification Challenge~6 가 사용
가능합니다~\cite{PaulEMcKenney2017VerificationChallenge6}.
한번 보세요!!!
\iffalse

However, if your code is so complex that you find yourself
relying too heavily on formal-verification
tools, you should carefully rethink your design, especially if your
formal-verification tools require your code to be hand-translated
to a special-purpose language.
For example, a complex implementation of the dynticks interface for
preemptible RCU that was presented in
Section~\ref{sec:formal:Promela Parable: dynticks and Preemptible RCU}
turned out to
have a much simpler alternative implementation, as discussed in
Section~\ref{sec:formal:Simplicity Avoids Formal Verification}.
All else being equal, a simpler implementation is much better than
a proof of correctness for a complex implementation!

And the open challenge to those working on formal verification techniques
and systems is to prove this summary wrong!
To assist in this task, Verification Challenge~6 is now
available~\cite{PaulEMcKenney2017VerificationChallenge6}.
Have at it!!!
\fi
