% advsync/advsync.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\QuickQuizChapter{sec:advsync:Advanced Synchronization}{Advanced Synchronization}{qqzadvsync}
%
\Epigraph{If a little knowledge is a dangerous thing, just think what
	  you could do with a lot of knowledge!}{\emph{Unknown}}

이 챕터는 lockless 알고리즘과 병렬 리얼타임 시스템에서 사용되는 동기화 기법들을
다룹니다.

Lockless 알고리즘이 극단적 요구사항을 마주할 때에는 상당히 도움이 되지만,
만병통치약은 아닙니다.
예를 들어, \cref{chp:Counting} 의 끝에서 이야기 되었듯, lockless 알고리즘을
생각하기 전에 여러분은 충분히 파티셔닝, 배칭, 그리고 잘 테스트되고 패키지 된
완화된 API 들을
(\cref{chp:Data Ownership,chp:Deferred Processing} 를 참고하세요)
사용해야 합니다.

\iffalse

This chapter covers synchronization techniques used for lockless
algorithms and parallel real-time systems.

Although lockless algorithms can be quite helpful when faced with
extreme requirements, they are no panacea.
For example, as noted at the end of \cref{chp:Counting},
you should thoroughly apply partitioning, batching, and
well-tested packaged weak APIs
(see \cref{chp:Data Ownership,chp:Deferred Processing})
before even thinking about lockless algorithms.

\fi

하지만 그걸 다 해본 후에도 여러분은 이 챕터에 설명되는 고급 기법들을 필요로
하게 될 수도 있습니다.
그런 경우,
\cref{sec:advsync:Avoiding Locks}
는 락을 회피하기 위해 그동안 사용되어온 기법들을 요약하고
\cref{sec:advsync:Non-Blocking Synchronization}
는 non-blocking 동기화에 대한 간단한 개론을 제공합니다.
메모리 순서 규칙은 또한 매우 중요합니다만 그건 자신만의
\lcnamecref{chp:Advanced Synchronization: Memory Ordering}, 즉
\cref{chp:Advanced Synchronization: Memory Ordering} 를 갖습니다.

고급 동기화의 두번째 형태는 병렬 리얼타임 컴퓨팅에서 필요한 더 강한 진행 보장을
제공하는데,
\cref{sec:advsync:Parallel Real-Time Computing} 의 주제입니다.

\iffalse

But after doing all that, you still might find yourself needing the
advanced techniques described in this chapter.
To that end,
\cref{sec:advsync:Avoiding Locks}
summarizes techniques used thus far for avoiding locks and
\cref{sec:advsync:Non-Blocking Synchronization}
gives a brief overview of non-blocking synchronization.
Memory ordering is also quite important, but it warrants its own
\lcnamecref{chp:Advanced Synchronization: Memory Ordering}, namely
\cref{chp:Advanced Synchronization: Memory Ordering}.

The second form of advanced synchronization provides the stronger
forward-progress guarantees needed for parallel real-time computing,
which is the topic of
\cref{sec:advsync:Parallel Real-Time Computing}.

\fi

\section{Avoiding Locks}
\label{sec:advsync:Avoiding Locks}
%
\epigraph{We are confronted with insurmountable opportunities.}
	 {\emph{Walt Kelly}}

락킹이 제품단계의 병렬성을 위한 일등공신이지만, 많은 상황에서 성능, 확장성,
그리고 리얼타임 응답이 모두 lockless 기법을 사용해 크게 개선될 수 있습니다.
그런 lockless 기법의 특히 인상적인 예는 
\cref{sec:count:Statistical Counters} 에서 설명한 통계적 카운터로 락만이 아니라
read-modify-write 어토믹 오퍼레이션, 메모리 배리어, 심지어 카운터 값 증가를
위한 캐쉬 미스까지 제거했습니다.
우리가 다룬 다른 예제들은 다음을 포함합니다:

\iffalse

Although locking is the workhorse of parallelism in production, in
many situations performance, scalability, and real-time response can
all be greatly improved through use of lockless techniques.
A particularly impressive example of such a lockless technique is
the statistical counters described in
\cref{sec:count:Statistical Counters},
which avoids not only locks, but also atomic operations, memory barriers,
and even cache misses for counter increments.
Other examples we have covered include:

\fi

\begin{enumerate}
\item	\Cref{chp:Counting} 의 많은 다른 카운팅 알고리즘의 빠른 수행경로들.
\item	\Cref{sec:SMPdesign:Resource Allocator Caches} 의 자원 할당 캐쉬의 빠른
	수행경로.
\item	\Cref{sec:SMPdesign:Beyond Partitioning} 의 미로 풀이기.
\item	\Cref{chp:Data Ownership} 의 데이터 소유권 기법.
\item	\Cref{chp:Deferred Processing} 의 레퍼런스 카운팅, 해저드 포인터,
	그리고 RCU 기법들.
\item	\Cref{chp:Data Structures} 의 탐색 코드경로들.
\item	\Cref{chp:Putting It All Together} 의 많은 기법들.

\iffalse

\item	The fastpaths through a number of other counting algorithms
	in \cref{chp:Counting}.
\item	The fastpath through resource allocator caches in
	\cref{sec:SMPdesign:Resource Allocator Caches}.
\item	The maze solver in \cref{sec:SMPdesign:Beyond Partitioning}.
\item	The data-ownership techniques in \cref{chp:Data Ownership}.
\item	The reference-counting, hazard-pointer, and RCU techniques
	in \cref{chp:Deferred Processing}.
\item	The lookup code paths in \cref{chp:Data Structures}.
\item	Many of the techniques in \cref{chp:Putting It All Together}.

\fi

\end{enumerate}

요약하자면, lockless 기법들은 상당히 유용하며 널리 사용됩니다.
그러나, lockless 기법은 예를 들면 \co{inc_count()}, \co{memblock_alloc()},
\co{rcu_read_lock()} 등의 잘 정의된 API 뒤에 숨겨지는게 가장 좋습니다.
그 이유는 lockless 기법의 훈련되지 않은 사용은 처리하기 어려운 버그를 만드는
좋은 방법이기 때문입니다.
그런 버그를 찾고 고치는게 애초에 나오지 않게 하는 것보다 쉽다고 생각한다면 부디
\cref{chp:Validation,chp:Formal Verification} 을 다시 읽어보시기 바랍니다.

\iffalse

In short, lockless techniques are quite useful and are heavily used.
However, it is best if lockless techniques are hidden behind a
well-defined API, such as the \co{inc_count()}, \co{memblock_alloc()},
\co{rcu_read_lock()}, and so on.
The reason for this is that undisciplined use of lockless techniques
is a good way to create difficult bugs.
If you believe that finding and fixing such bugs is easier than avoiding
them, please re-read
\cref{chp:Validation,chp:Formal Verification}.

\fi

\section{Non-Blocking Synchronization}
\label{sec:advsync:Non-Blocking Synchronization}
%
\epigraph{Never worry about theory as long as the machinery does what
	  it's supposed to do.}
	 {\emph{Robert A. Heinlein}}

\emph{Non-blocking synchronization} (NBS)~\cite{MauriceHerlihy90a} 라는 용어는
다음과 같이 다른 \emph{진행 보장}~\cite{DanAlitarh2013PracticalProgress} 을
갖는 일곱개의 클래스의 linearizable 알고리즘을 의미합니다:

\iffalse

The term \emph{non-blocking synchronization} (NBS)~\cite{MauriceHerlihy90a}
describes seven classes of linearizable algorithms with differing
\emph{forward-progress guarantees}~\cite{DanAlitarh2013PracticalProgress},
which are as follows:

\fi

\begin{enumerate}
\item	\emph{Bounded wait-free synchronization}: 모든 쓰레드가 특정 유한 시간
	내에 진행을 냅니다~\cite{Herlihy91}.
	이 단계는 이뤄질 수 없는 것으로 널리 여겨지는데, Alitarh 등이 이를
	생략한~\cite{DanAlitarh2013PracticalProgress} 이유일 수도 있습니다.
\item	\emph{Wait-free synchronization}: 모든 쓰레드가 유한 시간 내에 진행을
	냅니다~\cite{Herlihy93}.
\item	\emph{Lock-free synchronization}: 최소 하나의 쓰레드는 유한 시간 내에
	진행을 냅니다~\cite{Herlihy93}.
\item	\emph{Obstruction-free synchronization}: 경쟁이 없을 때 모든 쓰레드가
	유한 시간 내에 진행을 냅니다~\cite{HerlihyLM03}.
\item	\emph{Clash-free synchronization}: 경쟁이 없을 때 최소 하나의 쓰레드는 
	유한 시간 내에 진행을 냅니다~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Starvation-free synchronization}: 실패가 없을 때 모든 쓰레드가
	유한 시간 내에 진행을 냅니다~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Deadlock-free synchronization}: 실패가 없을 때 최소 하나의
	쓰레드는 진행을냅니다~\cite{DanAlitarh2013PracticalProgress}.

\iffalse

\item	\emph{Bounded wait-free synchronization}: Every thread
	will make progress within
	a specific finite period of time~\cite{Herlihy91}.
	This level is widely considered to be unachievable, which might be why
	Alitarh et al.\ omitted it~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Wait-free synchronization}: Every thread will make progress
	in finite time~\cite{Herlihy93}.
\item	\emph{Lock-free synchronization}: At least one thread will
	make progress in finite time~\cite{Herlihy93}.
\item	\emph{Obstruction-free synchronization}: Every thread will
	make progress in finite time in the absence of
	contention~\cite{HerlihyLM03}.
\item	\emph{Clash-free synchronization}: At least one thread will
	make progress in finite time in the absence of
	contention~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Starvation-free synchronization}: Every thread will
	make progress in finite time in the absence of
	failures~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Deadlock-free synchronization}: At least one thread will
	make progress in finite time in the absence of
	failures~\cite{DanAlitarh2013PracticalProgress}.

\fi

\end{enumerate}

NBS 클래스~1, 2, 그리고~3 이 1990년대 초에, 클래스~4 는 2000년대 초, 그리고
클래스~5 는 2013년에 처음 입안되었습니다.
마지막 두개의 클래스는 수십년동안 비공식적으로 널리 쓰였으나 2013년에 다시
정해졌습니다.

이론상, 모든 병렬 알고리즘은 wait-free 형태로 만들어질 수 있으나, 널리 쓰이는
NBS 알고리즘은 상대적으로 적습니다.
이것들 중 일부를 다음 섹션에서 나열합니다.

\iffalse

NBS classes~1, 2, and~3 were first formulated in the early 1990s,
class~4 was first formulated in the early 2000s,
and class~5 was first formulated in 2013.
The final two classes have seen informal use for a great many decades,
but were reformulated in 2013.

In theory, any parallel algorithm can be cast into wait-free form,
but there are a relatively small subset of NBS algorithms that are
in common use.
A few of these are listed in the following section.

\fi

\subsection{Simple NBS}
\label{sec:advsync:Simple NBS}

아마도 가장 간단한 NBS 알고리즘은 fetch-and-add (\co{atomic_add_return()})
기능을 사용한 원자적 정수 카운터 업데이트입니다.

\iffalse

Perhaps the simplest NBS algorithm is atomic update of an integer
counter using fetch-and-add (\co{atomic_add_return()}) primitives.

\fi

\subsubsection{NBS Sets}
\label{sec:advsync:NBS Sets}

또다른 간단한 NBS 알고리즘은 배열에 정수들의 집합을 구현합니다.
여기서 배열 인덱스는 이 집합의 멤버일 수도 있는 값을 알리며 배열의 원소는 그
값이 정말로 집합 멤버인지 알립니다.
NBS 알고리즘의 linearizability 기준은 이 배열에 대한 읽기와 쓰기가 어토믹
인스트럭션을 사용하거나 메모리 배리어를 동반해야 할 것을 필요로 합니다만, 그리
드물지는 않은 경우에 linearizability 는 중요치 않으며, 간단한 volatile 로드와
스토어 만으로도 충분한데, 예를 들어 \co{READ_ONCE()} 와 \co{WRITE_ONCE()} 를
사용하는 겁니다.

NBS 집합은 비트맵을 사용해 구현될 수도 있는데, 이 집합의 멤버일 수도 있는 각
값이 하나의 bit 에 연관되는 겁니다.
읽기와 쓰기는 일반적으로 원자적 bit 조정 인스트럭션을 통해 이루어져야 하는데,
compare-and-swap (\co{cmpxchg()} 또는 CAS) 인스트럭션들도 사용될 수 있기는
합니다.

\iffalse

Another simple NBS algorithm implements a set of integers in an array.
Here the array index indicates a value that might be a member of the set
and the array element indicates whether or not that value actually is
a set member.
The linearizability criterion for NBS algorithms requires that reads from
and updates to the array either use atomic instructions or be accompanied
by memory barriers, but in the not-uncommon case where linearizability
is not important, simple volatile loads and stores suffice, for example,
using \co{READ_ONCE()} and \co{WRITE_ONCE()}.

An NBS set may also be implemented using a bitmap, where each value that
might be a member of the set corresponds to one bit.
Reads and updates must normally be carried out via atomic bit-manipulation
instructions, although compare-and-swap (\co{cmpxchg()} or CAS)
instructions can also be used.

\fi

\subsubsection{NBS Counters}
\label{sec:advsync:NBS Counters}

\Cref{sec:count:Statistical Counters} 에서 설명한 통계적 카운터 알고리즘들은
bounded-wait-free 로 여겨질 수 있으나, 그 합이 정확한게 아니라 대략적인 것으로
여겨진다는 귀여운 정의상의 트릭이 사용될 때만 그렇습니다.\footnote{
	인용이 필요합니다.
	전 Mark Moir 로부터 이 트릭을 들었습니다.}
\co{read_count()} 함수가 이 카운터들의 합을 구하는데 걸리는 시간의 길이에 의해
정해지는 충분히 큰 오류 범위가 주어진다면 어떤 linearizable 하지 않은 행동이든
일어날 수 있다는 증명은 불가능합니다.
이 알고리즘은 리눅스 커널에서 가장 널리 쓰이는 NBS 알고리즘일 겁니다.

\iffalse

The statistical counters algorithm discussed in
\cref{sec:count:Statistical Counters}
can be considered to be bounded-wait-free, but only by using a cute
definitional trick in which the sum is considered to be approximate
rather than exact.\footnote{
	Citation needed.
	I heard of this trick verbally from Mark Moir.}
Given sufficiently wide error bounds that are a function of the length
of time that the \co{read_count()} function takes to sum the counters,
it is not possible to prove that any non-linearizable behavior occurred.
This definitely (if a bit artificially) classifies the statistical-counters
algorithm as bounded wait-free.
This algorithm is probably the most heavily used NBS algorithm in the
Linux kernel.

\fi

\subsubsection{Half-NBS Queue}
\label{sec:advsync:Half-NBS Queue}

\begin{fcvref}[ln:count:NBS Enqueue Algorithm]
또다른 흔한 NBS 알고리즘은 userspace-RCU 라이브러리
구현~\cite{MathieuDesnoyers2009URCU} 을 보이는
\cref{lst:count:NBS Enqueue Algorithm} 에 보인 것과 같이 원소들이 원자적 교환
인스트럭션을 이용해 넣어지고~\cite{MagedMichael1993JPDC}, 이어서 이 새 원소의 앞
원소의 \co{->next} 포인터가 저장되는 원자적 queue 일 겁니다.
\Clnref{tail} 은 tail 포인터를 새 원소를 참조하게 업데이트하면서 지역 변수
\co{old_tail} 에 그 앞 원소로의 참조를 저장합니다.
\Clnref{pred} 는 이어서 앞 원소의 \co{->next} 포인터가 이 새로 추가된 원소를
참조하게 업데이트 하고, 마지막으로 \clnref{ret} 는 이 queue 가 초기에 비어
있었는지 여부를 알리는 값을 리턴합니다.

\iffalse

\begin{fcvref}[ln:count:NBS Enqueue Algorithm]
Another common NBS algorithm is the atomic queue where elements are
enqueued using an atomic exchange instruction~\cite{MagedMichael1993JPDC},
followed by a store into the \co{->next} pointer of the new element's
predecessor, as shown in \cref{lst:count:NBS Enqueue Algorithm},
which shows the userspace-RCU library
implementation~\cite{MathieuDesnoyers2009URCU}.
\Clnref{tail} updates the tail pointer to reference the new element while
returning a reference to its predecessor, which is stored in
local variable \co{old_tail}.
\Clnref{pred} then updates the predecessor's \co{->next} pointer to
reference the newly added element, and finally \clnref{ret}
returns an indication as to whether or not the queue was initially
empty.

\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:count:NBS Enqueue Algorithm]
\begin{VerbatimL}[commandchars=\\\[\]]
static inline bool
___cds_wfcq_append(struct cds_wfcq_head *head,
                   struct cds_wfcq_tail *tail,
                   struct cds_wfcq_node *new_head,
                   struct cds_wfcq_node *new_tail)
{
	struct cds_wfcq_node *old_tail;

	old_tail = uatomic_xchg(&tail->p, new_tail);	\lnlbl[tail]
	CMM_STORE_SHARED(old_tail->next, new_head);     \lnlbl[pred]
	return old_tail != &head->node;			\lnlbl[ret]
}

static inline bool
_cds_wfcq_enqueue(struct cds_wfcq_head *head,
                  struct cds_wfcq_tail *tail,
                  struct cds_wfcq_node *new_tail)
{
	return ___cds_wfcq_append(head, tail,
	                          new_tail, new_tail);
}
\end{VerbatimL}
\end{fcvlabel}
\caption{NBS Enqueue Algorithm}
\label{lst:count:NBS Enqueue Algorithm}
\end{listing}

하나의 원소를 dequeue  하기 위해선 상호적 배타가 필요하지만 (따라서 dequeue 는
block 됩니다), 이 queued 의 전체 내용에 대한 non-blocking 제거가 가능합니다.
불가능한 건 특정 원소를 non-blocking 형식으로 dequeue 하는 겁니다: enqueue 를
한 쓰레드는 \clnref{tail,pred} 사이에서 실패했을 수도, 따라서 요청된 원소는
부분적으로 enqueue 되었을 수도 있습니다.
이는 enqueue 는 NBS 이지만 dequeue 는 blocking 인 half-NBS 알고리즘이 됩니다.
그러나 이 알고리즘은 현실에서 널리 쓰이고 있는데, 부분적으로는 대부분의 제품
소프트웨어가 임의의 fail-stop 오류들에 내성을 가질 필요를 갖지 않기 때문입니다.
\end{fcvref}

\iffalse

Although mutual exclusion is required to dequeue a single element
(so that dequeue is blocking), it is possible to carry out a non-blocking
removal of the entire contents of the queue.
What is not possible is to dequeue any given element in a non-blocking
manner: The enqueuer might have failed between \clnref{tail,pred} of the
listing, so that the element in question is only partially enqueued.
This results in a half-NBS algorithm where enqueues are NBS but
dequeues are blocking.
This algorithm is nevertheless heavily used in practice, in part because
most production software is not required to tolerate arbitrary fail-stop
errors.
\end{fcvref}

\fi

\subsubsection{NBS Stack}
\label{sec:advsync:NBS Stack}

\begin{fcvref}[ln:advsync:lifo_push:whole]
\Cref{lst:advsync:NBS Stack Algorithm}
는 NBS 스택을 이루는 lock-free push 와 bounded wait-free pop 을 뽐내는 LIFO
push 알고리즘 (\path{lifo-push.c}) 을 보입니다.
이 알고리즘의 원조는 알려지지 않았으나, 1975년에 얻어진
특허~\cite{PaulJBrown1975LIFOpush} 에서 참조되었습니다.
이 특허는 1973년에 청구되었는데 여러분의 편집자가 하나의 CPU 만을 가지고 있던
그의 첫 컴퓨터를 구매하기 몇달 전이었습니다.

\iffalse

\begin{fcvref}[ln:advsync:lifo_push:whole]
\Cref{lst:advsync:NBS Stack Algorithm}
shows the LIFO push algorithm, which boasts lock-free push and
bounded wait-free pop (\path{lifo-push.c}), forming an NBS stack.
The origins of this algorithm are unknown, but it was referred to in
a patent granted in 1975~\cite{PaulJBrown1975LIFOpush}.
This patent was filed in 1973, a few months before your editor
saw his first computer, which had but one CPU\@.

\fi

\begin{listing}[tbp]
\input{CodeSamples/advsync/lifo_push@whole.fcv}
\caption{NBS Stack Algorithm}
\label{lst:advsync:NBS Stack Algorithm}
\end{listing}

\Clnrefrange{struct:b}{struct:e} 는 임의의 값과 스택의 다음 구조체로의 포인터를 
포함하는 \co{node_t} 구조체를 보이며 \clnref{top} 은 스택 꼭대기 포인터를
보입니다.

\co{list_push()} 함수가 \clnrefrange{push:b}{push:e} 에 펼쳐져 있습니다.
\Clnref{push:alloc} 은 새 노드를 할당하고 \clnref{push:initialize} 는 이를
초기화 합니다.
\Clnref{push:next} 는 새로 할당된 노드의 \co{->next} 포인터를 초기화 하고,
\clnref{push:cmpxchg} 는 이를 스택에 밀어넣으려 합니다.
\Clnref{push:check} 가 \co{cmpxchg()} 가 실패했음을 파악하면, 반복문을 통한
또다른 시도가 이루어집니다.
그렇지 않다면, 이 새 노드는 성공적으로 넣어졌으며, 이 함수는 호출자에게
리턴됩니다.
\Clnref{push:check} 는 두개의 동시의 \co{list_push()} 인스턴스가 스택에 push 를
하려는 시도로 인한 경주 상황을 해결함을 유의하십시오.
\co{cmpxchg()} 는 하나에는 성공하고 다른 하나에는 실패할 것이어서 그 다른 쪽은
재시도를 하게 하며, 따라서 스택의 두 노드에 대한 임의의 순서를 선택합니다.

\iffalse

\Clnrefrange{struct:b}{struct:e} show the \co{node_t} structure,
which contains an arbitrary value and a pointer to the next structure
on the stack and
\clnref{top} shows the top-of-stack pointer.

The \co{list_push()} function spans \clnrefrange{push:b}{push:e}.
\Clnref{push:alloc} allocates a new node and
\clnref{push:initialize} initializes it.
\Clnref{push:next} initializes the newly allocated node's \co{->next}
pointer, and \clnref{push:cmpxchg} attempts to push it on the stack.
If \clnref{push:check} detects \co{cmpxchg()} failure, another pass
through the loop retries.
Otherwise, the new node has been successfully pushed, and this function
returns to its caller.
Note that \clnref{push:check} resolves races in which two concurrent
instances of \co{list_push()} attempt to push onto the stack.
The \co{cmpxchg()} will succeed for one and fail for the other,
causing the other to retry, thereby selecting an arbitrary order for
the two node on the stack.

\fi

\co{list_pop_all()} 함수가 \clnrefrange{popall:b}{popall:e} 에 있습니다.
\Clnref{popall:xchg} 의 \co{xchg()} 문은 원자적으로 스택의 모든 노드를
제거하고, 그 결과 만들어지는 리스트의 head 를 지역 변수 \co{p} 에 저장하고
\co{top} 을 \co{NULL} 로 만듭니다.
이 어토믹 오퍼레이션은 \co{list_pop_all()} 로의 동시 호출들을 줄세웁니다:
그 중 하나는 리스트를 얻을 것이고, 다른 것들은 \co{NULL} 포인터를 얻을 것인데
동시의 \co{list_push()} 호출이 없었다는 가정 하에서입니다.

\co{p} 에 비어있지 않은 리스트를 얻는 \co{list_pop_all()} 인스턴스는 이
리스트를 \clnrefrange{popall:loop:b}{popall:loop:e} 에 놓여진 반복문을 통해
처리합니다.
\Clnref{popall:next} 는 \co{->next} 포인터를 읽어오고, \clnref{popall:foo} 는
\co{foo()} 에 의해 참조되는 함수를 현재 노드에 대해 호출하고,
\clnref{popall:free} 는 현재 노드를 메모리 해제하며, \clnref{popall:pnext} 는
\co{p} 를 이 반복문의 다음 회차를 위해 설정합니다.

하지만 한쌍의 \co{list_push()} 인스턴스가 단일 \Node{A} 를 초기에 담고 있는
리스트에 동시의 \co{list_pop_all()} 과 함께 호출되었다고 해봅시다.
이 시나리오가 만들 수 있는 한 방법은 아래와 같습니다:

\iffalse

The \co{list_pop_all()} function spans \clnrefrange{popall:b}{popall:e}.
The \co{xchg()} statement on \clnref{popall:xchg} atomically removes
all nodes on the stack, placing the head of the resulting list in local
variable \co{p} and setting \co{top} to \co{NULL}.
This atomic operation serializes concurrent calls to \co{list_pop_all()}:
One of them will get the list, and the other a \co{NULL} pointer, at
least assuming that there were no concurrent calls to \co{list_push()}.

An instance of \co{list_pop_all()} that obtains a non-empty list in
\co{p} processes this list in the loop spanning
\clnrefrange{popall:loop:b}{popall:loop:e}.
\Clnref{popall:next} prefetches the \co{->next} pointer,
\clnref{popall:foo} invokes the function referenced by \co{foo()} on the
current node,
\clnref{popall:free} frees the current node, and
\clnref{popall:pnext} sets up \co{p} for the next pass through the loop.

But suppose that a pair of \co{list_push()} instances run concurrently
with a \co{list_pop_all()} with a list initially containing a single
\Node{A}.
Here is one way that this scenario might play out:

\fi

\begin{enumerate}
\item	첫번째 \co{list_push()} 인스턴스는 새 \Node{B} 를 밀어넣고,
	\clnref{push:next} 를 지나 수행되어, \Node{A} 로의 포인터를 \Node{B} 의
	\co{->next} 포인터에 저장합니다.
\item	\co{list_pop_all()} 인스턴스가 완료되어, \co{top} 을 \co{NULL} 로
	설정하고 \Node{A} 를 메모리 해제합니다.
\item	두번째 \co{list_push()} 인스턴스가 완료되어, 새 \Node{C} 를 밀어넣지만
	\Node{A} 에 속했던 메모리를 할당받게 됩니다.
\item	첫번째 \co{list_push()} 인스턴스가 \clnref{push:cmpxchg} 에서
	\co{cmpxchg()} 를 수행합니다.
	새 \Node{C} 는 새로 메모리 해제된 \Node{A} 와 동일한 주소를 가지므로 이
	\co{cmpxchg()} 는 성공하고 이 \co{list_push()} 인스턴스는 완료됩니다.

\iffalse

\item	The first \co{list_push()} instance pushes a new \Node{B},
	executing through \clnref{push:next}, having just stored
	a pointer to \Node{A} into \Node{B}'s \co{->next} pointer.
\item	The \co{list_pop_all()} instance runs to completion,
	setting \co{top} to \co{NULL} and freeing \Node{A}.
\item	The second \co{list_push()} instance runs to completion,
	pushing a new \Node{C}, but happens to allocate the memory
	that used to belong to \Node{A}.
\item	The first \co{list_push()} instance executes the \co{cmpxchg()}
	on \clnref{push:cmpxchg}.
	Because new \Node{C} has the same address as the newly freed \Node{A},
	this \co{cmpxchg()} succeeds and this \co{list_push()} instance
	runs to completion.

\fi

\end{enumerate}

두개의 밀어넣기와 전체 꺼내기가 \Node{A} 의 메모리의 재사용에도 불구하고 모두
성공적으로 수행되었음을 유의하세요.
이는 일반적이지 않은 특성입니다: 대부분의 데이터 구조는 ABA 문제라고 종종
불리는 문제에 대한 보호를 필요로 합니다.

하지만 이는 어셈블리어로 쓰인 알고리즘에만 적용됩니다.
슬픈 사실은 대부분의 언어들이 (C 와 C++ 포함) \Node{B} 의 \co{->next} 포인터에
저장된 기존 \Node{A} 로의 포인터 같은, 수명이 끝난 객체로의 포인터를 지원하지
않는다는 것입니다.
실제로, 컴파일러는 두 포인터가 (\co{p} 와 \co{q} 라고 해봅시다) \co{malloc()}
에 대한 두개의 다른 호출에서 리턴되었다면 그 포인터들은 동일하지 않아야 한다고
가정할 권리를 갖습니다.
실제 컴파일러들은 정말로 \co{p==q} 비교에 응답으로 항상 \co{false} 를 생성할
겁니다.
메모리 해제되었지만 호환 가능한 타입의 객체로 재할당된 객체로의 포인터는
\emph{좀비 보인터} 라고 명명됩니다.

\iffalse

Note that both pushes and the popall all ran successfully despite the
reuse of \Node{A}'s memory.
This is an unusual property: Most data structures require protection
against what is often called the ABA problem.

But this property holds only for algorithm written in assembly
language.
The sad fact is that most languages (including C and C++) do not support
pointers to lifetime-ended objects, such as the pointer to the old \Node{A}
contained in \Node{B}'s \co{->next} pointer.
In fact, compilers are within their rights to assume that if two pointers
(call them \co{p} and \co{q}) were returned from two different calls to
\co{malloc()}, then those pointers must not be equal.
Real compilers really will generate the constant \co{false} in
response to a \co{p==q} comparison.
A pointer to an object that has been freed, but whose memory has been
reallocated for a compatibly typed object is termed a \emph{zombie pointer}.

\fi

많은 동시성 어플리케이션이 주의 깊게 메모리 할당자를 컴파일러로부터 숨겨서
컴파일러가 옳지 않은 가정을 하는 것을 방지함으로써 이 문제를 막습니다.
이런 난독화 시도는 현재 실전에서 잘 동작합니다만, 언젠가는 갈수록 강화되어가는
최적화 기법들의 희생자가 될수도 있습니다.
이 문제를 해결하기 위한 C 와 C++ 표준 위원회의 노력이
진행중입니다~\cite{PaulEMcKenney2019PointerLifetimeEndZap,PaulEMcKenney2020PointerLifetimeEndZapCpp}.
그동안은, ABA에 내성이 있는 알고리즘을 아주 주의하며 짜도록 연습해 주시기
바랍니다.
\end{fcvref}

\iffalse

Many concurrent applications avoid this problem by carefully hiding the
memory allocator from the compiler, thus preventing the compiler from
making inappropriate assumptions.
This obfuscatory approach currently works in practice, but might well
one day fall victim to increasingly aggressive optimizers.
There is work underway in both the C and C++ standards committees
to address this
problem~\cite{PaulEMcKenney2019PointerLifetimeEndZap,PaulEMcKenney2020PointerLifetimeEndZapCpp}.
In the meantime, please exercise great care when coding ABA-tolerant
algorithms.
\end{fcvref}

\fi

\QuickQuiz{
	왜 C 와 C++ 같은 고전 언어를 더 현대적인 걸로 대체하지 않죠?

	\iffalse

	So why not ditch antique languages like C and C++ for something
	more modern?

	\fi

}\QuickQuizAnswer{
	그 더 현대적인 언어의 제안자가 그들 스스로의 컴파일러 백엔드를 작성할
	만큼 에너지가 넘치지 않는다면 도움이 되지 않을 겁니다.
	기존에 존재하는 백엔드를 재사용하는 일반적인 방법은 또한 수명이 종료된
	객체로의 퐁니터를 지원하길 거절하는 것과 같은 매력적인 속성 역시
	재사용합니다.

	\iffalse

	That won't help unless the more-modern languages proponents
	are energetic enough to write their own compiler backends.
	The usual practice of re-using existing backends also reuses
	charming properties such as refusal to support pointers to
	lifetime-ended objects.

	\fi

}\QuickQuizEnd

\subsection{Applicability of NBS Benefits}
\label{sec:advsync:Applicability of NBS Benefits}

가장 널리 인용된 NBS 의 장점은 그것의 진행 보장, fail-stop 버그에 대한 내성,
그리고 linearizability 에서 나옵니다.
다음 섹션들 중 하나에서 이것들 각각을 논합니다.

\iffalse

The most heavily cited NBS benefits stem from its forward-progress
guarantees, its tolerance of fail-stop bugs, and from its linearizability.
Each of these is discussed in one of the following sections.

\fi

\subsubsection{NBS Forward Progress Guarantees}
\label{sec:advsync:NBS Forward Progress Guarantees}

NBS 의 진행 보장은 이를 리얼타임 시스템에서 사용하도록 많은 사람들에게 제안하게
만들었으며 NBS 알고리즘은 실제로 매우 많은 그런 시스템에서 사용되었습니다.
그러나, 진행 보장은 리얼타임 프로그래밍의 기초를 이루는 것들과 많은 면에서
직교합니다:

\iffalse

NBS's forward-progress guarantees have caused many to suggest its use in
real-time systems, and NBS algorithms are in fact used in a great many
such systems.
However, it is important to note that forward-progress guarantees are
largely orthogonal to those that form the basis of real-time programming:

\fi

\begin{enumerate}
\item	리얼타임 진행 보장은 일반적으로 그것들과 연관된 어떤 특정 시간이
	있는데, 예를 들면 ``스케쥴 응답시간은 100 마이크로세컨드 미만이어야
	한다'' 같은 겁니다.
	반대로, NBS 의 가장 흔한 형태는 명확한 경계 없이 어떤 유한 시간 내에
	만들어질 것만을 보장합니다.
\item	리얼타임 존재 보장은 종종 확률적인데, 소프트 리얼타임에서의 ``99.9\,\%
	확률로 스케쥴 응답시간은 100 마이크로세컨드 미만이어야 한다'' 같은
	겁니다.
	대조적으로, 많은 NBS 의 진행 보장은 무조건적입니다.
\item	리얼타임 존재 보장은 종종 완경적 제한에 따라 조건적인데, 예를 들면:
	(1)~가장 높은 우선순위 태스크에 한하여,
	(2)~각 CPU 가 각자의 시간 중 최소 특정 부분은 idle 로 보내며,
	(3)~I/O 비율이 어떤 명시된 최대값 미만일 때.
	대조적으로, NBS 의 진행 보장은 종종 무조건적인데, 최근의 NBS 는 조건적
	보장을 수용하긴 합니다~\cite{DanAlitarh2013PracticalProgress}.

\iffalse

\item	Real-time forward-progress guarantees usually have some
	definite time associated with them, for example,
	``scheduling latency must be less than 100 microseconds.''
	In contrast, the most popular forms of NBS only guarantees
	that progress will be made in finite time, with no definite
	bound.
\item	Real-time forward-progress guarantees are often
	probabilistic, as in the soft-real-time guarantee that
	``at least 99.9\,\% of the time, scheduling latency must
	be less than 100 microseconds.''
	In contrast, many of NBS's forward-progress guarantees are
	unconditional.
\item	Real-time forward-progress guarantees are often conditioned on
	environmental constraints, for example, only being honored:
	(1)~For the highest-priority tasks,
	(2)~When each CPU spends at least a certain fraction of its time idle,
	and (3)~When I/O rates are below some specified maximum.
	In contrast, NBS's forward-progress
	guarantees are often unconditional, although recent NBS work
	accommodates conditional
	guarantees~\cite{DanAlitarh2013PracticalProgress}.

\fi

\item	리얼타임 프로그램의 환경에서 중요한 요소 중 하나는 스케쥴러입니다.
	NBS 알고리즘은 최악의 경우의 \emph{악마같은 스케쥴러} 를 가정합니다.
	반대로, 리얼타임 시스템은 스케쥴러가 알려진 모든 제한을 만족시키기 위해
	최선을 다하며 그런 제한이 없을 때에는 프로세스 우선순위를 따르고 같은
	우선순위의 프로세스에게는 공정한 스케쥴링을 하기 위해 최선을 다한다고
	가정합니다.
	이런 악마적이지 않은 스케쥴러에 대한 가정은 리얼타임 프로그램이 NBS 에
	요구되는 것 같은
	것들보다~\cite{DanAlitarh2013PracticalProgress,BjoernBrandenburgPhD}
	간단한 알고리즘을 사용할 수 있게 합니다.
\item	리얼타임 진행 보장은 보통 소프트웨어 버그가 없을 때에 적용됩니다.
	반대로, 많은 종류의 NBS 보장은 fail-stop 버그가 있을 때 조차도
	적용됩니다.
\item	NBS 진행 보장은 linearizability 를 내포합니다.
	반대로, 리얼타임 존재 보장은 종종 linearizability 같은 순서 규칙 제한에
	종속되지 않습니다.

\iffalse

\item	An important component of a real-time program's environment
	is the scheduler.
	NBS algorithms assume a worst-case \emph{demonic scheduler}.
	In contrast, real-time systems assume that the scheduler is
	doing its level best to satisfy any scheduling constraints
	it knows about, and, in the absence of such constraints,
	its level best to honor process priorities and to provide
	fair scheduling to processes of the same priority.
	This assumption of a non-demonic scheduler allows real-time
	programs to use simpler algorithms than those required for
	NBS~\cite{DanAlitarh2013PracticalProgress,BjoernBrandenburgPhD}.
\item	Real-time forward-progress guarantees usually apply only
	in the absence of software bugs.
	In contrast, many classes of NBS guarantees apply even in the
	face of fail-stop bugs.
\item	NBS forward-progress guarantee classes imply linearizability.
	In contrast, real-time forward progress guarantees are often
	independent of ordering constraints such as linearizability.

\fi

\end{enumerate}

다시 반복하자면, 이런 차이에도 불구하고 NBS 알고리즘 여럿이 리얼타임
프로그램에서 굉장히 유용합니다.

\iffalse

To reiterate, despite these differences, a number of NBS algorithms are
extremely useful in real-time programs.

\fi

\subsubsection{NBS Fail-Stop Tolerance}
\label{sec:advsync:NBS Fail-Stop Tolerance}

NBS 알고리즘들 가운데 wait-free 동기화 (경계선이 있든 없든), lock-free 동기화,
obstruction-free 동기화, 그리고 clash-free 동기화는 fail-stop 버그의 존재에도
불구하고 진행을 보장합니다.
Fail-stop 버그의 한 예는 어떤 쓰레드가 무한정 preemption 되게 할수도 있습니다.
곧 보게 되겠지만, 이 fail-stop 내성은 유용할 수 있지만, 사실 fail-stop 에
내성이 있는 메커니즘 집합을 엮는 것은 꼭 fail-stop 내성이 있는 시스템을
만들지는 않습니다.
이를 더 자세히 보기 위해, wait-free queue 여럿을 이용해 만들어져서 어떤 원소가
그 중 하나의 queue 에서 제거되고 처리되고 다음 queue 에 더해지는 시스템을
생각해 봅시다.

어떤 쓰레드가 enqueue 오퍼레이션 중간에 preemption 된다면 이론상 이 queue 의
wait-free 본성이 진행을 보장하므로 아무 문제 없습니다.
하지만 실전에서는 이 wait-free queue 의 fail-stop 내성이 이 queue 를 이용하는
코드에까지 확장되지 않으므로 이 처리중인 원소가 사라져버립니다.

\iffalse

Of the classes of NBS algorithms, wait-free synchronization (bounded or
otherwise), lock-free synchronization, obstruction-free synchronization,
and clash-free synchronization guarantee forward progress even in the
presence of fail-stop bugs.
An example fail-stop bug might cause some thread to be preempted indefinitely.
As we will see, this fail-stop-tolerant property can be useful, but the
fact is that composing a set of fail-stop-tolerant mechanisms does not
necessarily result in a fail-stop-tolerant system.
To see this, consider a system made up of a series of wait-free queues,
where an element is removed from one queue in the series, processed,
and then added to the next queue.

If a thread is preempted in the midst of a queuing operation, in theory
all is well because the wait-free nature of the queue will guarantee
forward progress.
But in practice, the element being processed is lost because the
fail-stop-tolerant nature of the wait-free queues does not extend to
the code using those queues.

\fi

그러나 NBS 의 제한된 fail-stop 내성이 유용한 일부 어플리케이션이 있습니다.
예를 들어, 어떤 네트워크 기반 웹 어플리케이션에서 fail-stop 이벤트는 결국
재전송을 초래하는데, fail-stop 이벤트로 사라진 모든 일을 재시작하게 할 겁니다.
따라서 그런 어플리케이션을 수행하는 시스템은 상당한 부하를 받게 되는데,
스케쥴러가 더이상 어떤 합리적인 공정성 보장을 하지 못할 수준까지도 이를 수
있습니다.
반대로, 어떤 쓰레드가 락을 잡은 채로 fail-stop 된다면, 이 어플리케이션은
재시작되어야 할수도 있습니다.
그러나, NBS 는 이 제한된 영역에서조차 만병통치약이 아닌데, 순수한 스케쥴링
지연으로 인한 가짜 재전송의 가능성 때문입니다.
어떤 경우에는 queueing 지연을 막기 위해 부하를 줄이는게 더 효율적일 수도
있으며, 이는 또한 스케쥴러의 공정성을 제공하는 능력을 개선해서 fail-stop
이벤트를 줄이거나 제거하고, 따라서 재시도 오퍼레이션의 수를 줄여서 결국 더욱
부하를 줄이게 될 겁니다.

\iffalse

Nevertheless, there are a few applications where NBS's rather limited
fail-stop-tolerance is useful.
For example, in some network-based or web applications, a fail-stop
event will eventually result in a retransmission, which will restart
any work that was lost due to the fail-stop event.
Systems running such applications can therefore be heavily loaded, even
to the point where the scheduler can no longer provide any reasonable
fairness guarantee.
In constrast, if a thread fail-stops while holding a lock, the application
might need to be restarted.
Nevertheless, NBS is not a panacea even within this restricted area,
due to the possibility of spurious retransmissions due to pure scheduling
delays.
In some cases, it may be more efficient to reduce the load to avoid
queueing delays, which will also improve the scheduler's ability to
provide fair access, reducing or even eliminating the fail-stop events,
thus reducing the number of retry operations, in turn further reducing
the load.

\fi

\subsubsection{NBS Linearizability}
\label{sec:advsync:NBS Linearizability}

Linearizability 는 상당히 유용할 수 있으며, 특히 엄격한 락킹과 완전한 순서
규칙의 어토믹 오퍼레이션을\footnote{
	예를 들어, 리눅스 커널의 값을 반환하는 어토믹 오퍼레이션.}
통해 만들어진 동시성 코드를 분석할 때 특히
그렇습니다.
더 나아가, 이 완전한 순서 규칙의 어토믹 오퍼레이션의 처리는 자동적으로 간단한
NBS 알고리즘을 처리합니다.

그러나, 복잡한 NBS 알고리즘의 linearization 포인트는 종종 그 알고리즘 내에 깊이
묻혀 있으며, 따라서 그런 알고리즘의 부분을 구현하는 라이브러리 함수의
사용자에게는 보이지 않습니다.
따라서, 사용자가 복잡한 NBS 알고리즘의 linearizability 속성으로부터 혜택을
받는다는 말에는 깊은 의심을 가져야 합니다~\cite{AndreasHaas2012FIFOisnt}.

\iffalse

It is important to note that linearizability can be quite useful,
especially when analyzing concurrent code made up of strict locking
and fully ordered atomic operations.\footnote{
	For example, the Linux kernel's value-returning atomic operations.}
Furthermore, this handling of fully ordered atomic operations
automatically covers simple NBS algorithms.

However, the linearization points of a complex NBS algorithms are often
buried deep within that algorithm, and thus not visible to users of
a library function implementing a part of such an algorithm.
Therefore, any claims that users benefit from the linearizability properties
of complex NBS algorithms should be regarded with deep
suspicion~\cite{AndreasHaas2012FIFOisnt}.

\fi

가끔은 개발자들이 동시성 코드의 올바름 증명을 하기 위해 linearizability 가
필요하다는게 단정되곤 합니다.
그러나, 그런 증명은 규칙이라기보다 예외이며, 증명을 만들어내는 현대의
개발자들은 종종 linearizability 에 의존하지 않는 현대의 증명 기법들을
사용합니다.
더 나아가, 개발자들은 종종 전체 명세를 필요로 하지 않는 현대의 증명 기법들을
사용하는데, 개발자들은 종종 그 명세를 시작 이후에 배우게 되며, 한번에 한 버그씩
찾는다는 점에서 그렇습니다.
그런 증명 기법들 중 일부가
\cref{chp:Formal Verification} 에서 이야기 되었습니다.\footnote{
	어떤 linearizability 의 대변인과의 기억에 남을만한 토론은 질문을
	초래했습니다:
	``linearizability 가 중요한 이유가 1980년대의 증명 기법을 구원하기
	위해서란 말인가?''
	그 대변인은 즉각적으로 긍정적인 답을 했고, 특정 현대 증명 기법을
	험담하는데 시간을 좀 보냈습니다.
	충분히 이상하게도, 그 기법은 리눅스 커널 RCU 에 성공적으로 적용된 것 중
	하나였습니다.}

\iffalse

It is sometimes asserted that linearizability is necessary for developers
to produce proofs of correctness for their concurrent code.
However, such proofs are the exception rather than the rule, and modern
developers who do produce proofs often use modern proof techniques that
do not depend on linearizability.
Furthermore, developers frequently use modern proof techniques that do
not require a full specification, given that developers often learn
their specification after the fact, one bug at a time.
A few such proof techniques were discussed in
\cref{chp:Formal Verification}.\footnote{
	A memorable verbal discussion with an advocate of linearizability
	resulted in question:
	``So the reason linearizability is important is to rescue 1980s
	proof techniques?''
	The advocate immediately replied in the affirmative, then spent
	some time disparaging a particular modern proof technique.
	Oddly enough, that technique was one of those successfully
	applied to Linux-kernel RCU\@.}

\fi

Linearizability 가 ㄷㅇ시성 명세보다 더 자연적이라고 이야기 되는 순차적 명세와
잘 연결된다는 이야기가 종종
있습니다~\cite{SergioRajsbaum2020HistoryLinearizability}.
하지만 이 주장은 우리의 상당히 동시적인 객체 우주에서는 통하지 않습니다.
이 우주의 존재들은 동시성을 처리할 능력을 가질 것으로 기대되며, 팀 스포츠나
작은 아이들을 봐야 하는 사람들에겐 특히 그렇습니다.
또한, 순차적 컴퓨팅을 가리츠니는 것은 여전히 어떤 흑마술로 여겨진다는 점을
생각하면~\cite{ElizabethPatitsas2020GradesNotBimodal}, 동시성 컴퓨팅을 가르치는
것은 비슷한 혼란의 상태로 예상하는게 합리적입니다.
따라서, 하나의 증명 기법에만 주목하는 것은 좋은 방향이 아닐 가능성이 높습니다.

\iffalse

It is often asserted that linearizability maps well to sequential
specifications, which are said to be more natural than are concurrent
specifications~\cite{SergioRajsbaum2020HistoryLinearizability}.
But this assertion fails to account for our highly concurrent objective
universe.
This universe can only be expected to select for ability to cope with
concurrency, especially for those participating in team sports or
overseeing small children.
In addition, given that the teaching of sequential
computing is still believed to be somewhat of a black
art~\cite{ElizabethPatitsas2020GradesNotBimodal}, it is reasonable
to expect that teaching of concurrent computing is in a similar state
of disarray.
Therefore, focusing on only one proof technique is unlikely to be a
good way forward.

\fi

다시 말하지만, linearizability 는 많은 상황에서 매우 유용함을 이해하세요.
그리고 또 다시 말하지만, 망치라는 권위있는 도구 역시 그렇습니다.
하지만 언젠가는 망치는 내려놓고 키보드를 골라야만 하는 컴퓨팅의 분야 중 한
부분이 나옵니다.
비슷하게, linearizability 가 그 일을 하는데 최고의 도구는 아닌 순간도 있을
겁니다.

Linearizability 의 단점 일부를 인지하고 있는 linearizability 대변인들도
있습니다~\cite{SergioRajsbaum2020HistoryLinearizability}.
Linearizability 를 확장하자는 제안도 있는데, 예를 들면 interval-linearizability
로, 완료되는데 0이 아닌 시간을 필요로 하는 오퍼레이션들의 흔한 경우를 처리하기
위한 것입니다~\cite{10.1145/3266457}.
이 제안들이 현대의 동시성 소프트웨어 작품들을 다룰 수 있는 이론이 될 것인지는
여전히 지켜봐야 하는 상태인데,
\cref{chp:Formal Verification} 에서 이야기한 증명 기법 여럿이 이미 많은 현대
동시성 소프트웨어 제품을 처리하고 있다는 점에서 특히 그렇습니다.

\iffalse

Again, please understand that linearizability is quite useful in many
situations.
Then again, so is that venerable tool, the hammer.
But there comes a point in the field of computing where one should put
down the hammer and pick up a keyboard.
Similarly, it appears that there are times when linearizability is not
the best tool for the job.

To their credit, there are some linearizability advocates who are aware
of some of its shortcomings~\cite{SergioRajsbaum2020HistoryLinearizability}.
There are also proposals to extend linearizability, for example,
interval-linearizability, which is intended to handle the common case
of operations that require non-zero time to
complete~\cite{10.1145/3266457}.
It remains to be seen whether these proposals will result in theories
able to handle modern concurrent software artifacts, especially given
that several of the proof techniques discussed in \cref{chp:Formal
Verification} already handle many modern concurrent software artifacts.

\fi

\subsection{NBS Discussion}
\label{sec:advsync:NBS Discussion}

It is possible to create fully non-blocking queues~\cite{MichaelScott96},
however, such queues are much more complex than the half-NBS algorithm
outlined above.
The lesson here is to carefully consider your actual requirements.
Relaxing irrelevant requirements can often result in great
improvements in simplicity, performance, and scalability.

Recent research points to another important way to relax requirements.
It turns out that systems providing fair scheduling can enjoy most
of the benefits of wait-free synchronization even when running
algorithms that provide only non-blocking
synchronization, both in theory~\cite{DanAlitarh2013PracticalProgress}
and in practice~\cite{SamyAlBahra2013NBS}.
Because most schedulers used in production do in fact provide fairness,
the more-complex algorithms providing wait-free synchronization usually
provide no practical advantages over simpler and faster non-wait-free
algorithms.

Interestingly enough, fair scheduling is but one beneficial
constraint that is often respected in practice.
Other sets of constraints can permit blocking algorithms to
achieve deterministic real-time response.
For example, given:
(1)~Fair locks granted in FIFO order within a given priority level,
(2)~Priority inversion avoidance (for example, priority
inheritance~\cite{Takada:1995:RSN:527074.828566,Cai-DongWang1996PrioInherLock}
or priority ceiling),
(3)~A bounded number of threads,
(4)~Bounded critical section durations,
(5)~Bounded load,
and
(6)~Absence of fail-stop bugs,
lock-based applications can provide deterministic
response times~\cite{BjoernBrandenburgPhD,DipankarSarma2004OLSscalability}.
This approach of course blurs the distinction between blocking and wait-free
synchronization, which is all to the good.
Hopefully theoretical frameworks will continue to improve their ability
to describe software actually used in practice.

Those who feel that theory should lead the way are referred to the
inimitable Peter Denning, who said of operating systems:
``Theory follows practice''~\cite{Denning:2015:POF:2830903.2830904},
or to the eminent Tony Hoare, who said of the whole of engineering:
``In all branches of engineering science, the engineering starts before
the science; indeed, without the early products of engineering, there
would be nothing for the scientist to
study!''~\cite{RichardMorris2007TonyHoareInterview}.
However, once an appropriate body of theory becomes available,\footnote{
	Note well that the first \emph{appropriate} body of theory is often one
	thing and the first \emph{proposed} body of theory quite another.}
it is wise to make use of it.

\input{advsync/rt}

\QuickQuizAnswersChp{qqzadvsync}
