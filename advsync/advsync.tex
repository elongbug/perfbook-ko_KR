% advsync/advsync.tex

\QuickQuizChapter{sec:advsync:Advanced Synchronization}{Advanced Synchronization}
%
\Epigraph{If a little knowledge is a dangerous thing, just imagine all
	  the havoc you could wreak with a lot of knowledge!}{\emph{Unknown}}

이 섹션에서는 더 약하지만, 비용이 적은 동기화 기능들에 대해 이야기 해 봅니다.
이 약함은 상당히 도움이 되는데, 실제로 어떤 사람들은 약함이 덕목이라
이야기~\cite{JadeAlglave2013-WeaknessIsVirtue} 하기도 했습니다.
삶의 다른 많은 분야들에서도 그러하듯이, 병렬 프로그래밍에서도 약함이
만병통치약은 아닙니다.
예를 들어, 아직 정리 안된 약화를 생각하기도 전에 Chapter~\ref{chp:Counting} 의
마지막에서 이야기 했듯, 철저하게 파티셔닝, 배칭, 그리고 잘 테스트된 약한 API
들을 적용해야 합니다 ( Chapter~\ref{chp:Data Ownership} 과
Chapter~\ref{chp:Deferred Processing} 을 참고하세요).

하지만 그것들을 모두 적용한 후라면, 이 챕터에서 이야기할 고급 테크닉들을 필요로
할수도 있을 겁니다.
그러기 위해, Section~\ref{sec:advsync:Avoiding Locks} 에서 락을 피하기 위해
사용되는 테크닉들을 요약하고, Section~\ref{sec:advsync:Memory Barriers} 에서
메모리 배리어를 다룬 후, 마지막으로 Section~\ref{sec:advsync:Non-Blocking
Synchronization} 에서 블로킹하지 않는 동기화를 짧게 다룹니다.
\iffalse

This section discusses a number of ways of using weaker, and hopefully
lower-cost, synchronization primitives.
This weakening can be quite helpful, in fact, some have argued
that weakness is a virtue~\cite{JadeAlglave2013-WeaknessIsVirtue}.
Nevertheless, in parallel programming, as in many other aspects
of life, weakness is not a panacea.
For example, as noted at the end of
Chapter~\ref{chp:Counting},
you should thoroughly apply partitioning, batching, and
well-tested packaged weak APIs (see Chapter~\ref{chp:Data Ownership}
and~\ref{chp:Deferred Processing})
before even thinking about unstructured weakening.

But after doing all that, you still might find yourself needing the
advanced techniques described in this chapter.
To that end,
Section~\ref{sec:advsync:Avoiding Locks}
summarizes techniques used thus far for avoiding locks,
Section~\ref{sec:advsync:Memory Barriers}
covers use of memory barriers, and finally
Section~\ref{sec:advsync:Non-Blocking Synchronization}
gives a brief overview of non-blocking synchronization.
\fi

\section{Avoiding Locks}
\label{sec:advsync:Avoiding Locks}

락킹은 제품화 레벨의 병렬성에서 매우 많이 사용되는 방법이지만, 많은 상황에서
락을 사용하지 않는 (lockless) 테크닉을 사용하는 것으로 성능, 확장성, 그리고
실시간 반응성을 모두 크게 개선시킬 수 있습니다.
그런 lockless 테크닉의 한 예는 Section~\ref{sec:count:Statistical Counters}
에서 보인, 카운터 증가에 락은 물론 어토믹 오퍼레이션, 메모리 배리어, 그리고
심지어 캐시 미스 까지 없앴던 통계적 카운터가 될 수 있을 것입니다.
그 외에 우리가 다뤘던 예들은 다음과 같습니다:

\begin{enumerate}
\item	Chapter~\ref{chp:Counting} 에서 다룬 다른 카운팅 알고리즘들의 빠른 수행
	경로들.
\item	Section~\ref{sec:SMPdesign:Resource Allocator Caches} 의 리소스
	얼로케이터 캐시들의 빠른 수행 경로.
\item	Section~\ref{sec:SMPdesign:Beyond Partitioning} 의 미로 풀기 알고리즘.
\item	Chapter~\ref{chp:Data Ownership} 에서 설명한 데이터 소유권 (Data
	Ownership) 테크닉.
\item	Chapter~\ref{chp:Deferred Processing} 에서 설명한 레퍼런스 카운팅과 RCU
	테크닉들.
\item	Chapter~\ref{chp:Data Structures} 에서 설명한 룩업 코드 경로.
\item	Chapter~\ref{chp:Putting It All Together} 에서 설명한 많은 테크닉들.
\end{enumerate}
\iffalse

Although locking is the workhorse of parallelism in production, in
many situations performance, scalability, and real-time response can
all be greatly improved through use of lockless techniques.
A particularly impressive example of such a lockless technique are
the statistical counters described in
Section~\ref{sec:count:Statistical Counters},
which avoids not only locks, but also atomic operations, memory barriers,
and even cache misses for counter increments.
Other examples we have covered include:

\begin{enumerate}
\item	The fastpaths through a number of other counting algorithms
	in Chapter~\ref{chp:Counting}.
\item	The fastpath through resource allocator caches in
	Section~\ref{sec:SMPdesign:Resource Allocator Caches}.
\item	The maze solver in Section~\ref{sec:SMPdesign:Beyond Partitioning}.
\item	The data-ownership techniques described in
	Chapter~\ref{chp:Data Ownership}.
\item	The reference-counting and RCU techinques described in
	Chapter~\ref{chp:Deferred Processing}.
\item	The lookup code paths described in Chapter~\ref{chp:Data Structures}.
\item	Many of the techniques described in
	Chapter~\ref{chp:Putting It All Together}.
\end{enumerate}
\fi

한마디로, lockless 테크닉들은 상당히 유용하고 많이 사용되고 있습니다.

하지만, lockless 테크닉들은 \co{inc_count()}, \co{memblock_alloc()},
\co{rcu_read_lock()} 등과 같은 잘 정의된 API 뒤에 숨겨져 있는게 제일 좋습니다.
과한 lockless 테크닉들의 사용은 어려운 버그를 만들어내기 쉽기 때문입니다.

많은 lockless 테크닉들의 핵심 요소는 다음 섹션에서 설명할 메모리 배리어입니다.
\iffalse

In short, lockless techniques are quite useful and are heavily used.

However, it is best if lockless techniques are hidden behind a
well-defined API, such as the \co{inc_count()}, \co{memblock_alloc()},
\co{rcu_read_lock()}, and so on.
The reason for this is that undisciplined use of lockless techniques
is a good way to create difficult bugs.
If you don't believe that avoiding such bugs is easier than finding
and fixing them, please re-read
Chapters~\ref{chp:Validation} and~\ref{chp:Formal Verification}.

A key component of many lockless techniques is the memory barrier,
which is described in the following section.
\fi

% \input{advsync/rcu} % @@@ need to clean up the files referenced.
\input{advsync/memorybarriers}

\section{Non-Blocking Synchronization}
\label{sec:advsync:Non-Blocking Synchronization}

\emph{non-blocking synchronization} (NBS) 라는 용어는
\emph{진행 보장사항 (forward-progress guarantee)} 들을 달리 하는, 6개의
linearizable 알고리즘 클래스들을 말합니다.
이 진행 보장사항 들은 리얼타임 프로그래밍 (Real-time programming) 의 근간을
형성하는 그것들과는 직교적입니다:
\iffalse

The term \emph{non-blocking synchronization} (NBS) describes six classes of
linearizable algorithms with differing \emph{forward-progress guarantees}.
These forward-progress guarantees are orthogonal to those that form the
basis of real-time programming:
\fi

\begin{enumerate}
\item	리얼타임 진행 보장사항들은 그것들과 관련된 분명한 시간을 갖는데, 예를
	들어, ``스케쥴링 대기시간은 100 마이크로세컨드 보다 작아야 한다.'' 같은
	것입니다.
	반면, 가장 인기있는 형태의 NBS 는 분명한 최대 제한 없이 유한한 시간
	내에 진행이 이뤄질 것만을 보장합니다.
\item	리얼타임 진행 보장사항들은 간혹 확률적인데, 소프트 리얼타임 보장사항은
	``최소 99.9\% 의 경우 스케쥴링 대기시간은 100 마이크로세컨드 이내여야
	한다.'' 와 같은 식입니다.
	반면, NBS 의 진행 보장사항은 전통적으로 무조건적입니다.
\item	리얼타임 진행 보장사항은 종종 환경 제약에 조건적인데, 예를 들어, 각 CPU
	가 최소한 어떤 특정한 양의 시간을 아무일도 하지 않고 보내거나, I/O 의
	비율이 특정 최대치 미만인 경우 가장 높은 우선순위의 작업들만이 그
	보장을 받게 됩니다.
	반면, NBS 의 진행 보장사항은 보통 무조건적입니다.\footnote{
		아래에서 보게 되겠지만, 최근의 일부 NBS 는 이 보장사항을
		완화시켰습니다.}
\item	리얼타임 진행 보장사항은 보통 소프트웨어 버그가 없을 때에만 적용됩니다.
	반면, 대부분의 NBS 보장사항은 멈춰버리는 버그가 있더라도 적용
	가능합니다.\footnote{
		다시 말하지만, 최근의 일부 NBS 는 이 보장사항을 완화했습니다.}
\item	NBS 진행 보장사항은 linearizability 를 내포합니다.
	반면, 리얼타임 진행 보장사항은 linearizability 와 같은 순서 제약과
	무관합니다.
\end{enumerate}
\iffalse

\item	Real-time forward-progress guarantees usually have some
	definite time associated with them, for example,
	``scheduling latency must be less than 100 microseconds.''.
	In contrast, the most popular forms of NBS only guarantees
	that progress will be made in finite time, with no definite
	bound.
\item	Real-time forward-progress guarantees are sometimes
	probabilistic, as in the soft-real-time guarantee that
	``at least 99.9\% of the time, scheduling latency must
	be less than 100 microseconds.''.
	In contrast, NBS's forward-progress
	guarantees have traditionally been unconditional.
\item	Real-time forward-progress guarantees are often conditioned on
	environmental constraints, for example, only being honored
	for the highest-priority tasks, when each CPU spends at least
	a certain fraction of its time idle, or when I/O rates are
	below some specified maximum.
	In contrast, NBS's forward-progress
	guarantees are usually unconditional.\footnote{
		As we will see below, some recent NBS work relaxes
		this guarantee.}
\item	Real-time forward-progress guarantees usually apply only
	in the absence of software bugs.
	In contrast, most NBS guarantees apply even in the face of
	fail-stop bugs.\footnote{
		Again, some recent NBS work relaxes this guarantee.}
\item	NBS forward-progress guarantee classes imply linearizability.
	In contrast, real-time forward progress guarantees are often
	independent of ordering constraints such as linearizability.
\end{enumerate}
\fi

이런 차이에도 불구하고, 여러 NBS 알고리즘들은 리얼타임 프로그램에 상당히
유용합니다.

현재 NBS 계층~\cite{DanAlitarh2013PracticalProgress} 에는 7개의 단계가 있는데,
간략히 설명하자면 다음과 같습니다:
\iffalse

Despite these differences, a number of NBS algorithms are extremely
useful in real-time programs.

There are currently seven levels in the NBS
hierarchy~\cite{DanAlitarh2013PracticalProgress}, which are roughly
as follows:
\fi

\begin{enumerate}
\item	\emph{Bounded wait-free synchronization}: 모든 쓰레드는 특정한 유한한
	시간 내에 진행을 만들어낸다~\cite{Herlihy91}.
	(이 레벨은 대부분의 사람들로부터 불가능할 것으로 여겨지는데, Alitarh
	등~\cite{DanAlitarh2013PracticalProgress} 이 해내지 못한 이유일 수도
	있습니다.)
\item	\emph{Wait-free synchronization}: 모든 쓰레드는 유한한 시간 내에 진행을
	만들어낸다~\cite{Herlihy93}.
\item	\emph{Lock-free synchronization}: 최소한 한 쓰레드는 유한한 시간 내에
	진행을 만들어낸다~\cite{Herlihy93}.
\item	\emph{Obstruction-free synchronization}: 경쟁이 없다면 모든 쓰레드가
	유한한 시간 내에 진행을 만들어낸다~\cite{HerlihyLM03}.
\item	\emph{Clash-free synchronization}: 경쟁이 없다면 최소한 하나의 쓰레드는
	유한한 시간 내에 진행을
	만들어낸다~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Starvation-free synchronization}: 실패가 없다면 모든 쓰레드가
	유한한 시간 내에 진행을
	만들어낸다~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Deadlock-free synchronization}: 실패가 없다면 적어도 하나의
	쓰레드는 유한한 시간 내에 진행을
	만들어낸다~\cite{DanAlitarh2013PracticalProgress}.
\end{enumerate}
\iffalse

\item	\emph{Bounded wait-free synchronization}: Every thread
	will make progress within
	a specific finite period of time~\cite{Herlihy91}.
	(Note that this level is 
	widely considered to be unachievable, which might be why
	Alitarh et al.~\cite{DanAlitarh2013PracticalProgress}
	omitted it.)
\item	\emph{Wait-free synchronization}: Every thread will make progress
	in finite time~\cite{Herlihy93}.
\item	\emph{Lock-free synchronization}: At least one thread will
	make progress in finite time~\cite{Herlihy93}.
\item	\emph{Obstruction-free synchronization}: Every thread will
	make progress in finite time in the absence of
	contention~\cite{HerlihyLM03}.
\item	\emph{Clash-free synchronization}: At least one thread will
	make progress in finite time in the absence of
	contention~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Starvation-free synchronization}: Every thread will
	make progress in finite time in the absence of
	failures~\cite{DanAlitarh2013PracticalProgress}.
\item	\emph{Deadlock-free synchronization}: At least one thread will
	make progress in finite time in the absence of
	failures~\cite{DanAlitarh2013PracticalProgress}.
\end{enumerate}
\fi

NBS 클래스~1, 2 그리고 3 은 1990년대 초, 클래스~4 는 2000년대 초, 그리고
클래스~5 는 2013년에 처음 입안되었습니다.
마지막 두개의 클래스들은 수십년동안 비공식적으로 사용되어왔습니다만 2013년에
들어 다시 입안되었습니다.

이론적으로는 어떤 병렬 알고리즘도 wait-free 형태로 변형될 수 있습니다만, 흔히
사용되는 NBS 알고리즘들의 부분집합은 상대적으로 작은 편입니다.
이것들 중 일부가 다음 섹션에서 설명됩니다.
\iffalse

NBS classes~1, 2 and~3 were first formulated in the early 1990s,
class~4 was first formulated in the early 2000s,
and class~5 was first formulated in 2013.
The final two classes have seen informal use for a great many decades,
but were reformulated in 2013.

In theory, any parallel algorithm can be cast into wait-free form,
but there are a relatively small subset of NBS algorithms that are
in common use.
A few of these are listed in the following section.
\fi

\subsection{Simple NBS}
\label{sec:advsync:Simple NBS}

아마도 가장 단순한 NBS 알고리즘은 fetch-and-add(\co{atomic_add_return()})
기능을 이용한 정수 카운터의 어토믹한 업데이트일 것입니다.

또다른 간단한 NBS 알고리즘은 한 배열 안의 정수들의 집합입니다.
여기서 배열 인덱스는 해당 집합의 멤버일 값을 가리키고 배열의 원소들은 해당 값이
실제로 집합의 멤버인지 아닌지를 알립니다.
NBS 알고리즘을 위한 Linearizability 규범은 이 배열에의 읽기와 쓰기가 어토믹
인스트럭션을 사용하거나 메모리 배리어를 수반할 것을 요구합니다만
linearizability 가 그다지 중요하지 않은, 그렇게 희귀하지도 않은 경우들에서는
간단한 volatile 로드와 스토어만으로도 충분한데, \co{ACCESS_ONCE()} 의 사용이 한
예일 것입니다.
\iffalse

Perhaps the simplest NBS algorithm is atomic update of an integer
counter using fetch-and-add (\co{atomic_add_return()}) primitives.

Another simple NBS algorithm implements a set of integers in an array.
Here the array index indicates a value that might be a member of the set
and the array element indicates whether or not that value actually is
a set member.
The linearizability criterion for NBS algorithms requires that reads from
and updates to the array either use atomic instructions or be accompanied
by memory barriers, but in the not-uncommon case where linearizability
is not important, simple volatile loads and stores suffice, for example,
using \co{ACCESS_ONCE()}.
\fi

NBS 집합은 비트맵을 이용해 구현될 수도 있을 텐데, 해당 집합의 멤버인 값은
하나의 비트와 연관될 것입니다.
읽기와 업데이트는 일반적으로 어토믹한 비트 조작 인스트럭션들로 이루어져야만
합니다만 compare-and-swap (\co{cmpxchg()} 또는 CAS) 인스트럭션 또한 사용될 수
있습니다.

Section~\ref{sec:count:Statistical Counters} 에서 이야기 되었던 통계적 카운터
알고리즘은 그 합이 정확하지는 않고 대략적이라는 분명한 트릭을 사용할 때라면
wait-free 로 간주될 수 있습니다.\footnote{
	인용이 필요합니다.
	전 이 트릭을 Mark Moir 로부터 구두로 들었습니다.}
\co{read_count()} 함수가 카운터들의 합을 구하는데 갖는 시간의 길이의 기능인
충분히 큰 에러 한계들을 감안하면, 어떤 linearizable 하지 않은 동작이 일어났음을
증명하는 것은 불가능합니다.
이는 분명히 (약간 인위적이라면) 이 통계적 카운터 알고리즘을 wait-free 로
분류합니다.
이 알고리즘은 아마도 리눅스 커널에서 가장 많이 사용하는 NBS 알고리즘입니다.
\iffalse

An NBS set may also be implemented using a bitmap, where each value that
might be a member of the set corresponds to one bit.
Reads and updates must normally be carried out via atomic bit-manipulation
instructions, although compare-and-swap (\co{cmpxchg()} or CAS)
instructions can also be used.

The statistical counters algorithm discussed in
Section~\ref{sec:count:Statistical Counters}
can be considered wait-free, but only but using a cute definitional trick
in which the sum is considered approximate rather than exact.\footnote{
	Citation needed.
	I hear of this trick verbally from Mark Moir.}
Given sufficiently wide error bounds that are a function of the length
of time that the \co{read_count()} function takes to sum the counters,
it is not possible to prove that any non-linearizable behavior occurred.
This definitely (if a bit artificially) classifies the statistical-counters
algorithm as wait-free.
This algorithm is probably the most heavily used NBS algorithm in
the Linux kernel.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbbox}
 1 static inline bool
 2 ___cds_wfcq_append(struct cds_wfcq_head *head,
 3                    struct cds_wfcq_tail *tail,
 4                    struct cds_wfcq_node *new_head,
 5                    struct cds_wfcq_node *new_tail)
 6 {
 7   struct cds_wfcq_node *old_tail;
 8 
 9   old_tail = uatomic_xchg(&tail->p, new_tail);
10   CMM_STORE_SHARED(old_tail->next, new_head);
11   return old_tail != &head->node;
12 }
13 
14 static inline bool
15 _cds_wfcq_enqueue(struct cds_wfcq_head *head,
16                   struct cds_wfcq_tail *tail,
17                   struct cds_wfcq_node *new_tail)
18 {
19   return ___cds_wfcq_append(head, tail,
20                             new_tail, new_tail);
21 }
\end{verbbox}
}
\centering
\theverbbox
\caption{NBS Enqueue Algorithm}
\label{fig:count:NBS Enqueue Algorithm}
\end{figure}

또다른 흔한 NBS 알고리즘은 하나의 어토믹한 큐로, 원소들의 추가는 어토믹한 교체
인스트럭션~\cite{MagedMichael1993JPDC} 을 사용하고, 이어서 새 원소의
\co{->next} 포인터를 저장하는데, 이는 유저스페이스-RCU 라이브러리
구현~\cite{MathieuDesnoyers2009URCU} 인 Figure~\ref{fig:count:NBS Enqueue
Algorithm} 에 나와 있습니다.
Line~9 는 tail 포인터가 새 원소를 가리키도록 업데이트 하면서 그 앞의 것으로의
레퍼런스를 리턴하는데, 이 값은 로컬 변수 \co{old_tail} 에 저장됩니다.
Line~10 은 이제 앞의 원소의 \co{->next} 포인터가 새로 추가된 원소를 가리키도록
업데이트 하며, 마지막으로 line~11 에서 해당 큐가 원래 비어있었는지 여부를
리턴합니다.
\iffalse

Another common NBS algorithm is the atomic queue where elements are
enqueued using an atomic exchange instruction~\cite{MagedMichael1993JPDC},
followed by a store into the \co{->next} pointer of the new element's
predecessor, as shown in
Figure~\ref{fig:count:NBS Enqueue Algorithm},
which shows the userspace-RCU library
implementation~\cite{MathieuDesnoyers2009URCU}.
Line~9 updates the tail pointer to reference the new element while
returning a reference to its predecessor, which is stored in
local variable \co{old_tail}.
Line~10 then updates the predecessor's \co{->next} pointer to
reference the newly added element, and finally line~11
returns an indication as to whether or not the queue was initially
empty.
\fi

하나의 원소를 꺼내기 위해선 상호 배타성이 필요하지만 (따라서 꺼내기 적업은
블락됩니다), 큐의 전체 컨텐츠를 제거하는 일은 블락킹하지 않게도 할 수 있습니다.
불가능한 것은 어떤 주어진 원소를 블락킹하지 않는 방법으로 꺼내는 것입니다:
원소를 넣는 쪽은 line~9 와 10 에서 실패할 것이고, 따라서 요청된 원소는
부분적으로만 추가되었을 것입니다.
이로 인해 원소를 집어넣는 작업은 NBS 지만 꺼내는 것은 블락킹되는 반만 NBS 인
알고리즘으로 귀결됩니다.
이 알고리즘은 실제 상황에서 사용되지는 않는데, 대부분의 상품화된 소프트웨어는
임의의 fail-stop 에러들을 견뎌내도록 요구되지는 않기 때문입니다.
\iffalse

Although mutual exclusion is required to dequeue a single element
(so that dequeue is blocking), it is possible to carry out a non-blocking
removal of the entire contents of the queue.
What is not possible is to dequeue any given element in a non-blocking
manner: The enqueuer might have failed between lines~9 and~10 of the
figure, so that the element in question is only partially enqueued.
This results in a half-NBS algorithm where enqueues are NBS but
dequeues are blocking.
This algorithm is nevertheless used in practice, in part because
most production software is not required to tolerate arbitrary fail-stop
errors.
\fi

\subsection{NBS Discussion}
\label{sec:advsync:NBS Discussion}

완전히 블락킹 없는 큐~\cite{MichaelScott96} 를 만드는 건 가능합니다만, 그런
큐들은 앞의 반만 NBS 인 알고리즘에 비해 훨씬 복잡합니다.
여기서 얻을 수 있는 교훈은 당신에게 정말로 요구되는 것이 무엇인지 주의깊게
생각해 봐야 한다는 것입니다.
무의미한 요구사항을 완화시키는 것은 간단성과 성능에서 커다란 개선을 가져올 수
있습니다.

최근의 연구는 요구사항들을 완화시키기 위한 또다른 중요한 방법을 이야기합니다.
공정한 (fair) 스케쥴링을 제공하는 시스템들은 wait-free 동기화의 장점 대부분을
심지어 블락킹 하지 않는 동기화만 제공하는 알고리즘을 사용할 때에도 얻을 수
있다고 이론~\cite{DanAlitarh2013PracticalProgress} 과
실제~\cite{SamyAlBahra2013NBS} 에서 모두 이야기 합니다.
상품화된 단계에서 사용되는 매우 많은 스케쥴러들이 실제로 공정성 (fairness) 을
제공하므로, wait-free 동기화를 제공하는 더 복잡한 알고리즘들은 일반적으로 더
간단하고 많은 경우 더 빠른 블락킹하지 않는 동기화 알고리즘들에 비해 실제
환경에서 더 나은 점을 제공하지 못하곤 합니다.
\iffalse

It is possible to create fully non-blocking queues~\cite{MichaelScott96},
however, such queues are much more complex than the half-NBS algorithm
outlined above.
The lesson here is to carefully consider what your requirements really are.
Relaxing irrelevant requirements can often result in great
improvements in both simplicity and performance.

Recent research points to another important way to relax requirements.
It turns out that systems providing fair scheduling can enjoy most
of the benefits of wait-free synchronization even when running
algorithms that provide only non-blocking
synchronization, both in theory~\cite{DanAlitarh2013PracticalProgress}
and in practice~\cite{SamyAlBahra2013NBS}.
Because a great many schedulers used in production do in fact
provide fairness,
the more-complex algorithms providing wait-free synchronization
usually provide no practical advantages over their simpler
and often faster non-blocking-synchronization counterparts.
\fi

흥미롭게도, 공정한 스케쥴링은 실제 상황에서 고려되는 이익적 제약들 중 하나일
뿐입니다.
다른 제약의 집합들은 블락킹 알고리즘들이 결정론적 리얼타임 반응을 달성할 수
있게 할 수 있습니다.
예를 들어, 그 획득이 주어진 우선순위에 따라 FIFO 순서로 이루어지게 하는 공정한
(fair) 락, (우선순위
상속~\cite{Takada:1995:RSN:527074.828566,Cai-DongWang1996PrioInherLock} 이나
우선순위 한도 문제와 같은) 우선순위 역전 문제를 회피하는 방법, 제한된 숫자의
쓰레드들, 제한된 크리티컬 섹션들, 제한된 부하량, 그리고 fail-stop 버그들의
회피가 주어진다면, 락 기반의 어플리케이션들은 결정론적 반응 시간을 제공할 수
있습니다~\cite{BjoernBrandenburgPhD}.
% @@@ Check dissertation details once internet is available.
물론 이런 시도는 블락킹과 wait-free 동기화 사이의 차이점을 흐리게 만드는데,
좋은 현상입니다.
이론적인 뼈대가 자랄수록, 소프트웨어가 실제로 현장에서 어떻게 구성되는지
설명하는 능력도 증가할 것입니다.
\iffalse

Interestingly enough, fair scheduling is but one beneficial
constraint that is often respected in practice.
Other sets of constraints can permit blocking algorithms to
achieve deterministic real-time response.
For example, given fair locks that are granted to requesters in FIFO order at
a given priority level,
a method of avoiding priority inversion (such as priority
inheritance~\cite{Takada:1995:RSN:527074.828566,Cai-DongWang1996PrioInherLock}
or priority ceiling), a bounded number of threads,
bounded critical sections,
bounded load,
and avoidance of fail-stop bugs,
lock-based applications can provide deterministic
response times~\cite{BjoernBrandenburgPhD}.
% @@@ Check dissertation details once internet is available.
This approach of course blurs the distinction between blocking and wait-free
synchronization, which is all to the good.
Hopefully theoeretical frameworks continue to grow, further increasing
their ability to
describe how software is actually constructed in practice.
\fi
