% appendix/toyrcu/toyrcu.tex
% mainfile: ../../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\QuickQuizChapter{chp:app:``Toy'' RCU Implementations}{``Toy'' RCU Implementations}{qqztoyrcu}
%
\Epigraph{The only difference between men and boys is the price of their toys.}
	 {\emph{M. H\'ebert}}
% https://www.ncbi.nlm.nih.gov/pubmed/11548147

이 부록의 toy RCU 구현은 높은 성능, 실용성, 또는 어떤 종류의 제품 단계에서의
사용을 위해서가 아닌\footnote{
	그러나, 제품 품질의 사용자 레벨 RCU 구현이
	있습니다~\cite{MathieuDesnoyers2009URCU,MathieuDesnoyers2012URCU}.}
명료성을 위해 설계되었습니다.
그러나, 여러분은 이 toy RCU 구현을 쉽게 이해하기 위해서라도
\cref{chp:Introduction,%
chp:Hardware and its Habits,%
chp:Tools of the Trade,%
cha:Partitioning and Synchronization Design,%
chp:Deferred Processing}
에 대한 깊은 이해를 필요로 할 겁니다.

\iffalse

The toy RCU implementations in this appendix are designed not for
high performance, practicality, or any kind of production use,\footnote{
	However, production-quality user-level RCU implementations
	are available~\cite{MathieuDesnoyers2009URCU,MathieuDesnoyers2012URCU}.}
but rather for clarity.
Nevertheless, you will need a thorough understanding of
\cref{chp:Introduction,%
chp:Hardware and its Habits,%
chp:Tools of the Trade,%
cha:Partitioning and Synchronization Design,%
chp:Deferred Processing}
for even these toy RCU implementations to be easily understandable.

\fi

이 부록은 RCU 구현 시리즈를 존재 보장 문제 해결의 관점에서 정교도를 높여가는
순서로 제공합니다.
\Cref{sec:app:toyrcu:Lock-Based RCU} 는 간단한 락킹에 기반한 간단한 RCU 구현을
보이고,
\crefthro{sec:app:toyrcu:Per-Thread Lock-Based RCU}
{sec:app:toyrcu:RCU Based on Quiescent States}
에서는 락킹,
\IXalt{reference counters}{reference count},
그리고 free-running 카운터에 기반한 RCU 구현 시리즈를 제공합니다.
마지막으로, \cref{sec:app:toyrcu:Summary of Toy RCU Implementations}
는 요약과 바람직한 RCU 속성의 나열을 제공합니다.

\iffalse

This appendix provides a series of RCU implementations in order of
increasing sophistication, from the viewpoint of solving the
existence-guarantee problem.
\Cref{sec:app:toyrcu:Lock-Based RCU} presents a rudimentary
RCU implementation based on simple locking, while
\crefthro{sec:app:toyrcu:Per-Thread Lock-Based RCU}
{sec:app:toyrcu:RCU Based on Quiescent States}
present a series of
simple RCU implementations based on locking, reference counters,
and free-running counters.
Finally, \cref{sec:app:toyrcu:Summary of Toy RCU Implementations}
provides a summary and a list of desirable RCU properties.

\fi

\section{Lock-Based RCU}
\label{sec:app:toyrcu:Lock-Based RCU}
\NoIndentAfterThis

\begin{listing}[htbp]
\input{CodeSamples/defer/rcu_lock@lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_lock@synchronize.fcv}\fvset{firstnumber=auto}
\caption{Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Lock-Based RCU Implementation}
\end{listing}

아마도 가장 간단한 RCU 구현은
\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
(\path{rcu_lock.h} 와 \path{rcu_lock.c}) 에 보인 것처럼 락을 사용하는 것일
겁니다.
이 구현에서, \co{rcu_read_lock()} 은 전역 spinlock 하나를 획득하고
\co{rcu_read_unlock()} 은 이를 해제하며, \co{synchronize_rcu()} 는 이 락을
획득하고는 곧바로 내려놓습니다.

\iffalse

Perhaps the simplest RCU implementation leverages locking, as
shown in
\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
(\path{rcu_lock.h} and \path{rcu_lock.c}).
In this implementation, \co{rcu_read_lock()} acquires a global
spinlock, \co{rcu_read_unlock()} releases it, and
\co{synchronize_rcu()} acquires it then immediately releases it.

\fi

\co{synchronize_rcu()} 는 락을 획득하기 (그리고 내려놓기) 전까지는 리턴하지
않으므로, 앞의 모든 RCU read-side 크리티컬 섹션이 완료되기 전까지는 리턴될 수
없고, 따라서 RCU semantic 을 완전히 구현합니다.
물론, 한번에 하나의 RCU 읽기 쓰레드만이 read-side 크리티컬 섹션에 들어가 있을
수 있는데, 이는 RCU 의 목적을 완전히 놓치는 것입니다.
또한, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 에서의 락 오퍼레이션은
굉장히 무거워서, read-side 오버헤드는 한개의 \Power{5} CPU 에서의
100~나노세컨드에서 64-CPU 시스템에서의 17~\emph{마이크로세컨드} 까지를
오갑니다.
더 나쁜게, 이 락 오퍼레이션은 \co{rcu_read_lock()} 이 데드락 사이클에 낄 수
있게 합니다.
더 나아가, 회귀적 락의 부재 시, RCU read-side 크리티컬 섹션은 중첩될 수 없고,
마지막으로, 동시의 RCU 업데이트는 흔한 grace priod 에 의해 완료되겠지만 이
구현은 grace period 들을 순차화 시켜서 grace-period 공유를 금지합니다.

\iffalse

Because \co{synchronize_rcu()} does not return until it has acquired
(and released) the lock, it cannot return until all prior RCU read-side
critical sections have completed, thus faithfully implementing
RCU semantics.
Of course, only one RCU reader may be in its read-side critical section
at a time, which almost entirely defeats the purpose of RCU\@.
In addition, the lock operations in \co{rcu_read_lock()} and
\co{rcu_read_unlock()} are extremely heavyweight,
with read-side overhead ranging from about 100~nanoseconds on a single \Power{5}
CPU up to more than 17~\emph{microseconds} on a 64-CPU system.
Worse yet,
these same lock operations permit \co{rcu_read_lock()}
to participate in deadlock cycles.
Furthermore, in absence of recursive locks,
RCU read-side critical sections cannot be nested, and, finally,
although concurrent RCU updates could in principle be satisfied by
a common grace period, this implementation serializes grace periods,
preventing grace-period sharing.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	왜
	\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
	에서의 RCU 구현 내의 모든 데드락은 다른 RCU 구현에서도 데드락이지
	않을까요?

	\iffalse

	Why wouldn't any deadlock in the RCU implementation in
	\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
	also be a deadlock in any other RCU implementation?

	\fi

}\QuickQuizAnswerB{
	\begin{fcvref}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
	\Cref{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation}
	에서의 함수 \co{foo()} 와 \co{bar()} 가 다른 CPU 에서 동시에
	호출되었다고 해봅시다.
	그럼 \co{foo()} 는 \clnref{foo:acq} 에서 \co{my_lock()} 을 획득하고,
	\clnref{bar:rrl} 에서 \co{bar()} 는 \co{rcu_gp_lock} 을 획득합니다.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
	Suppose the functions \co{foo()} and \co{bar()} in
	\cref{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation}
	are invoked concurrently from different CPUs.
	Then \co{foo()} will acquire \co{my_lock()} on \clnref{foo:acq},
	while \co{bar()} will acquire \co{rcu_gp_lock} on
	\clnref{bar:rrl}.
	\end{fcvref}

	\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
\begin{VerbatimL}[commandchars=\\\[\]]
void foo(void)
{
	spin_lock(&my_lock);		\lnlbl[foo:acq]
	rcu_read_lock();		\lnlbl[foo:rrl]
	do_something();
	rcu_read_unlock();
	do_something_else();
	spin_unlock(&my_lock);
}

void bar(void)
{
	rcu_read_lock();		\lnlbl[bar:rrl]
	spin_lock(&my_lock);		\lnlbl[bar:acq]
	do_some_other_thing();
	spin_unlock(&my_lock);
	do_whatever();
	rcu_read_unlock();
}
\end{VerbatimL}
\end{fcvlabel}
\caption{Deadlock in Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation}
\end{listing}

	\begin{fcvref}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
	\co{foo()} 가 \clnref{foo:rrl} 로 나아가면, \co{bar()} 가 잡고 있는
	\co{rcu_gp_lock} 을 획득하려 시도할 겁니다.
	그러면 \co{bar()} 가 \clnref{bar:acq} 로 나아갈 때, \co{foo()} 가 잡고
	있는 \co{my_lock} 을 획득하려 할 겁니다.
	\end{fcvref}

	그럼 각 함수는 서로가 잡고 있는 락을 기다리므로, 고전적인 데드락이
	됩니다.

	다른 RCU 구현은 \co{rcu_read_lock()} 에서 spin 하지도 block 하지도
	않으므로 데드락이 회피됩니다.

	\iffalse

	\begin{fcvref}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
	When \co{foo()} advances to \clnref{foo:rrl}, it will attempt to
	acquire \co{rcu_gp_lock}, which is held by \co{bar()}.
	Then when \co{bar()} advances to \clnref{bar:acq}, it will attempt
	to acquire \co{my_lock}, which is held by \co{foo()}.
	\end{fcvref}

	Each function is then waiting for a lock that the other
	holds, a classic deadlock.

	Other RCU implementations neither spin nor block in
	\co{rcu_read_lock()}, hence avoiding deadlocks.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	\Cref{lst:app:toyrcu:Lock-Based RCU Implementation}
	의 RCU 구현에서는 왜 RCU 읽기 쓰레드들이 병렬로 수행될 수 있게끔 단순히
	reader-writer 락을 사용하지 않죠?

	\iffalse

	Why not simply use reader-writer locks in the RCU implementation
	in
	\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
	in order to allow RCU readers to proceed in parallel?

	\fi

}\QuickQuizAnswerE{
	실제로 그런 방식으로 reader-writer 락을 사용할 수 있을 겁니다.
	그러나, 교재 상의 reader-writer 락은 메모리 경쟁으로 고통받으므로, 병렬
	수행을 실제로 허용하기 위해선 RCU read-side 크리티컬 섹션이 상당히
	길어져야 할 겁니다~\cite{McKenney03a}.

	다른 한편, \co{rcu_read_lock()} 에서 읽기 모드로 획득된 reader-writer
	락의 사용은 앞서 언급된 데드락 조건을 막을 겁니다.

	\iffalse

	One could in fact use reader-writer locks in this manner.
	However, textbook reader-writer locks suffer from memory
	contention, so that the RCU read-side critical sections would
	need to be quite long to actually permit parallel
	execution~\cite{McKenney03a}.

	On the other hand, use of a reader-writer lock that is
	read-acquired in \co{rcu_read_lock()} would avoid the
	deadlock condition noted above.

	\fi

}\QuickQuizEndE
}

이 구현이 제품 단계 환경에서 유용할 거라 상상하긴 어렵지만 거의 모든 사용자
단계 어플리케이션에서 구현될 수 있다는 장점을 갖추고 있긴 합니다.
더 나아가, CPU 별 락 또는 reader-writer 락을 사용하는 비슷한 구현이 2.4 리눅스
커널에 의해 제품 단계에서 사용된 바 있습니다.

이 CPU 별 락 방법의 쓰레드별 락으로 수정된 버전이 다음 섹션에서 설명됩니다.

\iffalse

It is hard to imagine this implementation being useful
in a production setting, though it does have the virtue
of being implementable in almost any user-level application.
Furthermore, similar implementations having one lock per CPU
or using reader-writer locks have been used in production
in the 2.4 Linux kernel.

A modified version of this one-lock-per-CPU approach, but instead using
one lock per thread, is described
in the next section.

\fi

\section{Per-Thread Lock-Based RCU}
\label{sec:app:toyrcu:Per-Thread Lock-Based RCU}

\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
(\path{rcu_lock_percpu.h} 와 \path{rcu_lock_percpu.c})
가 쓰레드별 락에 기반한 구현을 보입니다.
\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 함수는 현재 쓰레드의 락을 각각
획득하고 해제합니다.
\co{synchronize_rcu()} 함수는 각 쓰레드의 락을 순서대로 획득하고 해제합니다.
따라서, \co{synchronize_rcu()} 기 시작할 때 수행되고 있던 모든 RCU read-side
크리티컬 섹션은 \co{synchronize_rcu()} 가 리턴하기 전에 완료되어야만 합니다.

\iffalse

\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
(\path{rcu_lock_percpu.h} and \path{rcu_lock_percpu.c})
shows an implementation based on one lock per thread.
The \co{rcu_read_lock()} and \co{rcu_read_unlock()} functions
acquire and release, respectively, the current thread's lock.
The \co{synchronize_rcu()} function acquires and releases each thread's
lock in turn.
Therefore, all RCU read-side critical sections running
when \co{synchronize_rcu()} starts must have completed before
\co{synchronize_rcu()} can return.

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_lock_percpu@lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_lock_percpu@sync.fcv}\fvset{firstnumber=auto}
\caption{Per-Thread Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
\end{listing}

이 구현은 동시의 RCU 읽기 쓰레드를 허용하는 장점을 갖추고 있으며, 단일 전역
락에서는 일어날 수 있는 데드락 조건을 막습니다.
더 나아가, read-side 오버헤드는 약 140 나노세컨드로 높지만, CPU 의 수에 상관
없이 약 140 나노세컨드로 유지됩니다.
그러나, update-side 오버헤드는 단일 \Power{5} CPU 에서의 600 나노세컨드에서 64
CPU 에서의 100 \emph{마이크로세컨드} 까지를 오갑니다.

\iffalse

This implementation does have the virtue of permitting concurrent
RCU readers, and does avoid the deadlock condition that can arise
with a single global lock.
Furthermore, the read-side overhead, though high at roughly 140 nanoseconds,
remains at about 140 nanoseconds regardless of the number of CPUs.
However, the update-side overhead ranges from about 600 nanoseconds
on a single \Power{5} CPU
up to more than 100 \emph{microseconds} on 64 CPUs.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	\begin{fcvref}[ln:defer:rcu_lock_percpu:sync:loop]
	\Cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	의 \clnrefrange{b}{e} 에서의 반복문에서는 모든 락을 획득한 후 한번에
	해제하는게 더 깔끔하지 않을까요?
	어쨌건, 이 변경으로 인해 어떤 읽기 쓰레드도 존재하지 않는 시점이
	존재하게 되어서 모든 것을 훨씬 간단하게 만들 겁니다.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_lock_percpu:sync:loop]
	Wouldn't it be cleaner to acquire all the locks, and then
	release them all in the loop from \clnrefrange{b}{e} of
	\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}?
	After all, with this change, there would be a point in time
	when there were no readers, simplifying things greatly.
	\end{fcvref}

	\fi

}\QuickQuizAnswerB{
	이 변경을 가하는 것은 데드락을 다시 불러일으키며, 따라서 아니오, 그건
	더 깔끔하지 않습니다.

	\iffalse

	Making this change would re-introduce the deadlock, so
	no, it would not be cleaner.

	\fi

}\QuickQuizEndB
%
\QuickQuizM{
	\Cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	에 보인 구현은 데드락으로부터 자유로운가요?
	이유는 뭐죠?

	\iffalse

	Is the implementation shown in
	\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	free from deadlocks?
	Why or why not?

	\fi

}\QuickQuizAnswerM{
	한가지 데드락 상황은 어떤 락이 \co{synchronize_rcu()} 에 걸쳐 잡혀져
	있으며, 같은 락이 어떤 RCU read-side 크리티컬 섹션에 의해 획득될 때일
	겁니다.
	그러나, 이 상황은 모든 올바르게 설계된 RCU 구현을 데드락에 빠지게 할
	겁니다.
	어쨌건, \co{synchronize_rcu()} 기능은 모든 앞서 존재했던 RCU read-side 
	크리티컬 섹션이 완료되길 기다려야만 하지만, 이 크리티컬 섹션들 가운데
	하나가 \co{synchronize_rcu()} 가 수행중인 쓰레드에 의해 잡힌 락을
	기다린다면, RCU 의 정의에 내재한 데드락을 갖게 됩니다.

	또다른 데드락 상황은 RCU read-side 크리티컬 섹션을 중첩시키려 할 때
	발생합니다.
	이 데드락은 이 구현에만 있으며, 재귀 락을 사용하거나
	\co{rcu_read_lock()} 에 의해 읽기 모드로 획득되고
	\co{synchronize_rcu()} 에 의해 쓰기 모드로 획득되는 reader-writer 락의
	사용으로 회피될 수도 있을 겁니다.

	\iffalse

	One deadlock is where a lock is
	held across \co{synchronize_rcu()}, and that same lock is
	acquired within an RCU read-side critical section.
	However, this situation could deadlock any correctly designed
	RCU implementation.
	After all, the \co{synchronize_rcu()} primitive must wait for all
	pre-existing RCU read-side critical sections to complete,
	but if one of those critical sections is spinning on a lock
	held by the thread executing the \co{synchronize_rcu()},
	we have a deadlock inherent in the definition of RCU\@.

	Another deadlock happens when attempting to nest RCU read-side
	critical sections.
	This deadlock is peculiar to this implementation, and might
	be avoided by using recursive locks, or by using reader-writer
	locks that are read-acquired by \co{rcu_read_lock()} and
	write-acquired by \co{synchronize_rcu()}.

	\fi

	그러나, 앞의 두 경우를 배제한다면, 이 RCU 구현은 어떤 데드락 상황도
	초래하지 않습니다.
	이는 어떤 다른 쓰레드의 락이 획득된 시점은 \co{synchronize_rcu()} 가
	수행중일 때 뿐이며, 락은 곧바로 해제될 것이어서 앞의 첫번째 경우인,
	\co{synchronize_rcu()} 에 걸쳐 잡힌 락이 관여되는 데드락 사이클을
	방지하기 때문입니다.

	\iffalse

	However, if we exclude the above two cases,
	this implementation of RCU does not introduce any deadlock
	situations.
	This is because only time some other thread's lock is acquired is when
	executing \co{synchronize_rcu()}, and in that case, the lock
	is immediately released, prohibiting a deadlock cycle that
	does not involve a lock held across the \co{synchronize_rcu()}
	which is the first case above.

	\fi

}\QuickQuizEndM
%
\QuickQuizE{
	\Cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	에 보인 RCU 알고리즘의 한가지 장점은 예를 들면 POSIX pthreads 같은
	곳에서 널리 사용 가능한 기능만을 사용한다는 점일까요?

	\iffalse

	Isn't one advantage of the RCU algorithm shown in
	\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	that it uses only primitives that are widely available,
	for example, in POSIX pthreads?

	\fi

}\QuickQuizAnswerE{
	이는 실제로 장점입니다만, \co{rcu_dereference()} 와
	\co{rcu_assign_pointer()} 는 여전히 필요한데, \co{rcu_dereference()}
	에서의 \co{volatile} 조정과 \co{rcu_assign_pointer()} 에서의 메모리
	배리어 사용을 의미합니다.
	물론, 두 기능 모두 Alpha CPU 에서는 메모리 배리어가 필요할 겁니다.

	\iffalse

	This is indeed an advantage, but do not forget that
	\co{rcu_dereference()} and \co{rcu_assign_pointer()}
	are still required, which means \co{volatile} manipulation
	for \co{rcu_dereference()} and memory barriers for
	\co{rcu_assign_pointer()}.
	Of course, many Alpha CPUs require memory barriers for both
	primitives.

	\fi

}\QuickQuizEndE
}

이 방법은 비슷한 방법이 리눅스 2.4 커널에서 사용되었다는 점을 볼
때~\cite{Molnar00a} 일부 상황에서 유용할 수 있습니다.

이어서 소개될 카운터 기반 RCU 구현은 락 기반 구현의 단점들 일부를 극복합니다.

\iffalse

This approach could be useful in some situations, given that a similar
approach was used in the
Linux 2.4 kernel~\cite{Molnar00a}.

The counter-based RCU implementation described next overcomes some of
the shortcomings of the lock-based implementation.

\fi

\section{Simple Counter-Based RCU}
\label{sec:app:toyrcu:Simple Counter-Based RCU}

약간 더 진보된 RCU 구현이
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
(\path{rcu_rcg.h} 와 \path{rcu_rcg.c}) 에 보여 있습니다.
\begin{fcvref}[ln:defer:rcu_rcg]
이 구현은 \clnref{lock_unlock:grc} 에 정의된 전역 레퍼런스 카운터
\co{rcu_refcnt} 를 사용합니다.
\co{rcu_read_lock()} 기능은 이 카운터를 어토믹하게 증가시키고, RCU read-side
크리티컬 섹션이 이 어토믹 값 증가 뒤로 순서잡혔음을 보장하기 위해 메모리
배리어를 수행합니다.
비슷하게, \co{rcu_read_unlock()} 은 RCU read-side 크리티컬 섹션을 가두기 위해
메모리 배리어를 수행하고 이어서 이 카운터를 어토믹하게 감소시킵니다.
\co{synchronize_rcu()} 기능은 이 레퍼런스 카운터가 0이 되기를 메모리 배리어로
감싸진 가운데에서 기다립니다.
\Clnref{sync:poll} 의 \co{poll()} 은 그저 순수한 지연을 제공하며, 순수한 RCU
semantic 관점에서는 없어져도 됩니다.
다시 말하지만, 일단 \co{synchronize_rcu()} 가 리턴하면, 모든 앞의 RCU read-side
크리티컬 섹션은 완료되었을 것이 보장됩니다.
\end{fcvref}

\iffalse

A slightly more sophisticated RCU implementation is shown in
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
(\path{rcu_rcg.h} and \path{rcu_rcg.c}).
\begin{fcvref}[ln:defer:rcu_rcg]
This implementation makes use of a global reference counter
\co{rcu_refcnt} defined on \clnref{lock_unlock:grc}.
The \co{rcu_read_lock()} primitive atomically increments this
counter, then executes a memory barrier to ensure that the
RCU read-side critical section is ordered after the atomic
increment.
Similarly, \co{rcu_read_unlock()} executes a memory barrier to
confine the RCU read-side critical section, then atomically
decrements the counter.
The \co{synchronize_rcu()} primitive spins waiting for the reference
counter to reach zero, surrounded by memory barriers.
The \co{poll()} on \clnref{sync:poll} merely provides pure delay, and from
a pure RCU-semantics point of view could be omitted.
Again, once \co{synchronize_rcu()} returns, all prior
RCU read-side critical sections are guaranteed to have completed.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcg@lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_rcg@sync.fcv}\fvset{firstnumber=auto}
\caption{RCU Implementation Using Single Global Reference Counter}
\label{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
\end{listing}

\Cref{sec:app:toyrcu:Lock-Based RCU} 에 보인 락 기반 구현과의 행복한 대조로, 이
구현은 RCU read-side 크리티컬 섹션의 병렬 수행을 허용합니다.
\Cref{sec:app:toyrcu:Per-Thread Lock-Based RCU} 에 보인 쓰레드별 락 기반
구현과의 행복한 대조로, 이 구현은 또한 중첩을 허용합니다.
또한, \co{rcu_read_lock()} 기능은 데드락 사이클에 참여될 수 없는데, spin 도
block 도 하지 않기 때문입니다.

\iffalse

In happy contrast to the lock-based implementation shown in
\cref{sec:app:toyrcu:Lock-Based RCU}, this implementation
allows parallel execution of RCU read-side critical sections.
In happy contrast to the per-thread lock-based implementation shown in
\cref{sec:app:toyrcu:Per-Thread Lock-Based RCU},
it also allows them to be nested.
In addition, the \co{rcu_read_lock()} primitive cannot possibly
participate in deadlock cycles, as it never spins nor blocks.

\fi

\QuickQuiz{
	하지만 여러분이 \co{synchronize_rcu()} 호출 전반에 걸쳐 락을 잡고 있고,
	어떤 RCU read-side 크리티컬 섹션 내에서 같은 락을 잡으면 어떻게 될까요?

	\iffalse

	But what if you hold a lock across a call to
	\co{synchronize_rcu()}, and then acquire that same lock within
	an RCU read-side critical section?

	\fi

}\QuickQuizAnswer{
	실제로 이는 모든 합법적 RCU 구현에 데드락을 초래할 수 있습니다.
	하지만 \co{rcu_read_lock()} 은 \emph{정말로} 이 데드락 사이클에
	참여하고 있나요?
	그렇다고 믿는다면,
	\cref{sec:app:toyrcu:RCU Based on Quiescent States} 의 RCU 구현을 볼 때
	같은 질문을 스스로에게 해보세요.

	\iffalse

	Indeed, this would deadlock any legal RCU implementation.
	But is \co{rcu_read_lock()} \emph{really} participating in
	the deadlock cycle?
	If you believe that it is, then please
	ask yourself this same question when looking at the
	RCU implementation in
	\cref{sec:app:toyrcu:RCU Based on Quiescent States}.

	\fi

}\QuickQuizEnd

그러나, 이 구현은 여전히 심각한 단점이 있습니다.
첫째로, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 의 어토믹 오퍼레이션은
여전히 무거워서, read-side 오버헤드를 단일 \Power{5} CPU 에서의
100~나노세컨드에서 64-CPU 시스템에서의 40~\emph{마이크로세컨드} 를 오가게
합니다.
이는 RCU read-side 크리티컬 섹션이 실제 read-side 병렬성을 얻기 위해서는 굉장히
길어야 함을 의미합니다.
다른 한편, 읽기 쓰레드가 부재할 경우, grace period 는 40~\emph{나노세컨드}
가량에 끝나는데, 리눅스 커널의 제품 품질 구현보다 수십수백배 빠릅니다.

\iffalse

However, this implementation still has some serious shortcomings.
First, the atomic operations in \co{rcu_read_lock()} and
\co{rcu_read_unlock()} are still quite  heavyweight,
with read-side overhead ranging from about 100~nanoseconds on
a single \Power{5} CPU up to almost 40~\emph{microseconds}
on a 64-CPU system.
This means that the RCU read-side critical sections
have to be extremely long in order to get any real
read-side parallelism.
On the other hand, in the absence of readers, grace periods elapse
in about 40~\emph{nanoseconds}, many orders of magnitude faster
than production-quality implementations in the Linux kernel.

\fi

\QuickQuiz{
	\co{synchronize_rcu()} 가 10-밀리세컨드 지연을 갖는데 어떻게 grace
	peirod 는 40 나노세컨드에 끝날 수 있죠?

	\iffalse

	How can the grace period possibly elapse in 40 nanoseconds when
	\co{synchronize_rcu()} contains a 10-millisecond delay?

	\fi

}\QuickQuizAnswer{
	이 업데이트 쪽 테스트는 읽기 쓰레드의 부재 하에 수행되었으므로,
	\co{poll()} 시스템 콜이 아예 수행되지 않았습니다.
	또한, 실제 코드는 이 \co{poll()} 시스템콜이 주석처리 되어 있어서, 이
	업데이트 쪽 코드의 실제 오버헤드를 더 잘 평가할 수 있었습니다.
	이 코드의 제품 환경에서의 사용은 \co{poll()} 시스템 콜의 사용을 통해
	나아질 수 있겠습니다만, 다시 말하지만 제품 환경에서의 사용의 경우 이
	섹션의 뒤쪽에서 소개할 다른 구현을 사용하는게 나을 겁니다.

	\iffalse

	The update-side test was run in absence of readers, so the
	\co{poll()} system call was never invoked.
	In addition, the actual code has this \co{poll()}
	system call commented out, the better to evaluate the
	true overhead of the update-side code.
	Any production uses of this code would be better served by
	using the \co{poll()} system call, but then again,
	production uses would be even better served by other implementations
	shown later in this section.

	\fi

}\QuickQuizEnd

둘째로 수많은 동시의 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()}
오퍼레이션이 존재한다면, \co{rcu_refcnt} 에 상당한 메모리 경쟁이 존재할
것이어서 비싼 캐쉬 미스를 초래할 겁니다.
이 두개의 단점은 RCU 의 주요 목적인 낮은 오버헤드의 read-side 동기화 기능
제공하기를 크게 해칩니다.

마지막으로, 긴 read-side 크리티컬 섹션을 갖는 큰 수의 RCU 읽기 쓰레드는
\co{synchronize_rcu()} 가 평생 완료되지 못하게 할 수 있는데, 이 전역 카운터가
평생 0이 되지 않을 수도 있기 때문입니다.
이는 RCU 업데이트 쓰레드의 기아를 초래할 수 있는데, 이 역시 제품 환경에서는
받아들여질 수 없는 일입니다.

\iffalse

Second, if there are many concurrent \co{rcu_read_lock()}
and \co{rcu_read_unlock()} operations, there will
be extreme memory contention on \co{rcu_refcnt},
resulting in expensive cache misses.
Both of these first two shortcomings largely defeat a major purpose of
RCU, namely to provide low-overhead read-side synchronization primitives.

Finally, a large number of RCU readers with long read-side
critical sections could prevent \co{synchronize_rcu()}
from ever completing, as the global counter might
never reach zero.
This could result in starvation of RCU updates, which
is of course unacceptable in production settings.

\fi

\QuickQuiz{
	\Cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
	의 RCU 구현에서 \co{synchronize_rcu()} 가 너무 오래 기다리고 있었다면
	\co{rcu_read_lock()} 이 기다리게 하는건 어떤가요?
	이게 \co{synchronize_rcu()} 가 기아에 빠지는 걸 방지하지 않을까요?

	\iffalse

	Why not simply make \co{rcu_read_lock()} wait when a concurrent
	\co{synchronize_rcu()} has been waiting too long in
	the RCU implementation in
	\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}?
	Wouldn't that prevent \co{synchronize_rcu()} from starving?

	\fi

}\QuickQuizAnswer{
	이게 실제로 기아를 제거하겠지만, 이는 또한 \co{rcu_read_lock()} 이 쓰기
	쓰레드를 기다리느라 spin 또는 block 을 함을 의미하는데, 이는 결국 읽기
	쓰레드를 기다리는 일입니다.
	이 읽기 쓰레드들 중 하나가 이 spin/block 하는 \co{rcu_read_lock()} 이
	잡고 있는 락을 잡으려 한다면 우린 또다시 데드락에 빠집니다.

	짧게 발해서, 이 치료법은 질병보다 더 나쁩니다.
	올바른 치료를 위해선
	\cref{sec:app:toyrcu:Starvation-Free Counter-Based RCU} 를 보십시오.

	\iffalse

	Although this would in fact eliminate the starvation, it would
	also mean that \co{rcu_read_lock()} would spin or block waiting
	for the writer, which is in turn waiting on readers.
	If one of these readers is attempting to acquire a lock that
	the spinning/blocking \co{rcu_read_lock()} holds, we again
	have deadlock.

	In short, the cure is worse than the disease.
	See \cref{sec:app:toyrcu:Starvation-Free Counter-Based RCU}
	for a proper cure.

	\fi

}\QuickQuizEnd

따라서, 이 구현 역시 제품 환경에서 유용할 거라 상상하기는 어렵지만 락 기반
메커니즘에 비해서는 예를 들면 높은 부하에서의 디버깅 환경에 적합한 RCU
구현으로는 약간 더 나은 잠재력을 가지고 있습니다.
다음 섹션은 읽기 쓰레드에 더 선호될 레퍼런스 카운팅 방법의 변주를 설명합니다.

\iffalse

Therefore, it is still hard to imagine this implementation being useful
in a production setting, though it has a bit more potential
than the lock-based mechanism, for example, as an RCU implementation
suitable for a high-stress debugging environment.
The next section describes a variation on the reference-counting
scheme that is more favorable to writers.

\fi

\section{Starvation-Free Counter-Based RCU}
\label{sec:app:toyrcu:Starvation-Free Counter-Based RCU}

\Cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
(\path{rcu_rcpg.h})
가
\cref{lst:app:toyrcu:RCU Global Reference-Count Pair Data}
에 보인 한 쌍의 레퍼런스 카운터와 (\co{rcu_refcnt[]}) 이 쌍 중에서 하나의
카운터를 선택하는 전역 인덱스 (\co{rcu_idx}), 쓰레드별 중첩 카운터
(\co{rcu_nesting}), 쓰레드별 전역 인덱스의 스냅샷 (\co{rcu_read_idx}), 그리고
전역 락 (\co{rcu_gp_lock}) 을 사용하는 RCU 구현의 read-side 기능을 보이고
있습니다.

\iffalse

\Cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
(\path{rcu_rcpg.h})
shows the read-side primitives of an RCU implementation that uses a pair
of reference counters (\co{rcu_refcnt[]}),
along with a global index that
selects one counter out of the pair (\co{rcu_idx}),
a per-thread nesting counter (\co{rcu_nesting}),
a per-thread snapshot of the global index (\co{rcu_read_idx}),
and a global lock (\co{rcu_gp_lock}),
which are themselves shown in
\cref{lst:app:toyrcu:RCU Global Reference-Count Pair Data}.

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpg@define.fcv}
\caption{RCU Global Reference-Count Pair Data}
\label{lst:app:toyrcu:RCU Global Reference-Count Pair Data}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpg@r.fcv}
\caption{RCU Read-Side Using Global Reference-Count Pair}
\label{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
\end{listing}

\paragraph{Design}

기아로부터의 자유를 제공하는 건 \co{rcu_refcnt[]} 배열의 두 원소입니다.
핵심은 \co{synchronize_rcu()} 가 앞서 존재한 읽기 쓰레드들만을 기다리면 된다는
겁니다.
만약 어떤 새로운 읽기 쓰레드가 특정 \co{synchronize_rcu()} 호출이 수행을 시작한
후에 시작된다면, 이 \co{synchronize_rcu()} 수행은 이 새 읽기 쓰레드를 기다리지
않아도 됩니다.
언제든, 특정 읽기 쓰레드가 자신의 RCU read-side 크리티컬 섹션을
\co{rcu_read_lock()} 을 통해 시작했을 때, 이 쓰레드는 \co{rcu_idx} 변수로
가리켜지는 \co{rcu_refcnt[]} 배열의 원소를 값 증가시킵니다.
이 똑같은 읽기 쓰레드가 \co{rcu_read_unlock()} 을 통해 자신의 RCU read-side
크리티컬 섹션을 종료할 때, 이 쓰레드는 모든 가능한 \co{rcu_idx} 값으로의
뒤따르는 변화를 무시하고 무엇이든 자신이 증가시킨 원소의 값을 감소시킵니다.

\iffalse

It is the two-element \co{rcu_refcnt[]} array that provides the freedom
from starvation.
The key point is that \co{synchronize_rcu()} is only required to wait
for pre-existing readers.
If a new reader starts after a given instance of \co{synchronize_rcu()}
has already begun execution, then that instance of \co{synchronize_rcu()}
need not wait on that new reader.
At any given time, when a given reader enters its RCU read-side critical
section via \co{rcu_read_lock()},
it increments the element of the \co{rcu_refcnt[]} array indicated by
the \co{rcu_idx} variable.
When that same reader exits its RCU read-side critical section via
\co{rcu_read_unlock()}, it decrements whichever element it incremented,
ignoring any possible subsequent changes to the \co{rcu_idx} value.

\fi

이 조정은 \co{synchronize_rcu()} 는 \co{rcu_idx} 의 값을
\co{rcu_idx = !rcu_idx} 로 조정함으로써 기아를 막을 수 있음을 의미합니다.
\co{rcu_idx} 의 기존 값이 0 이었고, 따라서 새 값은 1이라고 해봅시다.
이 값 조정 오퍼레이션 뒤에 도착한 새 읽기 쓰레드는 \co{rcu_refcnt[1]} 의 값을
증가시킬 것이며, 앞서 \co{rcu_refcnt[0]} 의 값을 증가시킨 기존 읽기 쓰레드들은
자신의 RCU read-side 크리티컬 섹션을 종료할 때 \co{rcu_refcnt[0]} 의 값을
감소시킬 겁니다.
이는 \co{rcu_refcnt[0]} 의 값이 더이상 증가되지 않을 것이며, 따라서 단조 감소할
것을 의미합니다.\footnote{
	이 ``단조 감소'' 를 무시하는 경주 조건이 존재합니다.
	이 경주 조건은 \co{synchronize_rcu()} 코드를 통해 처리될 겁니다.
	그 전까지는 불신을 미뤄두길 제안합니다.}
이는 \co{synchronize_rcu()} 가 해야할 모든 일은 \co{rcu_refcnt[0]} 의 값이 0이
되길 기다리는 것 뿐임을 의미합니다.

이 배경지식과 함께라면, 실제 기능의 구현을 들여다볼 준비가 되었습니다.

\iffalse

This arrangement means that \co{synchronize_rcu()} can avoid starvation
by complementing the value of \co{rcu_idx}, as in \co{rcu_idx = !rcu_idx}.
Suppose that the old value of \co{rcu_idx} was zero, so that the new
value is one.
New readers that arrive after the complement operation will increment
\co{rcu_refcnt[1]}, while the old readers that previously incremented
\co{rcu_refcnt[0]} will decrement \co{rcu_refcnt[0]} when they exit their
RCU read-side critical sections.
This means that the value of \co{rcu_refcnt[0]} will no longer be incremented,
and thus will be monotonically decreasing.\footnote{
	There is a race condition that this ``monotonically decreasing''
	statement ignores.
	This race condition will be dealt with by the code for
	\co{synchronize_rcu()}.
	In the meantime, I suggest suspending disbelief.}
This means that all that \co{synchronize_rcu()} need do is wait for the
value of \co{rcu_refcnt[0]} to reach zero.

With the background, we are ready to look at the implementation of the
actual primitives.

\fi

\paragraph{Implementation}

\co{rcu_read_lock()} 기능은 \co{rcu_idx} 에 의해 인덱스되는 \co{rcu_refcnt[]}
쌍의 멤버를 값 증가시키고, 이 인덱스의 스냅샷을 쓰레드별 변수 \co{rcu_read_idx}
에 보관합니다.
\co{rcu_read_unlock()} 기능은 이어서 그게 무엇이든 연관된 \co{rcu_read_lock()}
이 값 증가시켰던 카운터의 값을 원자적으로 감소시킵니다.
그러나, 쓰레드당 단 하나의 \co{rcu_idx} 값만이 기억되었으므로, 중첩을 허용하기
위해선 추가적인 방법이 필요합니다.
이 추가적인 방법은 중첩을 추적하는 쓰레드별 \co{rcu_nesting} 변수를 사용합니다.

\iffalse

The \co{rcu_read_lock()} primitive atomically increments the member of the
\co{rcu_refcnt[]} pair indexed by \co{rcu_idx}, and keeps a
snapshot of this index in the per-thread variable \co{rcu_read_idx}.
The \co{rcu_read_unlock()} primitive then atomically decrements
whichever counter of the pair that the corresponding \co{rcu_read_lock()}
incremented.
However, because only one value of \co{rcu_idx} is remembered per thread,
additional measures must be taken to permit nesting.
These additional measures use the per-thread \co{rcu_nesting} variable
to track nesting.

\fi

\begin{fcvref}[ln:defer:rcu_rcpg:r:lock]
이 모든게 동작하게 하기 위해,
\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair} 의
\co{rcu_read_lock()} 의 \clnref{pick} 은 현재 쓰레드의 \co{rcu_nesting} 을
가져오고, \clnref{if} 가 이게 가장 바깥 \co{rcu_read_lock()} 임을 확인하면,
\clnrefrange{cur:b}{cur:e} 는 \co{rcu_idx} 의 현재 값을 가져오고, 그것을 이
쓰레드의 \co{rcu_read_idx} 에 저장한 후, \co{rcu_refcnt} 의 선택된 원소의 값을
어토믹하게 증가시킵니다.
\co{rcu_nesting} 의 값에 관계 없이, \clnref{inc} 는 이를 값 증가시킵니다.
\Clnref{mb} 는 이 RCU read-side 크리티컬 섹션이 \co{rcu_read_lock()} 코드
앞으로 새어나가지 않음을 보장하기 위해 메모리 배리어를 수행합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu_rcpg:r:lock]
To make all this work, \clnref{pick} of \co{rcu_read_lock()} in
\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
picks up the
current thread's instance of \co{rcu_nesting}, and if \clnref{if} finds
that this is the outermost \co{rcu_read_lock()},
then \clnrefrange{cur:b}{cur:e} pick up the current value of
\co{rcu_idx}, save it in this thread's instance of \co{rcu_read_idx},
and atomically increment the selected element of \co{rcu_refcnt}.
Regardless of the value of \co{rcu_nesting}, \clnref{inc} increments it.
\Clnref{mb} executes a memory barrier to ensure that the RCU read-side
critical section does not bleed out before the \co{rcu_read_lock()} code.
\end{fcvref}

\fi

\begin{fcvref}[ln:defer:rcu_rcpg:r:unlock]
비슷하게, \co{rcu_read_unlock()} 함수는 RCU read-side 크리티컬 섹션이
\co{rcu_read_unlock()} 코드 뒤로 새어나가지 않게끔 \clnref{mb} 에서 메모리
배리어를 수행합니다.
\Clnref{nest} 는 이 쓰레드의 \co{rcu_nesting} 인스턴스를 가져오고, \clnref{if}
에서 이것이 가장 바깥 \co{rcu_read_unlock()} 임을 확인하면, \clnref{idx,atmdec}
에서 이 쓰레드의 \co{rcu_read_idx} 인스턴스를 가져오고 (이는 가장 바깥의
\co{rcu_read_lock()} 에 의해 저장되었음) \co{rcu_refcnt} 의 선택된 원소의 값을
원자적으로 감소시킵니다.
중첩 단계에 관계 없이, \clnref{decnest} 는 이 쓰레드의 \co{rcu_nesting}
인스턴스의 값을 감소시킵니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu_rcpg:r:unlock]
Similarly, the \co{rcu_read_unlock()} function executes a memory barrier
at \clnref{mb}
to ensure that the RCU read-side critical section does not bleed out
after the \co{rcu_read_unlock()} code.
\Clnref{nest} picks up this thread's instance of \co{rcu_nesting}, and if
\clnref{if} finds that this is the outermost \co{rcu_read_unlock()},
then \clnref{idx,atmdec} pick up this thread's instance of \co{rcu_read_idx}
(saved by the outermost \co{rcu_read_lock()}) and atomically decrements
the selected element of \co{rcu_refcnt}.
Regardless of the nesting level, \clnref{decnest} decrements this thread's
instance of \co{rcu_nesting}.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpg@sync.fcv}
\caption{RCU Update Using Global Reference-Count Pair}
\label{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
\end{listing}

\begin{fcvref}[ln:defer:rcu_rcpg:sync]
\Cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
(\path{rcu_rcpg.c})
는 연관된 \co{synchronize_rcu()} 구현을 보입니다.
\Clnref{acq,rel} 은 하나 이상의 동시의 \co{synchronize_rcu()} 를 방지하기 위해
\co{rcu_gp_lock} 을 획득하고 해제합니다.
\Clnref{pick,compl} 은 각각 \co{rcu_idx} 값을 가져오고 이를 보상하여 뒤따르는
\co{rcu_read_lock()} 인스턴스는 앞의 인스턴스와 다른 \co{rcu_refcnt} 를
사용하게끔 만듭니다.
\Clnrefrange{while:b}{while:e} 는 이어서 \co{rcu_refcnt} 의 앞의 원소가 0이
되기를 \clnref{mb2} 에서의 \co{rcu_refcnt} 의 검사가 \co{rcu_idx} 보상을
앞지르게끔 재배치 되지 않게끔 보장하는 메모리 배리어와 함께 기다립니다.
\Clnrefrange{mb3}{while2:e} 는 이 과정을 반복하며, \clnref{mb5} 는 모든
뒤따르는 회수 오퍼레이션이 \co{rcu_refcnt} 의 검사를 앞지르게끔 재배치 되지
않게끔 보장합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu_rcpg:sync]
\Cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
(\path{rcu_rcpg.c})
shows the corresponding \co{synchronize_rcu()} implementation.
\Clnref{acq,rel} acquire and release \co{rcu_gp_lock} in order to
prevent more than one concurrent instance of \co{synchronize_rcu()}.
\Clnref{pick,compl} pick up the value of \co{rcu_idx} and complement it,
respectively, so that subsequent instances of \co{rcu_read_lock()}
will use a different element of \co{rcu_refcnt} than did preceding
instances.
\Clnrefrange{while:b}{while:e}
then wait for the prior element of \co{rcu_refcnt} to
reach zero, with the memory barrier on \clnref{mb2} ensuring that the check
of \co{rcu_refcnt} is not reordered to precede the complementing of
\co{rcu_idx}.
\Clnrefrange{mb3}{while2:e} repeat this process, and
\clnref{mb5} ensures that any
subsequent reclamation operations are not reordered to precede the
checking of \co{rcu_refcnt}.
\end{fcvref}

\fi

\QuickQuizSeries{%
\QuickQuizB{
	\begin{fcvref}[ln:defer:rcu_rcpg:sync]
	\Cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	의 \co{synchronize_rcu()} 에서의 \clnref{mb1} 에서의 메모리 배리어는
	바로 뒤에 스핀락 획득이 있는데 왜 필요하죠?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_rcpg:sync]
	Why the memory barrier on \clnref{mb1} of \co{synchronize_rcu()} in
	\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	given that there is a spin-lock acquisition immediately after?
	\end{fcvref}

	\fi

}\QuickQuizAnswerB{
	이 스핀락 획득은 이 스핀락의 크리티컬 섹션이 이 획득 앞으로
	``새어나가지'' 않게 보장할 뿐입니다.
	스핀락 획득을 앞서는 코드가 이 크리티컬 섹션 안으로 재배치 되는 것은
	막지 않습니다.
	그런 재배치는 RCU 로 보호되는 리스트로부터의 우너소 삭제가 \co{rcu_idx}
	의 보상을 뒤따르게끔 재배치 하는 것을 허용해서 새로 시작된 RCU
	read-side 크리티컬 섹션이 최근 제거된 데이터 원소를 볼 수 있게 할 수
	있습니다.

	독자 여러분을 위한 연습:
	\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	의 메모리 배리어 가운데 무엇이 정말로 필요한지 판단하기 위해
	Promela/spin 같은 도구를 사용해 보세요.
	이 도구들을 사용하는 법을 알기 위해 \cref{chp:Formal Verification} 을
	보세요.
	첫번째 올바르고 완전한 답은 상을 받을 겁니다.

	\iffalse

	The spin-lock acquisition only guarantees that the spin-lock's
	critical section will not ``bleed out'' to precede the
	acquisition.
	It in no way guarantees that code preceding the spin-lock
	acquisition won't be reordered into the critical section.
	Such reordering could cause a removal from an RCU-protected
	list to be reordered to follow the complementing of
	\co{rcu_idx}, which could allow a newly starting RCU
	read-side critical section to see the recently removed
	data element.

	Exercise for the reader: use a tool such as Promela/\co{spin}
	to determine which (if any) of the memory barriers in
	\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	are really needed.
	See \cref{chp:Formal Verification}
	for information on using these tools.
	The first correct and complete response will be credited.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	왜 이 카운터는
	\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	에서 두번 뒤집히나요?
	한번 뒤집고 기다리기만으로도 충분하지 않나요?

	\iffalse

	Why is the counter flipped twice in
	\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}?
	Shouldn't a single flip-and-wait cycle be sufficient?

	\fi

}\QuickQuizAnswerE{
	\begin{fcvref}[ln:defer:rcu_rcpg]
	두번의 뒤집기가 분명 필요합니다.
	이를 보기 위해, 다음 이벤트의 연속을 생각해 봅시다:
	\begin{enumerate}
	\item	\Cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
		의 \co{rcu_read_lock()} 의 \clnref{r:lock:cur:b} 에서
		\co{rcu_idx} 를 가져오고 그 값이 0임을 확인합니다.
	\item	\Cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
		의 \co{synchronize_rcu()} 의 \clnref{sync:compl} 에서
		\co{rcu_idx} 의 값을 보상해서 그 값을 1로 만듭니다.
	\item	\co{synchronize_rcu()} 의
		\clnrefrange{sync:while:b}{sync:while:e} 에서
		\co{rcu_refcnt[0]} 의 값이 0임을 확인하고 따라서 리턴합니다.
		(질문은 \clnrefrange{sync:mb3}{sync:mb5} 이 제거되면 어떻게
		되는가임을 상기합시다.)
	\item	\co{rcu_read_lock()} 의 \clnref{r:lock:set,r:lock:cur:e} 가 이
		쓰레드의 \co{rcu_read_idx} 인스턴스에 값 0을 저장하고
		\co{rcu_refcnt[0]} 의 값을 증가시킵니다.
		수행은 이제 이 RCU read-side 크리티컬 섹션 내부로 이어집니다.
		\label{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_rcpg]
	Both flips are absolutely required.
	To see this, consider the following sequence of events:
	\begin{enumerate}
	\item	\Clnref{r:lock:cur:b} of \co{rcu_read_lock()} in
		\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
		picks up \co{rcu_idx}, finding its value to be zero.
	\item	\Clnref{sync:compl} of \co{synchronize_rcu()} in
		\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
		complements the value of \co{rcu_idx}, setting its
		value to one.
	\item	\Clnrefrange{sync:while:b}{sync:while:e}
		of \co{synchronize_rcu()} find that the
		value of \co{rcu_refcnt[0]} is zero, and thus
		returns.
		(Recall that the question is asking what happens if
		\clnrefrange{sync:mb3}{sync:mb5} are omitted.)
	\item	\Clnref{r:lock:set,r:lock:cur:e}
		of \co{rcu_read_lock()} store the
		value zero to this thread's instance of \co{rcu_read_idx}
		and increments \co{rcu_refcnt[0]}, respectively.
		Execution then proceeds into the RCU read-side critical
		section.
		\label{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start}

	\fi

	\item	\co{synchronize_rcu()} 의 또다른 인스턴스가 다시 \co{rcu_idx}
		를 보상하는데, 이번에는 그 값을 0으로 만듭니다.
		\co{rcu_refcnt[1]} 은 0 이므로, \co{synchronize_rcu()} 는
		곧바로 리턴합니다.
		(\co{rcu_read_lock()} 은 \co{rcu_refcnt[1]} 이 아닌
		\co{rcu_refcnt[0]} 을 값 증가시켰음을 기억하세요!)
		\label{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
	\item	Step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
		에서 시작된 grace period 는 이제 종료가 허가되었는데, 이전에
		step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start} 
		에서 시작된 RCU read-side 크리티컬 섹션은 완료되지 않았으에도
		불구하고 그렇습니다.
		이는 RCU semantic 의 위반이며, 업데이트가 RCU read-side
		크리티컬 섹션이 여전히 참조하고 있는 데이터 원소를 메모리
		해제할 수 있게 합니다.

	\iffalse

	\item	Another instance of \co{synchronize_rcu()} again complements
		\co{rcu_idx}, this time setting its value to zero.
		Because \co{rcu_refcnt[1]} is zero, \co{synchronize_rcu()}
		returns immediately.
		(Recall that \co{rcu_read_lock()} incremented
		\co{rcu_refcnt[0]}, not \co{rcu_refcnt[1]}!)
		\label{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
	\item	The grace period that started in
		step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
		has been allowed to end, despite
		the fact that the RCU read-side critical section
		that started beforehand in
		step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start}
		has not completed.
		This violates RCU semantics, and could allow the update
		to free a data element that the RCU read-side critical
		section was still referencing.

	\fi

	\end{enumerate}

	독자 여러분을 위한 연습: \co{rcu_read_lock()} 이 \clnref{r:lock:cur:b}
	후에 매우 긴 시간 (수시간!) preemption 당하면 무슨 일이 벌어질까요?
	이 구현은 그런 경우에 잘 동작할까요?
	왜 그럴까요?
	첫번째 올바르고 완전한 답변은 상을 받을 겁니다.
	\end{fcvref}

	\iffalse

	Exercise for the reader: What happens if \co{rcu_read_lock()}
	is preempted for a very long time (hours!) just after
	\clnref{r:lock:cur:b}?
	Does this implementation operate correctly in that case?
	Why or why not?
	The first correct and complete response will be credited.
	\end{fcvref}

	\fi
}\QuickQuizEndE
}

이 구현은
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
에 보인 단일 카운터 기반 구현에서 일어날 수 있는 업데이트 starvation 문제를
막습니다.

\iffalse

This implementation avoids the update-starvation issues that could
occur in the single-counter implementation shown in
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}.

\fi

\paragraph{Discussion}

여전히 심각한 단점들이 있습니다.
첫째, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 의 어토믹 오퍼레이션들은
여전히 꽤 무겁습니다.
실제로, 이건
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
에 보인 단일 카운터 변종의 것들보다 더 복잡해서 읽기 쪽 기능들은 단일 \Power{5}
CPU 에서 약 150~나노세컨드, 64-CPU 시스템에서는 거의 40~\emph{마이크로세컨드}
의 시간을 소비합니다.
업데이트 쪽 \co{synchronize_rcu()} 기능은 이보다 더 비싼데, 단일 \Power{5} CPU
에서 약 200~나노세컨드에 64-CPU 시스템에서 40~\emph{마이크로세컨드} 를
소비합니다.
이는 RCU read-side 크리티컬 섹션이 실제 읽기 쪽의 병렬성을 얻기 위해선 굉장히
길어야 함을 의미합니다.

둘째, 많은 동시의 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 오퍼레이션이
존재한다면, \co{rcu_refcnt} 원소로의 상당한 메모리 경쟁이 있어서 비싼 캐쉬
미스를 초래합니다.
이는 병렬 read-side 액세스를 제공하기 위해 필요한 RCU read-side 크리티컬 섹션의
시간을 더 늘립니다.
이 두개의 단점들은 RCU 의 목적을 대부분의 상황에서 좌절시킵니다.

\iffalse

There are still some serious shortcomings.
First, the atomic operations in \co{rcu_read_lock()}
and \co{rcu_read_unlock()}
are still quite heavyweight.
In fact, they are more complex than those
of the single-counter variant shown in
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter},
with the read-side primitives consuming about 150~nanoseconds on a single
\Power{5} CPU and almost 40~\emph{microseconds} on a 64-CPU system.
The update-side \co{synchronize_rcu()} primitive is more costly as
well, ranging from about 200~nanoseconds on a single \Power{5} CPU to
more than 40~\emph{microseconds} on a 64-CPU system.
This means that the RCU read-side critical sections
have to be extremely long in order to get any real
read-side parallelism.

Second, if there are many concurrent \co{rcu_read_lock()}
and \co{rcu_read_unlock()} operations, there will
be extreme memory contention on the \co{rcu_refcnt}
elements, resulting in expensive cache misses.
This further extends the RCU read-side critical-section
duration required to provide parallel read-side access.
These first two shortcomings defeat the purpose of RCU in most
situations.

\fi

셋째, \co{rcu_idx} 를 두번 뒤집어야 하는 필요성은 업데이트에의 상당한
오버헤드를 부과하며, 특히 큰 수의 쓰레드가 있을때 그렇습니다.

마지막으로, 동시의 RCU 업데이트는 이론상 공통의 grace period 에 의해 처리될 수
있다는 사실에도 불구하고, 이 구현은 grace period 들을 순차화 시켜서
grace-period 공유를 막습니다.

\iffalse

Third, the need to flip \co{rcu_idx} twice imposes substantial
overhead on updates, especially if there are large
numbers of threads.

Finally, despite the fact that concurrent RCU updates could in principle be
satisfied by a common grace period, this implementation
serializes grace periods, preventing grace-period
sharing.

\fi

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu_rcpg:r]
	어토믹 값 증가와 감소가 그렇게 비싸면,
	\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
	의 \clnref{lock:cur:e} 에서 어토믹하지 않은 값 증가를 사용하고
	\clnref{unlock:atmdec} 에서 어토믹하지 않은 값 감소를 사용하는 건
	어떻습니까?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_rcpg:r]
	Given that atomic increment and decrement are so expensive,
	why not just use non-atomic increment on \clnref{lock:cur:e} and a
	non-atomic decrement on \clnref{unlock:atmdec} of
	\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	어토믹하지 않은 오퍼레이션을 사용하는 것은 값 증가와 감소를 손실되게
	만들어서 결국 이 구현이 실패하게 합니다.
	\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 에서 비 어토믹
	오퍼레이션을 사용하는 안전한 방법을 위해선
	\cref{sec:app:toyrcu:Scalable Counter-Based RCU} 를 참고하십시오.

	\iffalse

	Using non-atomic operations would cause increments and decrements
	to be lost, in turn causing the implementation to fail.
	See \cref{sec:app:toyrcu:Scalable Counter-Based RCU}
	for a safe way to use non-atomic operations in
	\co{rcu_read_lock()} and \co{rcu_read_unlock()}.

	\fi

}\QuickQuizEnd

이런 단점들에도 불구하고, 어떤 이는 이 RCU 변종이 작은 단단하게 결합된
멀티프로세서에서, 아마도 더 복잡한 구현과의 API 호환성을 유지하는 메모리 보호
구현으로 사용되는 걸 상상해 볼 수 있을 겁니다.
그러나, 이는 몇 CPU 이상으로는 확장되지 못할 가능성이 큽니다.

다음 섹션은 크게 향상된 read-side 성능과 확장성을 제공하는 레퍼런스 카운팅
방법의 또다른 변종을 설명합니다.

\iffalse

Despite these shortcomings, one could imagine this variant
of RCU being used on small tightly coupled multiprocessors,
perhaps as a memory-conserving implementation that maintains
API compatibility with more complex implementations.
However, it would not likely scale well beyond a few CPUs.

The next section describes yet another variation on the reference-counting
scheme that provides greatly improved read-side performance and scalability.

\fi

\section{Scalable Counter-Based RCU}
\label{sec:app:toyrcu:Scalable Counter-Based RCU}

\Cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.h})
는 쓰레드별 한쌍의 레퍼런스 카운터를 사용하는 RCU 구현의 read-side 기능들을
보입니다.
이 구현은
\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
에 보인 구현과 상당히 비슷하지만 유일한 차이점은 \co{rcu_refcnt} 가 이제
쓰레드별 배열이라는 겁니다
(\cref{lst:app:toyrcu:RCU Per-Thread Reference-Count Pair Data} 에 보인 바와
같습니다).
앞의 섹션에서의 알고리즘과 같이, 이 두 원소의 배열을 사용하는 것은 읽기
쓰레드가 업데이트 쓰레드를 기아상태에 빠뜨리는 걸 방지합니다.
쓰레드별 \co{rcu_refcnt[]} 배열의 한가지 장점은 \co{rcu_read_lock()} 과
\co{rcu_read_unlock()} 기능이 더이상 어토믹 오퍼레이션을 사용하지 않는다는
겁니다.

\iffalse

\Cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.h})
shows the read-side primitives of an RCU implementation that uses per-thread
pairs of reference counters.
This implementation is quite similar to that shown in
\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair},
the only difference being that \co{rcu_refcnt} is now a per-thread
array (as shown in
\cref{lst:app:toyrcu:RCU Per-Thread Reference-Count Pair Data}).
As with the algorithm in the previous section, use of this two-element
array prevents readers from starving updaters.
One benefit of per-thread \co{rcu_refcnt[]} array is that the
\co{rcu_read_lock()} and \co{rcu_read_unlock()} primitives no longer
perform atomic operations.

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpl@define.fcv}
\caption{RCU Per-Thread Reference-Count Pair Data}
\label{lst:app:toyrcu:RCU Per-Thread Reference-Count Pair Data}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpl@r.fcv}
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
\end{listing}

\QuickQuiz{
	나와요!
	\co{rcu_read_lock()} 의 \co{atomic_read()} 가 보인다구요!!!
	왜 \co{rcu_read_lock()} 이 어토믹 오퍼레이션을 가지고 있지 않은 척 하는
	거죠???

	\iffalse

	Come off it!
	We can see the \co{atomic_read()} primitive in
	\co{rcu_read_lock()}!!!
	So why are you trying to pretend that \co{rcu_read_lock()}
	contains no atomic operations???

	\fi

}\QuickQuizAnswer{
	이 \co{atomic_read()} 기능은 실제로 어토믹 기계명령을 수행하지 않고
	그저 평범한 \co{atomic_t} 로부터의 로드를 합니다.
	이것의 유일한 목적인 컴파일러의 타입 검사를 만족시키는 겁니다.
	만약 리눅스 커널이 8-bit CPU 에서 수행된다면 이는 또한 16-bit 포인터를
	두개의 8-bit 액세스를 통해 저장해야 하기 때문에 일부 8-bit 시스템에서
	발생하는 ``store tearing'' 을 방지하기 위해 필요합니다.
	그러나 감사하게도, 아무도 리눅스를 8-bit 시스템에서 수행하지 않는 듯
	합니다.

	\iffalse

	The \co{atomic_read()} primitives does not actually execute
	atomic machine instructions, but rather does a normal load
	from an \co{atomic_t}.
	Its sole purpose is to keep the compiler's type-checking happy.
	If the Linux kernel ran on 8-bit CPUs, it would also need to
	prevent ``store tearing'', which could happen due to the need
	to store a 16-bit pointer with two eight-bit accesses on some
	8-bit systems.
	But thankfully, it seems that no one runs Linux on 8-bit systems.

	\fi

}\QuickQuizEnd

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpl@u.fcv}
\caption{RCU Update Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
\end{listing}

\Cref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.c})
는 \co{flip_counter_and_wait()} 라 이름지어진 헬퍼 함수와 함께
\co{synchronize_rcu()} 의 구현을 보입니다.
\begin{fcvref}[ln:defer:rcu_rcpl:u:sync]
\co{synchronize_rcu()} 함수는
\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
에 보인 것과 닮았지만, 반복되는 카운터 뒤집기가 \clnref{flip1,flip2} 의 새로운
헬퍼 함수로의 호출 한쌍으로 대체된 게 차이점입니다.
\end{fcvref}

\begin{fcvref}[ln:defer:rcu_rcpl:u:flip]
이 새로운 \co{flip_counter_and_wait()} 함수는 \co{rcu_idx} 변수를
\clnref{atmset} 에서 업데이트 하고, \clnref{mb1} 에서 메모리 배리어를 수행하고,
\clnrefrange{loop:b}{loop:e} 에서 각 쓰레드의 기존 \co{rcu_refcnt} 원소에서
스핀하며 이것이 0이 되기를 기다립니다.
일단 모든 원소가 0이 되면 \clnref{mb2} 에서 메모리 배리어를 수행하고
리턴합니다.
\end{fcvref}

\iffalse

\Cref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.c})
shows the implementation of \co{synchronize_rcu()}, along with a helper
function named \co{flip_counter_and_wait()}.
\begin{fcvref}[ln:defer:rcu_rcpl:u:sync]
The \co{synchronize_rcu()} function resembles that shown in
\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair},
except that the repeated counter flip is replaced by a pair of calls
on \clnref{flip1,flip2} to the new helper function.
\end{fcvref}

\begin{fcvref}[ln:defer:rcu_rcpl:u:flip]
The new \co{flip_counter_and_wait()} function updates the
\co{rcu_idx} variable on \clnref{atmset},
executes a memory barrier on \clnref{mb1},
then \clnrefrange{loop:b}{loop:e}
spin on each thread's prior \co{rcu_refcnt} element,
waiting for it to go to zero.
Once all such elements have gone to zero,
it executes another memory barrier on \clnref{mb2} and returns.
\end{fcvref}

\fi

이 RCU 구현은 그것의 소프트웨어 환경에 새로운 중요 요구사항을 부과하는데,
그것은 (1) 쓰레드별 변수를 선언할 수 있어야 할 것, (2) 이 쓰레드별 변수들은
다른 쓰레드에서 액세스 가능해야 할 것, (3) 모든 쓰레드를 순회하는게 가능할 것
입니다.
이 요구사항들은 거의 모든 소프트웨어 환경에서 갖추어질 수 있습니다만, 쓰레드
수의 최대 한계를 종종 고정시킵니다.
더 복잡한 구현은 그런 한계를 막을텐데, 예를 들면 확장 가능한 해쉬 테이블을 쓰는
방식입니다.
그런 구현은 동적으로 쓰레드를 추적할 수도 있을텐데, 예를 들면
\co{rcu_read_lock()} 의 첫번째 호출 때 그것들을 추가시키는 겁니다.

\iffalse

This RCU implementation imposes important new requirements on its
software environment, namely, (1) that it be possible to declare
per-thread variables, (2) that these per-thread variables be accessible
from other threads, and (3) that it is possible to enumerate all threads.
These requirements can be met in almost all software environments,
but often result in fixed upper bounds on the number of threads.
More-complex implementations might avoid such bounds, for example, by using
expandable hash tables.
Such implementations might dynamically track threads, for example, by
adding them on their first call to \co{rcu_read_lock()}.

\fi

\QuickQuiz{
	훌륭하군요, 우리가 $N$ 쓰레드를 갖는다면 우린 $2N$ 수십 밀리세컨드
	(\co{flip_counter_and_wait()} 호출당 한 세트씩, 쓰레드별로 한번씩만
	기다린다 가정하더라도) 대기할 수 있군요.
	우린 grace period 가 \emph{훨씬} 더 빨리 끝나길 필요로 하지 않나요?

	\iffalse

	Great, if we have $N$ threads, we can have $2N$ ten-millisecond
	waits (one set per \co{flip_counter_and_wait()} invocation,
	and even that assumes that we wait only once for each thread).
	Don't we need the grace period to complete \emph{much} more quickly?

	\fi

}\QuickQuizAnswer{
	우린 쓰레드가 여전히 앞서서부터 존재한 RCU read-side 크리티컬 섹션 안에
	있을 때에만 그 쓰레드를 기다리며, 하나의 버티는 쓰레드를 기다리는 것은
	모든 다른 쓰레드에게 그들이 여전히 수행중일 수도 있는 기존부터 존재한
	RCU read-side 크리티컬 섹션을 완료시킬 기회를 줍니다.
	따라서 우리가 $2N$ 인터벌을 기다리게 되는 유일한 방법은 이 마지막
	쓰레드가 앞의 모든 쓰레드에 대한 모든 기다림에도 불구하고 여전히
	기존부터 존재한 RCU read-side 크리티컬 섹션에 남아있는 겁니다.
	짧게 말하자면, 이 구현은 불필요하게 기다리지 않을 겁니다.

	그러나, 여러분이 RCU 를 사용하는 코드를 스트레스 테스트 한다면,
	여러분은 RCU read-side 크리티컬 섹션 밖에서 RCU 로 보호되는 데이터
	원소를 잘못되게 참조하는 버그를 더 잘 발견하기 위해 이 \co{poll()} 문을
	주석처리하고 싶을 수도 있습니다.

	\iffalse

	Keep in mind that we only wait for a given thread if that thread
	is still in a pre-existing RCU read-side critical section,
	and that waiting for one hold-out thread gives all the other
	threads a chance to complete any pre-existing RCU read-side
	critical sections that they might still be executing.
	So the only way that we would wait for $2N$ intervals
	would be if the last thread still remained in a pre-existing
	RCU read-side critical section despite all the waiting for
	all the prior threads.
	In short, this implementation will not wait unnecessarily.

	However, if you are stress-testing code that uses RCU, you
	might want to comment out the \co{poll()} statement in
	order to better catch bugs that incorrectly retain a reference
	to an RCU-protected data element outside of an RCU
	read-side critical section.

	\fi

}\QuickQuizEnd

이 구현은 여전히 여러 단점을 가지고 있습니다.
첫째로, \co{rcu_idx} 를 두번 뒤집어야 하는 필요성은 업데이트에 상당한
오버헤드를 부과하는데, 특히 큰 수의 쓰레드가 있을때 그렇습니다.

둘째로, \co{synchronize_rcu()} 는 이제 쓰레드의 수와 함께 선형적으로 증가하는
수의 변수들을 검사해야 하는데, 큰 수의 쓰레드를 갖는 어플리케이션이 상당한
오버헤드를 부과합니다.

셋째로, 이전과 같이, 동시의 RCU 업데이트는 원칙상 공통의 grace period 에 의해
처리될 수 있어야 하지만, 이 구현은 grace period 들을 순차화 시켜서 grace-period
공유를 막습니다.

마지막으로, 앞서 설명했듯 쓰레드별 변수와 쓰레드들을 순회해야 하는 필요성은
일부 소프트웨어 환경에서는 문제가 될 수 있습니다.

\iffalse

This implementation still has several shortcomings.
First, the need to flip \co{rcu_idx} twice imposes substantial overhead
on updates, especially if there are large numbers of threads.

Second, \co{synchronize_rcu()} must now examine a number of variables
that increases linearly with the number of threads, imposing substantial
overhead on applications with large numbers of threads.

Third, as before, although concurrent RCU updates could in principle
be satisfied by a common grace period, this implementation serializes
grace periods, preventing grace-period sharing.

Finally, as noted in the text, the need for per-thread variables
and for enumerating threads may be problematic in some software
environments.

\fi

그렇다고는 하나, 이 read-side 기능은 매우 잘 확장되어서, 단일 CPU 나 64-CPU
\Power{5} 시스템에서 수행될 때나 상관 없이 약 115~나노세컨드를 소비합니다.
앞에서 언급되었듯, \co{synchronize_rcu()} 기능은 확장되지 못하는데, 단일
\Power{5} CPU 에서의 약 1 마이크로세컨드에서부터 64-CPU 시스템에서 약
200~마이크로세컨드의 오버헤드를 갖습니다.
이 구현은 제품 품질 사용자 레벨 RCU 구현의 기초를 형성할 수 있다고 생각될 수
있습니다.

다음 섹션은 더 효율적인 동시의 RCU 업데이트를 허용하는 알고리즘을 설명합니다.

\iffalse

That said, the read-side primitives scale very nicely, requiring about
115~nanoseconds regardless of whether running on a single-CPU or a 64-CPU
\Power{5} system.
As noted above, the \co{synchronize_rcu()} primitive does not scale,
ranging in overhead from almost a microsecond on a single \Power{5} CPU
up to almost 200~microseconds on a 64-CPU system.
This implementation could conceivably form the basis for a
production-quality user-level RCU implementation.

The next section describes an algorithm permitting more efficient
concurrent RCU updates.

\fi

\section{Scalable Counter-Based RCU With Shared Grace Periods}
\label{sec:app:toyrcu:Scalable Counter-Based RCU With Shared Grace Periods}

\Cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
(\path{rcu_rcpls.h})
는 앞에서와 같이 쓰레드별 레퍼런스 카운트 쌍을 이용하지만 업데이트들이 grace
period 를 공유하는 걸 허용하는 RCU 구현의 read-side 기능을 보입니다.
\begin{fcvref}[ln:defer:rcu_rcpls:r]
\Cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
에 보인
앞의 구현과의 주요 차이점은 \co{rcu_idx} 가 이제 \co{long} 이어서
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
의 \clnref{lock:idx} 는 아래쪽 비트를 마스킹 해 제거해야만 한다는 겁니다.
우린 또한 \co{atomic_read()} 와 \co{atomic_set()} 사용을 \co{READ_ONCE()}
사용으로 바꿨습니다.
데이터는 상당히 유사한데,
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data}
에 보였듯 \co{rcu_idx} 가 \co{atomic_t} 대신 \co{long} 이 되었을 뿐입니다.
\end{fcvref}

\iffalse

\Cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
(\path{rcu_rcpls.h})
shows the read-side primitives for an RCU implementation using per-thread
reference count pairs, as before, but permitting updates to share
grace periods.
\begin{fcvref}[ln:defer:rcu_rcpls:r]
The main difference from the earlier implementation shown in
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
is that \co{rcu_idx} is now a \co{long} that counts freely,
so that \clnref{lock:idx} of
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
must mask off the low-order bit.
We also switched from using \co{atomic_read()} and \co{atomic_set()}
to using \co{READ_ONCE()}.
The data is also quite similar, as shown in
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data},
with \co{rcu_idx} now being a \co{long} instead of an
\co{atomic_t}.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpls@define.fcv}
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpls@r.fcv}
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
\end{listing}

\Cref{lst:app:toyrcu:RCU Shared Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpls.c})
는 \co{synchronize_rcu()} 와 그 헬퍼 함수 \co{flip_counter_and_wait()} 를
보입니다.
이것들은
\cref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
의 것들과 비슷합니다.
\co{flip_counter_and_wait()} 의 차이점은 다음을 포함합니다:
\begin{fcvref}[ln:defer:rcu_rcpls:u:flip]
\begin{enumerate}
\item	\Clnref{inc} 는 \co{atomic_set()} 대신 \co{WRITE_ONCE()} 를 사용하고,
	보상하는 대신 값을 증가시킵니다.
\item	새로운 \clnref{mask} 는 이 카운터를 바닥 비트로 마스킹 합니다.
\end{enumerate}
\end{fcvref}

\iffalse

\Cref{lst:app:toyrcu:RCU Shared Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpls.c})
shows the implementation of \co{synchronize_rcu()} and its helper
function \co{flip_counter_and_wait()}.
These are similar to those in
\cref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}.
The differences in \co{flip_counter_and_wait()} include:
\begin{fcvref}[ln:defer:rcu_rcpls:u:flip]
\begin{enumerate}
\item	\Clnref{inc} uses \co{WRITE_ONCE()} instead of \co{atomic_set()},
	and increments rather than complementing.
\item	A new \clnref{mask} masks the counter down to its bottom bit.
\end{enumerate}
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpls@u.fcv}
\caption{RCU Shared Update Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Shared Update Using Per-Thread Reference-Count Pair}
\end{listing}

\begin{fcvref}[ln:defer:rcu_rcpls:u:sync]
\co{synchronize_rcu()} 로의 변경은 더 폭넓습니다:
\begin{enumerate}
\item	\Clnref{oldctr} 에서의 락 획득 전 \co{rcu_idx} 값을 잡아두는 지역 변수
	\co{oldctr} 이 생겼습니다.
\item	\Clnref{idx} 는 \co{atomic_read()} 대신 \co{READ_ONCE()} 를 사용합니다.
\item	\Clnrefrange{if:b}{ret} 는 락이 잡혀있는 사이 다른 쓰레드에 의해 최소
	세번의 카운터 뒤집기가 행해졌는지 보고, 그렇다면 락을 내려놓고, 메모리
	배리어를 수행하고, 리턴합니다.
	이 경우, 카우넡가 0이 되기까지의 완전한 기다림이 두번 있으므로 다른
	쓰레드들은 필요한 일을 이미 다 끝냈을 겁니다.
\item	\Clnrefrange{ifpair}{flip2} 에서, \co{flip_counter_and_wait()} 는 락이
	획득된 사이 두번 미만의 카운터 뒤집기가 행해졌다면 두번째에만
	수행됩니다.
	다른 한편, 두번의 카운터 뒤집기가 있었다면, 어떤 다른 쓰레드가 모든
	카운터가 0이 되기를 완전히 한번 기다렸으므로, 한번만 더 기다리면
	됩니다.
\end{enumerate}
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu_rcpls:u:sync]
The changes to \co{synchronize_rcu()} are more pervasive:
\begin{enumerate}
\item	There is a new \co{oldctr} local variable that captures
	the pre-lock-acquisition value of \co{rcu_idx} on
	\clnref{oldctr}.
\item	\Clnref{idx} uses \co{READ_ONCE()} instead of \co{atomic_read()}.
\item	\Clnrefrange{if:b}{ret} check to see if at least three counter flips were
	performed by other threads while the lock was being acquired,
	and, if so, releases the lock, does a memory barrier, and returns.
	In this case, there were two full waits for the counters to
	go to zero, so those other threads already did all the required work.
\item	At \clnrefrange{ifpair}{flip2}, \co{flip_counter_and_wait()} is only
	invoked a second time if there were fewer than two counter flips
	while the lock was being acquired.
	On the other hand, if there were two counter flips, some other
	thread did one full wait for all the counters to go to zero,
	so only one more is required.
\end{enumerate}
\end{fcvref}

\fi

이 방법과 함께, 임의의 큰 수의 쓰레드가 쓰레드당 CPU 하나를 가진 채 동시에
\co{synchronize_rcu()} 를 수행했다면, 카운터가 0이 되기를 기다리는 횟수는
세번만이 될겁니다.

이 개선에도 불구하고, 이 RCU 구현은 여전히 단점이 여럿 있습니다.
첫째로, 이전과 같이 \co{rcu_idx} 를 두번 뒤집어야 하는 필요성은 업데이트에
상당한 오버헤드를 부과하는데, 특히 큰 수의 쓰레드가 있을 때 그렇습니다.

둘째, 각 업데이트 쓰레드는 여전히 \co{rcu_gp_lock} 을 획득해야만 하며, 해야할
일이 없을 때조차도 그렇습니다.
이는 큰 수의 동시 업데이트가 존재하는 경우 상당한 확장성 한계를 초래할 수
있습니다.
리눅스 커널의 제품 품질 리얼타임 RCU 구현에서 이루어졌던
것처럼~\cite{PaulEMcKenney2007PreemptibleRCU} 이를 막는 방법들이 있습니다.

\iffalse

With this approach, if an arbitrarily large number of threads invoke
\co{synchronize_rcu()} concurrently, with one CPU for each thread, there
will be a total of only three waits for counters to go to zero.

Despite the improvements, this implementation of RCU still
has a few shortcomings.
First, as before, the need to flip \co{rcu_idx} twice imposes substantial
overhead on updates, especially if there are large
numbers of threads.

Second, each updater still acquires \co{rcu_gp_lock}, even if there
is no work to be done.
This can result in a severe scalability limitation
if there are large numbers of concurrent updates.
There are ways of avoiding this, as was done in a
production-quality real-time implementation of RCU for the Linux
kernel~\cite{PaulEMcKenney2007PreemptibleRCU}.

\fi

셋째, 이 구현은 쓰레드별 변수와 쓰레드를 순회하는 기능을 필요로 하는데, 다시
말하지만 어떤 소프트웨어 환경에서는 문제가 될 수 있습니다.

마지막으로, 32-bit 기계에서는 \co{rcu_idx} 카운터가 오버플로우되기까지 긴 시간
업데이트 쓰레드가 preemption 당해 있을 수도 있습니다.
이는 그런 쓰레드가 불필요한 카운터 뒤집기 두번을 강제하게 할 수 있습니다.
그러나, 각 grace period 가 1 마이크로세컨드만 소비했다고 하더라도, 공격하는
쓰레드는 한시간 이상을 preemption 당해야 할 것인데, 이 경우 추가적인 한쌍의
카운터 뒤집기가 여러분의 걱정거리 중 최소한의 것이 될 겁니다.

\iffalse

Third, this implementation requires per-thread variables
and the ability to enumerate threads, which again can be
problematic in some software environments.

Finally, on 32-bit machines, a given update thread might be
preempted long enough for the \co{rcu_idx}
counter to overflow.
This could cause such a thread to force an unnecessary
pair of counter flips.
However, even if each grace period took only one
microsecond, the offending thread would need to be
preempted for more than an hour, in which case an
extra pair of counter flips is likely the least of
your worries.

\fi

\Cref{sec:app:toyrcu:Simple Counter-Based RCU} 에서 설명한 구현에서와 같이, 이
read-side 기능은 매우 잘 확장하여, CPU 의 수에 관계 없이 약 115~나노세컨드의
오버헤드만을 일으킵니다.
\co{synchronize_rcu()} 기능은 여전히 비용이 높아서, 1 마이크로세컨드에서
16~마이크로세컨드까지의 오버헤드를 초래합니다.
그렇다고는 하나 이는
\cref{sec:app:toyrcu:Scalable Counter-Based RCU} 의 구현에서 발생하는 약
200~마이크로세컨드에 비하면 훨씬 낮은 것입니다.
따라서, 그 단점에도 불구하고, 어떤 사람들은 이 RCU 구현이 실제 삶의 제품 단계
어플리케이션에서 사용되는 걸 상상해 볼 수 있을 겁니다.

\iffalse

As with the implementation described in
\cref{sec:app:toyrcu:Simple Counter-Based RCU},
the read-side primitives scale extremely well, incurring roughly
115~nanoseconds of overhead regardless of the number of CPUs.
The \co{synchronize_rcu()} primitive is still expensive,
ranging from about one microsecond up to about 16~microseconds.
This is nevertheless much cheaper than the roughly 200~microseconds
incurred by the implementation in
\cref{sec:app:toyrcu:Scalable Counter-Based RCU}.
So, despite its shortcomings, one could imagine this
RCU implementation being used in production in real-life applications.

\fi

\QuickQuiz{
	이 모든 toy RCU 구현은 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()},
	또는 \co{synchronize_rcu()} 에서 어토믹 오퍼레이션을 가지고 있어서
	쓰레드의 수에 따라 오버헤드가 선형적으로 증가합니다.
	어떤 환경에서야 어떤 RCU 구현은 이 세개의 모든 기능이 결정적인
	($\O({1}$) 오버헤드와 응답시간을 제공하는 가벼운 구현을 즐길 수
	있을까요?

	\iffalse

	All of these toy RCU implementations have either atomic operations
	in \co{rcu_read_lock()} and \co{rcu_read_unlock()},
	or \co{synchronize_rcu()}
	overhead that increases linearly with the number of threads.
	Under what circumstances could an RCU implementation enjoy
	lightweight implementations for all three of these primitives,
	all having deterministic ($\O{1}$) overheads and latencies?

	\fi

}\QuickQuizAnswer{
	RCU 의 특수 목적 유니프로세서 구현은 이 이상을 달성할 수
	있습니다~\cite{PaulEMcKenney2009BloatwatchRCU}.

	\iffalse

	Special-purpose uniprocessor implementations of RCU can attain
	this ideal~\cite{PaulEMcKenney2009BloatwatchRCU}.

	\fi

}\QuickQuizEnd

\Cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
를 다시 참고해보면, 우린 전역 변수로의 한번의 액세스가 있고 쓰레드 지역
변수로의 네번 이상의 액세스가 있음을 볼 수 있습니다.
POSIX 쓰레드를 구현하는 시스템에서의 쓰레드 지역 액세스의 상대적으로 높은
비용을 놓고 생각해 보면, 이 세개의 쓰레드 지역 변수들을 하나의 구조체로 만들어
\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 이 각자의 쓰레드 지역 데이터를
하나의 쓰레드 지역 저장소 액세스로 액세스 할 수 있게 하고 싶을 겁니다.
그러나, 그보다도 나은 방법은 쓰레드 지역 액세스를 한번으로 줄이는 것일텐데,
이를 다음 섹션에서 합니다.

\iffalse

Referring back to
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update},
we see that there is one global-variable access and no fewer than four
accesses to thread-local variables.
Given the relatively high cost of thread-local accesses on systems
implementing POSIX threads, it is tempting to collapse the three
thread-local variables into a single structure, permitting
\co{rcu_read_lock()} and \co{rcu_read_unlock()} to access their
thread-local data with a single thread-local-storage access.
However, an even better approach would be to reduce the number of
thread-local accesses to one, as is done in the next section.

\fi

\section{RCU Based on Free-Running Counter}
\label{sec:app:toyrcu:RCU Based on Free-Running Counter}

\Cref{lst:app:toyrcu:Free-Running Counter Using RCU}
(\path{rcu.h} and \path{rcu.c}) 는
\cref{lst:app:toyrcu:Data for Free-Running Counter Using RCU}
에 보인 데이터와 함께 짝수 값만을 취하는 전역 free-running 카운터 하나에 기반한
RCU 구현을 보입니다.

\iffalse

\Cref{lst:app:toyrcu:Free-Running Counter Using RCU}
(\path{rcu.h} and \path{rcu.c})
shows an RCU implementation based on a single global free-running counter
that takes on only even-numbered values, with data shown in
\cref{lst:app:toyrcu:Data for Free-Running Counter Using RCU}.

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu@define.fcv}
\caption{Data for Free-Running Counter Using RCU}
\label{lst:app:toyrcu:Data for Free-Running Counter Using RCU}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu@read_lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu@synchronize.fcv}\fvset{firstnumber=auto}
\caption{Free-Running Counter Using RCU}
\label{lst:app:toyrcu:Free-Running Counter Using RCU}
\end{listing}

이로 인한 \co{rcu_read_lock()} 구현은 굉장히 간단합니다.
\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
\Clnref{gp1,gp2} 는 전역 free-running \co{rcu_gp_ctr} 변수에 1을 더하고 그 결과
만들어지는 홀수 값을 쓰레드별 변수 \co{rcu_reader_gp} 에 저장합니다.
\Clnref{mb} 는 뒤따르는 RCU read-side 크리티컬 섹션의 내용이 ``밖으로
새어나가는'' 것을 방지하기 위해 메모리 배리어를 수행합니다.
\end{fcvref}

\begin{fcvref}[ln:defer:rcu:read_lock_unlock:unlock]
\co{rcu_read_unlock()} 구현도 비슷합니다.
\Clnref{mb} 는 다시 앞의 RCU read-side 크리티컬 섹션이 ``새어 나오는'' 것을
막기 위해 메모리 배리어를 수행합니다.
\Clnref{gp1,gp2} 는 이어서 \co{rcu_gp_ctr} 전역 변수를 쓰레드별 변수
\co{rcu_reader_gp} 에 복사하고, 이 쓰레드별 변수를 짝수 값으로 남겨두어 동시의
\co{synchronize_rcu()} 가 이를 알고 무시할 수 있게 해줍니다.
\end{fcvref}

\iffalse

The resulting \co{rcu_read_lock()} implementation is extremely
straightforward.
\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
\Clnref{gp1,gp2} simply
add one to the global free-running \co{rcu_gp_ctr}
variable and stores the resulting odd-numbered value into the
\co{rcu_reader_gp} per-thread variable.
\Clnref{mb} executes a memory barrier to prevent the content of the
subsequent RCU read-side critical section from ``leaking out''.
\end{fcvref}

\begin{fcvref}[ln:defer:rcu:read_lock_unlock:unlock]
The \co{rcu_read_unlock()} implementation is similar.
\Clnref{mb} executes a memory barrier, again to prevent the prior RCU
read-side critical section from ``leaking out''.
\Clnref{gp1,gp2} then copy the \co{rcu_gp_ctr} global variable to the
\co{rcu_reader_gp} per-thread variable, leaving this per-thread
variable with an even-numbered value so that a concurrent instance
of \co{synchronize_rcu()} will know to ignore it.
\end{fcvref}

\fi

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu:read_lock_unlock:unlock]
	어떤 짝수 값이든 \co{synchronize_rcu()} 에게 그 태스크를 무시하라고
	말하기 충분하다면, 왜
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	의 \clnref{gp1,gp2} 는 간단히 \co{rcu_reader_gp} 에 0을 할당하지
	않나요?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu:read_lock_unlock:unlock]
	If any even value is sufficient to tell \co{synchronize_rcu()}
	to ignore a given task, why don't \clnref{gp1,gp2} of
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	simply assign zero to \co{rcu_reader_gp}?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	0 (또는 어떤 값이든 짝수 상수) 를 할당하는 것도 실제로 동작할
	것입니다만, \co{rcu_gp_ctr} 에 값을 할당하는 것은 의미있는 디버깅에
	도움이 될 것인데, 이는 개발자에게 언제 연관된 쓰레드가 마지막으로 RCU
	read-side 크리티컬 섹션을 빠져나왔는지 눈치챌 수 있게 해주기
	때문입니다.

	\iffalse

	Assigning zero (or any other even-numbered constant)
	would in fact work, but assigning the value of
	\co{rcu_gp_ctr} can provide a valuable debugging aid,
	as it gives the developer an idea of when the corresponding
	thread last exited an RCU read-side critical section.

	\fi

}\QuickQuizEnd

\begin{fcvref}[ln:defer:rcu:synchronize:syn]
따라서, \co{synchronize_rcu()} 는 모든 쓰레드별 \co{rcu_reader_gp} 변수가 짝수
값을 가지길 기다릴 수 있습니다.
그러나, \co{synchronize_rcu()} 는 \emph{앞에서부터 존재해온} RCU read-side
크리티컬 섹션만을 기다리면 되기 때문에 이보다 훨씬 더 잘할수 있습니다.
\Clnref{mb1} 은 앞의 RCU 로 보호되는 데이터 구조의 조정이 \clnref{increasegp}
뒤로 순서 재배치 되는 걸 (CPU 에 의해서든 컴파일러에 의해서든) 막기 위해 메모리
배리어를 수행합니다.
\Clnref{spinlock} 은 여러 \co{synchronize_rcu()} 인스턴스가 동시에 수행되는
것을 막기 위해 \co{rcu_gp_lock} 을 획득합니다 (그리고 \clnref{spinunlock} 에서
이를 해제합니다).
\Clnref{increasegp} 는 이어서 전역 \co{rcu_gp_ctr} 변수를 2 증가시켜서, 모든
앞서서부터 존재한 RCU read-side 크리티컬 섹션이 연관된 쓰레드별
\co{rcu_reader_gp} 변수에 \co{rcu_gp_ctr} 의 것에 해당 기계의 워드 크기로
modulo 연산한 값보다 작은 값을 갖게 합니다.
또한 \co{rcu_reader_gp} 의 짝수 값의 쓰레드는 RCU read-side 크리티컬 섹션에
있지 않으므로, \clnrefrange{scan:b}{scan:e} 는 \co{rcu_reader_gp} 값을 그 값이
모두 짝수이거나 (\clnref{even}) 전역 \co{rcu_gp_ctr} (\clnrefrange{gt1}{gt2})
보다 큰 값일 때까지 스캐닝 합니다.
\Clnref{poll} 은 앞서서부터 존재한 RCU read-side 크리티컬 섹션을 기다리기 위해
짧은 시간동안 블록됩니다만, 이는 grace-period 응답시간이 중요하다면
spin-반복문으로 대체될 수 있습니다.
마지막으로, \clnref{mb3} 에서의 메모리 배리어는 모든 뒤따르는 제거가 앞의
반복문 안으로 재배치 되지 않게 보장합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu:synchronize:syn]
Thus, \co{synchronize_rcu()} could wait for all of the per-thread
\co{rcu_reader_gp} variables to take on even-numbered values.
However, it is possible to do much better than that because
\co{synchronize_rcu()} need only wait on \emph{pre-existing}
RCU read-side critical sections.
\Clnref{mb1} executes a memory barrier to prevent prior manipulations
of RCU-protected data structures from being reordered (by either
the CPU or the compiler) to follow the increment on
\clnref{increasegp}.
\Clnref{spinlock} acquires the \co{rcu_gp_lock}
(and \clnref{spinunlock} releases it)
in order to prevent multiple
\co{synchronize_rcu()} instances from running concurrently.
\Clnref{increasegp} then increments the global \co{rcu_gp_ctr} variable by
two, so that all pre-existing RCU read-side critical sections will
have corresponding per-thread \co{rcu_reader_gp} variables with
values less than that of \co{rcu_gp_ctr}, modulo the machine's
word size.
Recall also that threads with even-numbered values of \co{rcu_reader_gp}
are not in an RCU read-side critical section,
so that \clnrefrange{scan:b}{scan:e}
scan the \co{rcu_reader_gp} values until they
all are either even (\clnref{even}) or are greater than the global
\co{rcu_gp_ctr} (\clnrefrange{gt1}{gt2}).
\Clnref{poll} blocks for a short period of time to wait for a
pre-existing RCU read-side critical section, but this can be replaced with
a spin-loop if grace-period latency is of the essence.
Finally, the memory barrier at \clnref{mb3} ensures that any subsequent
destruction will not be reordered into the preceding loop.
\end{fcvref}

\fi

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu:synchronize:syn]
	\Cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	의 \clnref{mb1,mb3} 의 메모리 배리어는 왜 필요하죠?
	\Clnref{spinlock,spinunlock} 의 락킹 기능에 내재된 메모리 배리어로
	충분하지 않나요?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu:synchronize:syn]
	Why are the memory barriers on \clnref{mb1,mb3} of
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	needed?
	Aren't the memory barriers inherent in the locking
	primitives on \clnref{spinlock,spinunlock} sufficient?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	락킹 기능은 크리티컬 섹션을 국한시키는 것만을 보장하기 때문에 이 메모리
	배리어들이 필요합니다.
	락킹 기능들은 다른 코드가 크리티컬 섹션 내로 새어들어오는 것을 막을
	책임은 전혀 없습니다.
	따라서 이런 류의 코드 움직임이 컴파일러에 의해서든 CPU 에 의해서든
	일어나는 걸 방지하기 위해 이 한쌍의 메모리 배리어가 필요합니다.

	\iffalse

	These memory barriers are required because the locking
	primitives are only guaranteed to confine the critical
	section.
	The locking primitives are under absolutely no obligation
	to keep other code from bleeding in to the critical section.
	The pair of memory barriers are therefore requires to prevent
	this sort of code motion, whether performed by the compiler
	or by the CPU\@.

	\fi

}\QuickQuizEnd

이 방법은 훨씬 나은 read-side 성능을 달성해서, \Power{5} CPU 의 갯수에 관계
없이 약 63~나노세컨드의 오버헤드를 일으킵니다.
업데이트는 더 큰 오버헤드를 일으키는데, 단일 \Power{5} CPU 에서의
500~나노세컨드에서 64 개의 CPU 에서의 100~\emph{마이크로세컨드} 를 오갑니다.

\iffalse

This approach achieves much better read-side performance, incurring
roughly 63~nanoseconds of overhead regardless of the number of
\Power{5} CPUs.
Updates incur more overhead, ranging from about 500~nanoseconds on
a single \Power{5} CPU to more than 100~\emph{microseconds} on 64
such CPUs.

\fi

\QuickQuiz{
	\Cref{sec:app:toyrcu:Scalable Counter-Based RCU With Shared Grace Periods}
	에 설명된 업데이트 쪽 batching 최적화는
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	에 보인 구현에 적용될 수 없나요?

	\iffalse

	Couldn't the update-side batching optimization described in
	\cref{sec:app:toyrcu:Scalable Counter-Based RCU With Shared Grace Periods}
	be applied to the implementation shown in
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}?

	\fi

}\QuickQuizAnswer{
	약간의 수정과 함께 실제로 그럴 수 있습니다.
	이 일은 독자 여러분의 연습을 위해 남겨둡니다.

	\iffalse

	Indeed it could, with a few modifications.
	This work is left as an exercise for the reader.

	\fi

}\QuickQuizEnd

\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
이 구현은 앞서 언급된 업데이트 쪽의 높은 오버헤드에 더해 일부 심각한 단점을
가지고 있습니다.
첫째, 더이상 RCU read-side 크리티컬 섹션의 중첩을 허용하지 않는데, 다음 섹션의
주제입니다.
둘째, 어떤 읽기 쓰레드가
\cref{lst:app:toyrcu:Free-Running Counter Using RCU} 의 \clnref{gp1} 에서
\co{rcu_gp_ctr} 에서 읽기를 했지만 \co{rcu_reader_gp} 에서 저장을 하기 전에
preemption 당한다면, 그리고 \co{rcu_gp_ctr} 카운터가 그것의 가능한 값들의
전부는 아니라도 절반 이상을 세어버린다면, \co{synchronize_rcu()} 는 뒤따르는
RCU read-side 크리티컬 섹션을 무시할 겁니다.
마지막이자 셋째, 이 구현은 소프트웨어 환경이 쓰레드를 순회할 수 있고 쓰레드별
변수를 유지할 수 있게 해야 합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
This implementation suffers from some serious shortcomings in
addition to the high update-side overhead noted earlier.
First, it is no longer permissible to nest RCU read-side critical
sections, a topic that is taken up in the next section.
Second, if a reader is preempted at \clnref{gp1} of
\cref{lst:app:toyrcu:Free-Running Counter Using RCU} after fetching from
\co{rcu_gp_ctr} but before storing to \co{rcu_reader_gp},
and if the \co{rcu_gp_ctr} counter then runs through more than half
but less than all of its possible values, then \co{synchronize_rcu()}
will ignore the subsequent RCU read-side critical section.
Third and finally, this implementation requires that the enclosing software
environment be able to enumerate threads and maintain per-thread
variables.
\end{fcvref}

\fi

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
	\Cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	의 \clnrefrange{gp1}{gp2} 에서 읽기 쓰레드가 preemption 될 수 있다는
	가능성이 잔짜로 문제인가요?  달리 말하자면, 문제를 일으킬 수 있는 실제
	이벤트 순서가 존재합니까?
	아니라면 왜 그렇습니까?
	그렇다면 그 이벤트 순서는 무엇이며 어떻게 그 문제가 처리될 수 있습니까?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
	Is the possibility of readers being preempted in
	\clnrefrange{gp1}{gp2} of
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	a real problem, in other words, is there a real sequence
	of events that could lead to failure?
	If not, why not?
	If so, what is the sequence of events, and how can the
	failure be addressed?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	이는 진짜 문제이고, 문제를 일으키는 이벤트의 순서가 존재하며, 이를
	해결하기 위한 여러 가능한 방법들이 있습니다.
	더 자세한 부분을 위해선,
	\cref{sec:app:toyrcu:Nestable RCU Based on Free-Running Counter}
	끝부분의 Quick Quizz 를 보시기 바랍니다.
	그 논의를 거기에 두는 이유는 (1) 여러분에게 생각할 시간을 더 드리기
	위해, 그리고 (2) 그 섹션에서 더해지는 중첩에 대한 지원이 카운터를
	오버플로우 시키는데 걸리는 시간을 크게 줄이기 때문입니다.

	\iffalse

	It is a real problem, there is a sequence of events leading to
	failure, and there are a number of possible ways of
	addressing it.
	For more details, see the Quick Quizzes near the end of
	\cref{sec:app:toyrcu:Nestable RCU Based on Free-Running Counter}.
	The reason for locating the discussion there is to (1) give you
	more time to think about it, and (2) because the nesting support
	added in that section greatly reduces the time required to
	overflow the counter.

	\fi

}\QuickQuizEnd

\section{Nestable RCU Based on Free-Running Counter}
\label{sec:app:toyrcu:Nestable RCU Based on Free-Running Counter}

\Cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
(\path{rcu_nest.h} 와 \path{rcu_nest.c})
는 단일 전역 free-running 카운터에 기반하나 RCU read-side 크리티컬 섹션의
중첩을 허용하는 RCU 구현을 보입니다.
이 중첩가능성은
\cref{lst:app:toyrcu:Data for Nestable RCU Using a Free-Running Counter}
에 보인 정의를 이용해 전역 \co{rcu_gp_ctr} 의 아래쪽 비트를 중첩 정도 세기를
위해 예약함으로써 이루어집니다.
이는
아래쪽의 한개 비트를 중첩 깊이를 세는데 예약해두는 것으로 생각될 수 있는,
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}
의 방법의 범용화입니다.
이를 위해 두개의 C 전처리기 매크로 \co{RCU_GP_CTR_NEST_MASK} 와
\co{RCU_GP_CTR_BOTTOM_BIT} 이 사용됩니다.
이것들은 연관되어 있습니다: \co{RCU_GP_CTR_NEST_MASK=RCU_GP_CTR_BOTTOM_BIT-1}.
이 \co{RCU_GP_CTR_BOTTOM_BIT} 매크로는 중첩을 세기 위해 예약된 비트들의 바로
앞에 위치하는 단일 비트를 담고 있고, \co{RCU_GP_CTR_NEST_MASK} 는 중첩을 세는데
사용되는 \co{rcu_gp_ctr} 의 영역을 덮는 모든 1 비트들을 갖습니다.
분명, 이 두개의 C 전처리기 매크로는 최대 필요한 RCU read-side 크리티컬 섹션
중첩을 허용하기 충분한 아래쪽 비트를 예약해야 하며, 이 구현은 최대 RCU
read-side 크리티컬 섹션 중첩 깊이 127을 위해 일곱 비트를 예약하는데, 대부분의
어플리케이션이 필요한 정도를 넘어설 겁니다.

\iffalse

\Cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
(\path{rcu_nest.h} and \path{rcu_nest.c})
shows an RCU implementation based on a single global free-running counter,
but that permits nesting of RCU read-side critical sections.
This nestability is accomplished by reserving the low-order bits of the
global \co{rcu_gp_ctr} to count nesting, using the definitions shown in
\cref{lst:app:toyrcu:Data for Nestable RCU Using a Free-Running Counter}.
This is a generalization of the scheme in
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter},
which can be thought of as having a single low-order bit reserved
for counting nesting depth.
Two C-preprocessor macros are used to arrange this,
\co{RCU_GP_CTR_NEST_MASK} and
\co{RCU_GP_CTR_BOTTOM_BIT}.
These are related: \co{RCU_GP_CTR_NEST_MASK=RCU_GP_CTR_BOTTOM_BIT-1}.
The \co{RCU_GP_CTR_BOTTOM_BIT} macro contains a single bit that is
positioned just above the bits reserved for counting nesting,
and the \co{RCU_GP_CTR_NEST_MASK} has all one bits covering the
region of \co{rcu_gp_ctr} used to count nesting.
Obviously, these two C-preprocessor macros must reserve enough
of the low-order bits of the counter to permit the maximum required
nesting of RCU read-side critical sections, and this implementation
reserves seven bits, for a maximum RCU read-side critical-section
nesting depth of 127, which should be well in excess of that needed
by most applications.

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_nest@define.fcv}
\caption{Data for Nestable RCU Using a Free-Running Counter}
\label{lst:app:toyrcu:Data for Nestable RCU Using a Free-Running Counter}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_nest@read_lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_nest@synchronize.fcv}\fvset{firstnumber=auto}
\caption{Nestable RCU Using a Free-Running Counter}
\label{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
\end{listing}

\begin{fcvref}[ln:defer:rcu_nest:read_lock_unlock:lock]
그 결과로 나오는 \co{rcu_read_lock()} 구현은 여전히 합리적 수준으로 간단합니다.
\Clnref{readgp} 는 이 쓰레드의 \co{rcu_reader_gp} 로의 포인터를 지역 변수
\co{rrgp} 에 위치시켜서 비싼 pthreads thread-local-state API 로의 호출 횟수를
최소화 합니다.
\Clnref{wtmp1} 은 \co{rcu_reader_gp} 의 현재 값을 또다른 지역 변수 \co{tmp} 에
저장하며, \clnref{checktmp} 는 이 아래쪽 비트들이 0인지, 즉 이게 가장 바깥
\co{rcu_read_lock} 인지, 검사합니다.
그렇다면 \clnref{wtmp2} 는 전역 \co{rcu_gp_ctr} 을 \co{tmp} 에 위치시키는데,
\clnref{wtmp1} 에 의해 앞서 읽은 현재값은 더이상 유효하지 않을 수 있기
때문입니다.
어느 경우든, \clnref{inctmp} 는 이 중첩 깊이를 증가시키는데, 즉 여러분이
기억해야 할 것은 이제 이 카운터의 아래쪽 7개 비트에 저장되어 있습니다.
\Clnref{writegp} 는 업데이트된 카운터를 이 쓰레드의 \co{rcu_reader_gp} 에
저장하고, 마지막으로 \clnref{mb1} 은 이 RCU read-side 크리티컬 섹션이
\co{rcu_read_lock()} 호출을 앞서는 코드로 새어나가는 걸 막기 위해 메모리
배리어를 수행합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu_nest:read_lock_unlock:lock]
The resulting \co{rcu_read_lock()} implementation is still reasonably
straightforward.
\Clnref{readgp} places a pointer to
this thread's instance of \co{rcu_reader_gp}
into the local variable \co{rrgp}, minimizing the number of expensive
calls to the pthreads thread-local-state API\@.
\Clnref{wtmp1} records the current value of \co{rcu_reader_gp}
into another local variable \co{tmp}, and \clnref{checktmp} checks
to see if the low-order bits are zero, which would indicate that
this is the outermost \co{rcu_read_lock()}.
If so, \clnref{wtmp2} places the global \co{rcu_gp_ctr}
into \co{tmp} because the current value previously fetched by
\clnref{wtmp1} is likely to be obsolete.
In either case, \clnref{inctmp} increments the nesting depth,
which you will recall is stored in the seven low-order bits of the counter.
\Clnref{writegp} stores the updated counter back into this thread's
instance of \co{rcu_reader_gp}, and,
finally, \clnref{mb1} executes a memory barrier
to prevent the RCU read-side critical section from bleeding out
into the code preceding the call to \co{rcu_read_lock()}.
\end{fcvref}

\fi

달리 말하자면, 이 \co{rcu_read_lock()} 구현은 현재 \co{rcu_read_lock()} 이 다른
RCU read-side 크리티컬 섹션의 안에 중첩되어 있지 않은한 전역 \co{rcu_gp_ctr} 의
복사본을 가져오고, 중첩되어 있다면 현재 쓰레드의 \co{rcu_reader_gp} 인스턴스의
내용을 가져온다는 겁니다.
어느 쪽이던, 추가적인 중첩 수준을 기록하기 위해 읽어온 값을 증가시키고, 그
결과를 현재 쓰레드의 \co{rcu_reader_gp} 인스턴스에 저장합니다.

\begin{fcvref}[ln:defer:rcu_nest:read_lock_unlock:unlock]
흥미롭게도, \co{rcu_read_lock()} 의 차이에도 불구하고 \co{rcu_read_unlock()}
구현은
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}
에 보인 것과 크게 유사합니다.
\Clnref{mb1} 은 RCU read-side 크리티컬 섹션이 \co{rcu_read_unlock()} 을
뒤따르는 코드로 새어나가는 걸 막기 위해 메모리 배리어를 수행하고,
\clnref{decgp} 는 이 쓰레드의 \co{rcu_reader_gp} 인스턴스의 값을 감소시키는데,
이는 \co{rcu_rader_gp} 의 아래쪽 비트에 저장된 중첩 횟수를 감소시키는 효과를
낳습니다.
이 기능의 디버깅 버전은 이 아래쪽 비트들이 0이 아니었는지 (값 감소 전에!)
검사할 겁니다.
\end{fcvref}

\iffalse

In other words, this implementation of \co{rcu_read_lock()} picks up a copy
of the global \co{rcu_gp_ctr} unless the current invocation of
\co{rcu_read_lock()} is nested within an RCU read-side critical section,
in which case it instead fetches the contents of the current thread's
instance of \co{rcu_reader_gp}.
Either way, it increments whatever value it fetched in order to record
an additional nesting level, and stores the result in the current
thread's instance of \co{rcu_reader_gp}.

\begin{fcvref}[ln:defer:rcu_nest:read_lock_unlock:unlock]
Interestingly enough, despite their \co{rcu_read_lock()} differences,
the implementation of \co{rcu_read_unlock()}
is broadly similar to that shown in
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}.
\Clnref{mb1} executes a memory barrier
in order to prevent the RCU read-side
critical section from bleeding out into code following the call
to \co{rcu_read_unlock()}, and
\clnref{decgp} decrements this thread's instance of \co{rcu_reader_gp},
which has the effect of decrementing the nesting count contained in
\co{rcu_reader_gp}'s low-order bits.
Debugging versions of this primitive would check (before decrementing!)
that these low-order bits were non-zero.
\end{fcvref}

\fi

\begin{fcvref}[ln:defer:rcu_nest:synchronize:syn]
\co{synchronize_rcu()} 의 구현은
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}
에 보인 것과 상당히 유사합니다.
두개의 차이점이 있습니다.
첫째는 \clnref{incgp1,incgp2} 가 전역 \co{rcu_gp_ctr} 에 상수 ``2'' 대신
\co{RCU_GP_CTR_BOTTOM_BIT} 을 더한다는 것이고, 두번째는 \clnref{ongoing} 에서의
비교가 별개 함수로 추상화 되었으며, 그 함수는 무조건적으로 아래쪽 비트를
검사하는게 아니라 \co{RCU_GP_CTR_BOTTOM_BIT} 에 의해 가리켜지는 비트를
검사한다는 겁니다.
\end{fcvref}

이 방법은
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter} 에 보인 것과 거의
똑같은 read-side 성능을 달성하여서 \Power{5} CPU 갯수에 관계 없이 약
65~나노세컨드를 소모합니다.
업데이트는 역시 더 큰 오버헤드를 일으키는데, 단일 \Power{5} CPU 에서의
600~나노세컨드에서 64 CPU 에서의 100~\emph{마이크로세컨드} 를 오갑니다.

\iffalse

\begin{fcvref}[ln:defer:rcu_nest:synchronize:syn]
The implementation of \co{synchronize_rcu()} is quite similar to
that shown in
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}.
There are two differences.
The first is that \clnref{incgp1,incgp2}
adds \co{RCU_GP_CTR_BOTTOM_BIT} to the global \co{rcu_gp_ctr}
instead of adding the constant ``2'',
and the second is that the comparison on \clnref{ongoing}
has been abstracted out to a separate function,
where it checks the bit indicated by \co{RCU_GP_CTR_BOTTOM_BIT}
instead of unconditionally checking the low-order bit.
\end{fcvref}

This approach achieves read-side performance almost equal to that
shown in
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}, incurring
roughly 65~nanoseconds of overhead regardless of the number of
\Power{5} CPUs.
Updates again incur more overhead, ranging from about 600~nanoseconds on
a single \Power{5} CPU to more than 100~\emph{microseconds} on 64
such CPUs.

\fi

\QuickQuiz{
	왜 이 복잡한 비트 조정 대신 앞의 섹션에서처럼 가난하게 별개의 쓰레드별
	중첩 수준 변수를 유지하지 않나요?

	\iffalse

	Why not simply maintain a separate per-thread nesting-level
	variable, as was done in previous section, rather than having
	all this complicated bit manipulation?

	\fi

}\QuickQuizAnswer{
	별개 쓰레드별 변수의 분명한 단순성은 사기입니다.
	이 방법은 오퍼레이션의 주의 깊은 순서 잡기라는 형태로 아주 큰 복잡도를
	일으키는데, 특히 시그널 핸들러가 RCU read-side 크리티컬 섹션을 포함할
	수 있을 때 그렇습니다.
	하지만 제말만 듣지 말고, 코드를 직접 짜보고 어떻게 되나 보세요!

	\iffalse

	The apparent simplicity of the separate per-thread variable
	is a red herring.
	This approach incurs much greater complexity in the guise
	of careful ordering of operations, especially if signal
	handlers are to be permitted to contain RCU read-side
	critical sections.
	But don't take my word for it, code it up and see what you
	end up with!

	\fi

}\QuickQuizEnd

이 구현은 이제 RCU read-side 크리티컬 섹션의 중첩이 허용되었다는 것만 제외하면
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}
의 것과 동일한 단점을 갖습니다.
또한, 32-bit 시스템에서 이 방법은 전역 \co{rcu_gp_ctr} 변수를 오버플로우
시키는데 걸리는 시간을 단축시킵니다.
다음 섹션은 오버플로우에 걸리는 시간을 크게 증가시키면서 read-side 오버헤드를
크게 줄이는 방법을 보입니다.

\iffalse

This implementation suffers from the same shortcomings as does that of
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}, except that
nesting of RCU read-side critical sections is now permitted.
In addition, on 32-bit systems, this approach shortens the time
required to overflow the global \co{rcu_gp_ctr} variable.
The following section shows one way to greatly increase the time
required for overflow to occur, while greatly reducing read-side
overhead.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	\Cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
	에 보인 알고리즘을 가지고 어떻게 전역 \co{rcu_gp_ctr} 의 오버플로우에
	걸리는 시간을 두배로 늘릴 수 있죠?

	\iffalse

	Given the algorithm shown in
	\cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter},
	how could you double the time required to overflow the global
	\co{rcu_gp_ctr}?

	\fi

}\QuickQuizAnswerB{
	\begin{fcvref}[ln:defer:rcu_nest:synchronize:syn]
	한가지 방법은 \clnref{lt1,lt2} 에서의 정도 비교를 쓰레드별
	\co{rcu_reader_gp} 변수의 \co{rcu_gp_ctr+RCU_GP_CTR_BOTTOM_BIT} 에 대한
	동일성 검사로 대체하는 것일 겁니다.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_nest:synchronize:syn]
	One way would be to replace the magnitude comparison on
	\clnref{lt1,lt2} with an inequality check of
	the per-thread \co{rcu_reader_gp} variable against
	\co{rcu_gp_ctr+RCU_GP_CTR_BOTTOM_BIT}.
	\end{fcvref}

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	다시,
	\cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
	의 알고리즘에서 카운터 오버플로우는 치명적인가요?
	왜 그렇죠?
	그게 치명적이라면 이를 고치기 위해 뭘 할 수 있을까요?

	\iffalse

	Again, given the algorithm shown in
	\cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter},
	is counter overflow fatal?
	Why or why not?
	If it is fatal, what can be done to fix it?

	\fi

}\QuickQuizAnswerE{
	이는 실제로 치명적일 수 있습니다.
	이를 보기 위해, 다음 이벤트 순서를 생각해 봅시다:

	\iffalse

	It can indeed be fatal.
	To see this, consider the following sequence of events:

	\fi

	\begin{enumerate}
	\item	쓰레드~0 이 \co{rcu_read_lock()} 을 진입하고, 중첩되지 않았음을
		파악한 후, 따라서 전역 \co{rcu_gp_ctr} 의 값을 가져옵니다.
		쓰레드~0 은 이어서 굉장히 긴 시간 동안 preemption 됩니다
		(자신의 쓰레드별 \co{rcu_reader_gp} 변수에 값을 저장하기 전).
	\item	다른 쓰레드들이 반복적으로 \co{synchronize_rcu()} 를 호출하고,
		따라서 전역 \co{rcu_gp_ctr} 의 새 값은 쓰레드~0 이 읽었을
		때보다 \co{RCU_GP_CTR_BOTTOM_BIT} 만큼 작은 값이 됩니다.
	\item	쓰레드~0 이 수행을 재개하고, 자신의 쓰레드별 \co{rcu_reader_gp}
		변수에 값을 저장합니다.
		이 때 저장되는 값은 전역 \co{rcu_gp_ctr} 보다
		\co{RCU_GP_CTR_BOTTOM_BIT+1} 큰 값입니다.
	\item	쓰레드~0 이 RCU 로 보호되는 데이터 원소~A 로의 참조를
		획득합니다.

	\iffalse

	\item	Thread~0 enters \co{rcu_read_lock()}, determines
		that it is not nested, and therefore fetches the
		value of the global \co{rcu_gp_ctr}.
		Thread~0 is then preempted for an extremely long time
		(before storing to its per-thread \co{rcu_reader_gp}
		variable).
	\item	Other threads repeatedly invoke \co{synchronize_rcu()},
		so that the new value of the global \co{rcu_gp_ctr}
		is now \co{RCU_GP_CTR_BOTTOM_BIT}
		less than it was when thread~0 fetched it.
	\item	Thread~0 now starts running again, and stores into
		its per-thread \co{rcu_reader_gp} variable.
		The value it stores is
		\co{RCU_GP_CTR_BOTTOM_BIT+1}
		greater than that of the global \co{rcu_gp_ctr}.
	\item	Thread~0 acquires a reference to RCU-protected data
		element~A.

	\fi

	\item	이제 쓰레드~1 이 쓰레드~0 이 막 참조를 획득한 데이터 원소~A 를
		제거합니다.
	\item	쓰레드~1 이 \co{synchronize_rcu()} 를 호출하는데, 이는 전역
		\co{rcu_gp_ctr} 을 \co{RCU_GP_CTR_BOTTOM_BIT} 만큼
		증가시킵니다.
		이어서 이 쓰레드는 모든 쓰레드별 \co{rcu_reader_gp} 변수를
		검사하지만, 쓰레드~0 의 값은 (잘못되게도) 자신이 쓰레드~1 의
		\co{synchronize_rcu()} 호출 되에 시작했다고 이야기 하므로,
		쓰레드~1 은 쓰레드~1 이 쓰레드~1 의 RCU read-side 크리티컬
		섹션을 완료할 때까지 기다리지 않습니다.
	\item	이제 쓰레드~1 은 쓰레드~0 이 여전히 참조하고 있는 데이터 원소~A
		를 메모리 해제합니다.

	\iffalse

	\item	Thread~1 now removes the data element~A that thread~0
		just acquired a reference to.
	\item	Thread~1 invokes \co{synchronize_rcu()}, which
		increments the global \co{rcu_gp_ctr} by
		\co{RCU_GP_CTR_BOTTOM_BIT}.
		It then checks all of the per-thread \co{rcu_reader_gp}
		variables, but thread~0's value (incorrectly) indicates
		that it started after thread~1's call to
		\co{synchronize_rcu()}, so thread~1 does not wait
		for thread~0 to complete its RCU read-side critical
		section.
	\item	Thread~1 then frees up data element~A, which thread~0
		is still referencing.

	\fi

	\end{enumerate}

	이 시나리오는
	\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}
	에 보인 구현에서도 발생 가능함을 알아 두십시오.

	이 문제를 해결하는 한가지 방법은 이를 오버플로우 시키는데 걸리는 시간이
	컴퓨터 시스템의 유용한 수명을 넘기게끔 64-비트 카운터를 쓰는 겁니다.
	골동품은 아닌 32-비트 x86 CPU 제품군의 멤버들은 \co{cmpxchg64b} 명령을
	통해 64-비트 카운터를 어토믹하게 조정할 수 있음을 알아 두시기 바랍니다.

	\iffalse

	Note that scenario can also occur in the implementation presented in
	\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}.

	One strategy for fixing this problem is to use 64-bit
	counters so that the time required to overflow them would exceed
	the useful lifetime of the computer system.
	Note that non-antique members of the 32-bit x86 CPU family
	allow atomic manipulation of 64-bit counters via the
	\co{cmpxchg64b} instruction.

	\fi

	또다른 방법은 비슷한 효과를 위해 grace period 가 허용되는 일어날 수
	있는 비율에 한계를 두는 겁니다.
	예를 들어, \co{synchronize_rcu()} 가 자신이 호출된 마지막 시간을 기록할
	수 있다면, 이를 뒤따르는 호출은 이 시간을 검사하고 필요한 기간을
	강제하기 위해 블록될 수 있습니다.
	예를 들어, 이 카운터의 아래쪽 네개 비트가 중첩을 위해 예약되었다면,
	그리고 grace period 가 초당 최대 10번 발생하는게 허용되어 있다면, 이
	카운터가 오버플로우 되기 위해선 300일이 넘게 걸릴 겁니다.
	그러나, 이 방법은 시스템이 CPU 위주의 높은 우선순위 리얼타임 쓰레드로
	인한 부하를 300일 동안 걸려 있을 수 있다면 도움이 되지 않습니다.
	(희박한 확률이겠지만 미리 생각해 두는게 최선입니다.)

	\iffalse

	Another strategy is to limit the rate at which grace periods are
	permitted to occur in order to achieve a similar effect.
	For example, \co{synchronize_rcu()} could record the last time
	that it was invoked, and any subsequent invocation would then
	check this time and block as needed to force the desired
	spacing.
	For example, if the low-order four bits of the counter were
	reserved for nesting, and if grace periods were permitted to
	occur at most ten times per second, then it would take more
	than 300 days for the counter to overflow.
	However, this approach is not helpful if there is any possibility
	that the system will be fully loaded with CPU-bound high-priority
	real-time threads for the full 300 days.
	(A remote possibility, perhaps, but best to consider it ahead
	of time.)

	\fi

	세번째 방법은 시스템에서 리얼타임 쓰레드를 없애버리는 겁니다.
	이 경우, preemption 당한 프로세스는 시간에 따라 우선순위를 높이고,
	따라서 카운터가 오버플로우 되기 한참 전에 수행을 재개합니다.
	물론, 이 방법은 리얼타임 어플리케이션에는 만족스럽지 못할 겁니다.

	마지막 방법은 \co{rcu_read_lock()} 이 전역 \co{rcu_gp_ctr} 의 값을
	자신의 쓰레드별 \co{rcu_reader_gp} 카운터에 저장한 후 다시 검사하고,
	전역 \co{rcu_gp_ctr} 의 새 값이 잘못되어 있다면 재시도 하는 겁니다.
	이는 동작하지만, 비결정적인 수행 시간을 \co{rcu_read_lock()} 에
	가져옵니다.
	다른 한편, 여러분의 어플리케이션이 카운터가 오버플로우 되기 충분할
	정도로 오래 preemption 당한다면, 어쨌든 결정적 수행 시간을 희망할 순
	없을 겁니다!

	\iffalse

	A third approach is to administratively abolish real-time threads
	from the system in question.
	In this case, the preempted process will age up in priority,
	thus getting to run long before the counter had a chance to
	overflow.
	Of course, this approach is less than helpful for real-time
	applications.

	A final approach would be for \co{rcu_read_lock()} to recheck
	the value of the global \co{rcu_gp_ctr} after storing to its
	per-thread \co{rcu_reader_gp} counter, retrying if the new
	value of the global \co{rcu_gp_ctr} is inappropriate.
	This works, but introduces non-deterministic execution time
	into \co{rcu_read_lock()}.
	On the other hand, if your application is being preempted long
	enough for the counter to overflow, you have no hope of
	deterministic execution time in any case!
	%
	% @@@ A fourth approach is rcu_nest32.[hc].

	\fi

}\QuickQuizEndE
}

\section{RCU Based on Quiescent States}
\label{sec:app:toyrcu:RCU Based on Quiescent States}

\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock]
\Cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
(\path{rcu_qs.h})
는
\cref{lst:app:toyrcu:Data for Quiescent-State-Based RCU}
에 보인 데이터와 함께 quiescent state 에 기반한 RCU 의 사용자 수준 구현에
사용된 read-side 기능들을 보입니다.
이 리스트의 \clnrefrange{lock:b}{unlock:e} 에 보인 것처럼 \co{rcu_read_lock()}
과 \co{rcu_read_unlock()} 기능은 아무 것도 하지 않으며, 실제로 inline 화 되고
최적화 되어 사라질 것으로 기대될 수 있는데, 리눅스 커널의 서버 빌드에서도
그렇습니다.
이는 quiescent-state 기반 RCU 구현은 RCU read-side 크리티컬 섹션의 길이를 앞서
언급한 quiescent state 를 사용해 \emph{추정} 하기 때문입니다.
이 quiescent state 각각은 이 리스트의 \clnrefrange{qs:b}{qs:e} 에 보인
\co{rcu_quiescent_state()} 호출을 포함합니다.
연장된 quiescent state (예를 들면, 블록킹) 에 진입하는 쓰레드는 이대신
\co{rcu_thread_offline()} (\clnrefrange{offline:b}{offline:e}) 를 연장된
quiescent state 에 진입할 때, 그리고 여기서 나갈 땐 \co{rcu_thread_online()}
(\clnrefrange{online:b}{online:e}) 을 호출합니다.
\co{rcu_thread_online()} 은 \co{rcu_red_lock()} 과,
\co{rcu_thread_offline()} 은 \co{rcu_read_unlock()} 과 유사합니다.
또한, \co{rcu_quiescent_state()} 는 \co{rcu_thread_online()} 뒤에 곧바로
\co{rcu_thread_offline()} 이 이어지는 것으로 생각될 수 있습니다.\footnote{
	이 리스트의 코드가 \co{rcu_quiescent_state()} 는
	\co{rcu_thread_online()} 뒤에 곧바로 \co{rcu_thread_offline()} 이
	따라오는 것으로 동일하게 일관적이지만, 이 관계는 성능 최적화에 의해
	사라집니다.}
RCU read-side 크리티컬 섹션에서 \co{rcu_quiescent_state()},
\co{rcu_thread_offline()}, 또는 \co{rcu_thread_online()} 을 호출하는 것은
불법입니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock]
\Cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
(\path{rcu_qs.h})
shows the read-side primitives used to construct a user-level
implementation of RCU based on quiescent states, with the data shown in
\cref{lst:app:toyrcu:Data for Quiescent-State-Based RCU}.
As can be seen from \clnrefrange{lock:b}{unlock:e} in the listing,
the \co{rcu_read_lock()}
and \co{rcu_read_unlock()} primitives do nothing, and can in fact
be expected to be inlined and optimized away, as they are in
server builds of the Linux kernel.
This is due to the fact that quiescent-state-based RCU implementations
\emph{approximate} the extents of RCU read-side critical sections
using the aforementioned quiescent states.
Each of these quiescent states contains a call to
\co{rcu_quiescent_state()}, which is shown from
\clnrefrange{qs:b}{qs:e} in the listing.
Threads entering extended quiescent states (for example, when blocking)
may instead call \co{rcu_thread_offline()}
(\clnrefrange{offline:b}{offline:e}) when entering
an extended quiescent state and then call
\co{rcu_thread_online()}
(\clnrefrange{online:b}{online:e}) when leaving it.
As such, \co{rcu_thread_online()} is analogous to \co{rcu_read_lock()}
and \co{rcu_thread_offline()} is analogous to \co{rcu_read_unlock()}.
In addition, \co{rcu_quiescent_state()} can be thought of as a
\co{rcu_thread_online()} immediately followed by a
\co{rcu_thread_offline()}.\footnote{
	Although the code in the listing is consistent with
	\co{rcu_quiescent_state()}
	being the same as \co{rcu_thread_online()} immediately followed by
	\co{rcu_thread_offline()}, this relationship is obscured by
	performance optimizations.}
It is illegal to invoke \co{rcu_quiescent_state()}, \co{rcu_thread_offline()},
or \co{rcu_thread_online()} from an RCU read-side critical section.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_qs@define.fcv}
\caption{Data for Quiescent-State-Based RCU}
\label{lst:app:toyrcu:Data for Quiescent-State-Based RCU}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_qs@read_lock_unlock.fcv}
\caption{Quiescent-State-Based RCU Read Side}
\label{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
\end{listing}

\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
\co{rcu_quiescent_state()} 에서, \clnref{mb1} 은 이 quiescent state 앞의 코드가
(RCU read-side 크리티컬 섹션 포함) quiescent state 안으로 재배치 되는 걸 막기
위해 메모리 배리어를 수행합니다.
\Clnrefrange{gp1}{gp2} 는 전역 \co{rcu_gp_ctr} 의 복사본을 가져오는데,
\co{rcu_gp_ctr} 이 여러번 읽혀지는 결과를 가져올 수 있는 어떤 컴파일러 최적화도
막기 위해 \co{READ_ONCE()} 를 사용하며, 이어서 읽혀진 값에 1을 더하고 이를
쓰레드별 \co{rcu_reader_qs_gp} 변수에 저장해서 모든 동시의
\co{synchronize_rcu()} 수행은 홀수 값을 읽고, 따라서 새 RCU read-side 크리티컬
섹션이 시작되었음을 알 수 있게 합니다.
이전의 RCU read-side 크리티컬 섹션을 기다리는 \co{synchronize_rcu()} 인스턴스는
따라서 이 새 것을 무시해도 됨을 알게 됩니다.
마지막으로, \clnref{mb2} 는 메모리 배리어를 수행하는데, 이는 뒤따르는 코드가
(RCU read-side 크리티컬 섹션 포함) \clnrefrange{gp1}{gp2} 와 순서를 바꾸는 걸
방지합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
In \co{rcu_quiescent_state()}, \clnref{mb1} executes a memory barrier
to prevent any code prior to the quiescent state (including possible
RCU read-side critical sections) from being reordered
into the quiescent state.
\Clnrefrange{gp1}{gp2} pick up
a copy of the global \co{rcu_gp_ctr}, using
\co{READ_ONCE()} to ensure that the compiler does not employ any
optimizations that would result in \co{rcu_gp_ctr} being fetched
more than once,
and then adds one to the value fetched and stores it into
the per-thread \co{rcu_reader_qs_gp} variable, so that any concurrent
instance of \co{synchronize_rcu()} will see an odd-numbered value,
thus becoming aware that a new RCU read-side critical section has started.
Instances of \co{synchronize_rcu()} that are waiting on older
RCU read-side critical sections will thus know to ignore this new one.
Finally, \clnref{mb2} executes a memory barrier, which prevents subsequent
code (including a possible RCU read-side critical section) from being
re-ordered with the \clnrefrange{gp1}{gp2}.
\end{fcvref}

\fi

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	\Cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	의 \clnref{mb2} 에 보인 추가적인 메모리 배리어는
	\co{rcu_quiescent_state()} 의 오버헤드를 크게 늘리지 않나요?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Doesn't the additional memory barrier shown on \clnref{mb2} of
	\cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	greatly increase the overhead of \co{rcu_quiescent_state()}?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	실제로 그렇습니다!
	따라서 이 구현의 RCU 를 사용하는 어플리케이션은
	\co{rcu_quiescent_state()} 를 절약하고 대부분의 경우
	\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 을 사용해야 합니다.

	그러나, 이 메모리 배리어는 다른 쓰레드가 그 호출자에 의해 뒤따르는 RCU
	read-side 크리티컬 섹션이 수행되기 전에 \clnrefrange{gp1}{gp2} 에
	저장된 값을 보게 하기 위해 절대적으로 필요합니다.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Indeed it does!
	An application using this implementation of RCU should therefore
	invoke \co{rcu_quiescent_state()} sparingly, instead using
	\co{rcu_read_lock()} and \co{rcu_read_unlock()} most of the
	time.

	However, this memory barrier is absolutely required so that
	other threads will see the store on
	\clnrefrange{gp1}{gp2} before any
	subsequent RCU read-side critical sections executed by the
	caller.
	\end{fcvref}

	\fi

}\QuickQuizEnd

어떤 어플리케이션들은 RCU 를 가끔만 사용하나, 사용할 때에는 많이 사용할 수도
있습니다.
그런 어플리케이션은 RCU 를 사용하기 시작할 때 \co{rcu_thread_online()} 을
사용하고 더이상 RCU 를 사용하지 않을 때 \co{rcu_thread_offline()} 을 사용할
수도 있을 겁니다.
\co{rcu_thread_offline()} 호출과 뒤따르는 \co{rcu_thread_online()} 호출 사이의
시간은 연장된 quiescent state 이므로, RCU 는 이 사이에 명시적인 quiescent state
가 등록되지 않을 것으로 예상할 겁니다.

\co{rcu_thread_offline()} 함수는 단순히 쓰레드별 \co{rcu_reader_qs_gp} 변수를
짝수 값을 가지고 있을 \co{rcu_gp_ctr} 의 현재 값으로 설정합니다.
따라서 모든 동시의 \co{synchronize_rcu()} 인스턴스는 이 쓰레드를 무시해도 됨을
알 겁니다.

\iffalse

Some applications might use RCU only occasionally, but use it very heavily
when they do use it.
Such applications might choose to use \co{rcu_thread_online()} when
starting to use RCU and \co{rcu_thread_offline()} when no longer
using RCU\@.
The time between a call to \co{rcu_thread_offline()} and a subsequent
call to \co{rcu_thread_online()} is an extended quiescent state,
so that RCU will not expect explicit quiescent states to be registered
during this time.

The \co{rcu_thread_offline()} function simply sets the
per-thread \co{rcu_reader_qs_gp} variable to the current value of
\co{rcu_gp_ctr}, which has an even-numbered value.
Any concurrent instances of \co{synchronize_rcu()} will thus know to
ignore this thread.

\fi

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	\Cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	의 \clnref{mb1,mb2} 의 메모리 배리어 한쌍은 왜 필요한가요?
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Why are the two memory barriers on \clnref{mb1,mb2} of
	\cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	needed?
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	\Clnref{mb1} 에서의 메모리 배리어는 \co{rcu_thread_offline()} 앞에 있을
	수 있는 RCU read-side 크리티컬 섹션이 컴파일러나 CPU 에 의해
	\clnrefrange{gp1}{gp2} 에서의 값 할당의 뒤로 재배치 되는 걸 방지합니다.
	\Clnref{mb2} 에서의 메모리 배리어는 엄밀히 말하면 불필요한데,
	\co{rcu_thread_offline()} 호출 뒤에 RCU read-side 크리티컬 섹션을 두는
	건 불법이기 때문입니다.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	The memory barrier on \clnref{mb1} prevents any RCU read-side
	critical sections that might precede the
	call to \co{rcu_thread_offline()} won't be reordered by either
	the compiler or the CPU to follow the assignment on
	\clnrefrange{gp1}{gp2}.
	The memory barrier on \clnref{mb2} is, strictly speaking, unnecessary,
	as it is illegal to have any RCU read-side critical sections
	following the call to \co{rcu_thread_offline()}.
	\end{fcvref}

	\fi

}\QuickQuizEnd

\co{rcu_thread_online()} 함수는 단순히 \co{rcu_quiescent_state()} 를
호출하는데, 따라서 연장된 quiescent state 의 끝을 표시합니다.

\iffalse

The \co{rcu_thread_online()} function simply invokes
\co{rcu_quiescent_state()}, thus marking the end of the extended
quiescent state.

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_qs@synchronize.fcv}
\caption{RCU Update Side Using Quiescent States}
\label{lst:app:toyrcu:RCU Update Side Using Quiescent States}
\end{listing}

\Cref{lst:app:toyrcu:RCU Update Side Using Quiescent States}
(\path{rcu_qs.c})
는 앞 섹션의 것과 상당히 비슷한 \co{synchronize_rcu()} 구현을 보입니다.

이 구현은 \co{rcu_read_lock()}--\co{rcu_read_unlock()} 왕복이 약
50~\emph{피코세컨드} 의 오버헤드를 가지는, 놀랍도록 빠른 read-side 기능을
가집니다.
\co{synchronize_rcu()} 오버헤드는 단일 CPU \Power{5} 시스템에서의
600~나노세컨드에서 64-CPU 시스템에서의 100~마이크로세컨드 사이를 오갑니다.

\iffalse

\Cref{lst:app:toyrcu:RCU Update Side Using Quiescent States}
(\path{rcu_qs.c})
shows the implementation of \co{synchronize_rcu()}, which is
quite similar to that of the preceding sections.

This implementation has blazingly fast read-side primitives, with
an \co{rcu_read_lock()}--\co{rcu_read_unlock()} round trip incurring
an overhead of roughly 50~\emph{picoseconds}.
The \co{synchronize_rcu()} overhead ranges from about 600~nanoseconds
on a single-CPU \Power{5} system up to more than 100~microseconds on
a 64-CPU system.

\fi

\QuickQuiz{
	분명히 해두자면, 2008년의 \Power{} 시스템의 클락 주파수는 상당히
	높았지만, 5\,GHz 클락 주파수조차도 반복문이 50~피코세컨드 내에 수행되게
	하는데에는 불충분해요!
	뭐가 어떻게 된거죠?

	\iffalse

	To be sure, the clock frequencies of \Power{}
	systems in 2008 were quite high, but even a 5\,GHz clock
	frequency is insufficient to allow
	loops to be executed in 50~picoseconds!
	What is going on here?

	\fi

}\QuickQuizAnswer{
	이 측정 반복문은 한쌍의 텅 빈 함수를 가지고 있으므로, 컴파일러는 이를
	최적화해 제거해 버립니다.
	이 측정 반복문은 \co{rcu_quiescent_state()} 호출 사이에 1,000 번 돌고,
	따라서 이 측정은 대략 \co{rcu_quiescent_state()} 호출 한번의 오버헤드를
	1,000 으로 나눈 값입니다.

	\iffalse

	Since the measurement loop contains a pair of empty functions,
	the compiler optimizes it away.
	The measurement loop takes 1,000 passes between each call to
	\co{rcu_quiescent_state()}, so this measurement is roughly
	one thousandth of the overhead of a single call to
	\co{rcu_quiescent_state()}.

	\fi

}\QuickQuizEnd

하지만, 이 구현은 각 쓰레드가 \co{rcu_quiescent_state()} 를 주기적으로
호출하거나 연장된 quiescent state 를 위해 \co{rcu_thread_offline()} 을 호출할
것을 필요로 합니다.
이 함수들을 주기적으로 호출해야 하는 필요성은 이 구현을 특정한 종류의
라이브러리 함수 같은 일부 상황에서는 사용하기 어렵게 할 수 있습니다.

\iffalse

However, this implementation requires that each thread either
invoke \co{rcu_quiescent_state()} periodically or to invoke
\co{rcu_thread_offline()} for extended quiescent states.
The need to invoke these functions periodically can make this
implementation difficult to use in some situations, such as for
certain types of library functions.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	왜 그 코드가 라이브러리에 있다는 사실이
	\cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side,%
	lst:app:toyrcu:RCU Update Side Using Quiescent States}
	에 보인 RCU 구현의 사용 편의성에 차이를 끼칠 수 있죠?

	\iffalse

	Why would the fact that the code is in a library make
	any difference for how easy it is to use the RCU
	implementation shown in
	\cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side,%
	lst:app:toyrcu:RCU Update Side Using Quiescent States}?

	\fi

}\QuickQuizAnswerB{
	라이브러리 함수는 호출자에 대한 제어가 전혀 없으며, 따라서 호출자가
	주기적으로 \co{rcu_quiescent_state()} 를 호출할 것을 강제할 수
	없습니다.
	다른 한편, 특정 RCU 로 보호되는 데이터 구조체로의 참조를 여럿 만든
	라이브러리 함수는 진입 시에 \co{rcu_thread_online()} 을, 주기적으로
	\co{rcu_quiescent_state()} 를, 그리고 종료 시에
	\co{rcu_thread_offline()} 을 호출할 수도 있을 겁니다.

	\iffalse

	A library function has absolutely no control over the caller,
	and thus cannot force the caller to invoke \co{rcu_quiescent_state()}
	periodically.
	On the other hand, a library function that made many references
	to a given RCU-protected data structure might be able to invoke
	\co{rcu_thread_online()} upon entry,
	\co{rcu_quiescent_state()} periodically, and
	\co{rcu_thread_offline()} upon exit.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	하지만 \co{synchronize_rcu()} 호출 동안 락을 잡고 있고, 똑같은 락을
	어떤 RCU read-side 크리티컬 섹션 내에서 잡는다면 어떻게 될까요?
	이는 데드락일 겁니다만, 어떤 코드도 만들어내지 않는 기능이 어떻게
	데드락 사이클에 참여할 수 있을까요?

	\iffalse

	But what if you hold a lock across a call to
	\co{synchronize_rcu()}, and then acquire that same lock within
	an RCU read-side critical section?
	This should be a deadlock, but how can a primitive that
	generates absolutely no code possibly participate in a
	deadlock cycle?

	\fi

}\QuickQuizAnswerE{
	이 RCU read-side 크리티컬 섹션은 이를 감싸는 \co{rcu_read_lock()} 과
	\co{rcu_read_unlock()} 을 넘어서서 앞과 나중의
	\co{rcu_quiescent_state()} 로 연장되는 효과를 가짐을 명심하십시오.
	이 \co{rcu_quiescent_state()} 는 \co{rcu_read_lock()} 뒤에 곧바로
	따라오는 \co{rcu_read_unlock()} 으로 생각될 수 있습니다.

	그렇다고 해도, 실제 데드락 그 자체는 RCU read-side 크리티컬 섹션과
	\co{synchronize_rcu()} 내에서의 락 획득에 연관되지,
	\co{rcu_quiescent_state()} 에 연관되지는 않을 겁니다.

	\iffalse

	Please note that the RCU read-side critical section is in
	effect extended beyond the enclosing
	\co{rcu_read_lock()} and \co{rcu_read_unlock()}, out to
	the previous and next call to \co{rcu_quiescent_state()}.
	This \co{rcu_quiescent_state()} can be thought of as an
	\co{rcu_read_unlock()} immediately followed by an
	\co{rcu_read_lock()}.

	Even so, the actual deadlock itself will involve the lock
	acquisition in the RCU read-side critical section and
	the \co{synchronize_rcu()}, never the \co{rcu_quiescent_state()}.

	\fi

}\QuickQuizEndE
}

또한, 이 구현은 동시의 \co{synchronize_rcu()} 호출이 grace period 를 공유하는
걸 허용하지 않습니다.
그러나, 이 버전의 RCU 에 기반한 제품 품질 RCU 구현을 쉽게 상상할 수 있을
겁니다.

\iffalse

In addition, this implementation does not permit concurrent calls
to \co{synchronize_rcu()} to share grace periods.
That said, one could easily imagine a production-quality RCU
implementation based on this version of RCU\@.

\fi

\section{Summary of Toy RCU Implementations}
\label{sec:app:toyrcu:Summary of Toy RCU Implementations}

If you made it this far, congratulations!
You should now have a much clearer understanding
not only of RCU itself, but also of the requirements of enclosing
software environments and applications.
Those wishing an even deeper understanding are invited to read
descriptions of production-quality RCU
implementations~\cite{MathieuDesnoyers2012URCU,PaulEMcKenney2007PreemptibleRCU,PaulEMcKenney2008HierarchicalRCU,PaulEMcKenney2009BloatwatchRCU}.

The preceding sections listed some desirable properties of the
various RCU primitives.
The following list is provided for easy reference for those wishing to
create a new RCU implementation.

\begin{enumerate}
\item	There must be read-side primitives (such as \co{rcu_read_lock()}
	and \co{rcu_read_unlock()}) and grace-period primitives
	(such as \co{synchronize_rcu()} and \co{call_rcu()}), such
	that any RCU read-side critical section in existence at the
	start of a grace period has completed by the end of the
	grace period.
\item	RCU read-side primitives should have minimal overhead.
	In particular, expensive operations such as cache misses,
	atomic instructions, memory barriers, and branches should
	be avoided.
\item	RCU read-side primitives should have $\O{1}$ computational
	complexity to enable real-time use.
	(This implies that readers run concurrently with updaters.)
\item	RCU read-side primitives should be usable in all contexts
	(in the Linux kernel, they are permitted everywhere except in
	the idle loop).
	An important special case is that RCU read-side primitives be
	usable within an RCU read-side critical section, in other words,
	that it be possible to nest RCU read-side critical sections.
\item	RCU read-side primitives should be unconditional, with no
	failure returns.
	This property is extremely important, as failure checking
	increases complexity and complicates testing and validation.
\item	Any operation other than a quiescent state (and thus a grace
	period) should be permitted in an RCU read-side critical section.
	In particular, irrevocable operations such as I/O should be
	permitted.
\item	It should be possible to update an RCU-protected data structure
	while executing within an RCU read-side critical section.
\item	Both RCU read-side and update-side primitives should be independent
	of memory allocator design and implementation, in other words,
	the same RCU implementation should be able to protect a given
	data structure regardless of how the data elements are allocated
	and freed.
\item	RCU grace periods should not be blocked by threads that
	halt outside of RCU read-side critical sections.
	(But note that most quiescent-state-based implementations
	violate this desideratum.)
\end{enumerate}

\QuickQuiz{
	Given that grace periods are prohibited within RCU read-side
	critical sections, how can an RCU data structure possibly be
	updated while in an RCU read-side critical section?
}\QuickQuizAnswer{
	This situation is one reason for the existence of asynchronous
	grace-period primitives such as \co{call_rcu()}.
	This primitive may be invoked within an RCU read-side critical
	section, and the specified RCU callback will in turn be invoked
	at a later time, after a grace period has elapsed.

	The ability to perform an RCU update while within an RCU read-side
	critical section can be extremely convenient, and is analogous
	to a (mythical) unconditional read-to-write upgrade for
	reader-writer locking.
}\QuickQuizEnd

\QuickQuizAnswersChp{qqztoyrcu}
