% appendix/toyrcu/toyrcu.tex
% mainfile: ../../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\QuickQuizChapter{chp:app:``Toy'' RCU Implementations}{``Toy'' RCU Implementations}{qqztoyrcu}
%
\Epigraph{The only difference between men and boys is the price of their toys.}
	 {\emph{M. H\'ebert}}
% https://www.ncbi.nlm.nih.gov/pubmed/11548147

이 부록의 toy RCU 구현은 높은 성능, 실용성, 또는 어떤 종류의 제품 단계에서의
사용을 위해서가 아닌\footnote{
	그러나, 제품 품질의 사용자 레벨 RCU 구현이
	있습니다~\cite{MathieuDesnoyers2009URCU,MathieuDesnoyers2012URCU}.}
명료성을 위해 설계되었습니다.
그러나, 여러분은 이 toy RCU 구현을 쉽게 이해하기 위해서라도
\cref{chp:Introduction,%
chp:Hardware and its Habits,%
chp:Tools of the Trade,%
cha:Partitioning and Synchronization Design,%
chp:Deferred Processing}
에 대한 깊은 이해를 필요로 할 겁니다.

\iffalse

The toy RCU implementations in this appendix are designed not for
high performance, practicality, or any kind of production use,\footnote{
	However, production-quality user-level RCU implementations
	are available~\cite{MathieuDesnoyers2009URCU,MathieuDesnoyers2012URCU}.}
but rather for clarity.
Nevertheless, you will need a thorough understanding of
\cref{chp:Introduction,%
chp:Hardware and its Habits,%
chp:Tools of the Trade,%
cha:Partitioning and Synchronization Design,%
chp:Deferred Processing}
for even these toy RCU implementations to be easily understandable.

\fi

이 부록은 RCU 구현 시리즈를 존재 보장 문제 해결의 관점에서 정교도를 높여가는
순서로 제공합니다.
\Cref{sec:app:toyrcu:Lock-Based RCU} 는 간단한 락킹에 기반한 간단한 RCU 구현을
보이고,
\crefthro{sec:app:toyrcu:Per-Thread Lock-Based RCU}
{sec:app:toyrcu:RCU Based on Quiescent States}
에서는 락킹,
\IXalt{reference counters}{reference count},
그리고 free-running 카운터에 기반한 RCU 구현 시리즈를 제공합니다.
마지막으로, \cref{sec:app:toyrcu:Summary of Toy RCU Implementations}
는 요약과 바람직한 RCU 속성의 나열을 제공합니다.

\iffalse

This appendix provides a series of RCU implementations in order of
increasing sophistication, from the viewpoint of solving the
existence-guarantee problem.
\Cref{sec:app:toyrcu:Lock-Based RCU} presents a rudimentary
RCU implementation based on simple locking, while
\crefthro{sec:app:toyrcu:Per-Thread Lock-Based RCU}
{sec:app:toyrcu:RCU Based on Quiescent States}
present a series of
simple RCU implementations based on locking, reference counters,
and free-running counters.
Finally, \cref{sec:app:toyrcu:Summary of Toy RCU Implementations}
provides a summary and a list of desirable RCU properties.

\fi

\section{Lock-Based RCU}
\label{sec:app:toyrcu:Lock-Based RCU}
\NoIndentAfterThis

\begin{listing}[htbp]
\input{CodeSamples/defer/rcu_lock@lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_lock@synchronize.fcv}\fvset{firstnumber=auto}
\caption{Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Lock-Based RCU Implementation}
\end{listing}

아마도 가장 간단한 RCU 구현은
\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
(\path{rcu_lock.h} 와 \path{rcu_lock.c}) 에 보인 것처럼 락을 사용하는 것일
겁니다.
이 구현에서, \co{rcu_read_lock()} 은 전역 spinlock 하나를 획득하고
\co{rcu_read_unlock()} 은 이를 해제하며, \co{synchronize_rcu()} 는 이 락을
획득하고는 곧바로 내려놓습니다.

\iffalse

Perhaps the simplest RCU implementation leverages locking, as
shown in
\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
(\path{rcu_lock.h} and \path{rcu_lock.c}).
In this implementation, \co{rcu_read_lock()} acquires a global
spinlock, \co{rcu_read_unlock()} releases it, and
\co{synchronize_rcu()} acquires it then immediately releases it.

\fi

\co{synchronize_rcu()} 는 락을 획득하기 (그리고 내려놓기) 전까지는 리턴하지
않으므로, 앞의 모든 RCU read-side 크리티컬 섹션이 완료되기 전까지는 리턴될 수
없고, 따라서 RCU semantic 을 완전히 구현합니다.
물론, 한번에 하나의 RCU 읽기 쓰레드만이 read-side 크리티컬 섹션에 들어가 있을
수 있는데, 이는 RCU 의 목적을 완전히 놓치는 것입니다.
또한, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 에서의 락 오퍼레이션은
굉장히 무거워서, read-side 오버헤드는 한개의 \Power{5} CPU 에서의
100~나노세컨드에서 64-CPU 시스템에서의 17~\emph{마이크로세컨드} 까지를
오갑니다.
더 나쁜게, 이 락 오퍼레이션은 \co{rcu_read_lock()} 이 데드락 사이클에 낄 수
있게 합니다.
더 나아가, 회귀적 락의 부재 시, RCU read-side 크리티컬 섹션은 중첩될 수 없고,
마지막으로, 동시의 RCU 업데이트는 흔한 grace priod 에 의해 완료되겠지만 이
구현은 grace period 들을 순차화 시켜서 grace-period 공유를 금지합니다.

\iffalse

Because \co{synchronize_rcu()} does not return until it has acquired
(and released) the lock, it cannot return until all prior RCU read-side
critical sections have completed, thus faithfully implementing
RCU semantics.
Of course, only one RCU reader may be in its read-side critical section
at a time, which almost entirely defeats the purpose of RCU\@.
In addition, the lock operations in \co{rcu_read_lock()} and
\co{rcu_read_unlock()} are extremely heavyweight,
with read-side overhead ranging from about 100~nanoseconds on a single \Power{5}
CPU up to more than 17~\emph{microseconds} on a 64-CPU system.
Worse yet,
these same lock operations permit \co{rcu_read_lock()}
to participate in deadlock cycles.
Furthermore, in absence of recursive locks,
RCU read-side critical sections cannot be nested, and, finally,
although concurrent RCU updates could in principle be satisfied by
a common grace period, this implementation serializes grace periods,
preventing grace-period sharing.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	왜
	\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
	에서의 RCU 구현 내의 모든 데드락은 다른 RCU 구현에서도 데드락이지
	않을까요?

	\iffalse

	Why wouldn't any deadlock in the RCU implementation in
	\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
	also be a deadlock in any other RCU implementation?

	\fi

}\QuickQuizAnswerB{
	\begin{fcvref}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
	\Cref{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation}
	에서의 함수 \co{foo()} 와 \co{bar()} 가 다른 CPU 에서 동시에
	호출되었다고 해봅시다.
	그럼 \co{foo()} 는 \clnref{foo:acq} 에서 \co{my_lock()} 을 획득하고,
	\clnref{bar:rrl} 에서 \co{bar()} 는 \co{rcu_gp_lock} 을 획득합니다.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
	Suppose the functions \co{foo()} and \co{bar()} in
	\cref{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation}
	are invoked concurrently from different CPUs.
	Then \co{foo()} will acquire \co{my_lock()} on \clnref{foo:acq},
	while \co{bar()} will acquire \co{rcu_gp_lock} on
	\clnref{bar:rrl}.
	\end{fcvref}

	\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
\begin{VerbatimL}[commandchars=\\\[\]]
void foo(void)
{
	spin_lock(&my_lock);		\lnlbl[foo:acq]
	rcu_read_lock();		\lnlbl[foo:rrl]
	do_something();
	rcu_read_unlock();
	do_something_else();
	spin_unlock(&my_lock);
}

void bar(void)
{
	rcu_read_lock();		\lnlbl[bar:rrl]
	spin_lock(&my_lock);		\lnlbl[bar:acq]
	do_some_other_thing();
	spin_unlock(&my_lock);
	do_whatever();
	rcu_read_unlock();
}
\end{VerbatimL}
\end{fcvlabel}
\caption{Deadlock in Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation}
\end{listing}

	\begin{fcvref}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
	\co{foo()} 가 \clnref{foo:rrl} 로 나아가면, \co{bar()} 가 잡고 있는
	\co{rcu_gp_lock} 을 획득하려 시도할 겁니다.
	그러면 \co{bar()} 가 \clnref{bar:acq} 로 나아갈 때, \co{foo()} 가 잡고
	있는 \co{my_lock} 을 획득하려 할 겁니다.
	\end{fcvref}

	그럼 각 함수는 서로가 잡고 있는 락을 기다리므로, 고전적인 데드락이
	됩니다.

	다른 RCU 구현은 \co{rcu_read_lock()} 에서 spin 하지도 block 하지도
	않으므로 데드락이 회피됩니다.

	\iffalse

	\begin{fcvref}[ln:app:toyrcu:Deadlock in Lock-Based RCU Implementation]
	When \co{foo()} advances to \clnref{foo:rrl}, it will attempt to
	acquire \co{rcu_gp_lock}, which is held by \co{bar()}.
	Then when \co{bar()} advances to \clnref{bar:acq}, it will attempt
	to acquire \co{my_lock}, which is held by \co{foo()}.
	\end{fcvref}

	Each function is then waiting for a lock that the other
	holds, a classic deadlock.

	Other RCU implementations neither spin nor block in
	\co{rcu_read_lock()}, hence avoiding deadlocks.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	\Cref{lst:app:toyrcu:Lock-Based RCU Implementation}
	의 RCU 구현에서는 왜 RCU 읽기 쓰레드들이 병렬로 수행될 수 있게끔 단순히
	reader-writer 락을 사용하지 않죠?

	\iffalse

	Why not simply use reader-writer locks in the RCU implementation
	in
	\cref{lst:app:toyrcu:Lock-Based RCU Implementation}
	in order to allow RCU readers to proceed in parallel?

	\fi

}\QuickQuizAnswerE{
	실제로 그런 방식으로 reader-writer 락을 사용할 수 있을 겁니다.
	그러나, 교재 상의 reader-writer 락은 메모리 경쟁으로 고통받으므로, 병렬
	수행을 실제로 허용하기 위해선 RCU read-side 크리티컬 섹션이 상당히
	길어져야 할 겁니다~\cite{McKenney03a}.

	다른 한편, \co{rcu_read_lock()} 에서 읽기 모드로 획득된 reader-writer
	락의 사용은 앞서 언급된 데드락 조건을 막을 겁니다.

	\iffalse

	One could in fact use reader-writer locks in this manner.
	However, textbook reader-writer locks suffer from memory
	contention, so that the RCU read-side critical sections would
	need to be quite long to actually permit parallel
	execution~\cite{McKenney03a}.

	On the other hand, use of a reader-writer lock that is
	read-acquired in \co{rcu_read_lock()} would avoid the
	deadlock condition noted above.

	\fi

}\QuickQuizEndE
}

이 구현이 제품 단계 환경에서 유용할 거라 상상하긴 어렵지만 거의 모든 사용자
단계 어플리케이션에서 구현될 수 있다는 장점을 갖추고 있긴 합니다.
더 나아가, CPU 별 락 또는 reader-writer 락을 사용하는 비슷한 구현이 2.4 리눅스
커널에 의해 제품 단계에서 사용된 바 있습니다.

이 CPU 별 락 방법의 쓰레드별 락으로 수정된 버전이 다음 섹션에서 설명됩니다.

\iffalse

It is hard to imagine this implementation being useful
in a production setting, though it does have the virtue
of being implementable in almost any user-level application.
Furthermore, similar implementations having one lock per CPU
or using reader-writer locks have been used in production
in the 2.4 Linux kernel.

A modified version of this one-lock-per-CPU approach, but instead using
one lock per thread, is described
in the next section.

\fi

\section{Per-Thread Lock-Based RCU}
\label{sec:app:toyrcu:Per-Thread Lock-Based RCU}

\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
(\path{rcu_lock_percpu.h} 와 \path{rcu_lock_percpu.c})
가 쓰레드별 락에 기반한 구현을 보입니다.
\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 함수는 현재 쓰레드의 락을 각각
획득하고 해제합니다.
\co{synchronize_rcu()} 함수는 각 쓰레드의 락을 순서대로 획득하고 해제합니다.
따라서, \co{synchronize_rcu()} 기 시작할 때 수행되고 있던 모든 RCU read-side
크리티컬 섹션은 \co{synchronize_rcu()} 가 리턴하기 전에 완료되어야만 합니다.

\iffalse

\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
(\path{rcu_lock_percpu.h} and \path{rcu_lock_percpu.c})
shows an implementation based on one lock per thread.
The \co{rcu_read_lock()} and \co{rcu_read_unlock()} functions
acquire and release, respectively, the current thread's lock.
The \co{synchronize_rcu()} function acquires and releases each thread's
lock in turn.
Therefore, all RCU read-side critical sections running
when \co{synchronize_rcu()} starts must have completed before
\co{synchronize_rcu()} can return.

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_lock_percpu@lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_lock_percpu@sync.fcv}\fvset{firstnumber=auto}
\caption{Per-Thread Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
\end{listing}

이 구현은 동시의 RCU 읽기 쓰레드를 허용하는 장점을 갖추고 있으며, 단일 전역
락에서는 일어날 수 있는 데드락 조건을 막습니다.
더 나아가, read-side 오버헤드는 약 140 나노세컨드로 높지만, CPU 의 수에 상관
없이 약 140 나노세컨드로 유지됩니다.
그러나, update-side 오버헤드는 단일 \Power{5} CPU 에서의 600 나노세컨드에서 64
CPU 에서의 100 \emph{마이크로세컨드} 까지를 오갑니다.

\iffalse

This implementation does have the virtue of permitting concurrent
RCU readers, and does avoid the deadlock condition that can arise
with a single global lock.
Furthermore, the read-side overhead, though high at roughly 140 nanoseconds,
remains at about 140 nanoseconds regardless of the number of CPUs.
However, the update-side overhead ranges from about 600 nanoseconds
on a single \Power{5} CPU
up to more than 100 \emph{microseconds} on 64 CPUs.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	\begin{fcvref}[ln:defer:rcu_lock_percpu:sync:loop]
	\Cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	의 \clnrefrange{b}{e} 에서의 반복문에서는 모든 락을 획득한 후 한번에
	해제하는게 더 깔끔하지 않을까요?
	어쨌건, 이 변경으로 인해 어떤 읽기 쓰레드도 존재하지 않는 시점이
	존재하게 되어서 모든 것을 훨씬 간단하게 만들 겁니다.
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:defer:rcu_lock_percpu:sync:loop]
	Wouldn't it be cleaner to acquire all the locks, and then
	release them all in the loop from \clnrefrange{b}{e} of
	\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}?
	After all, with this change, there would be a point in time
	when there were no readers, simplifying things greatly.
	\end{fcvref}

	\fi

}\QuickQuizAnswerB{
	이 변경을 가하는 것은 데드락을 다시 불러일으키며, 따라서 아니오, 그건
	더 깔끔하지 않습니다.

	\iffalse

	Making this change would re-introduce the deadlock, so
	no, it would not be cleaner.

	\fi

}\QuickQuizEndB
%
\QuickQuizM{
	\Cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	에 보인 구현은 데드락으로부터 자유로운가요?
	이유는 뭐죠?

	\iffalse

	Is the implementation shown in
	\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	free from deadlocks?
	Why or why not?

	\fi

}\QuickQuizAnswerM{
	한가지 데드락 상황은 어떤 락이 \co{synchronize_rcu()} 에 걸쳐 잡혀져
	있으며, 같은 락이 어떤 RCU read-side 크리티컬 섹션에 의해 획득될 때일
	겁니다.
	그러나, 이 상황은 모든 올바르게 설계된 RCU 구현을 데드락에 빠지게 할
	겁니다.
	어쨌건, \co{synchronize_rcu()} 기능은 모든 앞서 존재했던 RCU read-side 
	크리티컬 섹션이 완료되길 기다려야만 하지만, 이 크리티컬 섹션들 가운데
	하나가 \co{synchronize_rcu()} 가 수행중인 쓰레드에 의해 잡힌 락을
	기다린다면, RCU 의 정의에 내재한 데드락을 갖게 됩니다.

	또다른 데드락 상황은 RCU read-side 크리티컬 섹션을 중첩시키려 할 때
	발생합니다.
	이 데드락은 이 구현에만 있으며, 재귀 락을 사용하거나
	\co{rcu_read_lock()} 에 의해 읽기 모드로 획득되고
	\co{synchronize_rcu()} 에 의해 쓰기 모드로 획득되는 reader-writer 락의
	사용으로 회피될 수도 있을 겁니다.

	\iffalse

	One deadlock is where a lock is
	held across \co{synchronize_rcu()}, and that same lock is
	acquired within an RCU read-side critical section.
	However, this situation could deadlock any correctly designed
	RCU implementation.
	After all, the \co{synchronize_rcu()} primitive must wait for all
	pre-existing RCU read-side critical sections to complete,
	but if one of those critical sections is spinning on a lock
	held by the thread executing the \co{synchronize_rcu()},
	we have a deadlock inherent in the definition of RCU\@.

	Another deadlock happens when attempting to nest RCU read-side
	critical sections.
	This deadlock is peculiar to this implementation, and might
	be avoided by using recursive locks, or by using reader-writer
	locks that are read-acquired by \co{rcu_read_lock()} and
	write-acquired by \co{synchronize_rcu()}.

	\fi

	그러나, 앞의 두 경우를 배제한다면, 이 RCU 구현은 어떤 데드락 상황도
	초래하지 않습니다.
	이는 어떤 다른 쓰레드의 락이 획득된 시점은 \co{synchronize_rcu()} 가
	수행중일 때 뿐이며, 락은 곧바로 해제될 것이어서 앞의 첫번째 경우인,
	\co{synchronize_rcu()} 에 걸쳐 잡힌 락이 관여되는 데드락 사이클을
	방지하기 때문입니다.

	\iffalse

	However, if we exclude the above two cases,
	this implementation of RCU does not introduce any deadlock
	situations.
	This is because only time some other thread's lock is acquired is when
	executing \co{synchronize_rcu()}, and in that case, the lock
	is immediately released, prohibiting a deadlock cycle that
	does not involve a lock held across the \co{synchronize_rcu()}
	which is the first case above.

	\fi

}\QuickQuizEndM
%
\QuickQuizE{
	\Cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	에 보인 RCU 알고리즘의 한가지 장점은 예를 들면 POSIX pthreads 같은
	곳에서 널리 사용 가능한 기능만을 사용한다는 점일까요?

	\iffalse

	Isn't one advantage of the RCU algorithm shown in
	\cref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	that it uses only primitives that are widely available,
	for example, in POSIX pthreads?

	\fi

}\QuickQuizAnswerE{
	이는 실제로 장점입니다만, \co{rcu_dereference()} 와
	\co{rcu_assign_pointer()} 는 여전히 필요한데, \co{rcu_dereference()}
	에서의 \co{volatile} 조정과 \co{rcu_assign_pointer()} 에서의 메모리
	배리어 사용을 의미합니다.
	물론, 두 기능 모두 Alpha CPU 에서는 메모리 배리어가 필요할 겁니다.

	\iffalse

	This is indeed an advantage, but do not forget that
	\co{rcu_dereference()} and \co{rcu_assign_pointer()}
	are still required, which means \co{volatile} manipulation
	for \co{rcu_dereference()} and memory barriers for
	\co{rcu_assign_pointer()}.
	Of course, many Alpha CPUs require memory barriers for both
	primitives.

	\fi

}\QuickQuizEndE
}

이 방법은 비슷한 방법이 리눅스 2.4 커널에서 사용되었다는 점을 볼
때~\cite{Molnar00a} 일부 상황에서 유용할 수 있습니다.

이어서 소개될 카운터 기반 RCU 구현은 락 기반 구현의 단점들 일부를 극복합니다.

\iffalse

This approach could be useful in some situations, given that a similar
approach was used in the
Linux 2.4 kernel~\cite{Molnar00a}.

The counter-based RCU implementation described next overcomes some of
the shortcomings of the lock-based implementation.

\fi

\section{Simple Counter-Based RCU}
\label{sec:app:toyrcu:Simple Counter-Based RCU}

약간 더 진보된 RCU 구현이
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
(\path{rcu_rcg.h} 와 \path{rcu_rcg.c}) 에 보여 있습니다.
\begin{fcvref}[ln:defer:rcu_rcg]
이 구현은 \clnref{lock_unlock:grc} 에 정의된 전역 레퍼런스 카운터
\co{rcu_refcnt} 를 사용합니다.
\co{rcu_read_lock()} 기능은 이 카운터를 어토믹하게 증가시키고, RCU read-side
크리티컬 섹션이 이 어토믹 값 증가 뒤로 순서잡혔음을 보장하기 위해 메모리
배리어를 수행합니다.
비슷하게, \co{rcu_read_unlock()} 은 RCU read-side 크리티컬 섹션을 가두기 위해
메모리 배리어를 수행하고 이어서 이 카운터를 어토믹하게 감소시킵니다.
\co{synchronize_rcu()} 기능은 이 레퍼런스 카운터가 0이 되기를 메모리 배리어로
감싸진 가운데에서 기다립니다.
\Clnref{sync:poll} 의 \co{poll()} 은 그저 순수한 지연을 제공하며, 순수한 RCU
semantic 관점에서는 없어져도 됩니다.
다시 말하지만, 일단 \co{synchronize_rcu()} 가 리턴하면, 모든 앞의 RCU read-side
크리티컬 섹션은 완료되었을 것이 보장됩니다.
\end{fcvref}

\iffalse

A slightly more sophisticated RCU implementation is shown in
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
(\path{rcu_rcg.h} and \path{rcu_rcg.c}).
\begin{fcvref}[ln:defer:rcu_rcg]
This implementation makes use of a global reference counter
\co{rcu_refcnt} defined on \clnref{lock_unlock:grc}.
The \co{rcu_read_lock()} primitive atomically increments this
counter, then executes a memory barrier to ensure that the
RCU read-side critical section is ordered after the atomic
increment.
Similarly, \co{rcu_read_unlock()} executes a memory barrier to
confine the RCU read-side critical section, then atomically
decrements the counter.
The \co{synchronize_rcu()} primitive spins waiting for the reference
counter to reach zero, surrounded by memory barriers.
The \co{poll()} on \clnref{sync:poll} merely provides pure delay, and from
a pure RCU-semantics point of view could be omitted.
Again, once \co{synchronize_rcu()} returns, all prior
RCU read-side critical sections are guaranteed to have completed.
\end{fcvref}

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcg@lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_rcg@sync.fcv}\fvset{firstnumber=auto}
\caption{RCU Implementation Using Single Global Reference Counter}
\label{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
\end{listing}

\Cref{sec:app:toyrcu:Lock-Based RCU} 에 보인 락 기반 구현과의 행복한 대조로, 이
구현은 RCU read-side 크리티컬 섹션의 병렬 수행을 허용합니다.
\Cref{sec:app:toyrcu:Per-Thread Lock-Based RCU} 에 보인 쓰레드별 락 기반
구현과의 행복한 대조로, 이 구현은 또한 중첩을 허용합니다.
또한, \co{rcu_read_lock()} 기능은 데드락 사이클에 참여될 수 없는데, spin 도
block 도 하지 않기 때문입니다.

\iffalse

In happy contrast to the lock-based implementation shown in
\cref{sec:app:toyrcu:Lock-Based RCU}, this implementation
allows parallel execution of RCU read-side critical sections.
In happy contrast to the per-thread lock-based implementation shown in
\cref{sec:app:toyrcu:Per-Thread Lock-Based RCU},
it also allows them to be nested.
In addition, the \co{rcu_read_lock()} primitive cannot possibly
participate in deadlock cycles, as it never spins nor blocks.

\fi

\QuickQuiz{
	하지만 여러분이 \co{synchronize_rcu()} 호출 전반에 걸쳐 락을 잡고 있고,
	어떤 RCU read-side 크리티컬 섹션 내에서 같은 락을 잡으면 어떻게 될까요?

	\iffalse

	But what if you hold a lock across a call to
	\co{synchronize_rcu()}, and then acquire that same lock within
	an RCU read-side critical section?

	\fi

}\QuickQuizAnswer{
	실제로 이는 모든 합법적 RCU 구현에 데드락을 초래할 수 있습니다.
	하지만 \co{rcu_read_lock()} 은 \emph{정말로} 이 데드락 사이클에
	참여하고 있나요?
	그렇다고 믿는다면,
	\cref{sec:app:toyrcu:RCU Based on Quiescent States} 의 RCU 구현을 볼 때
	같은 질문을 스스로에게 해보세요.

	\iffalse

	Indeed, this would deadlock any legal RCU implementation.
	But is \co{rcu_read_lock()} \emph{really} participating in
	the deadlock cycle?
	If you believe that it is, then please
	ask yourself this same question when looking at the
	RCU implementation in
	\cref{sec:app:toyrcu:RCU Based on Quiescent States}.

	\fi

}\QuickQuizEnd

그러나, 이 구현은 여전히 심각한 단점이 있습니다.
첫째로, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 의 어토믹 오퍼레이션은
여전히 무거워서, read-side 오버헤드를 단일 \Power{5} CPU 에서의
100~나노세컨드에서 64-CPU 시스템에서의 40~\emph{마이크로세컨드} 를 오가게
합니다.
이는 RCU read-side 크리티컬 섹션이 실제 read-side 병렬성을 얻기 위해서는 굉장히
길어야 함을 의미합니다.
다른 한편, 읽기 쓰레드가 부재할 경우, grace period 는 40~\emph{나노세컨드}
가량에 끝나는데, 리눅스 커널의 제품 품질 구현보다 수십수백배 빠릅니다.

\iffalse

However, this implementation still has some serious shortcomings.
First, the atomic operations in \co{rcu_read_lock()} and
\co{rcu_read_unlock()} are still quite  heavyweight,
with read-side overhead ranging from about 100~nanoseconds on
a single \Power{5} CPU up to almost 40~\emph{microseconds}
on a 64-CPU system.
This means that the RCU read-side critical sections
have to be extremely long in order to get any real
read-side parallelism.
On the other hand, in the absence of readers, grace periods elapse
in about 40~\emph{nanoseconds}, many orders of magnitude faster
than production-quality implementations in the Linux kernel.

\fi

\QuickQuiz{
	\co{synchronize_rcu()} 가 10-밀리세컨드 지연을 갖는데 어떻게 grace
	peirod 는 40 나노세컨드에 끝날 수 있죠?

	\iffalse

	How can the grace period possibly elapse in 40 nanoseconds when
	\co{synchronize_rcu()} contains a 10-millisecond delay?

	\fi

}\QuickQuizAnswer{
	이 업데이트 쪽 테스트는 읽기 쓰레드의 부재 하에 수행되었으므로,
	\co{poll()} 시스템 콜이 아예 수행되지 않았습니다.
	또한, 실제 코드는 이 \co{poll()} 시스템콜이 주석처리 되어 있어서, 이
	업데이트 쪽 코드의 실제 오버헤드를 더 잘 평가할 수 있었습니다.
	이 코드의 제품 환경에서의 사용은 \co{poll()} 시스템 콜의 사용을 통해
	나아질 수 있겠습니다만, 다시 말하지만 제품 환경에서의 사용의 경우 이
	섹션의 뒤쪽에서 소개할 다른 구현을 사용하는게 나을 겁니다.

	\iffalse

	The update-side test was run in absence of readers, so the
	\co{poll()} system call was never invoked.
	In addition, the actual code has this \co{poll()}
	system call commented out, the better to evaluate the
	true overhead of the update-side code.
	Any production uses of this code would be better served by
	using the \co{poll()} system call, but then again,
	production uses would be even better served by other implementations
	shown later in this section.

	\fi

}\QuickQuizEnd

둘째로 수많은 동시의 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()}
오퍼레이션이 존재한다면, \co{rcu_refcnt} 에 상당한 메모리 경쟁이 존재할
것이어서 비싼 캐쉬 미스를 초래할 겁니다.
이 두개의 단점은 RCU 의 주요 목적인 낮은 오버헤드의 read-side 동기화 기능
제공하기를 크게 해칩니다.

마지막으로, 긴 read-side 크리티컬 섹션을 갖는 큰 수의 RCU 읽기 쓰레드는
\co{synchronize_rcu()} 가 평생 완료되지 못하게 할 수 있는데, 이 전역 카운터가
평생 0이 되지 않을 수도 있기 때문입니다.
이는 RCU 업데이트 쓰레드의 기아를 초래할 수 있는데, 이 역시 제품 환경에서는
받아들여질 수 없는 일입니다.

\iffalse

Second, if there are many concurrent \co{rcu_read_lock()}
and \co{rcu_read_unlock()} operations, there will
be extreme memory contention on \co{rcu_refcnt},
resulting in expensive cache misses.
Both of these first two shortcomings largely defeat a major purpose of
RCU, namely to provide low-overhead read-side synchronization primitives.

Finally, a large number of RCU readers with long read-side
critical sections could prevent \co{synchronize_rcu()}
from ever completing, as the global counter might
never reach zero.
This could result in starvation of RCU updates, which
is of course unacceptable in production settings.

\fi

\QuickQuiz{
	\Cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
	의 RCU 구현에서 \co{synchronize_rcu()} 가 너무 오래 기다리고 있었다면
	\co{rcu_read_lock()} 이 기다리게 하는건 어떤가요?
	이게 \co{synchronize_rcu()} 가 기아에 빠지는 걸 방지하지 않을까요?

	\iffalse

	Why not simply make \co{rcu_read_lock()} wait when a concurrent
	\co{synchronize_rcu()} has been waiting too long in
	the RCU implementation in
	\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}?
	Wouldn't that prevent \co{synchronize_rcu()} from starving?

	\fi

}\QuickQuizAnswer{
	이게 실제로 기아를 제거하겠지만, 이는 또한 \co{rcu_read_lock()} 이 쓰기
	쓰레드를 기다리느라 spin 또는 block 을 함을 의미하는데, 이는 결국 읽기
	쓰레드를 기다리는 일입니다.
	이 읽기 쓰레드들 중 하나가 이 spin/block 하는 \co{rcu_read_lock()} 이
	잡고 있는 락을 잡으려 한다면 우린 또다시 데드락에 빠집니다.

	짧게 발해서, 이 치료법은 질병보다 더 나쁩니다.
	올바른 치료를 위해선
	\cref{sec:app:toyrcu:Starvation-Free Counter-Based RCU} 를 보십시오.

	\iffalse

	Although this would in fact eliminate the starvation, it would
	also mean that \co{rcu_read_lock()} would spin or block waiting
	for the writer, which is in turn waiting on readers.
	If one of these readers is attempting to acquire a lock that
	the spinning/blocking \co{rcu_read_lock()} holds, we again
	have deadlock.

	In short, the cure is worse than the disease.
	See \cref{sec:app:toyrcu:Starvation-Free Counter-Based RCU}
	for a proper cure.

	\fi

}\QuickQuizEnd

따라서, 이 구현 역시 제품 환경에서 유용할 거라 상상하기는 어렵지만 락 기반
메커니즘에 비해서는 예를 들면 높은 부하에서의 디버깅 환경에 적합한 RCU
구현으로는 약간 더 나은 잠재력을 가지고 있습니다.
다음 섹션은 읽기 쓰레드에 더 선호될 레퍼런스 카운팅 방법의 변주를 설명합니다.

\iffalse

Therefore, it is still hard to imagine this implementation being useful
in a production setting, though it has a bit more potential
than the lock-based mechanism, for example, as an RCU implementation
suitable for a high-stress debugging environment.
The next section describes a variation on the reference-counting
scheme that is more favorable to writers.

\fi

\section{Starvation-Free Counter-Based RCU}
\label{sec:app:toyrcu:Starvation-Free Counter-Based RCU}

\Cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
(\path{rcu_rcpg.h})
가
\cref{lst:app:toyrcu:RCU Global Reference-Count Pair Data}
에 보인 한 쌍의 레퍼런스 카운터와 (\co{rcu_refcnt[]}) 이 쌍 중에서 하나의
카운터를 선택하는 전역 인덱스 (\co{rcu_idx}), 쓰레드별 중첩 카운터
(\co{rcu_nesting}), 쓰레드별 전역 인덱스의 스냅샷 (\co{rcu_read_idx}), 그리고
전역 락 (\co{rcu_gp_lock}) 을 사용하는 RCU 구현의 read-side 기능을 보이고
있습니다.

\iffalse

\Cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
(\path{rcu_rcpg.h})
shows the read-side primitives of an RCU implementation that uses a pair
of reference counters (\co{rcu_refcnt[]}),
along with a global index that
selects one counter out of the pair (\co{rcu_idx}),
a per-thread nesting counter (\co{rcu_nesting}),
a per-thread snapshot of the global index (\co{rcu_read_idx}),
and a global lock (\co{rcu_gp_lock}),
which are themselves shown in
\cref{lst:app:toyrcu:RCU Global Reference-Count Pair Data}.

\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpg@define.fcv}
\caption{RCU Global Reference-Count Pair Data}
\label{lst:app:toyrcu:RCU Global Reference-Count Pair Data}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpg@r.fcv}
\caption{RCU Read-Side Using Global Reference-Count Pair}
\label{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
\end{listing}

\paragraph{Design}

기아로부터의 자유를 제공하는 건 \co{rcu_refcnt[]} 배열의 두 원소입니다.
핵심은 \co{synchronize_rcu()} 가 앞서 존재한 읽기 쓰레드들만을 기다리면 된다는
겁니다.
만약 어떤 새로운 읽기 쓰레드가 특정 \co{synchronize_rcu()} 호출이 수행을 시작한
후에 시작된다면, 이 \co{synchronize_rcu()} 수행은 이 새 읽기 쓰레드를 기다리지
않아도 됩니다.
언제든, 특정 읽기 쓰레드가 자신의 RCU read-side 크리티컬 섹션을
\co{rcu_read_lock()} 을 통해 시작했을 때, 이 쓰레드는 \co{rcu_idx} 변수로
가리켜지는 \co{rcu_refcnt[]} 배열의 원소를 값 증가시킵니다.
이 똑같은 읽기 쓰레드가 \co{rcu_read_unlock()} 을 통해 자신의 RCU read-side
크리티컬 섹션을 종료할 때, 이 쓰레드는 모든 가능한 \co{rcu_idx} 값으로의
뒤따르는 변화를 무시하고 무엇이든 자신이 증가시킨 원소의 값을 감소시킵니다.

\iffalse

It is the two-element \co{rcu_refcnt[]} array that provides the freedom
from starvation.
The key point is that \co{synchronize_rcu()} is only required to wait
for pre-existing readers.
If a new reader starts after a given instance of \co{synchronize_rcu()}
has already begun execution, then that instance of \co{synchronize_rcu()}
need not wait on that new reader.
At any given time, when a given reader enters its RCU read-side critical
section via \co{rcu_read_lock()},
it increments the element of the \co{rcu_refcnt[]} array indicated by
the \co{rcu_idx} variable.
When that same reader exits its RCU read-side critical section via
\co{rcu_read_unlock()}, it decrements whichever element it incremented,
ignoring any possible subsequent changes to the \co{rcu_idx} value.

\fi

이 조정은 \co{synchronize_rcu()} 는 \co{rcu_idx} 의 값을
\co{rcu_idx = !rcu_idx} 로 조정함으로써 기아를 막을 수 있음을 의미합니다.
\co{rcu_idx} 의 기존 값이 0 이었고, 따라서 새 값은 1이라고 해봅시다.
이 값 조정 오퍼레이션 뒤에 도착한 새 읽기 쓰레드는 \co{rcu_refcnt[1]} 의 값을
증가시킬 것이며, 앞서 \co{rcu_refcnt[0]} 의 값을 증가시킨 기존 읽기 쓰레드들은
자신의 RCU read-side 크리티컬 섹션을 종료할 때 \co{rcu_refcnt[0]} 의 값을
감소시킬 겁니다.
이는 \co{rcu_refcnt[0]} 의 값이 더이상 증가되지 않을 것이며, 따라서 단조 감소할
것을 의미합니다.\footnote{
	이 ``단조 감소'' 를 무시하는 경주 조건이 존재합니다.
	이 경주 조건은 \co{synchronize_rcu()} 코드를 통해 처리될 겁니다.
	그 전까지는 불신을 미뤄두길 제안합니다.}
이는 \co{synchronize_rcu()} 가 해야할 모든 일은 \co{rcu_refcnt[0]} 의 값이 0이
되길 기다리는 것 뿐임을 의미합니다.

이 배경지식과 함께라면, 실제 기능의 구현을 들여다볼 준비가 되었습니다.

\iffalse

This arrangement means that \co{synchronize_rcu()} can avoid starvation
by complementing the value of \co{rcu_idx}, as in \co{rcu_idx = !rcu_idx}.
Suppose that the old value of \co{rcu_idx} was zero, so that the new
value is one.
New readers that arrive after the complement operation will increment
\co{rcu_refcnt[1]}, while the old readers that previously incremented
\co{rcu_refcnt[0]} will decrement \co{rcu_refcnt[0]} when they exit their
RCU read-side critical sections.
This means that the value of \co{rcu_refcnt[0]} will no longer be incremented,
and thus will be monotonically decreasing.\footnote{
	There is a race condition that this ``monotonically decreasing''
	statement ignores.
	This race condition will be dealt with by the code for
	\co{synchronize_rcu()}.
	In the meantime, I suggest suspending disbelief.}
This means that all that \co{synchronize_rcu()} need do is wait for the
value of \co{rcu_refcnt[0]} to reach zero.

With the background, we are ready to look at the implementation of the
actual primitives.

\fi

\paragraph{Implementation}

The \co{rcu_read_lock()} primitive atomically increments the member of the
\co{rcu_refcnt[]} pair indexed by \co{rcu_idx}, and keeps a
snapshot of this index in the per-thread variable \co{rcu_read_idx}.
The \co{rcu_read_unlock()} primitive then atomically decrements
whichever counter of the pair that the corresponding \co{rcu_read_lock()}
incremented.
However, because only one value of \co{rcu_idx} is remembered per thread,
additional measures must be taken to permit nesting.
These additional measures use the per-thread \co{rcu_nesting} variable
to track nesting.

\begin{fcvref}[ln:defer:rcu_rcpg:r:lock]
To make all this work, \clnref{pick} of \co{rcu_read_lock()} in
\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
picks up the
current thread's instance of \co{rcu_nesting}, and if \clnref{if} finds
that this is the outermost \co{rcu_read_lock()},
then \clnrefrange{cur:b}{cur:e} pick up the current value of
\co{rcu_idx}, save it in this thread's instance of \co{rcu_read_idx},
and atomically increment the selected element of \co{rcu_refcnt}.
Regardless of the value of \co{rcu_nesting}, \clnref{inc} increments it.
\Clnref{mb} executes a memory barrier to ensure that the RCU read-side
critical section does not bleed out before the \co{rcu_read_lock()} code.
\end{fcvref}

\begin{fcvref}[ln:defer:rcu_rcpg:r:unlock]
Similarly, the \co{rcu_read_unlock()} function executes a memory barrier
at \clnref{mb}
to ensure that the RCU read-side critical section does not bleed out
after the \co{rcu_read_unlock()} code.
\Clnref{nest} picks up this thread's instance of \co{rcu_nesting}, and if
\clnref{if} finds that this is the outermost \co{rcu_read_unlock()},
then \clnref{idx,atmdec} pick up this thread's instance of \co{rcu_read_idx}
(saved by the outermost \co{rcu_read_lock()}) and atomically decrements
the selected element of \co{rcu_refcnt}.
Regardless of the nesting level, \clnref{decnest} decrements this thread's
instance of \co{rcu_nesting}.
\end{fcvref}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpg@sync.fcv}
\caption{RCU Update Using Global Reference-Count Pair}
\label{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
\end{listing}

\begin{fcvref}[ln:defer:rcu_rcpg:sync]
\Cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
(\path{rcu_rcpg.c})
shows the corresponding \co{synchronize_rcu()} implementation.
\Clnref{acq,rel} acquire and release \co{rcu_gp_lock} in order to
prevent more than one concurrent instance of \co{synchronize_rcu()}.
\Clnref{pick,compl} pick up the value of \co{rcu_idx} and complement it,
respectively, so that subsequent instances of \co{rcu_read_lock()}
will use a different element of \co{rcu_refcnt} than did preceding
instances.
\Clnrefrange{while:b}{while:e}
then wait for the prior element of \co{rcu_refcnt} to
reach zero, with the memory barrier on \clnref{mb2} ensuring that the check
of \co{rcu_refcnt} is not reordered to precede the complementing of
\co{rcu_idx}.
\Clnrefrange{mb3}{while2:e} repeat this process, and
\clnref{mb5} ensures that any
subsequent reclamation operations are not reordered to precede the
checking of \co{rcu_refcnt}.
\end{fcvref}

\QuickQuizSeries{%
\QuickQuizB{
	\begin{fcvref}[ln:defer:rcu_rcpg:sync]
	Why the memory barrier on \clnref{mb1} of \co{synchronize_rcu()} in
	\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	given that there is a spin-lock acquisition immediately after?
	\end{fcvref}
}\QuickQuizAnswerB{
	The spin-lock acquisition only guarantees that the spin-lock's
	critical section will not ``bleed out'' to precede the
	acquisition.
	It in no way guarantees that code preceding the spin-lock
	acquisition won't be reordered into the critical section.
	Such reordering could cause a removal from an RCU-protected
	list to be reordered to follow the complementing of
	\co{rcu_idx}, which could allow a newly starting RCU
	read-side critical section to see the recently removed
	data element.

	Exercise for the reader: use a tool such as Promela/\co{spin}
	to determine which (if any) of the memory barriers in
	\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	are really needed.
	See \cref{chp:Formal Verification}
	for information on using these tools.
	The first correct and complete response will be credited.
}\QuickQuizEndB
%
\QuickQuizE{
	Why is the counter flipped twice in
	\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}?
	Shouldn't a single flip-and-wait cycle be sufficient?
}\QuickQuizAnswerE{
	\begin{fcvref}[ln:defer:rcu_rcpg]
	Both flips are absolutely required.
	To see this, consider the following sequence of events:
	\begin{enumerate}
	\item	\Clnref{r:lock:cur:b} of \co{rcu_read_lock()} in
		\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
		picks up \co{rcu_idx}, finding its value to be zero.
	\item	\Clnref{sync:compl} of \co{synchronize_rcu()} in
		\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
		complements the value of \co{rcu_idx}, setting its
		value to one.
	\item	\Clnrefrange{sync:while:b}{sync:while:e}
		of \co{synchronize_rcu()} find that the
		value of \co{rcu_refcnt[0]} is zero, and thus
		returns.
		(Recall that the question is asking what happens if
		\clnrefrange{sync:mb3}{sync:mb5} are omitted.)
	\item	\Clnref{r:lock:set,r:lock:cur:e}
		of \co{rcu_read_lock()} store the
		value zero to this thread's instance of \co{rcu_read_idx}
		and increments \co{rcu_refcnt[0]}, respectively.
		Execution then proceeds into the RCU read-side critical
		section.
		\label{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start}
	\item	Another instance of \co{synchronize_rcu()} again complements
		\co{rcu_idx}, this time setting its value to zero.
		Because \co{rcu_refcnt[1]} is zero, \co{synchronize_rcu()}
		returns immediately.
		(Recall that \co{rcu_read_lock()} incremented
		\co{rcu_refcnt[0]}, not \co{rcu_refcnt[1]}!)
		\label{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
	\item	The grace period that started in
		step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
		has been allowed to end, despite
		the fact that the RCU read-side critical section
		that started beforehand in
		step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start}
		has not completed.
		This violates RCU semantics, and could allow the update
		to free a data element that the RCU read-side critical
		section was still referencing.
	\end{enumerate}

	Exercise for the reader: What happens if \co{rcu_read_lock()}
	is preempted for a very long time (hours!) just after
	\clnref{r:lock:cur:b}?
	Does this implementation operate correctly in that case?
	Why or why not?
	The first correct and complete response will be credited.
	\end{fcvref}
}\QuickQuizEndE
}

This implementation avoids the update-starvation issues that could
occur in the single-counter implementation shown in
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}.

\paragraph{Discussion}

There are still some serious shortcomings.
First, the atomic operations in \co{rcu_read_lock()}
and \co{rcu_read_unlock()}
are still quite heavyweight.
In fact, they are more complex than those
of the single-counter variant shown in
\cref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter},
with the read-side primitives consuming about 150~nanoseconds on a single
\Power{5} CPU and almost 40~\emph{microseconds} on a 64-CPU system.
The update-side \co{synchronize_rcu()} primitive is more costly as
well, ranging from about 200~nanoseconds on a single \Power{5} CPU to
more than 40~\emph{microseconds} on a 64-CPU system.
This means that the RCU read-side critical sections
have to be extremely long in order to get any real
read-side parallelism.

Second, if there are many concurrent \co{rcu_read_lock()}
and \co{rcu_read_unlock()} operations, there will
be extreme memory contention on the \co{rcu_refcnt}
elements, resulting in expensive cache misses.
This further extends the RCU read-side critical-section
duration required to provide parallel read-side access.
These first two shortcomings defeat the purpose of RCU in most
situations.

Third, the need to flip \co{rcu_idx} twice imposes substantial
overhead on updates, especially if there are large
numbers of threads.

Finally, despite the fact that concurrent RCU updates could in principle be
satisfied by a common grace period, this implementation
serializes grace periods, preventing grace-period
sharing.

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu_rcpg:r]
	Given that atomic increment and decrement are so expensive,
	why not just use non-atomic increment on \clnref{lock:cur:e} and a
	non-atomic decrement on \clnref{unlock:atmdec} of
	\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}?
	\end{fcvref}
}\QuickQuizAnswer{
	Using non-atomic operations would cause increments and decrements
	to be lost, in turn causing the implementation to fail.
	See \cref{sec:app:toyrcu:Scalable Counter-Based RCU}
	for a safe way to use non-atomic operations in
	\co{rcu_read_lock()} and \co{rcu_read_unlock()}.
}\QuickQuizEnd

Despite these shortcomings, one could imagine this variant
of RCU being used on small tightly coupled multiprocessors,
perhaps as a memory-conserving implementation that maintains
API compatibility with more complex implementations.
However, it would not likely scale well beyond a few CPUs.

The next section describes yet another variation on the reference-counting
scheme that provides greatly improved read-side performance and scalability.

\section{Scalable Counter-Based RCU}
\label{sec:app:toyrcu:Scalable Counter-Based RCU}

\Cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.h})
shows the read-side primitives of an RCU implementation that uses per-thread
pairs of reference counters.
This implementation is quite similar to that shown in
\cref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair},
the only difference being that \co{rcu_refcnt} is now a per-thread
array (as shown in
\cref{lst:app:toyrcu:RCU Per-Thread Reference-Count Pair Data}).
As with the algorithm in the previous section, use of this two-element
array prevents readers from starving updaters.
One benefit of per-thread \co{rcu_refcnt[]} array is that the
\co{rcu_read_lock()} and \co{rcu_read_unlock()} primitives no longer
perform atomic operations.

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpl@define.fcv}
\caption{RCU Per-Thread Reference-Count Pair Data}
\label{lst:app:toyrcu:RCU Per-Thread Reference-Count Pair Data}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpl@r.fcv}
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
\end{listing}

\QuickQuiz{
	Come off it!
	We can see the \co{atomic_read()} primitive in
	\co{rcu_read_lock()}!!!
	So why are you trying to pretend that \co{rcu_read_lock()}
	contains no atomic operations???
}\QuickQuizAnswer{
	The \co{atomic_read()} primitives does not actually execute
	atomic machine instructions, but rather does a normal load
	from an \co{atomic_t}.
	Its sole purpose is to keep the compiler's type-checking happy.
	If the Linux kernel ran on 8-bit CPUs, it would also need to
	prevent ``store tearing'', which could happen due to the need
	to store a 16-bit pointer with two eight-bit accesses on some
	8-bit systems.
	But thankfully, it seems that no one runs Linux on 8-bit systems.
}\QuickQuizEnd

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpl@u.fcv}
\caption{RCU Update Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
\end{listing}

\Cref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.c})
shows the implementation of \co{synchronize_rcu()}, along with a helper
function named \co{flip_counter_and_wait()}.
\begin{fcvref}[ln:defer:rcu_rcpl:u:sync]
The \co{synchronize_rcu()} function resembles that shown in
\cref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair},
except that the repeated counter flip is replaced by a pair of calls
on \clnref{flip1,flip2} to the new helper function.
\end{fcvref}

\begin{fcvref}[ln:defer:rcu_rcpl:u:flip]
The new \co{flip_counter_and_wait()} function updates the
\co{rcu_idx} variable on \clnref{atmset},
executes a memory barrier on \clnref{mb1},
then \clnrefrange{loop:b}{loop:e}
spin on each thread's prior \co{rcu_refcnt} element,
waiting for it to go to zero.
Once all such elements have gone to zero,
it executes another memory barrier on \clnref{mb2} and returns.
\end{fcvref}

This RCU implementation imposes important new requirements on its
software environment, namely, (1) that it be possible to declare
per-thread variables, (2) that these per-thread variables be accessible
from other threads, and (3) that it is possible to enumerate all threads.
These requirements can be met in almost all software environments,
but often result in fixed upper bounds on the number of threads.
More-complex implementations might avoid such bounds, for example, by using
expandable hash tables.
Such implementations might dynamically track threads, for example, by
adding them on their first call to \co{rcu_read_lock()}.

\QuickQuiz{
	Great, if we have $N$ threads, we can have $2N$ ten-millisecond
	waits (one set per \co{flip_counter_and_wait()} invocation,
	and even that assumes that we wait only once for each thread.
	Don't we need the grace period to complete \emph{much} more quickly?
}\QuickQuizAnswer{
	Keep in mind that we only wait for a given thread if that thread
	is still in a pre-existing RCU read-side critical section,
	and that waiting for one hold-out thread gives all the other
	threads a chance to complete any pre-existing RCU read-side
	critical sections that they might still be executing.
	So the only way that we would wait for $2N$ intervals
	would be if the last thread still remained in a pre-existing
	RCU read-side critical section despite all the waiting for
	all the prior threads.
	In short, this implementation will not wait unnecessarily.

	However, if you are stress-testing code that uses RCU, you
	might want to comment out the \co{poll()} statement in
	order to better catch bugs that incorrectly retain a reference
	to an RCU-protected data element outside of an RCU
	read-side critical section.
}\QuickQuizEnd

This implementation still has several shortcomings.
First, the need to flip \co{rcu_idx} twice imposes substantial overhead
on updates, especially if there are large numbers of threads.

Second, \co{synchronize_rcu()} must now examine a number of variables
that increases linearly with the number of threads, imposing substantial
overhead on applications with large numbers of threads.

Third, as before, although concurrent RCU updates could in principle
be satisfied by a common grace period, this implementation serializes
grace periods, preventing grace-period sharing.

Finally, as noted in the text, the need for per-thread variables
and for enumerating threads may be problematic in some software
environments.

That said, the read-side primitives scale very nicely, requiring about
115~nanoseconds regardless of whether running on a single-CPU or a 64-CPU
\Power{5} system.
As noted above, the \co{synchronize_rcu()} primitive does not scale,
ranging in overhead from almost a microsecond on a single \Power{5} CPU
up to almost 200~microseconds on a 64-CPU system.
This implementation could conceivably form the basis for a
production-quality user-level RCU implementation.

The next section describes an algorithm permitting more efficient
concurrent RCU updates.

\section{Scalable Counter-Based RCU With Shared Grace Periods}
\label{sec:app:toyrcu:Scalable Counter-Based RCU With Shared Grace Periods}

\Cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
(\path{rcu_rcpls.h})
shows the read-side primitives for an RCU implementation using per-thread
reference count pairs, as before, but permitting updates to share
grace periods.
\begin{fcvref}[ln:defer:rcu_rcpls:r]
The main difference from the earlier implementation shown in
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
is that \co{rcu_idx} is now a \co{long} that counts freely,
so that \clnref{lock:idx} of
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
must mask off the low-order bit.
We also switched from using \co{atomic_read()} and \co{atomic_set()}
to using \co{READ_ONCE()}.
The data is also quite similar, as shown in
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data},
with \co{rcu_idx} now being a \co{long} instead of an
\co{atomic_t}.
\end{fcvref}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpls@define.fcv}
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpls@r.fcv}
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
\end{listing}

\Cref{lst:app:toyrcu:RCU Shared Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpls.c})
shows the implementation of \co{synchronize_rcu()} and its helper
function \co{flip_counter_and_wait()}.
These are similar to those in
\cref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}.
The differences in \co{flip_counter_and_wait()} include:
\begin{fcvref}[ln:defer:rcu_rcpls:u:flip]
\begin{enumerate}
\item	\Clnref{inc} uses \co{WRITE_ONCE()} instead of \co{atomic_set()},
	and increments rather than complementing.
\item	A new \clnref{mask} masks the counter down to its bottom bit.
\end{enumerate}
\end{fcvref}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_rcpls@u.fcv}
\caption{RCU Shared Update Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Shared Update Using Per-Thread Reference-Count Pair}
\end{listing}

\begin{fcvref}[ln:defer:rcu_rcpls:u:sync]
The changes to \co{synchronize_rcu()} are more pervasive:
\begin{enumerate}
\item	There is a new \co{oldctr} local variable that captures
	the pre-lock-acquisition value of \co{rcu_idx} on
	\clnref{oldctr}.
\item	\Clnref{idx} uses \co{READ_ONCE()} instead of \co{atomic_read()}.
\item	\Clnrefrange{if:b}{ret} check to see if at least three counter flips were
	performed by other threads while the lock was being acquired,
	and, if so, releases the lock, does a memory barrier, and returns.
	In this case, there were two full waits for the counters to
	go to zero, so those other threads already did all the required work.
\item	At \clnrefrange{ifpair}{flip2}, \co{flip_counter_and_wait()} is only
	invoked a second time if there were fewer than two counter flips
	while the lock was being acquired.
	On the other hand, if there were two counter flips, some other
	thread did one full wait for all the counters to go to zero,
	so only one more is required.
\end{enumerate}
\end{fcvref}

With this approach, if an arbitrarily large number of threads invoke
\co{synchronize_rcu()} concurrently, with one CPU for each thread, there
will be a total of only three waits for counters to go to zero.

Despite the improvements, this implementation of RCU still
has a few shortcomings.
First, as before, the need to flip \co{rcu_idx} twice imposes substantial
overhead on updates, especially if there are large
numbers of threads.

Second, each updater still acquires \co{rcu_gp_lock}, even if there
is no work to be done.
This can result in a severe scalability limitation
if there are large numbers of concurrent updates.
There are ways of avoiding this, as was done in a
production-quality real-time implementation of RCU for the Linux
kernel~\cite{PaulEMcKenney2007PreemptibleRCU}.

Third, this implementation requires per-thread variables
and the ability to enumerate threads, which again can be
problematic in some software environments.

Finally, on 32-bit machines, a given update thread might be
preempted long enough for the \co{rcu_idx}
counter to overflow.
This could cause such a thread to force an unnecessary
pair of counter flips.
However, even if each grace period took only one
microsecond, the offending thread would need to be
preempted for more than an hour, in which case an
extra pair of counter flips is likely the least of
your worries.

As with the implementation described in
\cref{sec:app:toyrcu:Simple Counter-Based RCU},
the read-side primitives scale extremely well, incurring roughly
115~nanoseconds of overhead regardless of the number of CPUs.
The \co{synchronize_rcu()} primitive is still expensive,
ranging from about one microsecond up to about 16~microseconds.
This is nevertheless much cheaper than the roughly 200~microseconds
incurred by the implementation in
\cref{sec:app:toyrcu:Scalable Counter-Based RCU}.
So, despite its shortcomings, one could imagine this
RCU implementation being used in production in real-life applications.

\QuickQuiz{
	All of these toy RCU implementations have either atomic operations
	in \co{rcu_read_lock()} and \co{rcu_read_unlock()},
	or \co{synchronize_rcu()}
	overhead that increases linearly with the number of threads.
	Under what circumstances could an RCU implementation enjoy
	lightweight implementations for all three of these primitives,
	all having deterministic ($\O{1}$) overheads and latencies?
}\QuickQuizAnswer{
	Special-purpose uniprocessor implementations of RCU can attain
	this ideal~\cite{PaulEMcKenney2009BloatwatchRCU}.
}\QuickQuizEnd

Referring back to
\cref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update},
we see that there is one global-variable access and no fewer than four
accesses to thread-local variables.
Given the relatively high cost of thread-local accesses on systems
implementing POSIX threads, it is tempting to collapse the three
thread-local variables into a single structure, permitting
\co{rcu_read_lock()} and \co{rcu_read_unlock()} to access their
thread-local data with a single thread-local-storage access.
However, an even better approach would be to reduce the number of
thread-local accesses to one, as is done in the next section.

\section{RCU Based on Free-Running Counter}
\label{sec:app:toyrcu:RCU Based on Free-Running Counter}

\Cref{lst:app:toyrcu:Free-Running Counter Using RCU}
(\path{rcu.h} and \path{rcu.c})
shows an RCU implementation based on a single global free-running counter
that takes on only even-numbered values, with data shown in
\cref{lst:app:toyrcu:Data for Free-Running Counter Using RCU}.

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu@define.fcv}
\caption{Data for Free-Running Counter Using RCU}
\label{lst:app:toyrcu:Data for Free-Running Counter Using RCU}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu@read_lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu@synchronize.fcv}\fvset{firstnumber=auto}
\caption{Free-Running Counter Using RCU}
\label{lst:app:toyrcu:Free-Running Counter Using RCU}
\end{listing}

The resulting \co{rcu_read_lock()} implementation is extremely
straightforward.
\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
\Clnref{gp1,gp2} simply
add one to the global free-running \co{rcu_gp_ctr}
variable and stores the resulting odd-numbered value into the
\co{rcu_reader_gp} per-thread variable.
\Clnref{mb} executes a memory barrier to prevent the content of the
subsequent RCU read-side critical section from ``leaking out''.
\end{fcvref}

\begin{fcvref}[ln:defer:rcu:read_lock_unlock:unlock]
The \co{rcu_read_unlock()} implementation is similar.
\Clnref{mb} executes a memory barrier, again to prevent the prior RCU
read-side critical section from ``leaking out''.
\Clnref{gp1,gp2} then copy the \co{rcu_gp_ctr} global variable to the
\co{rcu_reader_gp} per-thread variable, leaving this per-thread
variable with an even-numbered value so that a concurrent instance
of \co{synchronize_rcu()} will know to ignore it.
\end{fcvref}

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu:read_lock_unlock:unlock]
	If any even value is sufficient to tell \co{synchronize_rcu()}
	to ignore a given task, why don't \clnref{gp1,gp2} of
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	simply assign zero to \co{rcu_reader_gp}?
	\end{fcvref}
}\QuickQuizAnswer{
	Assigning zero (or any other even-numbered constant)
	would in fact work, but assigning the value of
	\co{rcu_gp_ctr} can provide a valuable debugging aid,
	as it gives the developer an idea of when the corresponding
	thread last exited an RCU read-side critical section.
}\QuickQuizEnd

\begin{fcvref}[ln:defer:rcu:synchronize:syn]
Thus, \co{synchronize_rcu()} could wait for all of the per-thread
\co{rcu_reader_gp} variables to take on even-numbered values.
However, it is possible to do much better than that because
\co{synchronize_rcu()} need only wait on \emph{pre-existing}
RCU read-side critical sections.
\Clnref{mb1} executes a memory barrier to prevent prior manipulations
of RCU-protected data structures from being reordered (by either
the CPU or the compiler) to follow the increment on
\clnref{increasegp}.
\Clnref{spinlock} acquires the \co{rcu_gp_lock}
(and \clnref{spinunlock} releases it)
in order to prevent multiple
\co{synchronize_rcu()} instances from running concurrently.
\Clnref{increasegp} then increments the global \co{rcu_gp_ctr} variable by
two, so that all pre-existing RCU read-side critical sections will
have corresponding per-thread \co{rcu_reader_gp} variables with
values less than that of \co{rcu_gp_ctr}, modulo the machine's
word size.
Recall also that threads with even-numbered values of \co{rcu_reader_gp}
are not in an RCU read-side critical section,
so that \clnrefrange{scan:b}{scan:e}
scan the \co{rcu_reader_gp} values until they
all are either even (\clnref{even}) or are greater than the global
\co{rcu_gp_ctr} (\clnrefrange{gt1}{gt2}).
\Clnref{poll} blocks for a short period of time to wait for a
pre-existing RCU read-side critical section, but this can be replaced with
a spin-loop if grace-period latency is of the essence.
Finally, the memory barrier at \clnref{mb3} ensures that any subsequent
destruction will not be reordered into the preceding loop.
\end{fcvref}

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu:synchronize:syn]
	Why are the memory barriers on \clnref{mb1,mb3} of
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	needed?
	Aren't the memory barriers inherent in the locking
	primitives on \clnref{spinlock,spinunlock} sufficient?
	\end{fcvref}
}\QuickQuizAnswer{
	These memory barriers are required because the locking
	primitives are only guaranteed to confine the critical
	section.
	The locking primitives are under absolutely no obligation
	to keep other code from bleeding in to the critical section.
	The pair of memory barriers are therefore requires to prevent
	this sort of code motion, whether performed by the compiler
	or by the CPU\@.
}\QuickQuizEnd

This approach achieves much better read-side performance, incurring
roughly 63~nanoseconds of overhead regardless of the number of
\Power{5} CPUs.
Updates incur more overhead, ranging from about 500~nanoseconds on
a single \Power{5} CPU to more than 100~\emph{microseconds} on 64
such CPUs.

\QuickQuiz{
	Couldn't the update-side batching optimization described in
	\cref{sec:app:toyrcu:Scalable Counter-Based RCU With Shared Grace Periods}
	be applied to the implementation shown in
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}?
}\QuickQuizAnswer{
	Indeed it could, with a few modifications.
	This work is left as an exercise for the reader.
}\QuickQuizEnd

\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
This implementation suffers from some serious shortcomings in
addition to the high update-side overhead noted earlier.
First, it is no longer permissible to nest RCU read-side critical
sections, a topic that is taken up in the next section.
Second, if a reader is preempted at \clnref{gp1} of
\cref{lst:app:toyrcu:Free-Running Counter Using RCU} after fetching from
\co{rcu_gp_ctr} but before storing to \co{rcu_reader_gp},
and if the \co{rcu_gp_ctr} counter then runs through more than half
but less than all of its possible values, then \co{synchronize_rcu()}
will ignore the subsequent RCU read-side critical section.
Third and finally, this implementation requires that the enclosing software
environment be able to enumerate threads and maintain per-thread
variables.
\end{fcvref}

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu:read_lock_unlock:lock]
	Is the possibility of readers being preempted in
	\clnrefrange{gp1}{gp2} of
	\cref{lst:app:toyrcu:Free-Running Counter Using RCU}
	a real problem, in other words, is there a real sequence
	of events that could lead to failure?
	If not, why not?
	If so, what is the sequence of events, and how can the
	failure be addressed?
	\end{fcvref}
}\QuickQuizAnswer{
	It is a real problem, there is a sequence of events leading to
	failure, and there are a number of possible ways of
	addressing it.
	For more details, see the Quick Quizzes near the end of
	\cref{sec:app:toyrcu:Nestable RCU Based on Free-Running Counter}.
	The reason for locating the discussion there is to (1) give you
	more time to think about it, and (2) because the nesting support
	added in that section greatly reduces the time required to
	overflow the counter.
}\QuickQuizEnd

\section{Nestable RCU Based on Free-Running Counter}
\label{sec:app:toyrcu:Nestable RCU Based on Free-Running Counter}

\Cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
(\path{rcu_nest.h} and \path{rcu_nest.c})
shows an RCU implementation based on a single global free-running counter,
but that permits nesting of RCU read-side critical sections.
This nestability is accomplished by reserving the low-order bits of the
global \co{rcu_gp_ctr} to count nesting, using the definitions shown in
\cref{lst:app:toyrcu:Data for Nestable RCU Using a Free-Running Counter}.
This is a generalization of the scheme in
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter},
which can be thought of as having a single low-order bit reserved
for counting nesting depth.
Two C-preprocessor macros are used to arrange this,
\co{RCU_GP_CTR_NEST_MASK} and
\co{RCU_GP_CTR_BOTTOM_BIT}.
These are related: \co{RCU_GP_CTR_NEST_MASK=RCU_GP_CTR_BOTTOM_BIT-1}.
The \co{RCU_GP_CTR_BOTTOM_BIT} macro contains a single bit that is
positioned just above the bits reserved for counting nesting,
and the \co{RCU_GP_CTR_NEST_MASK} has all one bits covering the
region of \co{rcu_gp_ctr} used to count nesting.
Obviously, these two C-preprocessor macros must reserve enough
of the low-order bits of the counter to permit the maximum required
nesting of RCU read-side critical sections, and this implementation
reserves seven bits, for a maximum RCU read-side critical-section
nesting depth of 127, which should be well in excess of that needed
by most applications.

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_nest@define.fcv}
\caption{Data for Nestable RCU Using a Free-Running Counter}
\label{lst:app:toyrcu:Data for Nestable RCU Using a Free-Running Counter}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_nest@read_lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_nest@synchronize.fcv}\fvset{firstnumber=auto}
\caption{Nestable RCU Using a Free-Running Counter}
\label{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
\end{listing}

\begin{fcvref}[ln:defer:rcu_nest:read_lock_unlock:lock]
The resulting \co{rcu_read_lock()} implementation is still reasonably
straightforward.
\Clnref{readgp} places a pointer to
this thread's instance of \co{rcu_reader_gp}
into the local variable \co{rrgp}, minimizing the number of expensive
calls to the pthreads thread-local-state API\@.
\Clnref{wtmp1} records the current value of \co{rcu_reader_gp}
into another local variable \co{tmp}, and \clnref{checktmp} checks
to see if the low-order bits are zero, which would indicate that
this is the outermost \co{rcu_read_lock()}.
If so, \clnref{wtmp2} places the global \co{rcu_gp_ctr}
into \co{tmp} because the current value previously fetched by
\clnref{wtmp1} is likely to be obsolete.
In either case, \clnref{inctmp} increments the nesting depth,
which you will recall is stored in the seven low-order bits of the counter.
\Clnref{writegp} stores the updated counter back into this thread's
instance of \co{rcu_reader_gp}, and,
finally, \clnref{mb1} executes a memory barrier
to prevent the RCU read-side critical section from bleeding out
into the code preceding the call to \co{rcu_read_lock()}.
\end{fcvref}

In other words, this implementation of \co{rcu_read_lock()} picks up a copy
of the global \co{rcu_gp_ctr} unless the current invocation of
\co{rcu_read_lock()} is nested within an RCU read-side critical section,
in which case it instead fetches the contents of the current thread's
instance of \co{rcu_reader_gp}.
Either way, it increments whatever value it fetched in order to record
an additional nesting level, and stores the result in the current
thread's instance of \co{rcu_reader_gp}.

\begin{fcvref}[ln:defer:rcu_nest:read_lock_unlock:unlock]
Interestingly enough, despite their \co{rcu_read_lock()} differences,
the implementation of \co{rcu_read_unlock()}
is broadly similar to that shown in
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}.
\Clnref{mb1} executes a memory barrier
in order to prevent the RCU read-side
critical section from bleeding out into code following the call
to \co{rcu_read_unlock()}, and
\clnref{decgp} decrements this thread's instance of \co{rcu_reader_gp},
which has the effect of decrementing the nesting count contained in
\co{rcu_reader_gp}'s low-order bits.
Debugging versions of this primitive would check (before decrementing!)
that these low-order bits were non-zero.
\end{fcvref}

\begin{fcvref}[ln:defer:rcu_nest:synchronize:syn]
The implementation of \co{synchronize_rcu()} is quite similar to
that shown in
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}.
There are two differences.
The first is that \clnref{incgp1,incgp2}
adds \co{RCU_GP_CTR_BOTTOM_BIT} to the global \co{rcu_gp_ctr}
instead of adding the constant ``2'',
and the second is that the comparison on \clnref{ongoing}
has been abstracted out to a separate function,
where it checks the bit indicated by \co{RCU_GP_CTR_BOTTOM_BIT}
instead of unconditionally checking the low-order bit.
\end{fcvref}

This approach achieves read-side performance almost equal to that
shown in
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}, incurring
roughly 65~nanoseconds of overhead regardless of the number of
\Power{5} CPUs.
Updates again incur more overhead, ranging from about 600~nanoseconds on
a single \Power{5} CPU to more than 100~\emph{microseconds} on 64
such CPUs.

\QuickQuiz{
	Why not simply maintain a separate per-thread nesting-level
	variable, as was done in previous section, rather than having
	all this complicated bit manipulation?
}\QuickQuizAnswer{
	The apparent simplicity of the separate per-thread variable
	is a red herring.
	This approach incurs much greater complexity in the guise
	of careful ordering of operations, especially if signal
	handlers are to be permitted to contain RCU read-side
	critical sections.
	But don't take my word for it, code it up and see what you
	end up with!
}\QuickQuizEnd

This implementation suffers from the same shortcomings as does that of
\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}, except that
nesting of RCU read-side critical sections is now permitted.
In addition, on 32-bit systems, this approach shortens the time
required to overflow the global \co{rcu_gp_ctr} variable.
The following section shows one way to greatly increase the time
required for overflow to occur, while greatly reducing read-side
overhead.

\QuickQuizSeries{%
\QuickQuizB{
	Given the algorithm shown in
	\cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter},
	how could you double the time required to overflow the global
	\co{rcu_gp_ctr}?
}\QuickQuizAnswerB{
	\begin{fcvref}[ln:defer:rcu_nest:synchronize:syn]
	One way would be to replace the magnitude comparison on
	\clnref{lt1,lt2} with an inequality check of
	the per-thread \co{rcu_reader_gp} variable against
	\co{rcu_gp_ctr+RCU_GP_CTR_BOTTOM_BIT}.
	\end{fcvref}
}\QuickQuizEndB
%
\QuickQuizE{
	Again, given the algorithm shown in
	\cref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter},
	is counter overflow fatal?
	Why or why not?
	If it is fatal, what can be done to fix it?
}\QuickQuizAnswerE{
	It can indeed be fatal.
	To see this, consider the following sequence of events:
	\begin{enumerate}
	\item	Thread~0 enters \co{rcu_read_lock()}, determines
		that it is not nested, and therefore fetches the
		value of the global \co{rcu_gp_ctr}.
		Thread~0 is then preempted for an extremely long time
		(before storing to its per-thread \co{rcu_reader_gp}
		variable).
	\item	Other threads repeatedly invoke \co{synchronize_rcu()},
		so that the new value of the global \co{rcu_gp_ctr}
		is now \co{RCU_GP_CTR_BOTTOM_BIT}
		less than it was when thread~0 fetched it.
	\item	Thread~0 now starts running again, and stores into
		its per-thread \co{rcu_reader_gp} variable.
		The value it stores is
		\co{RCU_GP_CTR_BOTTOM_BIT+1}
		greater than that of the global \co{rcu_gp_ctr}.
	\item	Thread~0 acquires a reference to RCU-protected data
		element~A.
	\item	Thread~1 now removes the data element~A that thread~0
		just acquired a reference to.
	\item	Thread~1 invokes \co{synchronize_rcu()}, which
		increments the global \co{rcu_gp_ctr} by
		\co{RCU_GP_CTR_BOTTOM_BIT}.
		It then checks all of the per-thread \co{rcu_reader_gp}
		variables, but thread~0's value (incorrectly) indicates
		that it started after thread~1's call to
		\co{synchronize_rcu()}, so thread~1 does not wait
		for thread~0 to complete its RCU read-side critical
		section.
	\item	Thread~1 then frees up data element~A, which thread~0
		is still referencing.
	\end{enumerate}

	Note that scenario can also occur in the implementation presented in
	\cref{sec:app:toyrcu:RCU Based on Free-Running Counter}.

	One strategy for fixing this problem is to use 64-bit
	counters so that the time required to overflow them would exceed
	the useful lifetime of the computer system.
	Note that non-antique members of the 32-bit x86 CPU family
	allow atomic manipulation of 64-bit counters via the
	\co{cmpxchg64b} instruction.

	Another strategy is to limit the rate at which grace periods are
	permitted to occur in order to achieve a similar effect.
	For example, \co{synchronize_rcu()} could record the last time
	that it was invoked, and any subsequent invocation would then
	check this time and block as needed to force the desired
	spacing.
	For example, if the low-order four bits of the counter were
	reserved for nesting, and if grace periods were permitted to
	occur at most ten times per second, then it would take more
	than 300 days for the counter to overflow.
	However, this approach is not helpful if there is any possibility
	that the system will be fully loaded with CPU-bound high-priority
	real-time threads for the full 300 days.
	(A remote possibility, perhaps, but best to consider it ahead
	of time.)

	A third approach is to administratively abolish real-time threads
	from the system in question.
	In this case, the preempted process will age up in priority,
	thus getting to run long before the counter had a chance to
	overflow.
	Of course, this approach is less than helpful for real-time
	applications.

	A final approach would be for \co{rcu_read_lock()} to recheck
	the value of the global \co{rcu_gp_ctr} after storing to its
	per-thread \co{rcu_reader_gp} counter, retrying if the new
	value of the global \co{rcu_gp_ctr} is inappropriate.
	This works, but introduces non-deterministic execution time
	into \co{rcu_read_lock()}.
	On the other hand, if your application is being preempted long
	enough for the counter to overflow, you have no hope of
	deterministic execution time in any case!
	%
	% @@@ A fourth approach is rcu_nest32.[hc].
}\QuickQuizEndE
}

\section{RCU Based on Quiescent States}
\label{sec:app:toyrcu:RCU Based on Quiescent States}

\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock]
\Cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
(\path{rcu_qs.h})
shows the read-side primitives used to construct a user-level
implementation of RCU based on quiescent states, with the data shown in
\cref{lst:app:toyrcu:Data for Quiescent-State-Based RCU}.
As can be seen from \clnrefrange{lock:b}{unlock:e} in the listing,
the \co{rcu_read_lock()}
and \co{rcu_read_unlock()} primitives do nothing, and can in fact
be expected to be inlined and optimized away, as they are in
server builds of the Linux kernel.
This is due to the fact that quiescent-state-based RCU implementations
\emph{approximate} the extents of RCU read-side critical sections
using the aforementioned quiescent states.
Each of these quiescent states contains a call to
\co{rcu_quiescent_state()}, which is shown from
\clnrefrange{qs:b}{qs:e} in the listing.
Threads entering extended quiescent states (for example, when blocking)
may instead call \co{rcu_thread_offline()}
(\clnrefrange{offline:b}{offline:e}) when entering
an extended quiescent state and then call
\co{rcu_thread_online()}
(\clnrefrange{online:b}{online:e}) when leaving it.
As such, \co{rcu_thread_online()} is analogous to \co{rcu_read_lock()}
and \co{rcu_thread_offline()} is analogous to \co{rcu_read_unlock()}.
In addition, \co{rcu_quiescent_state()} can be thought of as a
\co{rcu_thread_online()} immediately followed by a
\co{rcu_thread_offline()}.\footnote{
	Although the code in the listing is consistent with
	\co{rcu_quiescent_state()}
	being the same as \co{rcu_thread_online()} immediately followed by
	\co{rcu_thread_offline()}, this relationship is obscured by
	performance optimizations.}
It is illegal to invoke \co{rcu_quiescent_state()}, \co{rcu_thread_offline()},
or \co{rcu_thread_online()} from an RCU read-side critical section.
\end{fcvref}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_qs@define.fcv}
\caption{Data for Quiescent-State-Based RCU}
\label{lst:app:toyrcu:Data for Quiescent-State-Based RCU}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_qs@read_lock_unlock.fcv}
\caption{Quiescent-State-Based RCU Read Side}
\label{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
\end{listing}

\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
In \co{rcu_quiescent_state()}, \clnref{mb1} executes a memory barrier
to prevent any code prior to the quiescent state (including possible
RCU read-side critical sections) from being reordered
into the quiescent state.
\Clnrefrange{gp1}{gp2} pick up
a copy of the global \co{rcu_gp_ctr}, using
\co{READ_ONCE()} to ensure that the compiler does not employ any
optimizations that would result in \co{rcu_gp_ctr} being fetched
more than once,
and then adds one to the value fetched and stores it into
the per-thread \co{rcu_reader_qs_gp} variable, so that any concurrent
instance of \co{synchronize_rcu()} will see an odd-numbered value,
thus becoming aware that a new RCU read-side critical section has started.
Instances of \co{synchronize_rcu()} that are waiting on older
RCU read-side critical sections will thus know to ignore this new one.
Finally, \clnref{mb2} executes a memory barrier, which prevents subsequent
code (including a possible RCU read-side critical section) from being
re-ordered with the \clnrefrange{gp1}{gp2}.
\end{fcvref}

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Doesn't the additional memory barrier shown on \clnref{mb2} of
	\cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	greatly increase the overhead of \co{rcu_quiescent_state}?
	\end{fcvref}
}\QuickQuizAnswer{
	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Indeed it does!
	An application using this implementation of RCU should therefore
	invoke \co{rcu_quiescent_state} sparingly, instead using
	\co{rcu_read_lock()} and \co{rcu_read_unlock()} most of the
	time.

	However, this memory barrier is absolutely required so that
	other threads will see the store on
	\clnrefrange{gp1}{gp2} before any
	subsequent RCU read-side critical sections executed by the
	caller.
	\end{fcvref}
}\QuickQuizEnd

Some applications might use RCU only occasionally, but use it very heavily
when they do use it.
Such applications might choose to use \co{rcu_thread_online()} when
starting to use RCU and \co{rcu_thread_offline()} when no longer
using RCU\@.
The time between a call to \co{rcu_thread_offline()} and a subsequent
call to \co{rcu_thread_online()} is an extended quiescent state,
so that RCU will not expect explicit quiescent states to be registered
during this time.

The \co{rcu_thread_offline()} function simply sets the
per-thread \co{rcu_reader_qs_gp} variable to the current value of
\co{rcu_gp_ctr}, which has an even-numbered value.
Any concurrent instances of \co{synchronize_rcu()} will thus know to
ignore this thread.

\QuickQuiz{
	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Why are the two memory barriers on \clnref{mb1,mb2} of
	\cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	needed?
	\end{fcvref}
}\QuickQuizAnswer{
	\begin{fcvref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	The memory barrier on \clnref{mb1} prevents any RCU read-side
	critical sections that might precede the
	call to \co{rcu_thread_offline()} won't be reordered by either
	the compiler or the CPU to follow the assignment on
	\clnrefrange{gp1}{gp2}.
	The memory barrier on \clnref{mb2} is, strictly speaking, unnecessary,
	as it is illegal to have any RCU read-side critical sections
	following the call to \co{rcu_thread_offline()}.
	\end{fcvref}
}\QuickQuizEnd

The \co{rcu_thread_online()} function simply invokes
\co{rcu_quiescent_state()}, thus marking the end of the extended
quiescent state.

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_qs@synchronize.fcv}
\caption{RCU Update Side Using Quiescent States}
\label{lst:app:toyrcu:RCU Update Side Using Quiescent States}
\end{listing}

\Cref{lst:app:toyrcu:RCU Update Side Using Quiescent States}
(\path{rcu_qs.c})
shows the implementation of \co{synchronize_rcu()}, which is
quite similar to that of the preceding sections.

This implementation has blazingly fast read-side primitives, with
an \co{rcu_read_lock()}--\co{rcu_read_unlock()} round trip incurring
an overhead of roughly 50~\emph{picoseconds}.
The \co{synchronize_rcu()} overhead ranges from about 600~nanoseconds
on a single-CPU \Power{5} system up to more than 100~microseconds on
a 64-CPU system.

\QuickQuiz{
	To be sure, the clock frequencies of \Power{}
	systems in 2008 were quite high, but even a 5\,GHz clock
	frequency is insufficient to allow
	loops to be executed in 50~picoseconds!
	What is going on here?
}\QuickQuizAnswer{
	Since the measurement loop contains a pair of empty functions,
	the compiler optimizes it away.
	The measurement loop takes 1,000 passes between each call to
	\co{rcu_quiescent_state()}, so this measurement is roughly
	one thousandth of the overhead of a single call to
	\co{rcu_quiescent_state()}.
}\QuickQuizEnd

However, this implementation requires that each thread either
invoke \co{rcu_quiescent_state()} periodically or to invoke
\co{rcu_thread_offline()} for extended quiescent states.
The need to invoke these functions periodically can make this
implementation difficult to use in some situations, such as for
certain types of library functions.

\QuickQuizSeries{%
\QuickQuizB{
	Why would the fact that the code is in a library make
	any difference for how easy it is to use the RCU
	implementation shown in
	\cref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side,%
	lst:app:toyrcu:RCU Update Side Using Quiescent States}?
}\QuickQuizAnswerB{
	A library function has absolutely no control over the caller,
	and thus cannot force the caller to invoke \co{rcu_quiescent_state()}
	periodically.
	On the other hand, a library function that made many references
	to a given RCU-protected data structure might be able to invoke
	\co{rcu_thread_online()} upon entry,
	\co{rcu_quiescent_state()} periodically, and
	\co{rcu_thread_offline()} upon exit.
}\QuickQuizEndB
%
\QuickQuizE{
	But what if you hold a lock across a call to
	\co{synchronize_rcu()}, and then acquire that same lock within
	an RCU read-side critical section?
	This should be a deadlock, but how can a primitive that
	generates absolutely no code possibly participate in a
	deadlock cycle?
}\QuickQuizAnswerE{
	Please note that the RCU read-side critical section is in
	effect extended beyond the enclosing
	\co{rcu_read_lock()} and \co{rcu_read_unlock()}, out to
	the previous and next call to \co{rcu_quiescent_state()}.
	This \co{rcu_quiescent_state} can be thought of as an
	\co{rcu_read_unlock()} immediately followed by an
	\co{rcu_read_lock()}.

	Even so, the actual deadlock itself will involve the lock
	acquisition in the RCU read-side critical section and
	the \co{synchronize_rcu()}, never the \co{rcu_quiescent_state()}.
}\QuickQuizEndE
}

In addition, this implementation does not permit concurrent calls
to \co{synchronize_rcu()} to share grace periods.
That said, one could easily imagine a production-quality RCU
implementation based on this version of RCU\@.

\section{Summary of Toy RCU Implementations}
\label{sec:app:toyrcu:Summary of Toy RCU Implementations}

If you made it this far, congratulations!
You should now have a much clearer understanding
not only of RCU itself, but also of the requirements of enclosing
software environments and applications.
Those wishing an even deeper understanding are invited to read
descriptions of production-quality RCU
implementations~\cite{MathieuDesnoyers2012URCU,PaulEMcKenney2007PreemptibleRCU,PaulEMcKenney2008HierarchicalRCU,PaulEMcKenney2009BloatwatchRCU}.

The preceding sections listed some desirable properties of the
various RCU primitives.
The following list is provided for easy reference for those wishing to
create a new RCU implementation.

\begin{enumerate}
\item	There must be read-side primitives (such as \co{rcu_read_lock()}
	and \co{rcu_read_unlock()}) and grace-period primitives
	(such as \co{synchronize_rcu()} and \co{call_rcu()}), such
	that any RCU read-side critical section in existence at the
	start of a grace period has completed by the end of the
	grace period.
\item	RCU read-side primitives should have minimal overhead.
	In particular, expensive operations such as cache misses,
	atomic instructions, memory barriers, and branches should
	be avoided.
\item	RCU read-side primitives should have $\O{1}$ computational
	complexity to enable real-time use.
	(This implies that readers run concurrently with updaters.)
\item	RCU read-side primitives should be usable in all contexts
	(in the Linux kernel, they are permitted everywhere except in
	the idle loop).
	An important special case is that RCU read-side primitives be
	usable within an RCU read-side critical section, in other words,
	that it be possible to nest RCU read-side critical sections.
\item	RCU read-side primitives should be unconditional, with no
	failure returns.
	This property is extremely important, as failure checking
	increases complexity and complicates testing and validation.
\item	Any operation other than a quiescent state (and thus a grace
	period) should be permitted in an RCU read-side critical section.
	In particular, irrevocable operations such as I/O should be
	permitted.
\item	It should be possible to update an RCU-protected data structure
	while executing within an RCU read-side critical section.
\item	Both RCU read-side and update-side primitives should be independent
	of memory allocator design and implementation, in other words,
	the same RCU implementation should be able to protect a given
	data structure regardless of how the data elements are allocated
	and freed.
\item	RCU grace periods should not be blocked by threads that
	halt outside of RCU read-side critical sections.
	(But note that most quiescent-state-based implementations
	violate this desideratum.)
\end{enumerate}

\QuickQuiz{
	Given that grace periods are prohibited within RCU read-side
	critical sections, how can an RCU data structure possibly be
	updated while in an RCU read-side critical section?
}\QuickQuizAnswer{
	This situation is one reason for the existence of asynchronous
	grace-period primitives such as \co{call_rcu()}.
	This primitive may be invoked within an RCU read-side critical
	section, and the specified RCU callback will in turn be invoked
	at a later time, after a grace period has elapsed.

	The ability to perform an RCU update while within an RCU read-side
	critical section can be extremely convenient, and is analogous
	to a (mythical) unconditional read-to-write upgrade for
	reader-writer locking.
}\QuickQuizEnd

\QuickQuizAnswersChp{qqztoyrcu}
