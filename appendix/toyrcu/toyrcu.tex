% appendix/toyrcu/toyrcu.tex

\QuickQuizChapter{chp:app:``Toy'' RCU Implementations}{``Toy'' RCU Implementations}

이 부록의 장난감 RCU 구현은 높은 성능, 실용성, 또는 어떤 종류의 상품에의 사용을
위해 설계되지 않았고\footnote{
	하지만, 상품 품질의 사용자 레벨 RCU 구현은 구할 수
	있습니다~\cite{MathieuDesnoyers2009URCU}.}
그저 분명함을 위해 설계되었습니다.
이 장난감 RCU 구현을 쉽게 이해하기 위해서는 더도 아니고 덜도 아니고,
Chapter~\ref{chp:Introduction},
\ref{chp:Hardware and its Habits},
\ref{chp:Tools of the Trade}, 그리고
\ref{cha:Partitioning and Synchronization Design}
는 물론이고
Chapter~\ref{chp:Deferred Processing} 의 앞부분들에 대해서도 깊이 이해하고
있어야 합니다.
\iffalse

The toy RCU implementations in this appendix are designed not for
high performance, practicality, or any kind of production use,\footnote{
	However, production-quality user-level RCU implementations
	are available~\cite{MathieuDesnoyers2009URCU,MathieuDesnoyers2012URCU}.}
but rather for clarity.
Nevertheless, you will need a thorough understanding of
Chapters~\ref{chp:Introduction},
\ref{chp:Hardware and its Habits},
\ref{chp:Tools of the Trade},
\ref{cha:Partitioning and Synchronization Design},
and~\ref{chp:Deferred Processing}
for even these toy RCU implementations to be easily understandable.
\fi

이 부록은 존재 보장 문제를 풀어가는 관점에서 세련됨을 증가시켜가는 방향으로
일련의 RCU 구현들을 제공합니다.
Section~\ref{sec:app:toyrcu:Lock-Based RCU} 은 간단한 락킹에 기반한 초보적인 RCU 구현을
보이고,
Sections~\ref{sec:app:toyrcu:Per-Thread Lock-Based RCU} 에서
\ref{sec:app:toyrcu:RCU Based on Quiescent States}
까지는 락킹, 레퍼런스 카운터, 그리고 free-running 카운터들에 기반한 간단한 RCU
구현을 보입니다.
마지막으로,
Section~\ref{sec:app:toyrcu:Per-Thread Lock-Based RCU} 부터
\ref{sec:app:toyrcu:RCU Based on Quiescent States} 까지는
요약과 바래봄직한 RCU 속성들의 리스트를 제공합니다.
\iffalse

This appendix provides a series of RCU implementations in order of
increasing sophistication, from the viewpoint of solving the
existence-guarantee problem.
Section~\ref{sec:app:toyrcu:Lock-Based RCU} presents a rudimentary
RCU implementation based on simple locking, while
Sections~\ref{sec:app:toyrcu:Per-Thread Lock-Based RCU} through
\ref{sec:app:toyrcu:RCU Based on Quiescent States}
present a series of
simple RCU implementations based on locking, reference counters,
and free-running counters.
Finally, Section~\ref{sec:app:toyrcu:Summary of Toy RCU Implementations}
provides a summary and a list of desirable RCU properties.
\fi

\section{Lock-Based RCU}
\label{sec:app:toyrcu:Lock-Based RCU}

\begin{listing}[bp]
{ \scriptsize
\begin{verbbox}
  1 static void rcu_read_lock(void)
  2 {
  3   spin_lock(&rcu_gp_lock);
  4 }
  5
  6 static void rcu_read_unlock(void)
  7 {
  8   spin_unlock(&rcu_gp_lock);
  9 }
 10
 11 void synchronize_rcu(void)
 12 {
 13   spin_lock(&rcu_gp_lock);
 14   spin_unlock(&rcu_gp_lock);
 15 }
\end{verbbox}
}
\centering
\theverbbox
\caption{Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Lock-Based RCU Implementation}
\end{listing}

아마도 가장 간단한 RCU 구현은
Listing~\ref{lst:app:toyrcu:Lock-Based RCU Implementation}
(\path{rcu_lock.h} 와 \path{rcu_lock.c}) 에 보여진 것처럼 락킹을 사용할 겁니다.
이 구현에서 \co{rcu_read_lock()} 은 글로벌 스핀락을 잡고,
\co{rcu_read_unlock()} 은 그걸 놓으며, \co{synchronize_rcu()} 는 그걸 잡고는
바로 놓습니다.
\iffalse

Perhaps the simplest RCU implementation leverages locking, as
shown in
Listing~\ref{lst:app:toyrcu:Lock-Based RCU Implementation}
(\path{rcu_lock.h} and \path{rcu_lock.c}).
In this implementation, \co{rcu_read_lock()} acquires a global
spinlock, \co{rcu_read_unlock()} releases it, and
\co{synchronize_rcu()} acquires it then immediately releases it.
\fi

\co{synchronize_rcu()} 는 그 락을 잡기 (그리고 놓기) 전까지는 리턴하지 않기
때문에, 모든 앞의 RCU read-side 크리티컬 섹션들이 완료되기 전까지는 리턴할 수
없어서, RCU 시맨틱을 모두 구현하고 있습니다.
물론, 한번에 하나의 RCU 읽기 쓰레드만이 자신의 read-side 크리티컬 섹션을 수행할
수 있어서 RCU 의 목적 중 거의 모든 것을 이루지 못합니다.
또한, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 에서의 락 오퍼레이션들은
매우 무거운 일이어서, 하나의 \Power{5} CPU 에서 100~나노세컨드 정도의 read-side
오버헤드는 64-CPU 시스템에서는 17~\emph{마이크로세컨드} 까지 증가합니다.
더 나쁜건, 이것과 같은 락 오퍼레이션들은 \co{rcu_read_lock()} 이 데드락
사이클에 연관될 수 있게 한다는 것입니다.
더 나아가서, 재귀적인 락이 없다 해도, RCU read-side 크리티컬 섹션들은
중첩될수가 없고, 마지막으로, 동시의 RCU 업데이트들이 공통의 grace period 에
의해 원론적으로는 가능하지만, 이 구현은 grace period 들을 직렬화 시켜서
grace-period 공유를 불가능하게 합니다.
\iffalse

Because \co{synchronize_rcu()} does not return until it has acquired
(and released) the lock, it cannot return until all prior RCU read-side
critical sections have completed, thus faithfully implementing
RCU semantics.
Of course, only one RCU reader may be in its read-side critical section
at a time, which almost entirely defeats the purpose of RCU.
In addition, the lock operations in \co{rcu_read_lock()} and
\co{rcu_read_unlock()} are extremely heavyweight,
with read-side overhead ranging from about 100~nanoseconds on a single \Power{5}
CPU up to more than 17~\emph{microseconds} on a 64-CPU system.
Worse yet,
these same lock operations permit \co{rcu_read_lock()}
to participate in deadlock cycles.
Furthermore, in absence of recursive locks,
RCU read-side critical sections cannot be nested, and, finally,
although concurrent RCU updates could in principle be satisfied by
a common grace period, this implementation serializes grace periods,
preventing grace-period sharing.
\fi

\QuickQuiz{}
	Listing~\ref{lst:app:toyrcu:Lock-Based RCU Implementation} 에서의 RCU 구현의
	데드락이 다른 RCU 구현에서의 데드락이 될 수 없는 이유는 뭘까요?
	\iffalse

	Why wouldn't any deadlock in the RCU implementation in
	Listing~\ref{lst:app:toyrcu:Lock-Based RCU Implementation}
	also be a deadlock in any other RCU implementation?
	\fi
\QuickQuizAnswer{
%
\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 void foo(void)
  2 {
  3   spin_lock(&my_lock);
  4   rcu_read_lock();
  5   do_something();
  6   rcu_read_unlock();
  7   do_something_else();
  8   spin_unlock(&my_lock);
  9 }
 10
 11 void bar(void)
 12 {
 13   rcu_read_lock();
 14   spin_lock(&my_lock);
 15   do_some_other_thing();
 16   spin_unlock(&my_lock);
 17   do_whatever();
 18   rcu_read_unlock();
 19 }
\end{verbbox}
}
\centering
\theverbbox
\caption{Deadlock in Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation}
\end{listing}
%
	Listing~\ref{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation} 의
	함수 \co{foo()} 와 \co{bar()} 가 다른 CPU 들에서 동시에 호출된다고
	생각해 봅시다.
	\co{foo()} 는 \co{my_lock()} 을 line~3 에서 잡는데, 그동안 \co{bar()}
	는 line~13 에서 \co{rcu_gp_lock} 을 잡습니다.
	\co{foo()} 가 line~4 로 진행되면, \co{bar()} 에게 잡혀있는
	\co{rcu_gp_lock} 을 잡으려 합니다.
	그리고는 \co{bar()} 는 line~14 로 넘어가서 \co{foo()} 에게 잡혀 있는
	\co{my_lock} 을 잡으려 시도합니다.

	각 함수가 이제 서로가 잡고 있는 락을 기다리게 되는 고전적인 deadlock
	상황이 됩니다.

	다른 RCU 구현들은 \co{rcu_read_lock()} 안에서 스핀하지도 블록하지도
	않기 때문에 데드락이 예방됩니다.
	\iffalse

	Suppose the functions \co{foo()} and \co{bar()} in
	Listing~\ref{lst:app:toyrcu:Deadlock in Lock-Based RCU Implementation}
	are invoked concurrently from different CPUs.
	Then \co{foo()} will acquire \co{my_lock()} on line~3,
	while \co{bar()} will acquire \co{rcu_gp_lock} on
	line~13.
	When \co{foo()} advances to line~4, it will attempt to
	acquire \co{rcu_gp_lock}, which is held by \co{bar()}.
	Then when \co{bar()} advances to line~14, it will attempt
	to acquire \co{my_lock}, which is held by \co{foo()}.

	Each function is then waiting for a lock that the other
	holds, a classic deadlock.

	Other RCU implementations neither spin nor block in
	\co{rcu_read_lock()}, hence avoiding deadlocks.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	왜 Listing~\ref{lst:app:toyrcu:Lock-Based RCU Implementation}
	의 RCU 구현에서는 RCU 읽기 쓰레드들이 병렬로 수행될 수 있도록 간단하게
	reader-writer 락을 사용하지 않았나요?
	\iffalse

	Why not simply use reader-writer locks in the RCU implementation
	in
	Listing~\ref{lst:app:toyrcu:Lock-Based RCU Implementation}
	in order to allow RCU readers to proceed in parallel?
	\fi
\QuickQuizAnswer{
	누군가는 실제로 reader-writer 락을 이런식으로 사용할 수도 있겠습니다.
	하지만, 교재의 reader-writer 락은 메모리 경쟁에 취약해서 정말로 병렬
	수행이 가능해지려면 RCU read-side 크리티컬 섹션들이 상당히 길어져야
	할겁니다~\cite{McKenney03a}.

	한편으로는, \co{rcu_read_lock()} 에서 읽기 권한을 획득하는 식의
	reader-writer 락 사용은 앞서 언급된 데드락 조건은 막을 수 있을 겁니다.
	\iffalse

	One could in fact use reader-writer locks in this manner.
	However, textbook reader-writer locks suffer from memory
	contention, so that the RCU read-side critical sections would
	need to be quite long to actually permit parallel
	execution~\cite{McKenney03a}.

	On the other hand, use of a reader-writer lock that is
	read-acquired in \co{rcu_read_lock()} would avoid the
	deadlock condition noted above.
	\fi
} \QuickQuizEnd

이 구현이 실제 상품 구성에서 유용할 거라 생각하기는 어렵습니다만, 거의 모든
사용자 레벨 어플리케이션들에 구현할 수 있다는 장점을 가지고 있습니다.
나아가서, CPU 별로 하나의 락을 갖거나 reader-writer 락을 사용하는 비슷한
구현들은 2.4 리눅스 커널이라는 제품에서 사용된 바 있습니다.

이런 CPU 별로 하나의 락을 사용하는 전략의 수정된, 쓰레드별로 락을 하나씩 갖는
버전은 다음 섹션에서 설명됩니다.
\iffalse

It is hard to imagine this implementation being useful
in a production setting, though it does have the virtue
of being implementable in almost any user-level application.
Furthermore, similar implementations having one lock per CPU
or using reader-writer locks have been used in production
in the 2.4 Linux kernel.

A modified version of this one-lock-per-CPU approach, but instead using
one lock per thread, is described
in the next section.
\fi

\section{Per-Thread Lock-Based RCU}
\label{sec:app:toyrcu:Per-Thread Lock-Based RCU}

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 static void rcu_read_lock(void)
  2 {
  3   spin_lock(&__get_thread_var(rcu_gp_lock));
  4 }
  5
  6 static void rcu_read_unlock(void)
  7 {
  8   spin_unlock(&__get_thread_var(rcu_gp_lock));
  9 }
 10
 11 void synchronize_rcu(void)
 12 {
 13   int t;
 14
 15   for_each_running_thread(t) {
 16     spin_lock(&per_thread(rcu_gp_lock, t));
 17     spin_unlock(&per_thread(rcu_gp_lock, t));
 18   }
 19 }
\end{verbbox}
}
\centering
\theverbbox
\caption{Per-Thread Lock-Based RCU Implementation}
\label{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
\end{listing}

Listing~\ref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
(\path{rcu_lock_percpu.h} 와 \path{rcu_lock_percpu.c})
는 쓰레드별로 하나의 락 두기에 기반한 구현을 보입니다.
\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 함수들은 각각 현재 쓰레드의 락을
잡고 풉니다.
\co{synchronize_rcu()} 함수는 각 쓰레드의 락들을 한번에 모두 잡고 풉니다.
따라서, \co{synchronize_rcu()} 가 시작될 때 수행중인 모든 RCU read-side
크리티컬 섹션들은 \co{synchronize_rcu()} 가 리턴하기 전에 완료되어야만 합니다.
\iffalse

Listing~\ref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
(\path{rcu_lock_percpu.h} and \path{rcu_lock_percpu.c})
shows an implementation based on one lock per thread.
The \co{rcu_read_lock()} and \co{rcu_read_unlock()} functions
acquire and release, respectively, the current thread's lock.
The \co{synchronize_rcu()} function acquires and releases each thread's
lock in turn.
Therefore, all RCU read-side critical sections running
when \co{synchronize_rcu()} starts must have completed before
\co{synchronize_rcu()} can return.
\fi

이 구현은 동시의 RCU 읽기 쓰레드들을 가능하게 하고 하나의 글로벌 락을 사용할 때
생길 수 있는 데드락 조건을 예방하는 장점을 갖습니다.
더 나아가서, read-side 오버헤드는 비록 대략 140 나노세컨드 정도로 높긴 하지만
CPU 들의 수에 관계 없이 140 나노세컨드 정도로 유지됩니다.
하지만, 업데이트 쪽의 오버헤드는 하나의 \Power{5} CPU 에서 600 나노세컨드부터 64
CPU 에서의 100 \emph{마이크로세컨드} 정도까지 움직입니다.
\iffalse

This implementation does have the virtue of permitting concurrent
RCU readers, and does avoid the deadlock condition that can arise
with a single global lock.
Furthermore, the read-side overhead, though high at roughly 140 nanoseconds,
remains at about 140 nanoseconds regardless of the number of CPUs.
However, the update-side overhead ranges from about 600 nanoseconds
on a single \Power{5} CPU
up to more than 100 \emph{microseconds} on 64 CPUs.
\fi

\QuickQuiz{}
	Figure~\ref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation} 의
	line~15-18 의 루프에서는 락들을 일단 모두 다 잡고나서는 한번에 모두
	풀어주는게 더 깔끔하지 않나요?
	무엇보다, 이렇게 바꾸면 어떤 읽기 쓰레드도 존재하지 않는 시점이 생기게
	되어서 모든 것들이 매우 간단해질 겁니다.
	\iffalse

	Wouldn't it be cleaner to acquire all the locks, and then
	release them all in the loop from lines~15-18 of
	Listing~\ref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}?
	After all, with this change, there would be a point in time
	when there were no readers, simplifying things greatly.
	\fi
\QuickQuizAnswer{
	이 변경은 다시 deadlock 을 가능하게 할 것이므로, 안되고, 더 깔끔하지도
	않아요.
	\iffalse

	Making this change would re-introduce the deadlock, so
	no, it would not be cleaner.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	Figure~\ref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	에 보여진 구현은 deadlock 으로부터 자유로울까요?
	그렇다면, 또는 그렇지 않다면, 왜죠?
	\iffalse

	Is the implementation shown in
	Listing~\ref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	free from deadlocks?
	Why or why not?
	\fi
\QuickQuizAnswer{
	데드락 시나리오 중 하나는 한 락이 \co{synchronize_rcu()} 을 감싸고
	잡히고 같은 락이 한 RCU read-side 크리티컬 섹션에 잡힐 때가 될 수 있을
	겁니다.
	하지만, 이 상황은 어떤 RCU 구현에서도 데드락을 유발할 수 있습니다.
	무엇보다, \co{synchronize_rcu()} 기능은 모든 전부터 존재한 RCU
	read-side 크리티컬 섹션들이 끝나길 기다려야 하지만, 그런 크리티컬
	섹션들 가운데 하나가 \co{synchronize_rcu()} 를 수행한 쓰레드가 잡고
	있는 락에 스핀하고 있다면, RCU 의 정의상 피할 수 없는 데드락을 갖게
	됩니다.
	\iffalse

	One deadlock is where a lock is
	held across \co{synchronize_rcu()}, and that same lock is
	acquired within an RCU read-side critical section.
	However, this situation could deadlock any correctly designed
	RCU implementation.
	After all, the \co{synchronize_rcu()} primitive must wait for all
	pre-existing RCU read-side critical sections to complete,
	but if one of those critical sections is spinning on a lock
	held by the thread executing the \co{synchronize_rcu()},
	we have a deadlock inherent in the definition of RCU.
	\fi

	또다른 데드락 시나리오는 RCU read-side 크리티컬 섹션들을 중첩시키려 할
	때일 겁니다.
	이 데드락은 이 구현 특유의 것이고 재귀적 락을 사용하거나
	\co{rcu_read_lock()} 을 통해선 읽기 권한을, \co{synchronize_rcu()} 를
	통해선 쓰기 권한을 획득하는 reader-writer 락을 사용해서 막을 수도 있을
	겁니다.

	하지만, 앞의 두 경우를 제외하면, 이 RCU 구현은 어떤 데드락 상황도
	만들지 않습니다.
	이는 어떤 다른 쓰레드의 락을 획득하게 되는 경우는
	\co{synchronize_rcu()} 를 수행할 때 뿐이며, 이 경우에 그 락은 곧바로
	해제되기 때문에 앞의 경우처럼 \co{synchronize_rcu()} 전후로 잡히는 락과
	연관되는 데드락을 제외하고는 데드락 사이클을 예방합니다.
	\iffalse

	Another deadlock happens when attempting to nest RCU read-side
	critical sections.
	This deadlock is peculiar to this implementation, and might
	be avoided by using recursive locks, or by using reader-writer
	locks that are read-acquired by \co{rcu_read_lock()} and
	write-acquired by \co{synchronize_rcu()}.

	However, if we exclude the above two cases,
	this implementation of RCU does not introduce any deadlock
	situations.
	This is because only time some other thread's lock is acquired is when
	executing \co{synchronize_rcu()}, and in that case, the lock
	is immediately released, prohibiting a deadlock cycle that
	does not involve a lock held across the \co{synchronize_rcu()}
	which is the first case above.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	Figure~\ref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	에 보인 RCU 알고리즘의, 예를 들어 POSIX pthread 처럼 여러곳에서 사용
	가능한 기능들만을 사용하고 있는 점도 장점 아닌가요?
	\iffalse

	Isn't one advantage of the RCU algorithm shown in
	Listing~\ref{lst:app:toyrcu:Per-Thread Lock-Based RCU Implementation}
	that it uses only primitives that are widely available,
	for example, in POSIX pthreads?
	\fi
\QuickQuizAnswer{
	이는 실제로 장점입니다만 \co{rcu_dereference()} 와
	\co{rcu_asign_pointer()} 는 여전히 필요함을 잊지 말아야 하는데, 이는
	\co{rcu_dereference()} 를 위한 \co{volatile} 조정과
	\co{rcu_assign_pointer()} 를 위한 메모리 배리어의 필요를 뜻합니다.
	물론, 대부분의 Alpha CPU 들은 두 기능 모두에 메모리 배리어가
	필요합니다.
	\iffalse

	This is indeed an advantage, but do not forget that
	\co{rcu_dereference()} and \co{rcu_assign_pointer()}
	are still required, which means \co{volatile} manipulation
	for \co{rcu_dereference()} and memory barriers for
	\co{rcu_assign_pointer()}.
	Of course, many Alpha CPUs require memory barriers for both
	primitives.
	\fi
} \QuickQuizEnd

이 방법은 일부 환경에서는 유용할 수 있는데, 리눅스 2.4 커널에서도 비슷한 방법이
사용되었습니다~\cite{Molnar00a}.

이어서 소개될 카운터 기반의 RCU 구현은 락 기반 구현의 일부 한계들을 해결합니다.
\iffalse

This approach could be useful in some situations, given that a similar
approach was used in the
Linux 2.4 kernel~\cite{Molnar00a}.

The counter-based RCU implementation described next overcomes some of
the shortcomings of the lock-based implementation.
\fi

\section{Simple Counter-Based RCU}
\label{sec:app:toyrcu:Simple Counter-Based RCU}

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 atomic_t rcu_refcnt;
  2
  3 static void rcu_read_lock(void)
  4 {
  5   atomic_inc(&rcu_refcnt);
  6   smp_mb();
  7 }
  8
  9 static void rcu_read_unlock(void)
 10 {
 11   smp_mb();
 12   atomic_dec(&rcu_refcnt);
 13 }
 14
 15 void synchronize_rcu(void)
 16 {
 17   smp_mb();
 18   while (atomic_read(&rcu_refcnt) != 0) {
 19     poll(NULL, 0, 10);
 20   }
 21   smp_mb();
 22 }
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Implementation Using Single Global Reference Counter}
\label{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
\end{listing}

약간 더 세련된 RCU 구현이
Figure~\ref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
(\path{rcu_rcg.h} 와 \path{rcu_rcg.c}) 에 보여져 있습니다.
이 구현은 line~1 에 정의된 글로벌 레퍼런스 카운터 \co{rcu_refcnt} 를
사용합니다.
\co{rcu_read_lock()} 기능은 어토믹하게 이 카운터를 증가시키고, RCU read-side
크리티컬 섹션이 이 어토믹 값 증가 뒤로 순서지어지는 것을 보장시킵니다.
유사하게, \co{rcu_read_unlock()} 은 RCU read-side 크리티컬 섹션을 가두기 위해
메모리 배리어를 실행하고 어토믹하게 그 카운터를 감소시킵니다.
\co{synchronize_rcu()} 기능은 레퍼런스 카운터에 감싸인 채 이 레퍼런스 카운터가
0이 되기를 기다립니다.
Line~19 의 \co{poll()} 은 단순히 순수한 지연을 제공하고, 순수한 RCU 시맨틱의
관점에서는 허용될 수 있습니다.
다시, 일단 \co{synchronize_rcu()} 가 리턴하면 모든 앞의 RCU read-side 크리티컬
섹션들은 완료되었을 것이 보장됩니다.
\iffalse

A slightly more sophisticated RCU implementation is shown in
Listing~\ref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
(\path{rcu_rcg.h} and \path{rcu_rcg.c}).
This implementation makes use of a global reference counter
\co{rcu_refcnt} defined on line~1.
The \co{rcu_read_lock()} primitive atomically increments this
counter, then executes a memory barrier to ensure that the
RCU read-side critical section is ordered after the atomic
increment.
Similarly, \co{rcu_read_unlock()} executes a memory barrier to
confine the RCU read-side critical section, then atomically
decrements the counter.
The \co{synchronize_rcu()} primitive spins waiting for the reference
counter to reach zero, surrounded by memory barriers.
The \co{poll()} on line~19 merely provides pure delay, and from
a pure RCU-semantics point of view could be omitted.
Again, once \co{synchronize_rcu()} returns, all prior
RCU read-side critical sections are guaranteed to have completed.
\fi

Section~\ref{sec:app:toyrcu:Lock-Based RCU} 에서 보여진 락 기반의 구현과 상반되는
장점으로, 이 구현은 RCU read-side 크리티컬 섹션들의 병렬 수행을 가능하게
합니다.
Section~\ref{sec:app:toyrcu:Per-Thread Lock-Based RCU} 에서 보여진 쓰레드별 락 기반의
구현과 상반되는 장점으로, 이 구현은 또한 그것들이 중첩될 수 있게 합니다.
또한, \co{rcu_read_lock()} 기능은 결코 스핀하지도 블록하지도 않기 때문에 데드락
사이클에 연관될 수 없습니다.
\iffalse

In happy contrast to the lock-based implementation shown in
Section~\ref{sec:app:toyrcu:Lock-Based RCU}, this implementation
allows parallel execution of RCU read-side critical sections.
In happy contrast to the per-thread lock-based implementation shown in
Section~\ref{sec:app:toyrcu:Per-Thread Lock-Based RCU},
it also allows them to be nested.
In addition, the \co{rcu_read_lock()} primitive cannot possibly
participate in deadlock cycles, as it never spins nor blocks.
\fi

\QuickQuiz{}
	하지만 \co{synchronize_rc()} 을 감싸고 락을 잡고 같은 락을 RCU
	read-side 크리티컬 섹션 내에서 잡으면 어떻게 되죠?
	\iffalse

	But what if you hold a lock across a call to
	\co{synchronize_rcu()}, and then acquire that same lock within
	an RCU read-side critical section?
	\fi
\QuickQuizAnswer{
	사실, 이것은 모든 합법적인 RCU 구현에서 데드락을 일으킬 겁니다.
	하지만 \co{rcu_read_lock()} 은 \emph{정말로} 데드락 사이클에 참가하고 있는 걸까요?
	그렇게 믿는다면,
	Section~\ref{sec:app:toyrcu:RCU Based on Quiescent States} 의 RCU 구현을 보게
	될때 같은 질문을 해보시기 바랍니다.
	\iffalse

	Indeed, this would deadlock any legal RCU implementation.
	But is \co{rcu_read_lock()} \emph{really} participating in
	the deadlock cycle?
	If you believe that it is, then please
	ask yourself this same question when looking at the
	RCU implementation in
	Section~\ref{sec:app:toyrcu:RCU Based on Quiescent States}.
	\fi
	Section~\ref{sec:app:toyrcu:RCU Based on Quiescent States}.
} \QuickQuizEnd

하지만, 이 구현은 여전히 일부 심각한 한계점들을 가지고 있습니다.
첫째로, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 안의 어토믹
오퍼레이션들은 여전히 상당히 무겁고, read-side 오버헤드는 하나의 \Power{5} CPU
에서의 100~나노세컨드부터 64-CPU 시스템에서의 약 40~\emph{마이크로세컨드} 의
범위를 갖습니다.
이는 RCU read-side 크리티컬 섹션들은 실제 read-side 병렬성을 갖기 위해서는
상당히 길어야 함을 의미합니다.
반면에 읽기 쓰레드들이 존재하지 않는다면 grace period 는 40~\emph{나노세컨드}
만에 끝나는데, 이는 리눅스 커널의 제품 품질의 구현보다 수십 수백배는 빠른
겁니다.
\iffalse

However, this implementations still has some serious shortcomings.
First, the atomic operations in \co{rcu_read_lock()} and
\co{rcu_read_unlock()} are still quite  heavyweight,
with read-side overhead ranging from about 100~nanoseconds on
a single \Power{5} CPU up to almost 40~\emph{microseconds}
on a 64-CPU system.
This means that the RCU read-side critical sections
have to be extremely long in order to get any real
read-side parallelism.
On the other hand, in the absence of readers, grace periods elapse
in about 40~\emph{nanoseconds}, many orders of magnitude faster
than production-quality implementations in the Linux kernel.
\fi

\QuickQuiz{}
	\co{synchronize_rcu()} 가 10-밀리세컨드 지연을 포함하고 있는데 어떻게
	grace period 가 40 나노세컨드 만에 끝날수가 있나요?
	\iffalse

	How can the grace period possibly elapse in 40 nanoseconds when
	\co{synchronize_rcu()} contains a 10-millisecond delay?
	\fi
\QuickQuizAnswer{
	이 update 쪽 테스트는 읽기 쓰레드들 없이 수행되었고, 따라서 \co{poll()}
	시스템 콜은 결코 호출되지 않았습니다.
	또한, 실제 코드는 이 \co{poll()} 시스템 콜을 주석처리 해서 이
	update-side 코드의 진정한 오버헤드를 측정하기에 더 좋게 되어 있습니다.
	이 코드의 모든 제품에서 사용하기에는 \co{poll()} 시스템 콜을 사용하도록
	하는 편이 좋을 겁니다만 다시 말하지만 제품에서 사용하기에는 이 섹션의
	뒤에서 이야기될 다른 구현이 더 걸맞을 수도 있습니다.
	\iffalse

	The update-side test was run in absence of readers, so the
	\co{poll()} system call was never invoked.
	In addition, the actual code has this \co{poll()}
	system call commented out, the better to evaluate the
	true overhead of the update-side code.
	Any production uses of this code would be better served by
	using the \co{poll()} system call, but then again,
	production uses would be even better served by other implementations
	shown later in this section.
	\fi
} \QuickQuizEnd

둘째로, 많은 동시의 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()}
오퍼레이션들이 있다면, \co{rcu_refcnt} 에 굉장한 메모리 경쟁이 발생할 거고,
이는 비싼 캐시 미스를 유발할 겁니다.
이 두개의 한계점들은 RCU 의 주 목적인 read-side 동기화 기능에 낮은 오버헤드
제공하기를 매우 어렵게 만듭니다.

마지막으로, 긴 read-side 크리티컬 섹션들을 갖는 많은 수의 RCU 읽기 쓰레드들은
글로벌 카운터가 결코 0이 되지 못하게 해서 \co{synchronize_rcu()} 가 영원히
완료되지 못하게 만들 수도 있습니다.
이는 RCU 업데이트의 starvation 을 유발할 수 있는데 이는 당연하게도 제품
환경에서는 받아들여질 수 없는 특성입니다.
\iffalse

Second, if there are many concurrent \co{rcu_read_lock()}
and \co{rcu_read_unlock()} operations, there will
be extreme memory contention on \co{rcu_refcnt},
resulting in expensive cache misses.
Both of these first two shortcomings largely defeat a major purpose of
RCU, namely to provide low-overhead read-side synchronization primitives.

Finally, a large number of RCU readers with long read-side
critical sections could prevent \co{synchronize_rcu()}
from ever completing, as the global counter might
never reach zero.
This could result in starvation of RCU updates, which
is of course unacceptable in production settings.
\fi

\QuickQuiz{}
	Figure~\ref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
	의 RCU 구현은 동시의 \co{synchronize_rcu()} 가 너무 오래 기다리고
	있을때에는 왜 간단히 \co{rcu_read_lock()} 을 기다리게 만들지 않는거죠?
	그렇게 하면 \co{synchronize_rcu()} 의 starvation 을 막을 수 있지
	않나요?
	\iffalse

	Why not simply make \co{rcu_read_lock()} wait when a concurrent
	\co{synchronize_rcu()} has been waiting too long in
	the RCU implementation in
	Listing~\ref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}?
	Wouldn't that prevent \co{synchronize_rcu()} from starving?
	\fi
\QuickQuizAnswer{
	Although this would in fact eliminate the starvation, it would
	also mean that \co{rcu_read_lock()} would spin or block waiting
	for the writer, which is in turn waiting on readers.
	If one of these readers is attempting to acquire a lock that
	the spinning/blocking \co{rcu_read_lock()} holds, we again
	have deadlock.

	In short, the cure is worse than the disease.
	See Section~\ref{sec:app:toyrcu:Starvation-Free Counter-Based RCU}
	for a proper cure.
} \QuickQuizEnd

따라서, 이 구현은 락 기반의 메커니즘보다는 예를 들어 고도의 스트레스 디버깅
환경에서 적합한 RCU 구현과 같은 잠재성이 약간 있긴 하지만, 제품 환경에서 유용할
거라고 생각하기는 여전히 어렵습니다.
다음 섹션은 쓰기 쓰레드들에 좀 더 신경쓴 레퍼런스 카운팅 방법들을 설명합니다.
\iffalse

Therefore, it is still hard to imagine this implementation being useful
in a production setting, though it has a bit more potential
than the lock-based mechanism, for example, as an RCU implementation
suitable for a high-stress debugging environment.
The next section describes a variation on the reference-counting
scheme that is more favorable to writers.
\fi

\section{Starvation-Free Counter-Based RCU}
\label{sec:app:toyrcu:Starvation-Free Counter-Based RCU}

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 DEFINE_SPINLOCK(rcu_gp_lock);
  2 atomic_t rcu_refcnt[2];
  3 atomic_t rcu_idx;
  4 DEFINE_PER_THREAD(int, rcu_nesting);
  5 DEFINE_PER_THREAD(int, rcu_read_idx);
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Global Reference-Count Pair Data}
\label{lst:app:toyrcu:RCU Global Reference-Count Pair Data}
\end{listing}

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 static void rcu_read_lock(void)
  2 {
  3   int i;
  4   int n;
  5
  6   n = __get_thread_var(rcu_nesting);
  7   if (n == 0) {
  8     i = atomic_read(&rcu_idx);
  9     __get_thread_var(rcu_read_idx) = i;
 10     atomic_inc(&rcu_refcnt[i]);
 11   }
 12   __get_thread_var(rcu_nesting) = n + 1;
 13   smp_mb();
 14 }
 15
 16 static void rcu_read_unlock(void)
 17 {
 18   int i;
 19   int n;
 20
 21   smp_mb();
 22   n = __get_thread_var(rcu_nesting);
 23   if (n == 1) {
 24      i = __get_thread_var(rcu_read_idx);
 25      atomic_dec(&rcu_refcnt[i]);
 26   }
 27   __get_thread_var(rcu_nesting) = n - 1;
 28 }
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Read-Side Using Global Reference-Count Pair}
\label{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
\end{listing}

Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
(\path{rcu_rcgp.h})
는
Listing~\ref{lst:app:toyrcu:RCU Global Reference-Count Pair Data} 에 보여진
한쌍의 레퍼런스 카운터 (\co{rcu_refcnt[]}) 와 그 한쌍 중 하나의 카운터를
고르는데 사용되는 글로벌 인덱스 (\co{rcu_idx}), 쓰레드별 중첩 수준 카운터
\co{rcu_nesting}, 쓰레드별 글로벌 인덱스의 스냅샷 (\co{rcu_rad_idx}), 그리고
하나의 글로벌 락을 사용하는 RCU 구현의 read-side 기능들을 보이고 있습니다.
\iffalse

Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
(\path{rcu_rcgp.h})
shows the read-side primitives of an RCU implementation that uses a pair
of reference counters (\co{rcu_refcnt[]}),
along with a global index that
selects one counter out of the pair (\co{rcu_idx}),
a per-thread nesting counter \co{rcu_nesting},
a per-thread snapshot of the global index (\co{rcu_read_idx}),
and a global lock (\co{rcu_gp_lock}),
which are themselves shown in
Listing~\ref{lst:app:toyrcu:RCU Global Reference-Count Pair Data}.
\fi

\paragraph{Design}

두개의 원소를 갖는 \co{rcu_refcnt[]} 배열이야말로 starvation 으로부터 자유를
가져다 주는 그 무엇입니다.
핵심은 \co{synchronize_rcu()} 는 앞서 존재한 읽기 쓰레드들을 기다리는 것만이
요구된다는 점입니다.
만약 새로운 읽기 쓰레드가 이미 수행을 시작한 특정 \co{synchronize_rcu()}
인스턴스 뒤에 시작된다면, 그 \co{synchronize_rcu()} 인스턴스는 이 새로운 읽기
쓰레드를 기다려야 할 필요가 없습니다.
어떤 시점이든, 특정 읽기 쓰레드가 \co{rcu_read_lock()} 을 통해 자신의 RCU
read-side 크리티컬 섹션을 들어갈 때에, 이 읽기 쓰레드는 \co{rcu_idx} 변수로
가리켜지는 \co{rcu_refcnt[]} 배열의 원소의 값을 증가시킵니다.
같은 읽기 쓰레드가 \co{rcu_read_unlock()} 을 통해 자신의 RCU read-side 크리티컬
섹션을 나갈 때에는  이 읽기 쓰레드는 \co{rcu_idx} 값에 가해졌을 수 있는 모든
뒤의 변경들을 무시한 채 자신이 증가시켰던 원소의 값을 감소시킵니다.
\iffalse

It is the two-element \co{rcu_refcnt[]} array that provides the freedom
from starvation.
The key point is that \co{synchronize_rcu()} is only required to wait
for pre-existing readers.
If a new reader starts after a given instance of \co{synchronize_rcu()}
has already begun execution, then that instance of \co{synchronize_rcu()}
need not wait on that new reader.
At any given time, when a given reader enters its RCU read-side critical
section via \co{rcu_read_lock()},
it increments the element of the \co{rcu_refcnt[]} array indicated by
the \co{rcu_idx} variable.
When that same reader exits its RCU read-side critical section via
\co{rcu_read_unlock()}, it decrements whichever element it incremented,
ignoring any possible subsequent changes to the \co{rcu_idx} value.
\fi

이 구성은 \co{synchronize_rcu()} 가 \co{rcu_idx} 의 값을 \co{rcu_idx =
!rcu_idx} 식으로 보정함으로써 starvation 을 막을 수 있음을 의미합니다.
\co{rcu_idx} 의 예전 값이 0이었고, 따라서 새로운 값은 1이 될 것이라고 가정해
봅시다.
이 값 보정 오퍼레이션 후에 도착하는 새로운 읽기 쓰레드들은 \co{rcu_idx[1]} 을
증가시킬 것이고, 그동안 앞서 \co{rcu_idx[0]} 를 증가시켰던 과거의 읽기
쓰레드들은 각자의 RCU read-side 크리티컬 섹션들을 나갈 때마다 \co{rcu_idx[0]}을
감소시킬 겁니다.
이는 \co{rcu_idx[0]} 의 값은 더이상 증가하지 않을것이고, 따라서 단조롭게 감소를
하게 될것이라는 의미입니다.\footnote{
	이 ``단조로운 감소'' 문장이 무시하는 race condition 이 있습니다.
	이 race condition 은 \co{synchronize_rcu()} 코드와 함께 다루겠습니다.
	그전까지는, 의심을 멈춰주시길 바랍니다.}
이는 모든 \co{synchronize_rcu()} 가 해야할 일은 \co{rcu_refcnt[0]} 가 0이 될
때까지 기다려야 하는 것 뿐이란 의미입니다.

이 배경지식과 함께라면, 실제 기능들의 구현을 들여다 볼 준비가 되었습니다.
\iffalse

This arrangement means that \co{synchronize_rcu()} can avoid starvation
by complementing the value of \co{rcu_idx}, as in \co{rcu_idx = !rcu_idx}.
Suppose that the old value of \co{rcu_idx} was zero, so that the new
value is one.
New readers that arrive after the complement operation will increment
\co{rcu_refcnt[1]}, while the old readers that previously incremented
\co{rcu_refcnt[0]} will decrement \co{rcu_refcnt[0]} when they exit their
RCU read-side critical sections.
This means that the value of \co{rcu_refcnt[0]} will no longer be incremented,
and thus will be monotonically decreasing.\footnote{
	There is a race condition that this ``monotonically decreasing''
	statement ignores.
	This race condition will be dealt with by the code for
	\co{synchronize_rcu()}.
	In the meantime, I suggest suspending disbelief.}
This means that all that \co{synchronize_rcu()} need do is wait for the
value of \co{rcu_refcnt[0]} to reach zero.

With the background, we are ready to look at the implementation of the
actual primitives.
\fi

\paragraph{Implementation}

\co{rcu_read_lock()} 기능은 \co{rcu_idx} 로 인덱스되는 \co{rcu_refcnt[]} 배열의
멤버의 값을 어토믹하게 증가시키고, 이 인덱스의 스냅샷을 쓰레드별 변수인
\co{rcu_read_idx} 안에 보관합니다.
\co{rcu_read_unlock()} 함수는 연관된 \co{rcu_read_lock()} 에서 값을 증가시켰던
카운터의 값을 어토믹하게 감소시킵니다.
하지만, \co{rcu_idx} 의 하나의 값만이 쓰레드별로 기억되기 때문에 read-side
크리티컬 섹션의 중첩을 허용하게 위해서는 추가적인 방법들이 필요합니다.
이런 추가적인 방법들은 중첩 정보를 쫓아가는데에 쓰레드별 \co{rcu_nesting}
변수를 사용합니다.
\iffalse

The \co{rcu_read_lock()} primitive atomically increments the member of the
\co{rcu_refcnt[]} pair indexed by \co{rcu_idx}, and keeps a
snapshot of this index in the per-thread variable \co{rcu_read_idx}.
The \co{rcu_read_unlock()} primitive then atomically decrements
whichever counter of the pair that the corresponding \co{rcu_read_lock()}
incremented.
However, because only one value of \co{rcu_idx} is remembered per thread,
additional measures must be taken to permit nesting.
These additional measures use the per-thread \co{rcu_nesting} variable
to track nesting.
\fi

이것들이 모두 동작하도록 하기 위해,
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
의 \co{rcu_read_lock()} 의 line~6 에서는 현재 쓰레드의 \co{rcu_nesting}
인스턴스를 가져오고 line~7 에서는 지금 중첩된 \co{rcu_read_lock()} 중 가장
바깥에 있음을 확인한 후 line~8-10 에서는 \co{rcu_idx} 의 현재 값을 가져오고 이
값을 이 쓰레드의 \co{rcu_read_idx} 에 저장한 후 \co{rcu_refcnt} 의 선택된
원소의 값을 어토믹하게 증가시킵니다.
\co{rcu_nesting} 의 값과는 무관하게 line~12 에서는 그 값을 증가시킵니다.
Line~13 에서는 메모리 배리어를 실행해서 RCU read-side 크리티컬 섹션이
\co{rcu_read_lock()} 코드 앞으로 튀어나오지 않게 막아줍니다.
\iffalse

To make all this work, line~6 of \co{rcu_read_lock()} in
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
picks up the
current thread's instance of \co{rcu_nesting}, and if line~7 finds
that this is the outermost \co{rcu_read_lock()},
then lines~8-10 pick up the current value of
\co{rcu_idx}, save it in this thread's instance of \co{rcu_read_idx},
and atomically increment the selected element of \co{rcu_refcnt}.
Regardless of the value of \co{rcu_nesting}, line~12 increments it.
Line~13 executes a memory barrier to ensure that the RCU read-side
critical section does not bleed out before the \co{rcu_read_lock()} code.
\fi

비슷하게, \co{rcu_read_unlock()} 함수는 RCU read-side 크리티컬 섹션이
\co{rcu_read_unlock()} 코드 뒤로 삐져나가지 않도록 line~21 에서 메모리 배리어를
실행합니다.
Line~22 에서는 이 쓰레드의 \co{rcu_nesting} 인스턴스를 가져오고 line~23 에서
지금 중첩된 \co{rcu_read_unlock()} 가운데 가장 바깥임을 확인하고, line~24 와 25
에서 이 쓰레드의 (중첩된 \co{rcu_read_lock()} 중 가장 바깥의 것에서 저장된)
\co{rcu_read_idx} 인스턴스를 가져온 후 \co{rcu_refcnt} 의 선택된 원소의 값을
감소시킵니다.
중첩 단계와 관계없이, line~27 에서는 이 쓰레드의 \co{rcu_nesting} 인스턴스의
값을 감소시킵니다.
\iffalse

Similarly, the \co{rcu_read_unlock()} function executes a memory barrier
at line~21
to ensure that the RCU read-side critical section does not bleed out
after the \co{rcu_read_unlock()} code.
Line~22 picks up this thread's instance of \co{rcu_nesting}, and if
line~23 finds that this is the outermost \co{rcu_read_unlock()},
then lines~24 and 25 pick up this thread's instance of \co{rcu_read_idx}
(saved by the outermost \co{rcu_read_lock()}) and atomically decrements
the selected element of \co{rcu_refcnt}.
Regardless of the nesting level, line~27 decrements this thread's
instance of \co{rcu_nesting}.
\fi

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 void synchronize_rcu(void)
  2 {
  3   int i;
  4
  5   smp_mb();
  6   spin_lock(&rcu_gp_lock);
  7   i = atomic_read(&rcu_idx);
  8   atomic_set(&rcu_idx, !i);
  9   smp_mb();
 10   while (atomic_read(&rcu_refcnt[i]) != 0) {
 11     poll(NULL, 0, 10);
 12   }
 13   smp_mb();
 14   atomic_set(&rcu_idx, i);
 15   smp_mb();
 16   while (atomic_read(&rcu_refcnt[!i]) != 0) {
 17     poll(NULL, 0, 10);
 18   }
 19   spin_unlock(&rcu_gp_lock);
 20   smp_mb();
 21 }
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Update Using Global Reference-Count Pair}
\label{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
\end{listing}

Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
(\path{rcu_rcpg.c})
는 이에 연관되는 \co{synchronize_rcu()} 구현을 보입니다.
Line~6 과 19는 두개 이상의 \co{synchronize_rcu()} 인스턴스가 동시에 수행되는
것을 막기 위해 \co{rcu_gp_lock} 을 각각 잡고 풉니다.
Line~7-8 은 각각 \co{rcu_idx} 의 값을 가져오고 뒤따르는 \co{rcu_read_lock()} 이
앞의 인스턴스들과 다른 \co{rcu_idx} 원소를 사용하도록 보정합니다.
Line~10-12 는 \co{rcu_idx} 로 가리켜지는 원소의 값이 0이 될때까지 기다리는데
앞서 line~9 에서의 메모리 배리어를 통해 \co{rcu_idx} 의 체크가 \co{rcu_idx} 의
보정 앞으로 튀어오르지 않게 합니다.
Line~13-18 은 이 과정을 반복하고, line~20 은 어떤 뒤따르는 오퍼레이션들이
\co{rcu_refcnt} 의 검사를 앞질러 튀어오르지 않게 합니다.
\iffalse

Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
(\path{rcu_rcpg.c})
shows the corresponding \co{synchronize_rcu()} implementation.
Lines~6 and 19 acquire and release \co{rcu_gp_lock} in order to
prevent more than one concurrent instance of \co{synchronize_rcu()}.
Lines~7-8 pick up the value of \co{rcu_idx} and complement it,
respectively, so that subsequent instances of \co{rcu_read_lock()}
will use a different element of \co{rcu_refcnt} than did preceding
instances.
Lines~10-12 then wait for the prior element of \co{rcu_refcnt} to
reach zero, with the memory barrier on line~9 ensuring that the check
of \co{rcu_refcnt} is not reordered to precede the complementing of
\co{rcu_idx}.
Lines~13-18 repeat this process, and line~20 ensures that any
subsequent reclamation operations are not reordered to precede the
checking of \co{rcu_refcnt}.
\fi

\QuickQuiz{}
	Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	의 \co{synchronize_rcu()} 의 line~5 의 메모리 배리어는 바로 뒤에 스핀락
	획득이 있는데도 왜 필요한거죠?
	\iffalse

	Why the memory barrier on line~5 of \co{synchronize_rcu()} in
	Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	given that there is a spin-lock acquisition immediately after?
	\fi
\QuickQuizAnswer{
	스핀락 획득은 스핀락의 크리티컬 섹션이 이 획득 전으로 ``흘러나오지''
	않게 보장할 뿐입니다.
	이는 스핀락 획득 앞의 코드가 크리티컬 섹션 안으로 재배치되는 것은 막지
	않습니다.
	그런 재배치는 RCU 로 보호되는 리스트의 삭제 작업이 \co{rcu_idx} 보정
	뒤로 재배치되도록 해서 새로이 시작하는 RCU read-side 크리티컬 섹션이
	최근에 삭제된 데이터 원소를 보게 만들어 버릴 수 있습니다.
	\iffalse

	The spin-lock acquisition only guarantees that the spin-lock's
	critical section will not ``bleed out'' to precede the
	acquisition.
	It in no way guarantees that code preceding the spin-lock
	acquisition won't be reordered into the critical section.
	Such reordering could cause a removal from an RCU-protected
	list to be reordered to follow the complementing of
	\co{rcu_idx}, which could allow a newly starting RCU
	read-side critical section to see the recently removed
	data element.
	\fi

	독자를 위한 연습문제: Promela/spin 같은 도구를 사용해서
	Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	의 메모리 배리어들 가운데 (존재한다면) 무엇이 정말로 필요한 것인지
	가려내보세요.
	이 도구들의 사용법을 위해선
	Section~\ref{chp:Formal Verification} 를 참고하세요.
	처음으로 옳고 완벽한 답변은 인정을 받을 겁니다.
	\iffalse

	Exercise for the reader: use a tool such as Promela/spin
	to determine which (if any) of the memory barriers in
	Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	are really needed.
	See Chapter~\ref{chp:Formal Verification}
	for information on using these tools.
	The first correct and complete response will be credited.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
	에서 카운터는 왜 두번 뒤집히는 거죠?
	한번의 뒤집고 기다리는 사이클만으로도 충분하지 않나요?
	\iffalse

	Why is the counter flipped twice in
	Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}?
	Shouldn't a single flip-and-wait cycle be sufficient?
	\fi
\QuickQuizAnswer{
	두번의 뒤집기가 모두 필요합니다.
	이를 확인하기 위해서는 다음과 같은 일련의 이벤트를 생각해 보세요:
	\iffalse

	Both flips are absolutely required.
	To see this, consider the following sequence of events:
	\fi
	\begin{enumerate}
	\item	Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
		\co{rcu_read_lock()} 의 line~8 에서 \co{rcu_idx} 를 가져오고 그
		값이 0임을 확인합니다.
	\item	Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
		\co{synchronize_rcu()} 의 line~8 에서 \co{rcu_idx} 를 가져오고
		그 값이 0임을 확인합니다.
	\item	\co{synchronize_rcu()} 의 line~10-13 에서 \co{rcu_refcnt[0]} 의
		값이 0임을 확인하고 리턴합니다.
		(질문은 line~14-20 이 사라지면 어떻게 되는지이니까요.)
	\item	\co{rcu_read_lock()} 의 line~9 와 10 은 각각 이 쓰레드의
		\co{rcu_read_idx} 에 0을 저장하고, \co{rcu_refcnt[0]} 의 값을
		증가시킵니다.
		실행은 이제 read-side 크리티컬 섹션의 안으로 들어갑니다.
		\label{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start}
	\iffalse

	\item	Line~8 of \co{rcu_read_lock()} in
		Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
		picks up \co{rcu_idx}, finding its value to be zero.
	\item	Line~8 of \co{synchronize_rcu()} in
		Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair}
		complements the value of \co{rcu_idx}, setting its
		value to one.
	\item	Lines~10-13 of \co{synchronize_rcu()} find that the
		value of \co{rcu_refcnt[0]} is zero, and thus
		returns.
		(Recall that the question is asking what happens if
		lines~14-20 are omitted.)
	\item	Lines~9 and 10 of \co{rcu_read_lock()} store the
		value zero to this thread's instance of \co{rcu_read_idx}
		and increments \co{rcu_refcnt[0]}, respectively.
		Execution then proceeds into the RCU read-side critical
		section.
		\label{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start}
	\fi
	\item	\co{synchronize_rcu()} 의 또다른 인스턴스가 다시 \co{rcu_idx}
		를 바꾸는데, 이번에는 그 값을 0으로 바꿉니다.
		\co{rcu_refcnt[1]} 의 값이 0이므로, \co{synchronize_rcu()} 는
		곧바로 리턴합니다.
		(\co{rcu_read_lock()} 은 \co{rcu_refcnt[0]} 을 증가시켰지,
		\co{rcu_refcnt[1]} 을 증가시키지 않았으니까요!)
		\label{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
	\item	Step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start} 전에 시작된 RCU
		read-side 크리티컬 섹션이 완료되지 않았음에도
		step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start} 에서 시작한
		grace period 가 종료되는 것이 허가되었습니다.
		이는 RCU 시맨틱을 위반하는 것이고 업데이트가 RCU read-side
		크리티컬 섹션이 여전히 레퍼런스 하고 있는 데이터 원소를
		해제시킬 수 있게 할 수 있습니다.
	\iffalse

	\item	Another instance of \co{synchronize_rcu()} again complements
		\co{rcu_idx}, this time setting its value to zero.
		Because \co{rcu_refcnt[1]} is zero, \co{synchronize_rcu()}
		returns immediately.
		(Recall that \co{rcu_read_lock()} incremented
		\co{rcu_refcnt[0]}, not \co{rcu_refcnt[1]}!)
		\label{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
	\item	The grace period that started in
		step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Grace Period Start}
		has been allowed to end, despite
		the fact that the RCU read-side critical section
		that started beforehand in
		step~\ref{sec:app:toyrcu:rcu_rcgp:RCU Read Side Start}
		has not completed.
		This violates RCU semantics, and could allow the update
		to free a data element that the RCU read-side critical
		section was still referencing.
	\fi
	\end{enumerate}

	독자를 위한 연습문제: \co{rcu_read_lock()} 이 line~8 뒤에서 매우 긴
	시간 (몇시간정도!) preemption 당한다면 어떤 일이 일어날까요?
	이 구현은 그런 경우에도 똑바로 동작할까요?
	그 답의 이유는 뭐죠?
	맞고 완벽한 첫번째 답은 인정을 받을 겁니다.
	\iffalse

	Exercise for the reader: What happens if \co{rcu_read_lock()}
	is preempted for a very long time (hours!) just after
	line~8?
	Does this implementation operate correctly in that case?
	Why or why not?
	The first correct and complete response will be credited.
	\fi
} \QuickQuizEnd
\iffalse

이 구현은
Listing~\ref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
에서 보인 단일 카운터 구현에서 일어날 수 있는
업데이트 쪽의 starvation 문제를 배제합니다.
\fi

This implementation avoids the update-starvation issues that could
occur in the single-counter implementation shown in
Listing~\ref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}.

\paragraph{Discussion}

여전히 심각한 한계점들이 있습니다.
첫째로, \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 의 어토믹 오퍼레이션들은
여전히 상당히 무겁습니다.
사실, 이것들은
Listing~\ref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter}
의 하나의 카운터 사용 버전보다 더 복잡해서 read-side 기능들은 하나의 \Power{5}
CPU 에서 약 150~나노세컨드를, 그리고 64-CPU 시스템에서는 약
40~\emph{마이크로세컨드} 를 소모합니다.
업데이트 쪽의 \co{synchronize_rcu()} 기능은 이보다도 비싸서, 하나의 \Power{5}
CPU 에서는 200~나노세컨드 정도, 64-CPU 시스템에서는 40~\emph{마이크로세컨드}
정도를 소모합니다.
이 말은 정말 read-side 병렬성을 얻기 위해서는 RCU read-side 크리티컬 섹션들이
매우 길어야만 한다는 뜻입니다.
\iffalse

There are still some serious shortcomings.
First, the atomic operations in \co{rcu_read_lock()}
and \co{rcu_read_unlock()}
are still quite heavyweight.
In fact, they are more complex than those
of the single-counter variant shown in
Listing~\ref{lst:app:toyrcu:RCU Implementation Using Single Global Reference Counter},
with the read-side primitives consuming about 150~nanoseconds on a single
\Power{5} CPU and almost 40~\emph{microseconds} on a 64-CPU system.
The update-side \co{synchronize_rcu()} primitive is more costly as
well, ranging from about 200~nanoseconds on a single \Power{5} CPU to
more than 40~\emph{microseconds} on a 64-CPU system.
This means that the RCU read-side critical sections
have to be extremely long in order to get any real
read-side parallelism.
\fi

둘째로, 많은 동시적인 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()}
오퍼레이션들이 존재한다면, \co{rcu_refcnt} 원소들에의 극심한 경쟁이 만들어질
것이고, 이는 비싼 캐시 미스들을 유발할 것입니다.
이것은 더 나아가 병렬적인 read-side 액세스를 위해 필요시되는 RCU read-side
크리티컬 섹션 길이를 더욱 늘릴 겁니다.
이 두가지 한계점들은 대부분의 상황에서 RCU 의 목적을 달성하기 어렵게 합니다.
\iffalse

Second, if there are many concurrent \co{rcu_read_lock()}
and \co{rcu_read_unlock()} operations, there will
be extreme memory contention on the \co{rcu_refcnt}
elements, resulting in expensive cache misses.
This further extends the RCU read-side critical-section
duration required to provide parallel read-side access.
These first two shortcomings defeat the purpose of RCU in most
situations.
\fi

셋째로, \co{rcu_idx} 를 두번이나 뒤집어야 하는 필요성은 업데이트 쪽에 상당한
오버헤드를 의미하는데, 특히 쓰레드의 수가 클때에 더욱 그러합니다.

마지막으로, 동시의 RCU 업데이트들이 동일한 grace period 로 처리될 수 있음에도
불구하고 이 구현은 grace period 들을 직렬화 시켜서 grace-period 공유를
불가능하게 합니다.
\iffalse

Third, the need to flip \co{rcu_idx} twice imposes substantial
overhead on updates, especially if there are large
numbers of threads.

Finally, despite the fact that concurrent RCU updates could in principle be
satisfied by a common grace period, this implementation
serializes grace periods, preventing grace-period
sharing.
\fi

\QuickQuiz{}
	어토믹 값 증가와 값 감소가 그렇게 비싸다고 하면,
	Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}
	의 line~10 에서는 어토믹하지 않은 값 증가를, line~25 에서는 어토믹하지
	않은 값 감소를 하지 그래요?
	\iffalse

	Given that atomic increment and decrement are so expensive,
	why not just use non-atomic increment on line~10 and a
	non-atomic decrement on line~25 of
	Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair}?
	\fi
\QuickQuizAnswer{
	어토믹하지 않은 오퍼레이션들을 사용하면 값 증가와 감소가 사라지게 될 수
	있고, 이는 이 구현이 실패하게 할 수 있습니다.
	\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 에서 어토믹하지 않은
	오퍼레이션들을 사용하는 안전한 방법을 위해선
	Section~\ref{sec:app:toyrcu:Scalable Counter-Based RCU} 을 참고하세요.
	\iffalse

	Using non-atomic operations would cause increments and decrements
	to be lost, in turn causing the implementation to fail.
	See Section~\ref{sec:app:toyrcu:Scalable Counter-Based RCU}
	for a safe way to use non-atomic operations in
	\co{rcu_read_lock()} and \co{rcu_read_unlock()}.
	\fi
} \QuickQuizEnd

이런 한계점들에도 불구하고, 누군가는 이 RCU 변종이 적은 수의 타이트하게 연결된
CPU 들 위에서는 더 복잡한 구현들과의 API 호환성을 유지하는 메모리 절약
구현으로는 사용될 수도 있을거라 생각할 겁니다.
하지만, 그건 적은 CPU 들 위로는 확장되지 못할 겁니다.

다음 섹션은 훨씬 개선된 read-side 성능과 확장성을 제공하는 또다른 레퍼런스
카운팅 기반 방법을 설명합니다.
\iffalse

Despite these shortcomings, one could imagine this variant
of RCU being used on small tightly coupled multiprocessors,
perhaps as a memory-conserving implementation that maintains
API compatibility with more complex implementations.
However, it would not likely scale well beyond a few CPUs.

The next section describes yet another variation on the reference-counting
scheme that provides greatly improved read-side performance and scalability.
\fi

\section{Scalable Counter-Based RCU}
\label{sec:app:toyrcu:Scalable Counter-Based RCU}

\begin{listing}[tb]
{ \scriptsize
\begin{verbbox}
  1 DEFINE_SPINLOCK(rcu_gp_lock);
  2 DEFINE_PER_THREAD(int [2], rcu_refcnt);
  3 atomic_t rcu_idx;
  4 DEFINE_PER_THREAD(int, rcu_nesting);
  5 DEFINE_PER_THREAD(int, rcu_read_idx);
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Per-Thread Reference-Count Pair Data}
\label{lst:app:toyrcu:RCU Per-Thread Reference-Count Pair Data}
\end{listing}

\begin{listing}[tb]
{ \scriptsize
\begin{verbbox}
  1 static void rcu_read_lock(void)
  2 {
  3   int i;
  4   int n;
  5
  6   n = __get_thread_var(rcu_nesting);
  7   if (n == 0) {
  8     i = atomic_read(&rcu_idx);
  9     __get_thread_var(rcu_read_idx) = i;
 10     __get_thread_var(rcu_refcnt)[i]++;
 11   }
 12   __get_thread_var(rcu_nesting) = n + 1;
 13   smp_mb();
 14 }
 15
 16 static void rcu_read_unlock(void)
 17 {
 18   int i;
 19   int n;
 20
 21   smp_mb();
 22   n = __get_thread_var(rcu_nesting);
 23   if (n == 1) {
 24      i = __get_thread_var(rcu_read_idx);
 25      __get_thread_var(rcu_refcnt)[i]--;
 26   }
 27   __get_thread_var(rcu_nesting) = n - 1;
 28 }
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
\end{listing}

Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.h})
는 쓰레드별 레퍼런스 카운터 한쌍을 사용하는 RCU 구현의 read-side 기능들을
보입니다.
이 구현은
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair} 에서
보인 구현과 상당히 비슷한데, 차이점은 \co{rcu_refcnt} 가 (
Listing~\ref{lst:app:toyrcu:RCU Per-Thread Reference-Count Pair Data} 에 보인 것과
같이) 쓰레드별 배열이라는 것 뿐입니다.
앞 섹션에서의 알고리즘처럼, 이 두개의 배열의 원소를 사용하는 것은 읽기
쓰레드들이 업데이트 쓰레드들을 starvation 에 빠뜨리는 것을 막습니다.
쓰레드별 \co{rcu_refcnt[]} 배열의 한가지 장점은 \co{rcu_read_lock()} 과
\co{rcu_read_unlock()} 기능들이 더이상 어토믹 오퍼레이션들을 사용하지 않는다는
것입니다.
\iffalse

Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.h})
shows the read-side primitives of an RCU implementation that uses per-thread
pairs of reference counters.
This implementation is quite similar to that shown in
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Global Reference-Count Pair},
the only difference being that \co{rcu_refcnt} is now a per-thread
array (as shown in
Listing~\ref{lst:app:toyrcu:RCU Per-Thread Reference-Count Pair Data}).
As with the algorithm in the previous section, use of this two-element
array prevents readers from starving updaters.
One benefit of per-thread \co{rcu_refcnt[]} array is that the
\co{rcu_read_lock()} and \co{rcu_read_unlock()} primitives no longer
perform atomic operations.
\fi

\QuickQuiz{}
	집어쳐요!
	\co{rcu_read_lock()} 안에 \co{atomic_read()} 가 뻔히 보인다구요!!!
	왜 \co{rcu_read_lock()} 이 어토믹 오퍼레이션을 포함하고 있지 않은 척
	하시는거죠???
	\iffalse

	Come off it!
	We can see the \co{atomic_read()} primitive in
	\co{rcu_read_lock()}!!!
	So why are you trying to pretend that \co{rcu_read_lock()}
	contains no atomic operations???
	\fi
\QuickQuizAnswer{
	해당 \co{atomic_read()} 기능은 실제로는 어토믹한 머신 인스트럭션을
	실행하지 않고, 그저 \co{atomic_t} 로부터의 평범한 로드를 수행합니다.
	이 기능의 목적은 컴파일러의 타입 검사를 쉽게 해주려는 것입니다.
	리눅스 커널이 8비트 CPU 에서 수행된다면, 16 비트 포인터를 저장하는데에
	일부 8-bit 시스템에서의 8비트 액세스 두번이 행해지는 ``store tearing''
	을 막을 필요도 있을 겁니다.
	하지만 감사하게도, 누구도 리눅스를 8 비트 시스템에서 사용하고 있는 것
	같지는 않습니다.
	\iffalse

	The \co{atomic_read()} primitives does not actually execute
	atomic machine instructions, but rather does a normal load
	from an \co{atomic_t}.
	Its sole purpose is to keep the compiler's type-checking happy.
	If the Linux kernel ran on 8-bit CPUs, it would also need to
	prevent ``store tearing'', which could happen due to the need
	to store a 16-bit pointer with two eight-bit accesses on some
	8-bit systems.
	But thankfully, it seems that no one runs Linux on 8-bit systems.
	\fi
} \QuickQuizEnd

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 static void flip_counter_and_wait(int i)
  2 {
  3   int t;
  4
  5   atomic_set(&rcu_idx, !i);
  6   smp_mb();
  7   for_each_thread(t) {
  8     while (per_thread(rcu_refcnt, t)[i] != 0) {
  9       poll(NULL, 0, 10);
 10     }
 11   }
 12   smp_mb();
 13 }
 14
 15 void synchronize_rcu(void)
 16 {
 17   int i;
 18
 19   smp_mb();
 20   spin_lock(&rcu_gp_lock);
 21   i = atomic_read(&rcu_idx);
 22   flip_counter_and_wait(i);
 23   flip_counter_and_wait(!i);
 24   spin_unlock(&rcu_gp_lock);
 25   smp_mb();
 26 }
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Update Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
\end{listing}

Listing~\ref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.c})
는 \co{synchronize_rcu()} 의 구현을 \co{flip_counter_and_wait()} 라 이름지어진
함수와 함께 보이고 있습니다.
\co{synchronize_rcu()} 함수는
Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair} 에 보인
것과 유사합니다만, 반복된 카운터 뒤집기는 line~22 와 23 에서의 새로운 함수로의
호출 두개로 뒤바뀌었습니다.
\iffalse

Listing~\ref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpl.c})
shows the implementation of \co{synchronize_rcu()}, along with a helper
function named \co{flip_counter_and_wait()}.
The \co{synchronize_rcu()} function resembles that shown in
Listing~\ref{lst:app:toyrcu:RCU Update Using Global Reference-Count Pair},
except that the repeated counter flip is replaced by a pair of calls
on lines~22 and 23 to the new helper function.
\fi

이 새로운 \co{flip_counter_and_wait()} 함수는 \co{rcu_idx} 변수를 line~5 에서
업데이트 하고 line~6 에서 메모리 배리어를 실행한 후 line~7-11 에서 각 쓰레드의
기존 \co{rcu_refcnt} 원소가 0이 되기를 기다리며 스핀 하게 됩니다.
일단 모든 그런 원소들이 0이 된다면, 이 함수는 line~12 에서 또다른 메모리
배리어를 치고 리턴합니다.
\iffalse

The new \co{flip_counter_and_wait()} function updates the
\co{rcu_idx} variable on line~5, executes a memory barrier on line~6,
then lines~7-11 spin on each thread's prior \co{rcu_refcnt} element,
waiting for it to go to zero.
Once all such elements have gone to zero,
it executes another memory barrier on line~12 and returns.
\fi

이 RCU 구현은 그 소프트웨어 환경에 중요한 새로운 요구사항을 내포하고 있는데,
이는 (1) 쓰레드별 변수를 선언할 수 있어야 하고, (2) 이 쓰레드별 변수들은 다른
쓰레드들에서도 접근할 수 있어야 하며, (3) 모든 쓰레드의 것들을 하나하나
열거하기가 가능해야 한다는 것입니다.
이런 요구사항들은 거의 모든 소프트웨어 환경에서 충족됩니다만 종종 전체 쓰레드의
갯수의 상한선이 고정되는 결과가 나오곤 합니다.
더 복잡한 구현은 그런 상한선을 제거할 수 있는데, 예를 들면 확장 가능한 해시
테이블을 사용하거나 하는 형태입니다.
그런 구현은 동적으로 쓰레드들의 정보를 추적할 수 있을텐데, 예를 들면 각
쓰레드들의 정보를 \co{rcu_read_lock()} 호출 시에 추가하는 형태일 겁니다.
\iffalse

This RCU implementation imposes important new requirements on its
software environment, namely, (1) that it be possible to declare
per-thread variables, (2) that these per-thread variables be accessible
from other threads, and (3) that it is possible to enumerate all threads.
These requirements can be met in almost all software environments,
but often result in fixed upper bounds on the number of threads.
More-complex implementations might avoid such bounds, for example, by using
expandable hash tables.
Such implementations might dynamically track threads, for example, by
adding them on their first call to \co{rcu_read_lock()}.
\fi

\QuickQuiz{}
	좋아요, 우리가 $N$ 쓰레드들을 가지고 있다면 우리는 $2N$ 10 밀리세컨드의
	기다리는 호출 (\co{flip_counter_and_wait()} 당 한 세트) 을 할 수
	있을텐데, 우리가 각 쓰레드를 위해 오직 한번 기다린다고 가정해도
	그렇습니다.
	\iffalse

	grace period 는 \emph{훨씬} 더 빨리 완료되어야 하지 않을까요?
	Great, if we have $N$ threads, we can have $2N$ ten-millisecond
	waits (one set per \co{flip_counter_and_wait()} invocation,
	and even that assumes that we wait only once for each thread.
	Don't we need the grace period to complete \emph{much} more quickly?
	\fi
\QuickQuizAnswer{
	기다리는 것은 오로지 해당 쓰레드가 여전히 앞에서 시작된 RCU read-side
	크리티컬 섹션 안에 있을 때 뿐이라는 점을, 그리고 하나의 쓰레드를
	기다리는 것은 모든 다른 쓰레드들에게 여전히 수행중일 수도 있는 모든
	앞서 시작한 RCU read-side 크리티컬 섹션들을 완료할 기회를 준다는 점을
	기억하세요.
	따라서 우리가 $2N$ 간격을 기다리게 되는 경우는 모든 앞의 쓰레드들에의
	모든 기다림에도 불구하고 직전의 쓰레드가 여전히 앞서 시작된 RCU
	read-side 크리티컬 섹션 안에 있을 때 뿐입니다.
	짧게 말해서, 이 구현은 불필요하게 기다리지는 않을 겁니다.
	\iffalse

	Keep in mind that we only wait for a given thread if that thread
	is still in a pre-existing RCU read-side critical section,
	and that waiting for one hold-out thread gives all the other
	threads a chance to complete any pre-existing RCU read-side
	critical sections that they might still be executing.
	So the only way that we would wait for $2N$ intervals
	would be if the last thread still remained in a pre-existing
	RCU read-side critical section despite all the waiting for
	all the prior threads.
	In short, this implementation will not wait unnecessarily.
	\fi

	하지만, RCU 를 사용하는 코드를 스트레스 테스트 하고 있다면, 부정확하게
	RCU 로 보호되고 있는 데이터 원소로의 레퍼런스를 RCU read-side 크리티컬
	섹션 밖에서도 쥐고 있게 되는 버그를 더 잘 잡기 위해서는 \co{poll()}
	구문을 없애고 싶을 수도 있을 겁니다.
	\iffalse

	However, if you are stress-testing code that uses RCU, you
	might want to comment out the \co{poll()} statement in
	order to better catch bugs that incorrectly retain a reference
	to an RCU-protected data element outside of an RCU
	read-side critical section.
	\fi
} \QuickQuizEnd

이 구현은 여전히 일부 한계점들을 가지고 있습니다.
먼저, \co{rcu_idx} 를 두번 뒤집어야 하는 필요성은 업데이트 쪽에 상당한
오버헤드를 내포하고 있는데, 특히 많은 수의 쓰레드가 있을때 그렇습니다.

두번째로 \co{synchronize_rcu()} 는 이제 쓰레드들의 수가 늘어남에 따라
선형적으로 늘어나는 여러 변수들을 조사해야 하는데, 이는 쓰레드의 수가 많은
어플리케이션에 상당한 오버헤드가 있을 것을 암시합니다.

세번째로, 앞에서와 마찬가지로 동시의 RCU 업데이트들은 원론적으로는 공통의 grace
period 를 사용할 수 있음에도 이 구현은 grace period 들을 직렬화 시켜서 grace
period 공유를 막고 있습니다.

마지막으로, 글에서 이야기했듯, 쓰레드별 변수의 필요성과 쓰레드들을 모두 봐야
한다는 필요성은 일부 소프트웨어 환경에서는 문제가 될 수 있습니다.
\iffalse

This implementation still has several shortcomings.
First, the need to flip \co{rcu_idx} twice imposes substantial overhead
on updates, especially if there are large numbers of threads.

Second, \co{synchronize_rcu()} must now examine a number of variables
that increases linearly with the number of threads, imposing substantial
overhead on applications with large numbers of threads.

Third, as before, although concurrent RCU updates could in principle
be satisfied by a common grace period, this implementation serializes
grace periods, preventing grace-period sharing.

Finally, as noted in the text, the need for per-thread variables
and for enumerating threads may be problematic in some software
environments.
\fi

그렇다고는 하나, read-side 기능들은 매우 잘 확장되는데, 단일 CPU 에서 돌아가든
64-CPU \Power{5} 시스템에서 돌아가든 상관없이 약 115~나노세컨드를 필요로
합니다.
앞에서 이야기한 바와 같이, \co{synchronize_rcu()} 기능은 확장되지 못하는데, 그
오버헤드는 단일 \Power{5} CPU 에서의 약 1 마이크로세컨드를, 그리고 64-CPU
시스템에서는 200~마이크로세컨드를 보입니다.
이 구현은 생각건대 제품 품질의 사용자 수준 RCU 구현에 대한 토대가 될 수도 있을
것입니다.

다음 섹션에서는 더 효과적인 동시의 RCU 업데이트들을 가능하게 하는 알고리즘
하나를 설명합니다.
\iffalse

That said, the read-side primitives scale very nicely, requiring about
115~nanoseconds regardless of whether running on a single-CPU or a 64-CPU
\Power{5} system.
As noted above, the \co{synchronize_rcu()} primitive does not scale,
ranging in overhead from almost a microsecond on a single \Power{5} CPU
up to almost 200~microseconds on a 64-CPU system.
This implementation could conceivably form the basis for a
production-quality user-level RCU implementation.

The next section describes an algorithm permitting more efficient
concurrent RCU updates.
\fi

\section{Scalable Counter-Based RCU With Shared Grace Periods}
\label{sec:app:toyrcu:Scalable Counter-Based RCU With Shared Grace Periods}

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 DEFINE_SPINLOCK(rcu_gp_lock);
  2 DEFINE_PER_THREAD(int [2], rcu_refcnt);
  3 long rcu_idx;
  4 DEFINE_PER_THREAD(int, rcu_nesting);
  5 DEFINE_PER_THREAD(int, rcu_read_idx);
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data}
\end{listing}

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 static void rcu_read_lock(void)
  2 {
  3   int i;
  4   int n;
  5
  6   n = __get_thread_var(rcu_nesting);
  7   if (n == 0) {
  8     i = READ_ONCE(rcu_idx) & 0x1;
  9     __get_thread_var(rcu_read_idx) = i;
 10     __get_thread_var(rcu_refcnt)[i]++;
 11   }
 12   __get_thread_var(rcu_nesting) = n + 1;
 13   smp_mb();
 14 }
 15
 16 static void rcu_read_unlock(void)
 17 {
 18   int i;
 19   int n;
 20
 21   smp_mb();
 22   n = __get_thread_var(rcu_nesting);
 23   if (n == 1) {
 24      i = __get_thread_var(rcu_read_idx);
 25      __get_thread_var(rcu_refcnt)[i]--;
 26   }
 27   __get_thread_var(rcu_nesting) = n - 1;
 28 }
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
\label{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
\end{listing}

Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
(\path{rcu_rcpls.h})
는 기존과 같이 쓰레드별 레퍼런스 카운트 쌍을 사용하는, 하지만 업데이트들이
grace period 들을 공유할 수 있게 하는 RCU 구현을 위하 read-side 쪽의 기능들을
보입니다.
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair} 로
보인 앞의 구현과 주요한 차이점은 \co{rcu_idx} 가 이제는 자유롭게 수를 셀 수
있는 \co{long} 이어서,
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
의 line~8 은 아래쪽의 비트만을 집어내서 사용해야만 합니다.
또한 \co{atomic_read()} 와 \co{atomic_set()} 의 사용에서 \co{ACCESS_ONCE()} 로
바꿨습니다.
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data}
에 보인 것처럼, 데이터 또한 상당히 비슷한데 \co{rcu_idx} 는 \co{atomic_t} 가
아니라 \co{long} 으로 바뀌었습니다.
\iffalse

Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
(\path{rcu_rcpls.h})
shows the read-side primitives for an RCU implementation using per-thread
reference count pairs, as before, but permitting updates to share
grace periods.
The main difference from the earlier implementation shown in
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair}
is that \co{rcu_idx} is now a \co{long} that counts freely,
so that line~8 of
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
must mask off the low-order bit.
We also switched from using \co{atomic_read()} and \co{atomic_set()}
to using \co{READ_ONCE()}.
The data is also quite similar, as shown in
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update Data},
with \co{rcu_idx} now being a \co{long} instead of an
\co{atomic_t}.
\fi

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 static void flip_counter_and_wait(int ctr)
  2 {
  3   int i;
  4   int t;
  5
  6   WRITE_ONCE(rcu_idx, ctr + 1);
  7   i = ctr & 0x1;
  8   smp_mb();
  9   for_each_thread(t) {
 10     while (per_thread(rcu_refcnt, t)[i] != 0) {
 11       poll(NULL, 0, 10);
 12     }
 13   }
 14   smp_mb();
 15 }
 16
 17 void synchronize_rcu(void)
 18 {
 19   int ctr;
 20   int oldctr;
 21
 22   smp_mb();
 23   oldctr = READ_ONCE(rcu_idx);
 24   smp_mb();
 25   spin_lock(&rcu_gp_lock);
 26   ctr = READ_ONCE(rcu_idx);
 27   if (ctr - oldctr >= 3) {
 28     spin_unlock(&rcu_gp_lock);
 29     smp_mb();
 30     return;
 31   }
 32   flip_counter_and_wait(ctr);
 33   if (ctr - oldctr < 2)
 34     flip_counter_and_wait(ctr + 1);
 35   spin_unlock(&rcu_gp_lock);
 36   smp_mb();
 37 }
\end{verbbox}
}
\centering
\theverbbox
\caption{RCU Shared Update Using Per-Thread Reference-Count Pair}
\label{lst:app:toyrcu:RCU Shared Update Using Per-Thread Reference-Count Pair}
\end{listing}

Listing~\ref{lst:app:toyrcu:RCU Shared Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpls.c})
는 \co{synchronize_rcu()} 와 거기에 도움을 주는 \co{flip_counter_and_wait()}
함수를 보입니다.
이것들은
Listing~\ref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair} 에 있던
것들과 비슷합니다.
\co{flip_counter_and_wait()} 의 차이점에는 다음과 같은 것들이 있습니다:
\begin{enumerate}
\item	Line~6 는 \co{atomic_set()} 대신 \co{ACCESS_ONCE()} 를 사용하고 보정을
	하는 대신 값 증가를 시킵니다.
\item	새로운 line~7 은 카운터의 가장 아래 비트를 꺼내서 사용합니다.
\end{enumerate}
\iffalse

Listing~\ref{lst:app:toyrcu:RCU Shared Update Using Per-Thread Reference-Count Pair}
(\path{rcu_rcpls.c})
shows the implementation of \co{synchronize_rcu()} and its helper
function \co{flip_counter_and_wait()}.
These are similar to those in
Listing~\ref{lst:app:toyrcu:RCU Update Using Per-Thread Reference-Count Pair}.
The differences in \co{flip_counter_and_wait()} include:
\begin{enumerate}
\item	Line~6 uses \co{WRITE_ONCE()} instead of \co{atomic_set()},
	and increments rather than complementing.
\item	A new line~7 masks the counter down to its bottom bit.
\end{enumerate}
\fi

\co{synchronize_rcu()} 의 변경은 더 많습니다:
\begin{enumerate}
\item	락을 잡기 전의 \co{rcu_idx} 의 값을 Line~23 에서 저장해 두는, 새로운
	로컬 변수 \co{oldctr} 이 존재합니다.
\item	Line~26 에서는 \co{atomic_read()} 대신에 \co{ACCESS_ONCE()} 를
	사용합니다.
\item	Line~27-30 은 락을 잡는 동안 다른 쓰레드에 의해 카운터 뒤집기가 최소
	세번 이상 이루어졌는지를 확인해보고, 만약 그렇다면 락을 놓고 메모리
	배리어를 수행한 후 리턴합니다.
	이 경우, 카운터가 0 이 될때까지 두번의 완전한 기다림이 있었던 것이고,
	따라서 다른 쓰레드들은 이미 모든 필요한 일들을 했습니다.
\item	Line~33-34 에서, \co{flip_counter_and_wait()} 는 락이 잡히는 동안 두번
	미만의 카운터 뒤집기가 이루어졌을 때에만 \co{flip_counter_and_wait()}
	를 수행합니다.
	한편으로는, 두번의 카운터 뒤집기가 있었다면, 일부 다른 쓰레드는 모든
	카운터가 0으로 갈 때까지 완전한 기다림을 수행했으므로, 한번만 더 하면
	됩니다.
\end{enumerate}
\iffalse

The changes to \co{synchronize_rcu()} are more pervasive:
\begin{enumerate}
\item	There is a new \co{oldctr} local variable that captures
	the pre-lock-acquisition value of \co{rcu_idx} on
	line~23.
\item	Line~26 uses \co{READ_ONCE()} instead of \co{atomic_read()}.
\item	Lines~27-30 check to see if at least three counter flips were
	performed by other threads while the lock was being acquired,
	and, if so, releases the lock, does a memory barrier, and returns.
	In this case, there were two full waits for the counters to
	go to zero, so those other threads already did all the required work.
\item	At lines~33-34, \co{flip_counter_and_wait()} is only
	invoked a second time if there were fewer than two counter flips
	while the lock was being acquired.
	On the other hand, if there were two counter flips, some other
	thread did one full wait for all the counters to go to zero,
	so only one more is required.
\end{enumerate}
\fi

이 방법에서는 임의의 많은 수의 쓰레드들이 각 쓰레드별로 CPU 하나를 가지고
\co{synchronize_rcu()} 를 동시에 수행하게 되면, 카운터가 0이 되기를 총 세번만
기다리게 될 것입니다.

이 개선에도 불구하고, 이 RCU 구현은 여전히 몇가지 한계점들을 가지고 있습니다.
첫째로, 앞에서와 같이 \co{rcu_idx} 를 두번 뒤집어야 하는 필요성은 업데이트 쪽에
상당한 오버헤드를 암시하는데, 많은 수의 쓰레드들이 존재할 때 특히 그렇습니다.

둘째로, 각 업데이트 쓰레드는 여전히 \co{rcu_gp_lock} 을 잡는데, 할 일이
없을때조차도 그렇습니다.
이는 수많은 동시의 업데이트들이 존재한다면 상당한 확장성 한계점으로 작용할 수
있습니다.
리눅스 커널의 제품 품질의 RCU 리얼타임
구현~\cite{PaulEMcKenney2007PreemptibleRCU} 에서 사용 되었던 것처럼, 이 문제를
막는 방법들은 존재합니다.
\iffalse

With this approach, if an arbitrarily large number of threads invoke
\co{synchronize_rcu()} concurrently, with one CPU for each thread, there
will be a total of only three waits for counters to go to zero.

Despite the improvements, this implementation of RCU still
has a few shortcomings.
First, as before, the need to flip \co{rcu_idx} twice imposes substantial
overhead on updates, especially if there are large
numbers of threads.

Second, each updater still acquires \co{rcu_gp_lock}, even if there
is no work to be done.
This can result in a severe scalability limitation
if there are large numbers of concurrent updates.
There are ways of avoiding this, as was done in a
production-quality real-time implementation of RCU for the Linux
kernel~\cite{PaulEMcKenney2007PreemptibleRCU}.
\fi

세번째로, 이 구현은 쓰레드별 변수와 쓰레드들을 모두 돌아봐야 하는 기능을 필요로
하는데, 이는 역시 일부 소프트웨어 환경에서는 문제가 될 수 있습니다.

마지막으로, 32-bit 머신에서는 특정 업데이트 쓰레드가 \co{rcu_idx} 카운터가
오버헤드 되도록 긴 시간동안 preemption 당할 수 있습니다.
이는 그런 쓰레드가 불필요한 카운터 뒤집기를 하도록 하게 만들 수도 있습니다.
하지만, 각각의 grace period 가 1 마이크로세컨드 만을 가진다 하더라도, 문제의
쓰레드는 한시간 이상을 preemption 당할 수 있어서 추가적인 카운터 뒤집기만
걱정해도 될 가능성이 큽니다.
\iffalse

Third, this implementation requires per-thread variables
and the ability to enumerate threads, which again can be
problematic in some software environments.

Finally, on 32-bit machines, a given update thread might be
preempted long enough for the \co{rcu_idx}
counter to overflow.
This could cause such a thread to force an unnecessary
pair of counter flips.
However, even if each grace period took only one
microsecond, the offending thread would need to be
preempted for more than an hour, in which case an
extra pair of counter flips is likely the least of
your worries.
\fi

Section~\ref{sec:app:toyrcu:Simple Counter-Based RCU} 에서 설명한 구현에서와 같이, 이
read-side 기능들은 상당히 잘 확장되는데, CPU 의 수에 관계없이 대략
115~나노세컨드의 오버헤드를 갖습니다.
\co{synchronize_rcu()} 기능은 여전히 비싼 편인데, 1 마이크로세컨드에서
16~마이크로세컨드 사이의 오버헤드를 갖습니다.
이는 Section~\ref{sec:app:toyrcu:Scalable Counter-Based RCU} 의 구현에서 가졌던 대략
200~마이크로세컨드의 오버헤드에 비하면 더도 덜도 아니고 훨씬 저렴한 비용입니다.
따라서, 그 제한점들에도 불구하고, 이 RCU 구현은 실제 삶에서 접하는 활용처의
제품에서 사용될 수도 있을 거라고 생각될 수 있을 겁니다.
\iffalse

As with the implementation described in
Section~\ref{sec:app:toyrcu:Simple Counter-Based RCU},
the read-side primitives scale extremely well, incurring roughly
115~nanoseconds of overhead regardless of the number of CPUs.
The \co{synchronize_rcu()} primitive is still expensive,
ranging from about one microsecond up to about 16~microseconds.
This is nevertheless much cheaper than the roughly 200~microseconds
incurred by the implementation in
Section~\ref{sec:app:toyrcu:Scalable Counter-Based RCU}.
So, despite its shortcomings, one could imagine this
RCU implementation being used in production in real-life applications.
\fi

\QuickQuiz{}
	이 모든 장난감 RCU 구현들은 \co{rcu_read_lock()} 과
	\co{rcu_read_unlock()} 안에 어토믹 오퍼레이션들을 가지고 있거나
	쓰레드의 수에 따라 선형적으로 증가하는 \co{synchronize_rcu()} 의
	오버헤드를 갖습니다.
	어떤 환경에서라면 RCU 구현이 이 세개의 기능들이 모두 결정적인
	($O\left(1\right)$) 의 오버헤드와 대기시간을 갖는 가벼운 구현을 가질 수
	있을까요?
	\iffalse

	All of these toy RCU implementations have either atomic operations
	in \co{rcu_read_lock()} and \co{rcu_read_unlock()},
	or \co{synchronize_rcu()}
	overhead that increases linearly with the number of threads.
	Under what circumstances could an RCU implementation enjoy
	light-weight implementations for all three of these primitives,
	all having deterministic ($O\left(1\right)$) overheads and latencies?
	\fi
\QuickQuizAnswer{
	특수한 목적의 RCU 유니프로세서 구현이 이 이상적인 상황을 만들 수 있을
	겁니다~\cite{PaulEMcKenney2009BloatwatchRCU}.
	\iffalse

	Special-purpose uniprocessor implementations of RCU can attain
	this ideal~\cite{PaulEMcKenney2009BloatwatchRCU}.
	\fi
} \QuickQuizEnd

Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update}
로 돌아가서, 우리는 하나의 전역 변수 접근과 thread-local 변수들로의 네번보다
적지 않은 액세스들이 존재함을 볼 수 있습니다.
POSIX 쓰레드를 구현하는 시스템에서의 상대적으로 비싼 비용의 thread-local
액세스들을 놓고 보면, 이 세개의 thread-local 변수들을 하나의 구조체로 만들어서
\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 의 thread-local 데이터로의
접근을 하나의 thread-local-storage 로의 접근으로 바꾸고 싶을 수 있을 겁니다.
하지만, 그보다도 더 나은 접근은 다음 섹션에서 하듯이, thread-local 액세스의
수를 하나로 바꾸는 것일 겁니다.
\iffalse

Referring back to
Listing~\ref{lst:app:toyrcu:RCU Read-Side Using Per-Thread Reference-Count Pair and Shared Update},
we see that there is one global-variable access and no fewer than four
accesses to thread-local variables.
Given the relatively high cost of thread-local accesses on systems
implementing POSIX threads, it is tempting to collapse the three
thread-local variables into a single structure, permitting
\co{rcu_read_lock()} and \co{rcu_read_unlock()} to access their
thread-local data with a single thread-local-storage access.
However, an even better approach would be to reduce the number of
thread-local accesses to one, as is done in the next section.
\fi

\section{RCU Based on Free-Running Counter}
\label{sec:app:toyrcu:RCU Based on Free-Running Counter}

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 DEFINE_SPINLOCK(rcu_gp_lock);
  2 long rcu_gp_ctr = 0;
  3 DEFINE_PER_THREAD(long, rcu_reader_gp);
  4 DEFINE_PER_THREAD(long, rcu_reader_gp_snap);
\end{verbbox}
}
\centering
\theverbbox
\caption{Data for Free-Running Counter Using RCU}
\label{lst:app:toyrcu:Data for Free-Running Counter Using RCU}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu@read_lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu@synchronize.fcv}\fvset{firstnumber=auto}
\caption{Free-Running Counter Using RCU}
\label{lst:app:toyrcu:Free-Running Counter Using RCU}
\end{listing}

Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU}
(\path{rcu.h} and \path{rcu.c})
는 Listing~\ref{lst:app:toyrcu:Data for Free-Running Counter Using RCU} 에 보여진
데이터와 함께 짝수 값만을 갖는 글로벌한 자유롭게 동작하는 카운터에 기반한 RCU
구현을 보입니다.
이렇게 만들어진 \co{rcu_read_lock()} 구현은 상당히 단순합니다.
Line~3 과 4 에서는 단순히 글로벌한 자유롭게 동작하는 \co{rcu_gp_ctr} 변수에 1을
더한 값으로 만들어진 홀수를 쓰레드별 변수인 \co{rcu_reader_gp} 에 저장합니다.
Line~5 는 뒤따르는 RCU read-side 크리티컬 섹션의 내용이 ``삐져나오는 것''을
방지하기 위해 메모리 배리어를 실행합니다.
\iffalse

Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU}
(\path{rcu.h} and \path{rcu.c})
shows an RCU implementation based on a single global free-running counter
that takes on only even-numbered values, with data shown in
Listing~\ref{lst:app:toyrcu:Data for Free-Running Counter Using RCU}.
The resulting \co{rcu_read_lock()} implementation is extremely
straightforward.
\begin{lineref}[ln:defer:rcu:read_lock_unlock:lock]
Lines~\lnref{gp1} and~\lnref{gp2} simply
add one to the global free-running \co{rcu_gp_ctr}
variable and stores the resulting odd-numbered value into the
\co{rcu_reader_gp} per-thread variable.
Line~\lnref{mb} executes a memory barrier to prevent the content of the
subsequent RCU read-side critical section from ``leaking out''.
\end{lineref}
\fi

\co{rcu_read_unlock()} 구현 역시 비슷합니다.
Line~10 에서는 이번에도 앞의 RCU read-side 크리티컬 섹션이 ``삐져나오는 것'' 을
방지하기 위해 메모리 배리어를 실행합니다.
Line~11 과 12 는 \co{rcu_gp_ctr} 글로벌 변수의 값을 쓰레드별 변수인
\co{rcu_reader_gp} 에 복사해서 이 쓰레드별 변수의 값을 짝수로 만듦으로 인해
동시의 \co{synchronize_rcu()} 인스턴스가 이를 무시해도 좋을 것임을 알립니다.
\iffalse

\begin{lineref}[ln:defer:rcu:read_lock_unlock:unlock]
The \co{rcu_read_unlock()} implementation is similar.
Line~\lnref{mb} executes a memory barrier, again to prevent the prior RCU
read-side critical section from ``leaking out''.
Lines~\lnref{gp1} and~\lnref{gp2} then
copy the \co{rcu_gp_ctr} global variable to the
\co{rcu_reader_gp} per-thread variable, leaving this per-thread
variable with an even-numbered value so that a concurrent instance
of \co{synchronize_rcu()} will know to ignore it.
\fi

\QuickQuiz{}
	짝수만으로도 해당 태스크를 무시해도 좋다고 \co{synchronize_rcu()} 에
	말하기에 충분하다면
	Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU} 의 line~10 과 11
	은 왜 단순히 \co{rcu_reader_gp} 에 0을 할당하지 않나요?
	\iffalse

	\begin{lineref}[ln:defer:rcu:read_lock_unlock:unlock]
	If any even value is sufficient to tell \co{synchronize_rcu()}
	to ignore a given task, why don't lines~\lnref{gp1}
	and~\lnref{gp2} of
	Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU}
	simply assign zero to \co{rcu_reader_gp}?
	\end{lineref}
	\fi
\QuickQuizAnswer{
	0을 (또는 어떤 다른 짝수의 상수를) 할당하는 것은 실제로 동작할
	것입니다만 \co{rcu_gp_ctr} 의 값을 할당하는 것은 개발자에게 언제 연관된
	쓰레드가 마지막으로 RCU read-side 크리티컬 섹션을 끝냈는지와 같은,
	디버깅을 위한 가치 있는 도움을 제공할 수 있습니다.
	\iffalse

	Assigning zero (or any other even-numbered constant)
	would in fact work, but assigning the value of
	\co{rcu_gp_ctr} can provide a valuable debugging aid,
	as it gives the developer an idea of when the corresponding
	thread last exited an RCU read-side critical section.
	\fi
} \QuickQuizEnd

따라서, \co{synchronize_rcu()} 는 이 모든 쓰레드별 \co{rcu_reader_gp} 변수들이
짝수를 가지게 될때까지 기다릴 수도 있습니다.
하지만, 그보다 훨씬 나은 방법이 있는데 \co{synchronize_rcu()} 는 \emph{전부터
존재한} RCU read-side 크리티컬 섹션들만 기다리면 그만이기 때문입니다.
Line~19 에서는 앞의 RCU 로 보호되는 데이터 구조체의 조정이 line~21 의 값 증가
뒤로 (CPU 에 의해서든 컴파일러에 의해서든) 재배치 되는 것을 막기 위해 메모리
배리어를 실행합니다.
Line~20 에서는 여러개의 \co{synchronize_rcu()} 인스턴스들이 동시에 수행되는
것을 막기 위해 \co{rcu_gp_lock} 을 획득합니다 (그리고 line~30 에서 이를
해제합니다).
Line~21 은 글로벌 변수인 \co{rcu_gp_ctr} 의 값을 2 만큼 증가시켜서 모든 전부터
존재해온 RCU read-side 크리티컬 섹션들이 갖는 그들과 연관된 쓰레드별 변수
\co{rcu_reader_gp} 는 \co{rcu_gp_ctr} 보다 작은 값을 가지게 될 것입니다.
짝수 값의 \co{rcu_reader_gp} 를 갖는 쓰레드들은 RCU read-side 크리티컬 섹션에
들어가 있지않다는 점을 다시 상기해서, line~23-29 는 \co{rcu_reader_gp} 값들을
그 모든 것들이 짝수이거나 (line~24) 글로벌한 \co{rcu_gp_ctr} 보다 큰 동안
(line~25-26) 스캔합니다.
Line~27 에서는 앞서 존재해온 RCU read-side 크리티컬 섹션을 기다리기 위해 짧은
시간동안 블록하지만 만약 grace-period 대기시간이 중요하다면 스핀 루프로 교체될
수 있습니다.
마지막으로, line~31 에서의 메모리 배리어는 뒤따르는 모든 오브젝트 해체가 루프의
앞으로 재배치 되지 않도록 보장합니다.
\iffalse

\begin{lineref}[ln:defer:rcu:synchronize:syn]
Thus, \co{synchronize_rcu()} could wait for all of the per-thread
\co{rcu_reader_gp} variables to take on even-numbered values.
However, it is possible to do much better than that because
\co{synchronize_rcu()} need only wait on \emph{pre-existing}
RCU read-side critical sections.
Line~\lnref{mb1} executes a memory barrier to prevent prior manipulations
of RCU-protected data structures from being reordered (by either
the CPU or the compiler) to follow the increment on
line~\lnref{increasegp}.
Line~\lnref{spinlock} acquires the \co{rcu_gp_lock}
(and line~\lnref{spinunlock} releases it)
in order to prevent multiple
\co{synchronize_rcu()} instances from running concurrently.
Line~\lnref{increasegp} then increments the global \co{rcu_gp_ctr} variable by
two, so that all pre-existing RCU read-side critical sections will
have corresponding per-thread \co{rcu_reader_gp} variables with
values less than that of \co{rcu_gp_ctr}, modulo the machine's
word size.
Recall also that threads with even-numbered values of \co{rcu_reader_gp}
are not in an RCU read-side critical section,
so that lines~\lnref{scan:b}-\lnref{scan:e}
scan the \co{rcu_reader_gp} values until they
all are either even (line~\lnref{even}) or are greater than the global
\co{rcu_gp_ctr} (lines~\lnref{gt1}-\lnref{gt2}).
Line~\lnref{poll} blocks for a short period of time to wait for a
pre-existing RCU read-side critical section, but this can be replaced with
a spin-loop if grace-period latency is of the essence.
Finally, the memory barrier at line~\lnref{mb3} ensures that any subsequent
destruction will not be reordered into the preceding loop.
\end{lineref}
\fi

\QuickQuiz{}
	Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU}
	의 line~19 와 31 에서의 메모리 배리어들은 왜 필요한 건가요?
	line~20 과 30 에서의 락킹이 충분한데 메모리 배리어는 피할 수 있지
	않나요?
	\iffalse

	\begin{lineref}[ln:defer:rcu:synchronize:syn]
	Why are the memory barriers on lines~\lnref{mb1} and~\lnref{mb3} of
	Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU}
	needed?
	Aren't the memory barriers inherent in the locking
	primitives on lines~\lnref{spinlock} and~\lnref{spinunlock} sufficient?
	\end{lineref}
	\fi
\QuickQuizAnswer{
	락킹 기능들은 단지 크리티컬 섹션을 가두는 것만을 보장하기 때문에 이
	메모리 배리어들이  필요합니다.
	락킹 도구들은 다른 코드가 크리티컬 섹션 안으로 흘러들어오는 것을 막기
	위한 어떤 의무도 가지고 있지 않습니다.
	따라서 이런 종류의, 컴파일러에 의해서든 CPU 에 의해서든 행해질 수 있는
	코드의 움직임을 방지하기 위해 이 두개의 메모리 배리어들이 필요합니다.
	\iffalse

	These memory barriers are required because the locking
	primitives are only guaranteed to confine the critical
	section.
	The locking primitives are under absolutely no obligation
	to keep other code from bleeding in to the critical section.
	The pair of memory barriers are therefore requires to prevent
	this sort of code motion, whether performed by the compiler
	or by the CPU.
	\fi
} \QuickQuizEnd

이 전략은 훨씬 나은 read-side 성능을 달성할 수 있게 하는데, \Power{5} CPU 들의
숫자에 관계 없이 대략 63~나노세컨드의 오버헤드를 갖습니다.
업데이트는 더 많은 오버헤드를 갖는데, 하나의 \Power{5} CPU 에서
500~나노세컨드로부터 64 개의 CPU 에서 100~\emph{마이크로세컨드} 까지 갖습니다.
\iffalse

This approach achieves much better read-side performance, incurring
roughly 63~nanoseconds of overhead regardless of the number of
\Power{5} CPUs.
Updates incur more overhead, ranging from about 500~nanoseconds on
a single \Power{5} CPU to more than 100~\emph{microseconds} on 64
such CPUs.
\fi

\QuickQuiz{}
	Section~\ref{sec:app:toyrcu:Scalable Counter-Based RCU With Shared Grace Periods}
	에서 설명한 update-side batching 이
	Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU} 에 보인 구현에
	적용될 수도 있지 않을까요?
	\iffalse

	Couldn't the update-side batching optimization described in
	Section~\ref{sec:app:toyrcu:Scalable Counter-Based RCU With Shared Grace Periods}
	be applied to the implementation shown in
	Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU}?
	\fi
\QuickQuizAnswer{
	실제로, 약간의 수정과 함께라면 그럴 수 있습니다.
	이 작업은 독자의 연습문제로 남겨두겠습니다.
	\iffalse

	Indeed it could, with a few modifications.
	This work is left as an exercise for the reader.
	\fi
} \QuickQuizEnd

이 구현은 앞서 언급한 많은 update-side 오버헤드 외에도 몇가지 심각한 한계점들로
인해 문제가 될 수 있습니다.
먼저, 더이상 중첩된 RCU read-side 크리티컬 섹션들이 불가능한데, 이에 대해선
다음 섹션에서 다루도록 합니다.
둘째로, 읽기 쓰레드가 \co{rcu_gp_ctr} 에서 값을 읽어왔지만 \co{rcu_reader_gp}
에 값을 저장하기 전에 Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU} 의
line~3 에서 preemption 당하고 \co{rcu_gp_ctr} 카운터가 가질 수 있는 값들보다는
적게, 하지만 그 절반보다는 많게 값 증가를 반복한다면, \co{synchronize_rcu()} 는
이 뒤의 RCU read-side 크리티컬 섹션을 무시하게 될겁니다.
마지막으로, 이 구현은 쓰레드별 변수들을 유지할 수 있고 모든 쓰레드들을 검사할
수 있는 소프트웨어 환경에 들어가 있을 것을 필요로 합니다.
\iffalse

\begin{lineref}[ln:defer:rcu:read_lock_unlock:lock]
This implementation suffers from some serious shortcomings in
addition to the high update-side overhead noted earlier.
First, it is no longer permissible to nest RCU read-side critical
sections, a topic that is taken up in the next section.
Second, if a reader is preempted at line~\lnref{gp1} of
Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU} after fetching from
\co{rcu_gp_ctr} but before storing to \co{rcu_reader_gp},
and if the \co{rcu_gp_ctr} counter then runs through more than half
but less than all of its possible values, then \co{synchronize_rcu()}
will ignore the subsequent RCU read-side critical section.
Third and finally, this implementation requires that the enclosing software
environment be able to enumerate threads and maintain per-thread
variables.
\end{lineref}
\fi

\QuickQuiz{}
	Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU} 의 line~3-4 에서
	읽기 쓰레드들이 preemption 당할 수 있다는 사실은 진짜 문제일까요? 달리
	말하자면, 정말 실패를 만들 수 있는 실제의 이벤트들이 존재하나요?
	그렇지 않다면, 왜죠?
	그렇다면, 그 이벤트들은 어떤 것이고, 그 실패는 어떻게 해결될 수
	있을까요?
	\iffalse

	\begin{lineref}[ln:defer:rcu:read_lock_unlock:lock]
	Is the possibility of readers being preempted in
	lines~\lnref{gp1}-\lnref{gp2} of
	Listing~\ref{lst:app:toyrcu:Free-Running Counter Using RCU}
	a real problem, in other words, is there a real sequence
	of events that could lead to failure?
	If not, why not?
	If so, what is the sequence of events, and how can the
	failure be addressed?
	\end{lineref}
	\fi
\QuickQuizAnswer{
	진짜 문제입니다, 그리고 실패를 이끌어내는 일련의 이벤트들이 존재하며,
	이를 해결하기 위한 방법들이 여럿 있습니다.
	더 자세한 내용을 위해서는
	Section~\ref{sec:app:toyrcu:Nestable RCU Based on Free-Running Counter} 의
	끝부분의 Quick Quizz 들을 참고하세요.
	이에 대한 토론을 거기에 두는 이유는 (1) 당신에게 생각할 시간을 더 주고,
	(2) 그 섹션에서 추가되는 중첩 지원은 카운터를 오버플로우 시키는데
	걸리는 시간을 훨씬 줄여주기 때문입니다.
	\iffalse

	It is a real problem, there is a sequence of events leading to
	failure, and there are a number of possible ways of
	addressing it.
	For more details, see the Quick Quizzes near the end of
	Section~\ref{sec:app:toyrcu:Nestable RCU Based on Free-Running Counter}.
	The reason for locating the discussion there is to (1) give you
	more time to think about it, and (2) because the nesting support
	added in that section greatly reduces the time required to
	overflow the counter.
	\fi
} \QuickQuizEnd

\section{Nestable RCU Based on Free-Running Counter}
\label{sec:app:toyrcu:Nestable RCU Based on Free-Running Counter}

\begin{listing}[tb]
{ \scriptsize
\begin{verbbox}
  1 DEFINE_SPINLOCK(rcu_gp_lock);
  2 #define RCU_GP_CTR_SHIFT 7
  3 #define RCU_GP_CTR_BOTTOM_BIT (1 << RCU_GP_CTR_SHIFT)
  4 #define RCU_GP_CTR_NEST_MASK (RCU_GP_CTR_BOTTOM_BIT - 1)
  5 long rcu_gp_ctr = 0;
  6 DEFINE_PER_THREAD(long, rcu_reader_gp);
\end{verbbox}
}
\centering
\theverbbox
\caption{Data for Nestable RCU Using a Free-Running Counter}
\label{lst:app:toyrcu:Data for Nestable RCU Using a Free-Running Counter}
\end{listing}

\begin{listing}[tb]
\input{CodeSamples/defer/rcu_nest@read_lock_unlock.fcv}\vspace*{-11pt}\fvset{firstnumber=last}
\input{CodeSamples/defer/rcu_nest@synchronize.fcv}\fvset{firstnumber=auto}
\caption{Nestable RCU Using a Free-Running Counter}
\label{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
\end{listing}

Listing~\ref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
(\path{rcu_nest.h} and \path{rcu_nest.c})
는 하나의 글로벌한 자유롭게 동작하는 카운터에 기반하지만 RCU read-side 크리티컬
섹션들의 중첩을 허용하는 RCU 구현을 보입니다.
이 중첩 가능성은
Listing~\ref{lst:app:toyrcu:Data for Nestable RCU Using a Free-Running Counter} 에
보인 정의들을 사용해서 글로벌한 \co{rcu_gp_ctr} 의 아래쪽 비트들을 중첩을
세는데 사용하도록 전용화 함으로써 이루어집니다.
이는
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter} 에서 보인, 아래쪽의
하나의 비트를 중첩 단계를 세는데에 사용한 것으로 생각될 수 있는 방법의 일반화된
방법입니다.
이를 위해 두개의 C 프리프로세서 매크로인 \co{RCU_GP_CTR_NEST_MASK} 와
\co{RCU_GP_CTR_BOTTOM_BIT} 이 사용됩니다.
이 매크로들은 연관되어 있습니다:
\co{RCU_GP_CTR_NEST_MASK=RCU_GP_CTR_BOTTOM_BIT-1}.
\co{RCU_GP_CTR_BOTTOM_BIT} 매크로는 중첩 단계를 세기 위해 전용화된 비트들의
바로 앞에 자리잡은 하나의 비트를 가지고 있으며, \co{RCU_GP_CTR_NEST_MASK} 는
\co{rcu_gp_ctr} 에서 중첩 단계를 세기 위해 사용되는 지역에 모두 1 비트를 채워
가지고 있습니다.
분명하게, 두개의 C 프리프로세서 매크로들은 요구되는 최대의 RCU read-side
크리티컬 섹션들의 중첩을 허용하기 충분한 만큼의 카운터의 아래쪽 비트들을 가지고
있어야 하고, 이 구현은 대부분의 어플리케이션들에서는 충분할 만한 크기인 최대
127 단계의 RCU read-side 크리티컬 섹션 중첩을 위해 일곱개의 비트를 준비해 두고
있습니다.
\iffalse

Listing~\ref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
(\path{rcu_nest.h} and \path{rcu_nest.c})
shows an RCU implementation based on a single global free-running counter,
but that permits nesting of RCU read-side critical sections.
This nestability is accomplished by reserving the low-order bits of the
global \co{rcu_gp_ctr} to count nesting, using the definitions shown in
Listing~\ref{lst:app:toyrcu:Data for Nestable RCU Using a Free-Running Counter}.
This is a generalization of the scheme in
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter},
which can be thought of as having a single low-order bit reserved
for counting nesting depth.
Two C-preprocessor macros are used to arrange this,
\co{RCU_GP_CTR_NEST_MASK} and
\co{RCU_GP_CTR_BOTTOM_BIT}.
These are related: \co{RCU_GP_CTR_NEST_MASK=RCU_GP_CTR_BOTTOM_BIT-1}.
The \co{RCU_GP_CTR_BOTTOM_BIT} macro contains a single bit that is
positioned just above the bits reserved for counting nesting,
and the \co{RCU_GP_CTR_NEST_MASK} has all one bits covering the
region of \co{rcu_gp_ctr} used to count nesting.
Obviously, these two C-preprocessor macros must reserve enough
of the low-order bits of the counter to permit the maximum required
nesting of RCU read-side critical sections, and this implementation
reserves seven bits, for a maximum RCU read-side critical-section
nesting depth of 127, which should be well in excess of that needed
by most applications.
\fi

그렇게 해서 만들어진 \co{rcu_read_lock()} 구현은 여전히 합리적인 수준으로
간단합니다.
Line~6 에서는 이 쓰레드의 \co{rcu_reader_gp} 인스턴스로의 포인터를 지역 변수인
\co{rrgp} 로 가져와서 비싼 pthreads thread-local-state API 의 호출 횟수를
최소화 합니다.
Line~7 에서는 \co{rcu_reader_gp} 의 현재 값을 또다른 지역 변수인 \co{tmp} 에
기록하고, line~8 에서 그 아래쪽 비트들이 0인지 확인하는데, 이는 이 쓰레드가
가장 바깥의 \co{rcu_read_lock()} 을 수행중인지 확인하게 됩니다.
만약 그렇다면, line~9 에서는 line~7 에서 앞서 가져왔던 현재의 값은 더이상
유효하지 않을 수 있으므로 글로벌 변수인 \co{rcu_gp_ctr} 를 \co{tmp} 에
넣습니다.
어떤 경우든, line~10 에서는 중첩 단계를 증가시키는데, 이는 카운터의 아래쪽
7개의 비트들에 저장됩니다.
Line~11 에서는 업데이트된 카운터를 이 쓰레드의 \co{rcu_reader_gp} 인스턴스에
업데이트하고, 마지막으로 line~12 에서는 RCU read-side 크리티컬 섹션이 앞의
\co{rcu_read_lock()} 안으로 삐져나오지 않도록 메모리 배리어를 실행합니다.
\iffalse

\begin{lineref}[ln:defer:rcu_nest:read_lock_unlock:lock]
The resulting \co{rcu_read_lock()} implementation is still reasonably
straightforward.
Line~\lnref{readgp} places a pointer to
this thread's instance of \co{rcu_reader_gp}
into the local variable \co{rrgp}, minimizing the number of expensive
calls to the pthreads thread-local-state API.
Line~\lnref{wtmp1} records the current value of \co{rcu_reader_gp}
into another local variable \co{tmp}, and line~\lnref{checktmp} checks
to see if the low-order bits are zero, which would indicate that
this is the outermost \co{rcu_read_lock()}.
If so, line~\lnref{wtmp2} places the global \co{rcu_gp_ctr}
into \co{tmp} because the current value previously fetched by
line~\lnref{wtmp1} is likely to be obsolete.
In either case, line~\lnref{inctmp} increments the nesting depth,
which you will recall is stored in the seven low-order bits of the counter.
Line~\lnref{writegp} stores the updated counter back into this thread's
instance of \co{rcu_reader_gp}, and,
finally, line~\lnref{mb1} executes a memory barrier
to prevent the RCU read-side critical section from bleeding out
into the code preceding the call to \co{rcu_read_lock()}.
\end{lineref}
\fi

달리 말하면, 이 \co{rcu_read_lock()} 구현은 현재의 \co{rcu_read_lock()} 의
실행이 RCU read-side 크리티컬 섹션 안에서 중첩되어 있지 않다면 글로벌 변수
\co{rcu_gp_ctr} 의 복사본을 가져오고, 그렇지 않다면 현재 쓰레드의
\co{rcu_reader_gp} 의 값을 가져옵니다.
어떤 경우든, 추가적인 중첩 단계를 기록하기 위해 뭐가 가져와졌든 가져온 값을
증가시키고 그 결과를 현재 쓰레드의 \co{rcu_reader_gp} 인스턴스에 저장합니다.
\iffalse

In other words, this implementation of \co{rcu_read_lock()} picks up a copy
of the global \co{rcu_gp_ctr} unless the current invocation of
\co{rcu_read_lock()} is nested within an RCU read-side critical section,
in which case it instead fetches the contents of the current thread's
instance of \co{rcu_reader_gp}.
Either way, it increments whatever value it fetched in order to record
an additional nesting level, and stores the result in the current
thread's instance of \co{rcu_reader_gp}.
\fi

흥미롭게도, 이 \co{rcu_read_lock()} 의 차이점에도 불구하고,
\co{rcu_read_unlock()} 의 구현은
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter} 에 보인 것과 상당히
유사합니다.
Line~19 에서는 RCU read-side 크리티컬 섹션이 뒤따르는 \co{rcu_read_unlock()}
으로 삐져나오는 걸 막기 위해 메모리 배리어를 실행하고, line~20 에서 이 쓰레드의
\co{rcu_reader_gp} 의 인스턴스를 값 감소시키는데, 이는 \co{rcu_reader_gp} 의
아래쪽 비트들에 저장되어 있는 중첩 단계 카운트를 감소시키는 효과를 갖습니다.
이 기능의 디버깅 버전은 (값을 감소시키기 전에!) 이 아래쪽 비트들이 0이 아닌지
검사할 수도 있을 겁니다.
\iffalse

\begin{lineref}[ln:defer:rcu_nest:read_lock_unlock:unlock]
Interestingly enough, despite their \co{rcu_read_lock()} differences,
the implementation of \co{rcu_read_unlock()}
is broadly similar to that shown in
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter}.
Line~\lnref{mb1} executes a memory barrier
in order to prevent the RCU read-side
critical section from bleeding out into code following the call
to \co{rcu_read_unlock()}, and
line~\lnref{decgp} decrements this thread's instance of \co{rcu_reader_gp},
which has the effect of decrementing the nesting count contained in
\co{rcu_reader_gp}'s low-order bits.
Debugging versions of this primitive would check (before decrementing!)
that these low-order bits were non-zero.
\end{lineref}
\fi

\co{synchronize_rcu()} 의 구현은
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter} 에 보인 것과 상당히
유사합니다.
그 사이엔 두가지 차이가 있습니다.
첫번째는 line~29 와 30 에서 상수 ``2'' 가 아니라 \co{RCU_GP_CTR_BOTTOM_BIT} 을
\co{rcu_gp_ctr} 에 더한다는 것이고, 두번째는 line~33 에서의 비교가 조건에
관계없이 아래쪽 비트를 검사하는게 아니라 \co{RCU_GP_CTR_BOTTOM_BIT} 을 검사하는
별도의 함수로 추상화 되었다는 점입니다.
\iffalse

\begin{lineref}[ln:defer:rcu_nest:synchronize:syn]
The implementation of \co{synchronize_rcu()} is quite similar to
that shown in
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter}.
There are two differences.
The first is that lines~\lnref{incgp1} and~\lnref{incgp2}
adds \co{RCU_GP_CTR_BOTTOM_BIT} to the global \co{rcu_gp_ctr}
instead of adding the constant ``2'',
and the second is that the comparison on line~\lnref{ongoing}
has been abstracted out to a separate function,
where it checks the bit indicated by \co{RCU_GP_CTR_BOTTOM_BIT}
instead of unconditionally checking the low-order bit.
\end{lineref}
\fi

이 방법은
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter} 에 보인 것과 거의 유사한
read-side 성능을 달성하는데, \Power{5} CPU 의 수와 관계 없이 대략 65~나노세컨드의
오버헤드를 보입니다.
업데이트는 이번에도 더 많은 오버헤드를 갖는데, 하나의 \Power{5} CPU 에서 약
600~나노세컨드부터 64 CPU 에서 약 100~\emph{마이크로세컨드} 를 갖습니다.
\iffalse

This approach achieves read-side performance almost equal to that
shown in
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter}, incurring
roughly 65~nanoseconds of overhead regardless of the number of
\Power{5} CPUs.
Updates again incur more overhead, ranging from about 600~nanoseconds on
a single \Power{5} CPU to more than 100~\emph{microseconds} on 64
such CPUs.
\fi

\QuickQuiz{}
	이 복잡한 비트 조정을 하는 대신에 앞의 섹션에서 그랬듯이 별도의
	쓰레드별 중첩 수준 변수를 갖지 않는 건가요?
	\iffalse

	Why not simply maintain a separate per-thread nesting-level
	variable, as was done in previous section, rather than having
	all this complicated bit manipulation?
	\fi
\QuickQuizAnswer{
	별도의 쓰레드별 변수의 분명한 단순성은 주의를 돌리는 것일 뿐입니다.
	이 방법은 조심스럽게 오퍼레이션들을 순서맞추는 데에서 훨씬 큰 복잡도를
	만들어내는데, 특히 시그널 핸들러들이 RCU read-side 크리티컬 섹션들을
	가질 수 있게 허용되는 경우에서 특히 그렇습니다.
	하지만 그냥 제 말에서 멈추지 말고, 코딩을 직접 해보시고 그렇게 해서
	뭐가 나오는지 한번 보시기 바랍니다!
	\iffalse

	The apparent simplicity of the separate per-thread variable
	is a red herring.
	This approach incurs much greater complexity in the guise
	of careful ordering of operations, especially if signal
	handlers are to be permitted to contain RCU read-side
	critical sections.
	But don't take my word for it, code it up and see what you
	end up with!
	\fi
} \QuickQuizEnd

이 구현은 RCU read-side 크리티컬 섹션들의 중첩이 이제는 가능하다는 점을
제외하고는
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter} 에서의 것과 동일한
한계점들로 문제가 될 수 있습니다.
또한, 32 비트 시스템에서라면, 이 전략은 global \co{rcu_gp_ctr} 변수를
오버플로우 시키는데 필요한 시간을 더 줄여버릴 수 있습니다.
다음 섹션은 오버플로우가 일어나는데 필요한 시간을 훨씬 증가시키면서도 read-side
오버헤드는 훨씬 줄이는 한가지 방법을 보입니다.
\iffalse

This implementation suffers from the same shortcomings as does that of
Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter}, except that
nesting of RCU read-side critical sections is now permitted.
In addition, on 32-bit systems, this approach shortens the time
required to overflow the global \co{rcu_gp_ctr} variable.
The following section shows one way to greatly increase the time
required for overflow to occur, while greatly reducing read-side
overhead.
\fi

\QuickQuiz{}
	Listing~\ref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter} 에
	보여진 알고리즘에서, 어떻게 하면 전역 변수인 \co{rcu_gp_ctr} 가
	오버플로우 되는데 걸리는 시간을 두배로 늘릴 수 있을까요?
	\iffalse

	Given the algorithm shown in
	Listing~\ref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter},
	how could you double the time required to overflow the global
	\co{rcu_gp_ctr}?
	\fi
\QuickQuizAnswer{
	한가지 방법은 line~33 과 34 에서의 비교의 규모를 쓰레드별
	\co{rcu_reader_gp} 변수와 \co{rcu_gp_ctr+RCU_GP_CTR_BOTTOM_BIT} 사이의
	동일 여부 검사로 바꾸는 게 될겁니다.
	\iffalse

	\begin{lineref}[ln:defer:rcu_nest:synchronize:syn]
	One way would be to replace the magnitude comparison on
	lines~\lnref{lt1} and \lnref{lt2} with an inequality check of
	the per-thread \co{rcu_reader_gp} variable against
	\co{rcu_gp_ctr+RCU_GP_CTR_BOTTOM_BIT}.
	\end{lineref}
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	다시, Listing~\ref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter}
	에 보여진 알고리즘에서, 카운터 오버플로우는 치명적인가요?
	그 이유는 무엇이죠?
	만약 치명적이라면, 그걸 고치기 위해 뭘 할 수 있을까요?
	\iffalse

	Again, given the algorithm shown in
	Listing~\ref{lst:app:toyrcu:Nestable RCU Using a Free-Running Counter},
	is counter overflow fatal?
	Why or why not?
	If it is fatal, what can be done to fix it?
	\fi
\QuickQuizAnswer{
	실제로 치명적일 수 있습니다.
	이를 보기 위해, 다음의 일련의 이벤트들을 생각해 봅시다:
	\iffalse

	It can indeed be fatal.
	To see this, consider the following sequence of events:
	\fi
	\begin{enumerate}
	\item	Thread~0 가 \co{rcu_read_lock()} 에 들어와 아직 중첩되지 않은
		상태임을 확인하고 글로벌 변수 \co{rcu_gp_ctr} 의 값을
		가져옵니다.
		Thread~0 는 그러고나서 (자신의 쓰레드별 변수 \co{rcu_reader_gp}
		에 값을 저장하기 전에) 상당히 긴 시간동안 preemption 당합니다.
	\item	다른 쓰레드들이 반복적으로 \co{synchronize_rcu()} 를 호출해서
		\co{rcu_gp_ctr} 의 새로운 값이 Thread~0 가 가져왔을 때의 값보다
		\co{RCU_GP_CTR_BOTTOM_BIT} 적은 값이 됩니다.
	\item	Thread~0 는 이제 다시 수행을 시작하고, 자신의 쓰레드별 변수인
		\co{rcu_reader_gp} 에 값을 저장합니다.
		이 값은 전역변수인 \co{rcu_gp_ctr} 의 현재 값보다
		\co{RCU_GP_CTR_BOTTOM_BIT + 1} 만큼 큽니다.
	\iffalse

	\item	Thread~0 enters \co{rcu_read_lock()}, determines
		that it is not nested, and therefore fetches the
		value of the global \co{rcu_gp_ctr}.
		Thread~0 is then preempted for an extremely long time
		(before storing to its per-thread \co{rcu_reader_gp}
		variable).
	\item	Other threads repeatedly invoke \co{synchronize_rcu()},
		so that the new value of the global \co{rcu_gp_ctr}
		is now \co{RCU_GP_CTR_BOTTOM_BIT}
		less than it was when thread~0 fetched it.
	\item	Thread~0 now starts running again, and stores into
		its per-thread \co{rcu_reader_gp} variable.
		The value it stores is
		\co{RCU_GP_CTR_BOTTOM_BIT+1}
		greater than that of the global \co{rcu_gp_ctr}.
	\fi
	\item	Thread~0 가 RCU 로 보호되는 데이터 원소~A 로의 레퍼런스를
		얻습니다.
	\item	Thread~1 이 이제 thread~0 가 방금 레퍼런스를 얻어간 원소~A 를
		제거합니다.
	\item	Thread~1 이 \co{synchronize_rcu()} 를 호출해서 글로벌 변수
		\co{rcu_gp_ctr} 의 값을 \co{RCU_GP_CTR_BOTTOM_BIT} 만큼
		증가시킵니다.
		그리고는 모든 쓰레드별 \co{rcu_reader_gp} 변수의 값을
		검사하지만, thread~0 의 값은 (부정확하게도) 자신이 thread~1 의
		\co{synchronize_rcu()} 호출 뒤에 시작되었다고 알려서 thread~1
		은 thread~0 가 RCU read-side 크리티컬 섹션을 완료하기를
		기다리지 않게 됩니다.
	\item	Thread~1 은 thread~0 가 여전히 레퍼런스를 가지고 있는 데이터
		원소~A 를 메모리 해제시켜버리게 됩니다.
	\iffalse

	\item	Thread~0 acquires a reference to RCU-protected data
		element~A.
	\item	Thread~1 now removes the data element~A that thread~0
		just acquired a reference to.
	\item	Thread~1 invokes \co{synchronize_rcu()}, which
		increments the global \co{rcu_gp_ctr} by
		\co{RCU_GP_CTR_BOTTOM_BIT}.
		It then checks all of the per-thread \co{rcu_reader_gp}
		variables, but thread~0's value (incorrectly) indicates
		that it started after thread~1's call to
		\co{synchronize_rcu()}, so thread~1 does not wait
		for thread~0 to complete its RCU read-side critical
		section.
	\item	Thread~1 then frees up data element~A, which thread~0
		is still referencing.
	\fi
	\end{enumerate}

	이 시나리오는
	Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter} 에서 보인
	구현에서도 역시 일어날 수 있음에 주의하세요.

	이 문제를 고치는 한가지 방법은 64-bit 카운터를 사용해서 오버플로우에
	필요한 시간이 컴퓨터 시스템의 일반적인 수행시간을 넘어서도록 하는
	것입니다.
	x86 CPU 계열의 최신 CPU 들은 64-bit 카운터들을 \co{cmpxchg64b}
	인스트럭션을 통해 어토믹하게 조정할 수 있게 함을 알아두세요.
	\iffalse

	Note that scenario can also occur in the implementation presented in
	Section~\ref{sec:app:toyrcu:RCU Based on Free-Running Counter}.

	One strategy for fixing this problem is to use 64-bit
	counters so that the time required to overflow them would exceed
	the useful lifetime of the computer system.
	Note that non-antique members of the 32-bit x86 CPU family
	allow atomic manipulation of 64-bit counters via the
	\co{cmpxchg64b} instruction.
	\fi

	또다른 방법은 비슷한 효과를 얻기 위해 grace period 가 일어나도록
	허용되는 비율에 제한을 두는 것입니다.
	예를 들어, \co{synchronize_rcu()} 는 자신이 호출된 마지막 시간을 기록해
	두고, 그 뒤의 모든 수행은 이 시간을 체크하고 원하는 간격을 유지하는데
	필요한 만큼 블록될 수 있을 겁니다.
	예를 들어, 카운터의 아랫쪽 네개의 비트들이 중첩을 위해 전용화 되어
	있다면, 그리고 grace period 는 초당 열번까지 일어나는 것이 허용되어
	있다면, 이 카운터가 오버플로우 되는데에는 300일 이상이 걸릴 겁니다.
	하지만, 이 방법은 이 시스템이 CPU 에 성능이 제한되는 높은 우선순위의
	리얼타임 쓰레드를 300일 이상 돌리게 될 가능성이 있는 경우에는 도움이
	되지 않습니다.
	(아마도 희박한 가능성이지만 먼저 고려해 보는게 최선입니다.)
	\iffalse

	Another strategy is to limit the rate at which grace periods are
	permitted to occur in order to achieve a similar effect.
	For example, \co{synchronize_rcu()} could record the last time
	that it was invoked, and any subsequent invocation would then
	check this time and block as needed to force the desired
	spacing.
	For example, if the low-order four bits of the counter were
	reserved for nesting, and if grace periods were permitted to
	occur at most ten times per second, then it would take more
	than 300 days for the counter to overflow.
	However, this approach is not helpful if there is any possibility
	that the system will be fully loaded with CPU-bound high-priority
	real-time threads for the full 300 days.
	(A remote possibility, perhaps, but best to consider it ahead
	of time.)
	\fi

	세번째 방법은 이 경우에는 시스템에서 리얼타임 쓰레드를 사용할 수 없도록
	관리하는 것입니다.
	이 경우, preemption 당한 프로세스는 우선순위를 높여갈 것이고, 따라서
	카운터가 오버플로우 날 기회를 얻기 전까지의 수행을 길게 할 것입니다.
	물론, 이 전략은 리얼 타임 어플리케이션들에는 별로 도움이 되지 않습니다.

	마지막 방법은 \co{rcu_read_lock()} 이 전역 변수 \co{rcu_gp_ctr} 의 값을
	자신의 쓰레드별 변수 \co{rcu_reader_gp} 마운터에 저장한 후에 다시
	검사해서 전역 변수 \co{rcu_gp_ctr} 의 새로운 값이 적절하지 않다면 다시
	일을 시도하는 것입니다.
	이 방법은 동작하지만, \co{rcu_read_lock()} 에 예측 불가한 실행 시간을
	가져오게 됩니다.
	달리 말하며, 당신의 어플리케이션이 카운터가 오버플로우 나기에 충분한
	시간만큼 preemption 당하면, 당신은 예측 가능한 실행 시간을 기대할 수
	없을 겁니다!
	\iffalse

	A third approach is to administratively abolish real-time threads
	from the system in question.
	In this case, the preempted process will age up in priority,
	thus getting to run long before the counter had a chance to
	overflow.
	Of course, this approach is less than helpful for real-time
	applications.

	A final approach would be for \co{rcu_read_lock()} to recheck
	the value of the global \co{rcu_gp_ctr} after storing to its
	per-thread \co{rcu_reader_gp} counter, retrying if the new
	value of the global \co{rcu_gp_ctr} is inappropriate.
	This works, but introduces non-deterministic execution time
	into \co{rcu_read_lock()}.
	On the other hand, if your application is being preempted long
	enough for the counter to overflow, you have no hope of
	deterministic execution time in any case!
	\fi

	% @@@ A fourth approach is rcu_nest32.[hc].
} \QuickQuizEnd

\section{RCU Based on Quiescent States}
\label{sec:app:toyrcu:RCU Based on Quiescent States}

\begin{listing}[tbp]
{ \scriptsize
\begin{verbbox}
  1 DEFINE_SPINLOCK(rcu_gp_lock);
  2 long rcu_gp_ctr = 0;
  3 DEFINE_PER_THREAD(long, rcu_reader_qs_gp);
\end{verbbox}
}
\centering
\theverbbox
\caption{Data for Quiescent-State-Based RCU}
\label{lst:app:toyrcu:Data for Quiescent-State-Based RCU}
\end{listing}

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_qs@read_lock_unlock.fcv}
\caption{Quiescent-State-Based RCU Read Side}
\label{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
\end{listing}

\begin{lineref}[ln:defer:rcu_qs:read_lock_unlock]
Listing~\ref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
(\path{rcu_qs.h})
는 조용한 상태에 기반한 사용자 레벨 RCU 구현을 만드는데에
Listing~\ref{lst:app:toyrcu:Data for Quiescent-State-Based RCU} 에 보인 데이터와 함께
사용되는 read-side 기능들을 보입니다.
그림의 line~1-7 에서 볼 수 있듯이, \co{rcu_read_lock()} 과
\co{rcu_read_unlock()} 기능들은 아무일도 하지 않고, 따라서 인라인 함수로 바뀌고
최적화 단계에서 아예 사라져서 버릴 거라 예상할 수 있고, 리눅스 커널의 서버
빌드에서는 그렇습니다.
이는 조용한-상태-기반의 RCU 구현들은 RCU read-side 크리티컬 섹션들의 양을 앞서
언급한 조용한 상태들을 사용해서 \emph{어림잡는다는} 사실 때문입니다.
이러한 각각의 조용한 상태들은 \co{rcu_quiescent_state()} 호출을 포함하는데, 이
함수는 이 그림의 line~9-15 에 보여져 있습니다.
확장된 조용한 상태에 들어가는 쓰레드는 (예를 들어, 블록되었을 때) 대신
\co{rcu_thread_offline()} (line~17-23) 을 호출하고 그로부터 빠져나올 때에는
\co{rcu_thread_online()} (line~25-28) 을 호출할 수 있습니다.
그런 식으로, \co{rcu_quiescent_state()} 는 \co{rcu_read_lock()} 과 유사하고
\co{rcu_thread_offline()} 은 \co{rcu_read_unlock()} 과 유사합니다.
또한, \co{rcu_quiscent_state()} 는 \co{rcu_thread_online()} 뒤에 곧바로
\co{rcu_thread_offline()} 이 이어지는 것으로 생각될 수 있습니다.\footnote{
	비록 이 그림의 코드가 \co{rcu_quiescent_state()} 가
	\co{rcu_thread_online()} 뒤에 곧바로 \co{rcu_thread_offline()} 이
	따라오는 것과 같지만, 이 관계는 성능 최적화로 인해 불투명해집니다.}
RCU read-side 크리티컬 섹션 내에서 \co{rcu_quiescent_state()},
\co{rcu_thread_offline()}, 또는 \co{rcu_thrad_online()} 을 호출하는 건 금지된
행위입니다.
\iffalse

Listing~\ref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
(\path{rcu_qs.h})
shows the read-side primitives used to construct a user-level
implementation of RCU based on quiescent states, with the data shown in
Listing~\ref{lst:app:toyrcu:Data for Quiescent-State-Based RCU}.
As can be seen from lines~\lnref{lock:b}-\lnref{unlock:e} in the listing,
the \co{rcu_read_lock()}
and \co{rcu_read_unlock()} primitives do nothing, and can in fact
be expected to be inlined and optimized away, as they are in
server builds of the Linux kernel.
This is due to the fact that quiescent-state-based RCU implementations
\emph{approximate} the extents of RCU read-side critical sections
using the aforementioned quiescent states.
Each of these quiescent states contains a call to
\co{rcu_quiescent_state()}, which is shown from
lines~\lnref{qs:b}-\lnref{qs:e} in the listing.
Threads entering extended quiescent states (for example, when blocking)
may instead call \co{rcu_thread_offline()}
(lines~\lnref{offline:b}-\lnref{offline:e}) when entering
an extended quiescent state and then call
\co{rcu_thread_online()}
(lines~\lnref{online:b}-\lnref{online:e}) when leaving it.
As such, \co{rcu_thread_online()} is analogous to \co{rcu_read_lock()}
and \co{rcu_thread_offline()} is analogous to \co{rcu_read_unlock()}.
In addition, \co{rcu_quiescent_state()} can be thought of as a
\co{rcu_thread_online()} immediately followed by a
\co{rcu_thread_offline()}.\footnote{
	Although the code in the listing is consistent with
	\co{rcu_quiescent_state()}
	being the same as \co{rcu_thread_online()} immediately followed by
	\co{rcu_thread_offline()}, this relationship is obscured by
	performance optimizations.}
It is illegal to invoke \co{rcu_quiescent_state()}, \co{rcu_thread_offline()},
or \co{rcu_thread_online()} from an RCU read-side critical section.
\end{lineref}
\fi

\co{rcu_quiescent_state()} 에서, line~11 에서는 이 quiescent state (조용한
상태) 앞의 (RCU read-side 크리티컬 섹션들을 포함해서) 어떤 코드가 quiescent
state 앞으로 재배치 되는 것을 막기 위해 메모리 배리어를 칩니다.
Line~12-13 에서는 글로벌 변수 \co{rcu_gp_ctr} 의 복사본을 가져오는데,
\co{rcu_gp_ctr} 가 두번 이상 가져와지는 최적화가 만들어지거나 하지 않게
\co{ACCESS_ONCE()} 를 사용합니다. 그리고 나서 가져온 값에 1을 더하고 쓰레드별
변수인 \co{rcu_reader_qs_gp} 에 저장해서 모든 동시에 수행되는
\co{sychronize_rcu()} 인스턴스들은 홀수를 볼 수 있게 해서, 새로운 RCU read-side
크리티컬 섹션이 시작되었음을 알 수 있게 합니다.
예전의 RCU read-side 크리티컬 섹션들을 기다리는 \co{synchronize_rcu()} 의
인스턴스들은 따라서 이것을 무시해도 좋을 것임을 알 수 있게 됩니다.
마지막으로, line~14 에서는 메모리 배리어를 실행해서 (RCU read-side 크리티컬
섹션을 포함해서) 뒤따르는 코드가 line~12-13 과 재배치 되는 일을 방지합니다.
\iffalse

\begin{lineref}[ln:defer:rcu_qs:read_lock_unlock:qs]
In \co{rcu_quiescent_state()}, line~\lnref{mb1} executes a memory barrier
to prevent any code prior to the quiescent state (including possible
RCU read-side critical sections) from being reordered
into the quiescent state.
Lines~\lnref{gp1}-\lnref{gp2} pick up
a copy of the global \co{rcu_gp_ctr}, using
\co{READ_ONCE()} to ensure that the compiler does not employ any
optimizations that would result in \co{rcu_gp_ctr} being fetched
more than once,
and then adds one to the value fetched and stores it into
the per-thread \co{rcu_reader_qs_gp} variable, so that any concurrent
instance of \co{synchronize_rcu()} will see an odd-numbered value,
thus becoming aware that a new RCU read-side critical section has started.
Instances of \co{synchronize_rcu()} that are waiting on older
RCU read-side critical sections will thus know to ignore this new one.
Finally, line~\lnref{mb2} executes a memory barrier, which prevents subsequent
code (including a possible RCU read-side critical section) from being
re-ordered with the lines~\lnref{gp1}-\lnref{gp2}.
\end{lineref}
\fi

\QuickQuiz{}
	Listing~\ref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	의 line~14 에 보인 추가적인 메모리 배리어는 \co{rcu_quiescent_state} 의
	오버헤드를 많이 늘리지 않을까요?
	\iffalse

	\begin{lineref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Doesn't the additional memory barrier shown on line~\lnref{mb2} of
	Listing~\ref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	greatly increase the overhead of \co{rcu_quiescent_state}?
	\end{lineref}
	\fi
\QuickQuizAnswer{
	실제로 그렇습니다!
	따라서 이 RCU 구현을 사용하는 어플리케이션은 \co{rcu_quiescent_state}
	를 아껴서 사용하고, 대부분의 경우에는 그대신 \co{rcu_read_lock()} 과
	\co{rcu_read_unlock()} 을 사용해야 합니다.

	하지만, 이 메모리 배리어는 호출자에 의해 실행될 뒤따르는 RCU read-side
	크리티컬 섹션 전에 다른 쓰레드들이 line~12-13 의 저장 결과들을 볼 수
	있도록 하기 위해 반드시 필요합니다.
	\iffalse

	\begin{lineref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Indeed it does!
	An application using this implementation of RCU should therefore
	invoke \co{rcu_quiescent_state} sparingly, instead using
	\co{rcu_read_lock()} and \co{rcu_read_unlock()} most of the
	time.

	However, this memory barrier is absolutely required so that
	other threads will see the store on
	lines~\lnref{gp1}-\lnref{gp2} before any
	subsequent RCU read-side critical sections executed by the
	caller.
	\end{lineref}
	\fi
} \QuickQuizEnd

어떤 어플리케이션들은 RCU 를 가끔씩만 쓰지만, 사용할 때에는 매우 자주 사용할
수도 있습니다.
그런 어플리케이션들은 RCU 를 사용하기 시작할 때 \co{rcu_thread_online()} 을
사용하고 더이상 RCU 를 사용하지 않을 때에 \co{rcu_thread_offline()} 을 사용할
수 있을 겁니다.
\co{rcu_thread_offline()} 호출과 뒤따르는 \co{rcu_thread_online()} 사이의
시간은 하나의 확장된 quiescent state 여서, RCU 는 이 시간동안 명시적으로
quiescent state 가 등록되지는 않을 것이라고 예상할 수 있습니다.
\iffalse

Some applications might use RCU only occasionally, but use it very heavily
when they do use it.
Such applications might choose to use \co{rcu_thread_online()} when
starting to use RCU and \co{rcu_thread_offline()} when no longer
using RCU.
The time between a call to \co{rcu_thread_offline()} and a subsequent
call to \co{rcu_thread_online()} is an extended quiescent state,
so that RCU will not expect explicit quiescent states to be registered
during this time.
\fi

\co{rcu_thrad_offline()} 함수는 쓰레드별 변수 \co{rcu_reader_qs_gp} 변수를
\co{rcu_gp_ctr} 의 현재 값으로 설정하는데, 이 값은 짝수 값을 가질 겁니다.
따라서 동시에 수행되는 \co{synchronize_rcu()}  인스턴스들은 이 쓰레드를
무시해도 됨을 알 것입니다.
\iffalse

The \co{rcu_thread_offline()} function simply sets the
per-thread \co{rcu_reader_qs_gp} variable to the current value of
\co{rcu_gp_ctr}, which has an even-numbered value.
Any concurrent instances of \co{synchronize_rcu()} will thus know to
ignore this thread.
\fi

\QuickQuiz{}
	Listing~\ref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	의 line~19 와 22 의 메모리 배리어들은 왜 필요한 건가요?
	\iffalse

	\begin{lineref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	Why are the two memory barriers on lines~\lnref{mb1} and \lnref{mb2} of
	Listing~\ref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side}
	needed?
	\end{lineref}
	\fi
\QuickQuizAnswer{
	Line~19 의 메모리 배리어는 \co{rcu_thread_offline()} 에 앞서는 어떤 RCU
	read-side 크리티컬 섹션들도 컴파일러나 CPU 에 의해 line~20-21 의 값
	할당 뒤로 재배치 되지 않게 합니다.
	Line~22 에서의 메모리 배리어는 엄밀하게 말하면 불필요한데,
	\co{rcu_thrad_offline()} 뒤에 RCU read-side 크리티컬 섹션들을 두는 것은
	금지된 행위이기 때문입니다.
	\iffalse

	\begin{lineref}[ln:defer:rcu_qs:read_lock_unlock:qs]
	The memory barrier on line~\lnref{mb1} prevents any RCU read-side
	critical sections that might precede the
	call to \co{rcu_thread_offline()} won't be reordered by either
	the compiler or the CPU to follow the assignment on
	lines~\lnref{gp1}-\lnref{gp2}.
	The memory barrier on line~\lnref{mb2} is, strictly speaking, unnecessary,
	as it is illegal to have any RCU read-side critical sections
	following the call to \co{rcu_thread_offline()}.
	\end{lineref}
	\fi
} \QuickQuizEnd

\co{rcu_thread_online()} 은 단순히 \co{rcu_quiescent_state()} 를 호출해서
연장된 quiescent state 의 종료를 표시합니다.
\iffalse

The \co{rcu_thread_online()} function simply invokes
\co{rcu_quiescent_state()}, thus marking the end of the extended
quiescent state.
\fi

\begin{listing}[tbp]
\input{CodeSamples/defer/rcu_qs@synchronize.fcv}
\caption{RCU Update Side Using Quiescent States}
\label{lst:app:toyrcu:RCU Update Side Using Quiescent States}
\end{listing}

Listing~\ref{lst:app:toyrcu:RCU Update Side Using Quiescent States}
(\path{rcu_qs.c})
는 \co{synchronize_rcu()} 의 구현을 보이는데, 이는 앞 섹션들에서의 것과 상당히
유사합니다.

이 구현은 \co{rcu_read_lock()}-\co{rcu_read_unlock()} 왕복에 대략
50~\emph{피코세컨드} 라는 엄청나게 빠른 read-side 기능들을 갖습니다.
\co{synchronize_rcu()} 의 오버헤드는 단일 CPU 의 \Power{5} 시스템에서
600~나노세컨드부터 64-CPU 시스템에서 100~마이크로세컨드 까지의 오버헤드를
갖습니다.
\iffalse

Listing~\ref{lst:app:toyrcu:RCU Update Side Using Quiescent States}
(\path{rcu_qs.c})
shows the implementation of \co{synchronize_rcu()}, which is
quite similar to that of the preceding sections.

This implementation has blazingly fast read-side primitives, with
an \co{rcu_read_lock()}-\co{rcu_read_unlock()} round trip incurring
an overhead of roughly 50~\emph{picoseconds}.
The \co{synchronize_rcu()} overhead ranges from about 600~nanoseconds
on a single-CPU \Power{5} system up to more than 100~microseconds on
a 64-CPU system.
\fi

\QuickQuiz{}
	분명히 해두겠는데, 2008 년의 \Power{} 시스템들의 클락 주파수는 상당히
	높았지만, 5GHz 클락 주파수도 루프가 50~피코세컨드만에 실행되게
	하는데에는 부족해요!
	무슨 일이 벌어진 거죠?
	\iffalse

	To be sure, the clock frequencies of \Power{}
	systems in 2008 were quite high, but even a 5\,GHz clock
	frequency is insufficient to allow
	loops to be executed in 50~picoseconds!
	What is going on here?
	\fi
\QuickQuizAnswer{
	측정을 하는 루프는 한쌍의 텅빈 함수들만을 가지고 있으므로, 컴파일러는
	이것을 최적화해서 없애버립니다.
	이 측정 루프는 매번의 \co{rcu_quiescent_state()} 호출마다 1,000 번
	넘어가므로, 이 측정은 한번의 \co{rcu_quiescent_state()} 호출마다 대략
	천번의 오버헤드를 가진 걸로 치는 셈입니다.
	\iffalse

	Since the measurement loop contains a pair of empty functions,
	the compiler optimizes it away.
	The measurement loop takes 1,000 passes between each call to
	\co{rcu_quiescent_state()}, so this measurement is roughly
	one thousandth of the overhead of a single call to
	\co{rcu_quiescent_state()}.
	\fi
} \QuickQuizEnd

하지만, 이 구현은 각 쓰레드가 주기적으로 \co{rcu_quiescent_state()} 를
호출하거나 연장된 quiescent state 를 위해 \co{rcu_thread_offline()} 을 호출해
줄것을 필요로 합니다.
이 함수들을 주기적으로 실행해야 하는 필요성은 이 구현을 특정 타입의 라이브러리
함수들과 같은 일부 환경에서는 사용하기 어렵게 할 수 있습니다.
\iffalse

However, this implementation requires that each thread either
invoke \co{rcu_quiescent_state()} periodically or to invoke
\co{rcu_thread_offline()} for extended quiescent states.
The need to invoke these functions periodically can make this
implementation difficult to use in some situations, such as for
certain types of library functions.
\fi

\QuickQuiz{}
	코드가 라이브러리에 있다는 사실이 왜
	Listing~\ref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side} 와
	\ref{lst:app:toyrcu:RCU Update Side Using Quiescent States} 에 보여진 RCU
	구현의 사용에 어려움을 가져올 수 있는 건가요?
	\iffalse

	Why would the fact that the code is in a library make
	any difference for how easy it is to use the RCU
	implementation shown in
	Listings~\ref{lst:app:toyrcu:Quiescent-State-Based RCU Read Side} and
	\ref{lst:app:toyrcu:RCU Update Side Using Quiescent States}?
	\fi
\QuickQuizAnswer{
	라이브러리 함수는 호출자에 대한 제어가 전혀 존재치 않고 따라서 호출자가
	\co{rcu_quiescent_state()} 를 주기적으로 실행할 것을 강제하지 못합니다.
	다른 편으로는, 주어진 RCU 로 보호되는 데이터 구조체에 많은 레퍼런스를
	가지고 있을 수도 있는 라이브러리 함수는 \co{rcu_thrad_online()} 을 매
	원소마다, \co{rcu_quiescent_state()} 를 주기적으로, 그리고
	\co{rcu_thread_offline()} 을 종료될 때에 호출할 수도 있을 겁니다.
	\iffalse

	A library function has absolutely no control over the caller,
	and thus cannot force the caller to invoke \co{rcu_quiescent_state()}
	periodically.
	On the other hand, a library function that made many references
	to a given RCU-protected data structure might be able to invoke
	\co{rcu_thread_online()} upon entry,
	\co{rcu_quiescent_state()} periodically, and
	\co{rcu_thread_offline()} upon exit.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	하지만 락을 \co{synchronize_rcu()} 전후에 걸쳐 잡고, 같은 락을 RCU
	read-side 크리티컬 섹션에서 잡으면 어떻게 되나요?
	이건 데드락이 되어야 할텐데, 하지만 어떻게 어떤 코드도 만들지 않는
	기능이 데드락 사이클에 참여될 수가 있죠?
	\iffalse

	But what if you hold a lock across a call to
	\co{synchronize_rcu()}, and then acquire that same lock within
	an RCU read-side critical section?
	This should be a deadlock, but how can a primitive that
	generates absolutely no code possibly participate in a
	deadlock cycle?
	\fi
\QuickQuizAnswer{
	RCU read-side 크리티컬 섹션은 둘러싸는 \co{rcu_read_lock()} 과
	\co{rcu_read_unlock()} 너머로 확장되어서 앞과 뒤의
	\co{rcu_quiescent_state()} 에 닿음을 알아두시기 바랍니다.
	이 \co{rcu_quiescent_State} 는 \co{rcu_read_lock()} 을 곧바로 뒤따르는
	\co{rcu_read_unlock()} 으로 생각될 수 있습니다.

	비록 그렇다 해도, 실제 데드락 자신은 RCU read-side 크리티컬 섹션
	내에서와 \co{synchronize_rcu()} 에서의 락 획득에 연구되지,
	\co{rcu_quiescent_state()} 와 연루되지는 않을 겁니다.
	\iffalse

	Please note that the RCU read-side critical section is in
	effect extended beyond the enclosing
	\co{rcu_read_lock()} and \co{rcu_read_unlock()}, out to
	the previous and next call to \co{rcu_quiescent_state()}.
	This \co{rcu_quiescent_state} can be thought of as an
	\co{rcu_read_unlock()} immediately followed by an
	\co{rcu_read_lock()}.

	Even so, the actual deadlock itself will involve the lock
	acquisition in the RCU read-side critical section and
	the \co{synchronize_rcu()}, never the \co{rcu_quiescent_state()}.
	\fi
} \QuickQuizEnd

또한, 이 구현은 동시의 \co{synchronize_rcu()} 호출이 grace period 를 공유할 수
있도록 허용하지 않습니다.
그렇다곤 하나, 이 버전의 RCU 에 기초해서 제품 품질의 RCU 구현을 쉽게 생각해 볼
수 있을 겁니다.
\iffalse

In addition, this implementation does not permit concurrent calls
to \co{synchronize_rcu()} to share grace periods.
That said, one could easily imagine a production-quality RCU
implementation based on this version of RCU.
\fi

\section{Summary of Toy RCU Implementations}
\label{sec:app:toyrcu:Summary of Toy RCU Implementations}

여기까지 잘 도착했다면, 축하합니다!
이제 독자 여러분은 RCU 자체에 대해서만이 아니라 그걸 둘러싸고 있는 소프트웨어
환경들과 어플리케이션들의 요구사항들에 대해서도 분명한 이해를 가지게 되었을
겁니다.
이보다도 더 깊은 이해를 원하는 분들은 제품 품질의 RCU 구현에 대한 설명을
읽어보시기
바랍니다~\cite{MathieuDesnoyers2012URCU,PaulEMcKenney2007PreemptibleRCU,PaulEMcKenney2008HierarchicalRCU,PaulEMcKenney2009BloatwatchRCU}.

앞의 섹션들에서는 다양한 RCU 기능들의 바랄법한 속성들을 열거해 보았습니다.
새로운 RCU 구현을 만들고자 하는 분들이 쉽게 참조해 볼 수 있도록 다음의 리스트를
제공합니다.
\iffalse

If you made it this far, congratulations!
You should now have a much clearer understanding
not only of RCU itself, but also of the requirements of enclosing
software environments and applications.
Those wishing an even deeper understanding are invited to read
descriptions of production-quality RCU
implementations~\cite{MathieuDesnoyers2012URCU,PaulEMcKenney2007PreemptibleRCU,PaulEMcKenney2008HierarchicalRCU,PaulEMcKenney2009BloatwatchRCU}.

The preceding sections listed some desirable properties of the
various RCU primitives.
The following list is provided for easy reference for those wishing to
create a new RCU implementation.
\fi

\begin{enumerate}
\item	Read-side 기능들 (\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 과
	같은 것들) 과 grace-period 기능들 (\co{synchronize_rcu()} 와
	\co{call_rcu()} 와 같은 것들) 이 반드시 있어야만 하는데, 그것들은 grace
	period 의 시작 시점에 존재한 read-side 크리티컬 섹션은 모두 그 grace
	period 의 종료 전까지는 완료되어야 합니다.
\item	RCU read-side 기능들은 최소한의 오버헤드만을 가져야 합니다.
	구체적으로는, 캐시 미스, 어토믹 인스트럭션, 메모리 배리어, 그리고
	브랜칭과 같은 비싼 오퍼레이션들은 방지되어야 합니다.
\item	리얼타임 쪽에서의 사용을 위해선 RCU read-side 기능들은
	$O\left(1\right)$ 의 계산 복잡도를 가져야 합니다.
	(이는 읽기 쓰레드들은 업데이트 쓰레드들과 동사에 수행됨을 암시합니다.)
\iffalse

\item	There must be read-side primitives (such as \co{rcu_read_lock()}
	and \co{rcu_read_unlock()}) and grace-period primitives
	(such as \co{synchronize_rcu()} and \co{call_rcu()}), such
	that any RCU read-side critical section in existence at the
	start of a grace period has completed by the end of the
	grace period.
\item	RCU read-side primitives should have minimal overhead.
	In particular, expensive operations such as cache misses,
	atomic instructions, memory barriers, and branches should
	be avoided.
\item	RCU read-side primitives should have $O\left(1\right)$ computational
	complexity to enable real-time use.
	(This implies that readers run concurrently with updaters.)
\fi
\item	RCU read-side 기능들은 모든 컨텍스트에서 사용이 가능해야 합니다
	(리눅스 커널에서는, idle 루프를 제외한 모든 곳에서 사용이 가능합니다).
	중요한 특수 케이스는 RCU read-side 기능들이 RCU read-side 크리티컬 섹션
	내부에서 사용되는 것으로, 달리 말하면, RCU read-side 크리티컬 섹션들은
	중첩될 수 있어야 합니다.
\item	RCU read-side 기능들은 무조건적으로 수행되어서 실패를 리턴하거나 하지
	않아야 합니다.
	이 속성은 굉장히 중요한데, 실패여부 검사는 복잡성을 증가시키고 테스트와
	검증을 번거롭게 만들기 때문입니다.
\item	Quiescent state (그리고 grace period) 를 제외한 모든 오퍼레이션은 RCU
	read-side 크리티컬 섹션 내에서 사용 가능해야 합니다.
	구체적으로는, I/O 와 같이 취소 불가능한 오퍼레이션들이 사용 가능해야
	합니다.
\iffalse

\item	RCU read-side primitives should be usable in all contexts
	(in the Linux kernel, they are permitted everywhere except in
	the idle loop).
	An important special case is that RCU read-side primitives be
	usable within an RCU read-side critical section, in other words,
	that it be possible to nest RCU read-side critical sections.
\item	RCU read-side primitives should be unconditional, with no
	failure returns.
	This property is extremely important, as failure checking
	increases complexity and complicates testing and validation.
\item	Any operation other than a quiescent state (and thus a grace
	period) should be permitted in an RCU read-side critical section.
	In particular, irrevocable operations such as I/O should be
	permitted.
\fi
\item	RCU 로 보호되는 데이터 구조체는 RCU read-side 크리티컬 섹션에서 실행
	중일 때에도 업데이트 할 수 있어야 합니다.
\item	RCU read-side 기능들도 update-side 기능들도 메모리 할당자 설계와
	구현과는 독립적이어야 하는데, 달리 말해서, 같은 RCU 구현은 특정 데이터
	구조에 대해 그 데이터 원소들이 어떻게 할당되고 해제되는가에 관계없이 그
	데이터 구조를 보호할 수 있어야 합니다.
\item	RCU grace period 는 RCU read-side 크리티컬 섹션들 바깥에서 종료되는
	쓰레드들에 의해 블록되지 않아야 합니다.
	(하지만 대부분의 quiescent-state 기반의 구현은 이 필요성을 위반합니다.)
\iffalse

\item	It should be possible to update an RCU-protected data structure
	while executing within an RCU read-side critical section.
\item	Both RCU read-side and update-side primitives should be independent
	of memory allocator design and implementation, in other words,
	the same RCU implementation should be able to protect a given
	data structure regardless of how the data elements are allocated
	and freed.
\item	RCU grace periods should not be blocked by threads that
	halt outside of RCU read-side critical sections.
	(But note that most quiescent-state-based implementations
	violate this desideratum.)
\fi
\end{enumerate}

\QuickQuiz{}
	Grace period 가 RCU read-side 크리티컬 섹션들로 통제된다면, RCU로
	보호되는 데이터 구조체는 어떻게 RCU read-side 크리티컬 섹션 내에서
	업데이트 될 수 있을까요?
	\iffalse

	Given that grace periods are prohibited within RCU read-side
	critical sections, how can an RCU data structure possibly be
	updated while in an RCU read-side critical section?
	\fi
\QuickQuizAnswer{
	이 상황이 \co{call_rcu()} 와 같은 비동기적 grace-period 기능들의 존재
	이유 중 하나입니다.
	이 기능은 RCU read-side 크리티컬 섹션 내에서 실행될 수도 있고, 이 특정
	RCU 콜백은 하나의 grace period 가 종료된 이후에 뒤늦게 실행될 것입니다.

	RCU read-side 크리티컬 섹션 내에서 RCU 업데이트를 할 수 있는 능력은
	상당히 편리할 수 있고, (허구의) reader-writer 락킹에서의 무조건적인
	read-to-write 업그레이드로 비유될 수 있습니다.
	\iffalse

	This situation is one reason for the existence of asynchronous
	grace-period primitives such as \co{call_rcu()}.
	This primitive may be invoked within an RCU read-side critical
	section, and the specified RCU callback will in turn be invoked
	at a later time, after a grace period has elapsed.

	The ability to perform an RCU update while within an RCU read-side
	critical section can be extremely convenient, and is analogous
	to a (mythical) unconditional read-to-write upgrade for
	reader-writer locking.
	\fi
} \QuickQuizEnd
