% appendix/rcuimpl/rcupreempt.tex

\section{Preemptible RCU}
\label{app:rcuimpl:Preemptible RCU}
\OriginallyPublished{Appendix}{app:rcuimpl:Preemptible RCU}{Preemptible RCU}{Linux Weekly News}{PaulEMcKenney2007PreemptibleRCU}

Preemptible RCU 구현은 read-side 크리티컬 섹션이 preemption 당하고 락들을
오래도록 기다리게 만들 수 있다는 점에서 일반적이지 않습니다.
하지만, 이 구현은 (예를 들어, \co{wait_event()} 기능을 통해) 일반적인 블록킹을
처리하지 않습니다:
여러분이 이게 필요하다면, 여러분은
Appendix~\ref{app:rcuimpl:Sleepable RCU Implementation}
에서 소개한 SRCU 를 대신 사용해야 합니다.
SRCU 와 대조적으로, preemptible RCU 는 non-\co{CONFIG_PREEMPT} 커널에서
우선순위 상속과 non-blocking 에 모두 해당하는 기능들 안에서만 블록킹을
허용합니다.
블락되어 있는 락을 획득하고 RCU read-side 크리티컬 섹션 내에서 preemption 당할
수 있는 능력은 Ingo Molnar 의 -rt 패치셋에서 제공된 강한 real-time 기능성을
위해 필요합니다.
하지만, 최초의 preemptible RCU 구현~\cite{PaulMcKenney2005d} 은 일부 한계가
있는데, 다음과 같습니다:
\iffalse

The preemptible RCU implementation is unusual in that
it permits read-side critical
sections to be preempted and to be blocked waiting for locks.
However, it does not handle general blocking
(for example, via the \co{wait_event()} primitive):
if you need that, you should instead use SRCU, which is described in
Appendix~\ref{app:rcuimpl:Sleepable RCU Implementation}.
In contrast to SRCU,
preemptible RCU only permits blocking within primitives that are
both subject to priority inheritance and non-blocking in a
non-\co{CONFIG_PREEMPT} kernel.
This ability to acquire blocking locks and to be preempted within
RCU read-side critical sections is required for the aggressive real-time
capabilities provided by Ingo Molnar's -rt patchset.
However, the initial preemptible RCU implementation~\cite{PaulMcKenney2005d}
had some limitations, including:
\fi

\begin{enumerate}
\item	Read-side 기능들은 non-maskable 인터럽트 (NMI) 나 system 관리 인터럽트
	핸들러 내에서 호출될 수 없습니다.
\item	Read-side 기능들은 어토믹 인스트럭션들과 메모리 배리어를 모두
	사용하는데, 이것들은 모두 상당한 오버헤드를 갖습니다.
\item	RCU read-side 크리티컬 섹션의 priority
	boosting~\cite{PaulEMcKenney2007BoostRCU} 을 하지 않습니다.
\iffalse

\item	Its read-side primitives cannot be called from within
	non-maskable interrupt (NMI) or systems-management interrupt
	handlers.
\item	Its read-side primitives use both atomic instructions and
	memory barriers, both of which have excessive overhead.
\item	It does no priority boosting of RCU read-side critical
	sections~\cite{PaulEMcKenney2007BoostRCU}.
\fi
\end{enumerate}

2.6.26 리눅스 커널에 받아들여진 새로운 preemptible RCU 구현은 이 한계점들을
제거했고, 이 부록은 그 설계에 대한 LWN
기사~\cite{PaulEMcKenney2007PreemptibleRCU} 에 대한 업데이트 역할을 합니다.
하지만, 이 구현은 더 빠르고 간단한 2.6.32 리눅스 커널에서의 구현으로
교체되었다는 점을 알아두시기 바랍니다.
이 설명은 다만 기존에 고안되었던 RCU 구현들 중 가장 복잡한 것에 대한 증언일
뿐입니다.
\iffalse

The new preemptible RCU implementation that accepted into the 2.6.26
Linux kernel
removes these limitations, and this appendix describes its design,
serving as an update to the LWN article~\cite{PaulEMcKenney2007PreemptibleRCU}.
However, please note that this implementation was replaced with a faster
and simpler implementation in the 2.6.32 Linux kernel.
This description nevertheless remains to bear witness to the most complex
RCU implementation ever devised.
\fi

\QuickQuiz{}
	Preemptible-RCU read-side 크리티컬 섹션 내에서 호출되는 블록킹 기능들이
	우선순위 상속에 걸리기 쉬워야 한다는 점이 중요한 이유가 뭐죠?
	\iffalse

	Why is it important that blocking primitives
	called from within a preemptible-RCU read-side critical section be
	subject to priority inheritance?
	\fi
\QuickQuizAnswer{
	블록당한 읽기 쓰레드들은 RCU grace period 를 멈추게 만들어서 OOM 을
	일으킬 수 있기 때문입니다.
	예를 들어, 한 읽기 쓰레드가 RCU read-side 크리티컬 섹션 내에서
	\co{wait_event()} 를 호출했고, 그 이벤트가 절대 일어나지 않는다면, RCU
	grace period 는 비결정적으로 지속될 것이고, 이는 이 시스템이 금방이든
	나중이든 OOM 을 일으킬 것을 보장합니다.
	따라서, 그런 OOM 을 막기 위해 이런 읽기 쓰레드들이 read-side 크리티컬
	섹션에 대해 진행을 할 수 있도록 하는 어떤 방법이 있어야만 합니다.
	Priority boosting 은 그런 진행을 강제하기 위핸한가지 방법입니다만, 읽기
	쓰레드들이 priority boosting 을 통해 깨어날 수 있다던지 하는 제한된
	블록킹에 있을 때에만 가능합니다.

	물론, 우선순위 상속 외에도 우선순위 역전 문제를 해결하는 priority
	ceiling, preemption disabling 등의 다른 방법들이 존재합니다.
	하지만, 리눅스 커널에서 우선순위 상속이 사용되는 좋은 이유가 존재하고,
	그런 이유로 RCU 에서 사용하기로 했습니다.
	\iffalse

	Because blocked readers stall RCU grace periods,
	which can result in OOM.
	For example, if a reader did a \co{wait_event()} within
	an RCU read-side critical section, and that event never occurred,
	then RCU grace periods would stall indefinitely, guaranteeing that
	the system would OOM sooner or later.
	There must therefore be some way to cause these readers to progress
	through their read-side critical sections in order to avoid such OOMs.
	Priority boosting is one way to force such progress, but only if
	readers are restricted to blocking such that they can be awakened via
	priority boosting.

	Of course, there are other methods besides priority inheritance
	that handle the priority inversion problem, including priority ceiling,
	preemption disabling, and so on.
	However, there are good reasons why priority inheritance is the approach
	used in the Linux kernel, so this is what is used for RCU.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	Non-\co{CONFIG_PREEMPT} 커널 내에서 블록될 수 있는 기능들을 사용할 수
	있게 하는 게 가능할까요, 그리고 만약 그렇다면, 어떤 조건 하에서
	가능할까요?
	\iffalse

	Could the prohibition against using primitives
	that would block in a non-\co{CONFIG_PREEMPT} kernel be lifted,
	and if so, under what conditions?
	\fi
\QuickQuizAnswer{
	테스트와 벤치마크가 preemptible RCU 가 classic RCU 가 완전히 사라질 수
	있을 정도로 잘 동작한다는 것을 보인다면, 그리고 우선순위 상속이
	\co{semaphore} 들과 같은 블록킹 동기화 기능들을 위해서도 구현된다면,
	그런 기능들은 RCU read-side 크리티컬 섹션에서 사용될 수 있을 겁니다.
	\iffalse

	If testing and benchmarking demonstrated that the
	preemptible RCU worked well enough that classic RCU could be dispensed
	with entirely, and if priority inheritance was implemented for blocking
	synchronization primitives
	such as \co{semaphore}s, then those primitives could be
	used in RCU read-side critical sections.
	\fi
} \QuickQuizEnd

\subsection{Conceptual RCU}
\label{app:rcuimpl:Conceptual RCU}

가장 낮은 단계에서의 RCU 에 대한 이해를 놓고 보면 RCU 구현에 대한 이해와 검증은
훨씬 쉬워집니다.
이 섹션은 RCU 구현이 반드시 지원해야 하는 가장 기본적인 동시성에 대한
요구사항에 대한 간단한 개요를 제공합니다.
더 자세한 내용을 위해선,
Section~\ref{sec:defer:RCU Fundamentals} 을 보세요.

RCU 구현은 다음 규칙을 준수해야만 합니다: 특정 RCU read-side 크리티컬 섹션의
명령이 어떤 grace period 를 앞선다면, 해당 RCU read-side 크리티컬 섹션의 모든
명령은 해당 grace period 가 끝나기 전에 완료되어야만 합니다.
\iffalse

Understanding and validating an RCU implementation is much easier given
a view of RCU at the lowest possible level.
This section gives a very brief overview of the
most basic concurrency requirements that an RCU implementation must
support.
For more detail, please see
Section~\ref{sec:defer:RCU Fundamentals}.

RCU implementations must obey the following rule: if any
statement in a given RCU read-side critical section precedes a
grace period, then all statements in that RCU read-side critical
section must complete before that grace period ends.
\fi

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/GracePeriodBad}}
\caption{Buggy Grace Period From Broken RCU}
\label{app:rcuimpl:Buggy Grace Period From Broken RCU}
\end{figure}

Figure~\ref{app:rcuimpl:Buggy Grace Period From Broken RCU} 에 시간축을
왼쪽에서 오른쪽으로 표현하면서 이를 표현했습니다.
빨간색 ``Removal'' 박스는 RCU 로 보호되는 데이터 구조를 예를 들면
\co{list_del_rcu()} 를 사용하는 식으로 수정하는 update-side 크르티컬 섹션을
표현합니다; 커다란 노란색의 ``Grace Period'' 박스는 \co{synchronize_rcu()} 를
통해 호출될 수 있는 grace period 를 의미하며, 초록색의 ``Reclamation'' 박스는
\co{kfree()} 등을 통한, 영향 받은 데이터 원소의 해제를 의미합니다.
파란색의 ``Reader'' 박스들은 각각 RCU read-side 크리티컬 섹션을 표현하는데,
예를 들면 \co{rcu_read_lock()} 으로 시작되고 \co{rcu_read_unlock()} 으로
종료됩니다.
빨간색으로 테두리 쳐진 ``Reader'' 박스는 비합법적인 상황에 대한 예입니다:
Read-side 크리티컬 섹션이 grace period 에 겹칠 수 있도록 하는 RCU 구현이라
불리는 것들은 버그가 존재하는 것으로, update 쓰레드가 이 읽기 쓰레드가 여전히
사용하고 있는 메모리 영역을 해제해 버릴 수 있기 때문입니다.

그럼, 이 상황에서 RCU 구현이 해야 할 건 무엇일까요?
\iffalse

This is illustrated by
Figure~\ref{app:rcuimpl:Buggy Grace Period From Broken RCU},
where time advances from left to right.
The red ``Removal'' box represents the update-side critical section that
modifies the RCU-protected data structure, for example, via
\co{list_del_rcu()}; the large yellow ``Grace Period'' box
represents a grace period (surprise!) which might be invoked via
\co{synchronize_rcu()}, and the green ``Reclamation'' box
represents freeing the affected data element,
perhaps via \co{kfree()}.
The blue ``Reader'' boxes each represent an RCU read-side critical section,
for example, beginning with \co{rcu_read_lock()} and ending with
\co{rcu_read_unlock()}.
The red-rimmed ``Reader'' box is an example of an illegal situation:
any so-called RCU implementation that permits a read-side critical section
to completely overlap a grace period is buggy, since the updater might
free up memory that this reader is still using.

So, what is the poor RCU implementation to do in this situation?
\fi

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/GracePeriodGood}}
\caption{Good Grace Period From Correct RCU}
\label{app:rcuimpl:Good Grace Period From Correct RCU}
\end{figure}

RCU 구현은 이 grace period 를 연장해야 하는데,
Figure~\ref{app:rcuimpl:Good Grace Period From Correct RCU} 에 보여진 것과 같은
형태가 될 수 있겠습니다.
짧게 말해서, 이 RCU 구현은 특정 grace period 의 시작 시점에서 진행 중이던 모든
RCU read-side 크리티컬 섹션은 해당 grace period 가 완료되기 전에 메모리
오퍼레이션들 등의 모든 것이 완전히 종료되었음을 보장해야 합니다.
이 점은 RCU 검증이 집중될 수 있게 해줍니다: 컴파일러나 CPU 가 RCU 구현이 한
일을 무효화 시키는 것을 막도록 충분히 배리어를 써서 하나의 grace period 의 시작
시점에 진행 중이던 RCU read-side 크리티컬 섹션은 모두 해당 grace period 가
종료되기 전에 끝나는 것을  보이는 겁니다.
\iffalse

It must extend the grace period, perhaps as shown in
Figure~\ref{app:rcuimpl:Good Grace Period From Correct RCU}.
In short, the RCU implementation must ensure that any
RCU read-side critical sections in progress at the start of a given grace
period have completely finished, memory operations and all, before that
grace period is permitted to complete.
This fact allows RCU validation to be extremely focused: simply demonstrate
that any RCU read-side critical section in progress at the beginning of
a grace period must terminate before that grace period ends, along with
sufficient barriers to prevent either the compiler or the CPU from undoing
the RCU implementation's work.
\fi

\subsection{Overview of Preemptible RCU Algorithm}
\label{app:rcuimpl:Overview of Preemptible RCU Algorithm}

이 섹션은 preemptible RCU 의 특정 구현에 집중합니다.
많은 다른 구현들이 있을 수 있겠지만, 그에 대해선 다른
곳~\cite{PaulEMcKenney2006b,PaulMcKenney05b} 에서 다루어졌습니다.
이 글은 이 특정 구현의 일반적인 방법들과 데이터 구조, grace-period state
machine, 그리고 read-side 기능들에 대한 파악에 집중합니다.
\iffalse

This section focuses on a specific implementation of preemptible RCU.
Many other implementations are possible, and are described
elsewhere~\cite{PaulEMcKenney2006b,PaulMcKenney05b}.
This article focuses on this specific implementation's
general approach, the data structures,
the grace-period state machine, and a walk through the read-side primitives.
\fi

\subsubsection{General Approach}
\label{app:rcuimpl:General Approach}

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/RCUpreemptListsCompare}}
\caption{Classic vs. Preemptible RCU Callback Processing}
\label{app:rcuimpl:Classic vs. Preemptible RCU Callback Processing}
\end{figure}

이 preemptible RCU 구현은 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 에
메모리 배리어를 필요로 하지 않기 때문에, 다단계 grace-period 탐지 알고리즘이
필요합니다.
콜백들을 위한 (기존의 RCU 구현들을 위해선 충분했던) 하나의 \co{wait} queue 를
사용하는 대신에, 이 구현은 \co{wait} 큐들의 배열을 사용해서 RCU 콜백들이 이
배열의 각 원소에 차례차례 enqueue 될 수 있게 합니다.
콜백의 흐름에 있어서의 이 차이가
Figure~\ref{app:rcuimpl:Classic vs. Preemptible RCU Callback Processing}
에 grace period 당 두개의 waitlist stage 들을 갖는 (반면, 2007년 9월 10일의 -rt
로의 패치~\cite{PaulEMcKenney2007PreemptibleRCUPatch} 는 네개의 waitlist stage
를 사용합니다) preemptible RCU 구현에 대해 그려져 있습니다.

Grace period 당 두개의 stage 를 갖기 때문에, 한쌍의 stage 들은 하나의 완전한
grace period 를 구성합니다.
비삿하게, grace period 당 네개의 stage 를 갖는 구현에서는 네개의 stage 의
연속이 하나의 완전한 grace period 를 구성합니다.
\iffalse

Because this implementation of preemptible RCU does not require memory
barriers in \co{rcu_read_lock()} and \co{rcu_read_unlock()},
a multi-stage grace-period detection algorithm is required.
Instead of using a single \co{wait} queue of callbacks
(which has sufficed for earlier RCU implementations), this implementation
uses an array of \co{wait} queues, so that RCU callbacks
are enqueued on each element of this array in turn.
This difference in callback flow is shown in
Figure~\ref{app:rcuimpl:Classic vs. Preemptible RCU Callback Processing}
for a preemptible RCU implementation with two waitlist stages per grace period
(in contrast,
the September 10 2007 patch to -rt~\cite{PaulEMcKenney2007PreemptibleRCUPatch}
uses four waitlist stages).

Given two stages per grace period, any pair of
stages forms a full grace period.
Similarly, in an implementation with four stages per grace period,
any sequence of four stages would form a full grace period.
\fi

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/RCUpreemptCounterFlip}}
\caption{Preemptible RCU Counter Flip Operation}
\label{app:rcuimpl:Preemptible RCU Counter Flip Operation}
\end{figure}

언제 하나의 grace-period stage 가 끝날 수 있는지 판단하기 위해, preemptible RCU
는 진행중인 RCU read-side 크리티컬 섹션들을 추적하는 두개의 원소로 구성된
per-CPU \co{rcu_flipctr} 배열을 사용합니다.
특정 CPU 의 \co{rcu_flipctr} 배열의 하나의 원소는 오래된 RCU read-side 크리티컬
섹션들, 달리 말하자면 현재의 grace-period stage 보다 먼저 시작된 크리티컬
섹션들을 추적합니다.
다른 원소는 새로운 RCU read-side 크리티컬 섹션들을 추적하는데, 이것들은 현재
grace-period stage 중간에 시작된 것들입니다.
이 배열의 원소들은 새로운 grace-period stage 각각의 시작 때마다 그 역할을
바꾸는데,
Figure~\ref{app:rcuimpl:Preemptible RCU Counter Flip Operation} 에 그 모습이
그려져 있습니다.
\iffalse

To determine when a grace-period stage can end,
preemptible RCU uses a per-CPU two-element \co{rcu_flipctr} array
that tracks in-progress RCU read-side critical sections.
One element of a given CPU's \co{rcu_flipctr} array tracks
old RCU read-side critical sections, in other words, critical sections
that started before the current grace-period stage.
The other element tracks new RCU read-side critical
sections, namely those starting during the current grace-period stage.
The array elements switch roles at the beginning of each new grace-period
stage, as shown in
Figure~\ref{app:rcuimpl:Preemptible RCU Counter Flip Operation}.
\fi

앞의 그림의 왼쪽의 첫번째 stage 동안, \co{rcu_flipctr[0]} 는 새로운 RCU
read-side 크리티컬 섹션들을 추적하고, 따라서 \co{rcu_read_lock()} 에 의해 그
값이 증가하고 \co{rcu_read_unlock()} 에 의해 그 값이 감소합니다.
비슷하게, \co{rcu_flipctr[1]} 은 오래된 (앞의 stage 동안 시작된) RCU read-side
크리티컬 섹션들을 추적하고, 따라서 \co{rcu_read_unlock()} 에 의해 그 값이
감소되고 결코 그 값이 증가하지 않습니다.
\iffalse

During the first stage on the left-hand side of the above figure,
\co{rcu_flipctr[0]} tracks the new
RCU read-side critical sections, and is therefore incremented by
\co{rcu_read_lock()} and decremented by \co{rcu_read_unlock()}.
Similarly, \co{rcu_flipctr[1]} tracks the old RCU read-side
critical sections (those that started during earlier stages), and
is therefore decremented by \co{rcu_read_unlock()} and never
incremented at all.
\fi

각 CPU 의 \co{rcu_flipctr[1]} 원소는 결코 그 값이 증가되지 않기 때문에, 모든
CPU 들의 그 원소의 값의 합은 결국은 0이 됩니다, RCU read-side 크리티컬 섹션
중간의 preemption 은 개별적 카운터가 0이 아니게 놔두거나 심지어 음수를 만들
수도 있겠지만 말입니다.
예를 들어, 하나의 task 가 한 CPU 위에서 \co{rcu_read_lock()} 을 호출했고,
preemption 당한 후, 다른 CPU 에서 다시 시작되어서 \co{rcu_read_unlock()} 을
호출했다고 생각해 보세요.
첫번째 CPU 의 카운터는 +1 될것이고 두번째 CPU 의 카운터는 -1 됩니다만, 그 합은
0이 됩니다.
Preemption 의 가능성에 관계 없이, 이 카운터 원소들의 합이 0이 된다면, 앞의
그림의 오른쪽에 보여진 것처럼 다음 grace-period stage 로 넘어가도 안전합니다.
\iffalse

Because each CPU's old \co{rcu_flipctr[1]} elements are never
incremented, their sum across all CPUs must eventually go to zero,
although preemption in the midst of an RCU read-side critical section might
cause any individual counter to remain non-zero or even to go negative.
For example, suppose that a task calls \co{rcu_read_lock()} on
one CPU, is preempted, resumes on another CPU, and then calls
\co{rcu_read_unlock()}.
The first CPU's counter will then be +1 and the second CPU's counter
will be -1, however, they will still sum to zero.
Regardless of possible preemption, when the sum of the old counter
elements does go to zero, it is safe to move to the next grace-period
stage, as shown on the right-hand side of the above figure.
\fi

이 두번째 stage 에서, 각 CPU 의 \co{rcu_flipctr} 카운터 배열의 원소들은 그
역할을 서로 바꿉니다.
\co{rcu_flipctr[0]} 카운터는 이제 오래된 RCU read-side 크리티컬 섹션, 달리 말해
grace period stage 0 동안 시작된 것들을 추적합니다.
비슷하게, \co{rcu_flipctr[1]} 카운터는 이제 grace period stage 1 안에서 시작된
새로운 RCU read-side 크리티컬 섹션들을 추적합니다.
따라서, \co{rcu_read_lock()} 은 이제 \co{rcu_flipctr[1]} 의 값을 증가시키며,
\co{rcu_read_unlock()} 은 여전히 각 카운터의 값을 감소시킵니다.
특히, \co{rcu_read_lock()} 이 grace-period stage 0 (이 시점에선 과거의 stage)
동안 수행되었다면, \co{rcu_read_unlock()} 은 \co{rcu_flipctr[0]} 의 값을
감소시키지만, \co{rcu_read_lock()} 이 grace-period stage 1 (새로운 stage) 동안
수행되었다면, \co{rcu_read_unlock()} 은 \co{rcu_flipctr[1]} 의 값을 감소시켜야
합니다.
\iffalse

In this second stage, the elements of each CPU's \co{rcu_flipctr}
counter array switch roles.
The \co{rcu_flipctr[0]} counter now tracks the old RCU read-side
critical sections, in other words, the ones that started during
grace period stage 0.
Similarly, the \co{rcu_flipctr[1]} counter now tracks the new
RCU read-side critical sections that start in grace period stage 1.
Therefore, \co{rcu_read_lock()} now increments
\co{rcu_flipctr[1]}, while \co{rcu_read_unlock()} still
might decrement either counter.
Specifically, if the matching \co{rcu_read_lock()} executed
during grace-period stage 0 (the old stage at this point), then
\co{rcu_read_unlock()} must decrement \co{rcu_flipctr[0]},
but if the matching \co{rcu_read_lock()} executed during
grace-period stage 1 (the new stage), then \co{rcu_read_unlock()}
must instead decrement \co{rcu_flipctr[1]}.
\fi

여기서의 핵심은 과거의 RCU read-side 크리티컬 섹션들을 추적하는 모든
\co{rcu_flipctr} 원소들이 확실히 감소되어야 한다는 겁니다.
따라서, 일단 이 과거의 것들에 대한 카운터의 합이 0이 된다면, 이는 바뀔 수
없습니다.

\co{rcu_read_lock()} 기능은 \co{rcu_flipctr} 배열을 인덱스 하기 위해 현재
grace-period 카운터의 가장 바닥 bit (\co{rcu_ctrlblk.completed & 0x1}) 을
사용하고, 이 인덱스를 task 구조체 안에 기록해 둡니다.
여기 짝을 맞추는 \co{rcu_read_unlock()} 은 이 기록된 값을 \co{rcu_read_lock()}
이 값 증가시킨 것에 걸맞는 카운터의 값을 감소시킨다는 것을 보장하기 위해
사용합니다.
물론, 이 RCU read-side 크리팈러 섹션이 preemption 당했다면,
\co{rcu_read_unlock()} 은 짝이 맞는 \co{rcu_read_lock()} 이 값을 증가시킨
카운터가 아니라, 다른 CPU 에 속한 카운터의 값을 감소시킬 수도 있습니다.
\iffalse

The critical point is that all \co{rcu_flipctr} elements
tracking the old RCU read-side critical sections must strictly decrease.
Therefore, once the sum of these old counters reaches zero,
it cannot change.

The \co{rcu_read_lock()} primitive uses the bottom
bit of the current grace-period counter
(\co{rcu_ctrlblk.completed & 0x1}) to index the
\co{rcu_flipctr} array,
and records this index in the task structure.
The matching \co{rcu_read_unlock()} uses this recorded
value to ensure that it decrements a counter corresponding to
the one that the matching \co{rcu_read_lock()} incremented.
Of course, if the RCU read-side critical section has been preempted,
\co{rcu_read_unlock()} might be decrementing the counter
belonging to a different CPU than the one whose counter was incremented
by the matching \co{rcu_read_lock()}.
\fi

각각의 CPU 는 또한 \co{rcu_flip_flag} 와 \co{rcu_mb_flag} per-CPU 변수들을 갖고
있습니다.
\co{rcu_flip_flag} 변수는 각 grace-period stage 의 시작을 동기화 시키는 데에
사용됩니다: 일단 특정 CPU 가 \co{rcu_flip_flag} 에 응답했다면, 이제 과거의
grace-period stage 에 연관된 \co{rcu_flip} 배열의 원소의 값을 증가시키는걸
중단해야 합니다.
이 카운터의 값 (\co{rcu_ctrlblk.completed}) 을 증가시키는 CPU 는 각 CPU 의
\co{rcu_mb_flag} 의 값을 \co{rcu_flipped} 로 바꿉니다만, 특정 \co{rcu_mb_flag}
는 연관된 CPU 에 의해서만 \co{rcu_flip_seen} 으로 되바뀔 겁니다.
\iffalse

Each CPU also maintains \co{rcu_flip_flag} and
\co{rcu_mb_flag} per-CPU variables.
The \co{rcu_flip_flag} variable is used to synchronize the
start of each grace-period stage: once a given CPU has responded
to its \co{rcu_flip_flag}, it must refrain from incrementing
the \co{rcu_flip} array element that now corresponds to
the old grace-period stage.
The CPU that advances the counter (\co{rcu_ctrlblk.completed})
changes the value of each CPU's \co{rcu_mb_flag} to
\co{rcu_flipped}, but a given \co{rcu_mb_flag}
may be changed back to \co{rcu_flip_seen} only by
the corresponding CPU.
\fi

\co{rcu_mb_flag} 변수는 각 CPU 가 각 grace-period stage 의 끝에서 메몰
비래이러르 실행하도록 강제하는데에 사용됩니다.
이런 메모리 배리어들은 주어진 grace-period stage 에서 끝나는 RCU read-side
크리티컬 섹션들로부터의 메모리 접근이 이 stage 의 종료 전으로 순서잡힐 것을
보장하는데 필요합니다.
이 방법은 RCU read-side 크리티컬 섹션의 시작과 끝에 비싼 메모리 배리어를 실제로
수행하지 않고도 수행한 것과 같은 효과를 얻게 해줍니다.
\co{rcu_mb_flag} 는 과거의 것들의 카운터의 합이 0이 되는 것을 파악하는 CPU 에
의해 \co{rcu_mb_needed} 로 설정됩니다만, 해당 \co{rcu_mb_flag} 는 연관된 CPU 에
의해서만, 메모리 배리어를 수행한 후에만 \co{rcu_mb_done} 으로 되돌려집니다.
\iffalse

The \co{rcu_mb_flag} variable is used to force each CPU to
execute a memory barrier at the end of each grace-period stage.
These memory barriers are required to ensure that memory accesses from
RCU read-side critical sections ending in a given grace-period stage
are ordered before the end of that stage.
This approach gains the benefits memory barriers at the
beginning and end of each RCU read-side critical section without
having to actually execute all those costly barriers.
The \co{rcu_mb_flag} is set to \co{rcu_mb_needed} by
the CPU that detects that the sum of the old counters is zero,
but a given \co{rcu_mb_flag} is changed back to
\co{rcu_mb_done} only by the corresponding CPU, and even
then only after executing a memory barrier.
\fi

\subsubsection{Data Structures}
\label{app:rcuimpl:Data Structures}

이 섹션은 preemptible RCU 의 주요 데이터 구조인
\co{rcu_ctrlblk}, \co{rcu_data}, \co{rcu_flipctr},
\co{rcu_try_flip_state}, \co{rcu_try_flip_flag}, 그리고
\co{rcu_mb_flag} 를 설명합니다.
\iffalse

This section describes preemptible RCU's major data structures, including
\co{rcu_ctrlblk}, \co{rcu_data}, \co{rcu_flipctr},
\co{rcu_try_flip_state}, \co{rcu_try_flip_flag}, and
\co{rcu_mb_flag}.
\fi

\paragraph{{\tt rcu\_ctrlblk}}
\label{app:rcuimpl:rcu_ctrlblk}

\co{rcu_ctrlblk} 구조체는 전역적으로, grace-period 처리를 보호하는 락
(\co{filplock}) 과 global grace-period 카운터 (\co{completed}) 를 보호하는 락을
잡고 수정됩니다.
\co{completed} 의 가장 아래쪽 bit 은 \co{rcu_read_lock()} 이 어떤 카운터 집합의
값을 증가시킬지 결정하는데 사용됩니다.
\iffalse

The \co{rcu_ctrlblk} structure is global, and holds the lock
that protects grace-period processing (\co{fliplock}) as well
as holding the global grace-period counter (\co{completed}).
The least-significant bit of \co{completed} is used by
\co{rcu_read_lock()} to select which set of counters to increment.
\fi

\paragraph{{\tt rcu\_data}}
\label{app:rcuimpl:rcu_data}

\co{rcu_data} 구조체는 per-CPU 구조체로, 다음과 같은 필드들을 갖습니다:
\iffalse

The \co{rcu_data} structure is a per-CPU structure, and
contains the following fields:
\fi

\begin{itemize}
\item	\co{lock} 은 이 구조체의 나머지 필드들을 보호합니다.
\item	\co{completed} 는 CPU-local 한 활동들을 \co{rcu_ctrlblk} 의 글로벌
	카운터들과 동기화 시키는데에 사용됩니다.
\item	\co{waitlistcount} 는 비어있지 않은 wait-list 의 수를 세는데에
	사용됩니다.
	이 필드는 이 CPU 가 처리해야할 RCU 에 관련된 일을 가지고 있는지
	파악하는걸 돕는데에 \co{rcu_pending()} 에 의해 사용됩니다.
\item	\co{nextlist}, \co{nextail}, \co{waitlist},
	\co{waittail}, \co{donelist}, 그리고
	\co{donetail} 은 grace period 의 종료 시점에 호출되기를 기다리고 있는
	RCU 콜백들로 구성된 리스트들을 형성합니다.
	각각의 리스트는 tail 포인터를 가지고 있어서, $O\left(1\right)$ 삽입을
	허용합니다.
	이 RCU 콜백들은 이 리스트들을 통해 아래에 보여진 것처럼 흘러갑니다.
\item	\co{rcupreempt_trace} 는 통계를 누적합니다.
\iffalse

\item	\co{lock} guards the remaining fields in this structure.
\item	\co{completed} is used to synchronize CPU-local
	activity with the global counter in \co{rcu_ctrlblk}.
\item	\co{waitlistcount} is used to maintain a count of the
	number of non-empty wait-lists.
	This field is used by \co{rcu_pending()} to help determine
	if this CPU has any RCU-related work left to be done.
\item	\co{nextlist}, \co{nextail}, \co{waitlist},
	\co{waittail}, \co{donelist}, and
	\co{donetail} form lists containing
	RCU callbacks that are waiting for invocation at the end
	of a grace period.
	Each list has a tail pointer, allowing $O\left(1\right)$ appends.
	The RCU callbacks flow through these lists as shown below.
\item	\co{rcupreempt_trace} accumulates statistics.
\fi
\end{itemize}

\begin{figure}[htb]
\centering
\resizebox{1.5in}{!}{\includegraphics{appendix/rcuimpl/RCUpreemptLists}}
\caption{Preemptible RCU Callback Flow}
\label{app:rcuimpl:Preemptible RCU Callback Flow}
\end{figure}

Figure~\ref{app:rcuimpl:Preemptible RCU Callback Flow}
는 RCU 콜백들이 \co{rcu_data} 구조체의 리스트들을 \co{call_rcu()} 를 통한
생성부터 \co{rcu_process_callbacks()} 를 통한 호출까지 어떻게 흘러가는지
보입니다.
파란색 화살표는 각각 grace-period state machine 을 통한 이동을 나타내는데, 뒤의
섹션에서 이에 대해 설명합니다.
\iffalse

Figure~\ref{app:rcuimpl:Preemptible RCU Callback Flow}
shows how RCU callbacks flow through a given
\co{rcu_data} structure's lists, from creation by
\co{call_rcu()} through invocation by
\co{rcu_process_callbacks()}.
Each blue arrow represents one pass by the grace-period state machine,
which is described in a later section.
\fi



\paragraph{{\tt rcu\_flipctr}}
\label{app:rcuimpl:rcu_flipctr}

앞에서도 이야기했듯이, \co{rcu_flipctr} per-CPU 카운터 배열은 RCU read-side
크리티컬 섹션들을 추적하는 카운터 쌍들을 담습니다.
이 배열의 어떤 카운터든 음수가 될 수 있는데, 예를 들면 한 task 가 RCU read-side
크리티컬 센션 내에서 다른 CPU 로 옮겨가거나 하는 경우입니다.
하지만, 이 카운터들의 값의 합은 연관된 grace period 동안은 양수로 유지될
것이며, 이 grace period 의 종료 시점에서는 0이 될겁니다.
\iffalse

As noted earlier, the \co{rcu_flipctr}
per-CPU array of counters contains the
counter pairs that track outstanding RCU read-side critical sections.
Any given counter in this array can go negative, for example, when
a task is migrated to a different CPU in the middle of an RCU
read-side critical section.
However, the sum of the counters will
still remain positive throughout the corresponding grace period, and will
furthermore go to zero at the end of that grace period.
\fi

\paragraph{{\tt rcu\_try\_flip\_state}}
\label{app:rcuimpl:rcu_try_flip_state}

\co{rcu_try_flip_state} 변수는 다음 센션에서 설명하는대로 grace-period state
machine 의 현재 상태를 추적합니다.
\iffalse

The \co{rcu_try_flip_state} variable tracks the current state of
the grace-period state machine, as described in the next section.
\fi

\paragraph{{\tt rcu\_try\_flip\_flag}}
\label{app:rcuimpl:rcu_try_flip_flag}

\co{rcu_try_flip_flag} per-CPU 변수는 grace-period 캉누터가 최근에 그 값을
증가시킨데 연관된 CPU 를 알리며 해당 CPU 의 확인을 기록하기도 합니다.
일단 어떤 CPU 가 카운터 뒤집기를 확인하면, 해당 CPU 에서 \co{rcu_read_lock()}
에 의해 취해지는 후속의 동작들은 해당 grace-period 카운터의 새로운 값을 가져야
하는데, 특히 \co{rcu_read_lock()} 내에서 \co{rcu_flipctr} 의 값을 증가시킬 때가
그렇습니다.
\iffalse

The \co{rcu_try_flip_flag} per-CPU variable alerts the corresponding
CPU that the grace-period counter has recently been incremented, and
also records that CPU's acknowledgment.
Once a given CPU has acknowledged the counter flip, all subsequent actions
taken by \co{rcu_read_lock()} on that CPU must account for the
new value of the grace-period counter, in particular, when incrementing
\co{rcu_flipctr} in \co{rcu_read_lock()}.
\fi

\paragraph{{\tt rcu\_mb\_flag}}
\label{app:rcuimpl:rcu_mb_flag}

\co{rcu_mb_flag} per-CPU 변수는 grace-period state machine 이 진행될 수 있도록
하기 위해 메모리 배리어를 반드시 수행해야 하는, 연관된 CPU 를 알리며, 또한 해당
CPU 의 확인을 기록합니다.
일단 어떤 CPU 가 메모리 배리어를 수행하면, RCU read-side 크리티컬 섹션 앞의
모든 메모리 오퍼레이션들은 연관된 grace period 뒤의 코드에 보여질 겁니다.
\iffalse

The \co{rcu_mb_flag} per-CPU variable alerts the corresponding
CPU that it must execute a memory barrier in order for the grace-period
state machine to proceed, and also records that CPU's acknowledgment.
Once a given CPU has executed its memory barrier, the memory operations
of all prior RCU read-side critical will be visible to any code sequenced
after the corresponding grace period.
\fi


\subsubsection{Grace-Period State Machine}
\label{app:rcuimpl:Grace-Period State Machine}

이 섹션은 grace-period state machine 에 의해 수행되는 state 들에 대한 개괄을
제공하고 관련된 코드들을 살펴봅니다.
\iffalse

This section gives an overview of the states executed by the grace-period
state machine, and then walks through the relevant code.
\fi

\paragraph{Grace-Period State Machine Overview}
\label{app:rcuimpl:Grace-Period State Machine Overview}

이 상태 (\co{rcu_try_flip_state} 에 기록되어짐) 는 다음과 같은 값들을 가질 수
있습니다:
\iffalse

The state (recorded in \co{rcu_try_flip_state})
can take on the following values:
\fi

\begin{itemize}
\item	\co{rcu_try_flip_idle_state}:  어떤 RCU grace-period 활동도 없기에
	Grace-period state machine 이 idle 상태에 있음.
	\co{rcu_ctrlblk.completed} grace-period 카운터는 이 상태로부터 빠져나갈
	때마다 값이 증가되고, 모든 per-CPU \co{rcu_flip_flag} 변수들은
	\co{rcu_flipped} 로 설정됩니다.
\item	\co{rcu_try_flip_waitack_state}:
	모든 CPU 들이 각자의 \co{rcu_flip_fflag} 변수를 \co{rcu_flip_seen} 으로
	설정함으로써 기존 state 의 증가를 보았음을 보고하기를 기다리는 상태.
	일단 모든 CPU 들이 이렇게 보고를 하게 되면, 우린 과거의 카운터 집합은
	더이상 값 증가할 수 없음을 알게 됩니다.
\item	\co{rcu_try_flip_waitack_state}:
	기존 카운터들의 값의 합이 0이 되길 기다리는 상태.
	일단 카운터들의 값의 합이 0이 되면, 모든 per-CPU \co{rcu_mb_flag}
	변수들은 \co{rcu_mb_needed} 로 설정됩니다.
\item	\co{rcu_try_flip_waitmb_state}:
	모든 CPU 들이 각자의 \co{rcu_mb_flag} 변수의 값을 \co{rcu_mb_done} 으로
	설정함으로써 메모리 배리어 인스트럭션을 수행했음을 알리기를 기다리는
	상태.
	일단 모든 CPU 들이 메모리 배리어 인스트럭션을 수행하면, 연관된 grace
	period 의 시작 전에 시작된 read-side 크리티컬 섹션에 의해 만들어진
	변경사항은 모든 CPU 들이 볼 수 있을 것임이 완화된 순서규칙의 기계에서도
	보장됩니다.
\iffalse

\item	\co{rcu_try_flip_idle_state}:  the grace-period state
	machine is idle due to there being no RCU grace-period activity.
	The \co{rcu_ctrlblk.completed} grace-period counter
	is incremented upon exit from this state, and all of the
	per-CPU \co{rcu_flip_flag} variables are set
	to \co{rcu_flipped}.
\item	\co{rcu_try_flip_waitack_state}:
	waiting for all CPUs to acknowledge that they have seen the
	previous state's increment, which they do by setting their
	\co{rcu_flip_flag} variables to \co{rcu_flip_seen}.
	Once all CPUs have so acknowledged, we know that the old
	set of counters can no longer be incremented.
\item	\co{rcu_try_flip_waitzero_state}:
	waiting for the old counters to sum to zero.
	Once the counters sum to zero, all of the per-CPU
	\co{rcu_mb_flag} variables are set to
	\co{rcu_mb_needed}.
\item	\co{rcu_try_flip_waitmb_state}:
	waiting for all CPUs to execute a memory-barrier instruction,
	which they signify by setting their \co{rcu_mb_flag}
	variables to \co{rcu_mb_done}.
	Once all CPUs have done so, all CPUs are guaranteed to see
	the changes made by any RCU read-side critical section that
	started before the beginning of the corresponding grace period,
	even on weakly ordered machines.
\fi
\end{itemize}

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/RCUpreemptStates}}
\caption{Preemptible RCU State Machine}
\label{app:rcuimpl:Preemptible RCU State Machine}
\end{figure}

Grace period state machine 은
Figure~\ref{app:rcuimpl:Preemptible RCU State Machine}
에 보여진 것처럼 이 상태들을 순차적으로 돌아갑니다.
\iffalse

The grace period state machine cycles through these states sequentially,
as shown in
Figure~\ref{app:rcuimpl:Preemptible RCU State Machine}.
\fi

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/RCUpreemptTimeline}}
\caption{Preemptible RCU State Machine Timeline}
\label{app:rcuimpl:Preemptible RCU State Machine Timeline}
\end{figure}

Figure~\ref{app:rcuimpl:Preemptible RCU State Machine Timeline}
는 이 state machine 이 어떻게 시간의 흐름에 따라 동작하는지 보입니다.
상태들은 이 그림의 왼쪽에 보여져 있고 연관된 이벤트들이 시간의 흐름에 따라
보여져 있는데, 시간은 아래쪽으로 흐르고 있습니다.
우리는 뒤의 섹션에서 이 알고리즘을 검증할 때에 이 그림을 상세히 설명할 겁니다.

그 전까지는, 여기에 알아둘 중요한 사항들이 있으니 알아두시기 바랍니다:
\iffalse

Figure~\ref{app:rcuimpl:Preemptible RCU State Machine Timeline}
shows how the state machine operates over time.
The states are shown along the figure's left-hand side and the relevant events
are shown along the timeline, with time proceeding in the downward direction.
We will elaborate on this figure when we validate the algorithm in
a later section.

In the meantime, here are some important things to note:
\fi

\begin{enumerate}
\item	\co{rcu_ctrlblk.completed} 카운터의 값 증가는 파란 타원으로 표시된
	것처럼 다른 시간에 다른 CPU 들에 의해 관측되어질 수 있습니다.  하지만,
	해당 CPU 가 이 값 증가를 알아챈 다음에는, 새로운 카운터를 사용해야
	합니다.
	따라서, 일단 모든 CPU 들이 알아챘음을 알린다면, 과거의 카운터의 값은
	감소만 될 수 있습니다.
\item	특정 CPU 는 이 카운터의 값 증가를 알기 전까지만 콜백 리스트들을
	진행시킬 수 있습니다.
\item	파란 타원은 메모리 오퍼레이션 재배치가 다른 CPU 들이 값 증가를 다른
	시간에 볼 수 있음을 알립니다.
	이는 특정 CPU 는 어떤 다른 CPU 가 이 카운터의 새로운 값을 해당 카운터가
	진짜로 증가하기 전에 사용해서 이 구간을 건너뛰었다고 믿을 수도 있음을
	의미합니다.
	실제로, 이론상으로는, 특정 CPU 는 \co{rcu_ctrlblk.completed} 카운터의
	다음의 값 증가를 기존의 메모리 배리어가 쳐진 시점만큼 빠른 시간에
	볼수도 있습니다.
	(이 문장은 매우 부정확함을 알아두시기 바랍니다.
	메모리 배리어에 대한 올바름의 증명을 하고자 한다면,
	Appendix~\ref{app:rcuimpl:Formal Validation} 를 보기 바랍니다.
\iffalse

\item	The increment of the \co{rcu_ctrlblk.completed} counter
	might be observed at different times by different CPUs, as
	indicated by the blue oval.  However, after a given
	CPU has acknowledged the increment, it is required to
	use the new counter.
	Therefore, once all CPUs have acknowledged, the old counter
	can only be decremented.
\item	A given CPU advances its callback lists just before
	acknowledging the counter increment.
\item	The blue oval represents the fact that memory reordering
	might cause different CPUs to see the increment at
	different times.
	This means that a given CPU might believe that some
	other CPU has jumped the gun, using the new value of the counter
	before the counter was actually incremented.
	In fact, in theory, a given CPU might see the next increment of the
	\co{rcu_ctrlblk.completed} counter as early as
	the last preceding memory barrier.
	(Note well that this sentence is very imprecise.
	If you intend to do correctness proofs involving memory barriers,
	please see Appendix~\ref{app:rcuimpl:Formal Validation}.
\fi
\item	\co{rcu_read_lock()} 은 어떤 메모리 배리어도 포함하고 있지 않기 때문에,
	연관된 RCU read-side 크리티컬 섹션들은 해당 CPU 에 의해
	\co{rcu_read_unlock()} 을 뒤따르도록 재배치 될수도 있습니다.
	따라서, 이 RCU read-side 크리티컬 섹션들의 행동들이 실제로 완료되었음을
	보장하기 위해 메모리 배리어가 필요합니다.
\item	이어서 보게 되겠지만, 서로 다른 CPU 들이 카운터의 flip 을 서로 다른
	시간에 볼 수 있다는 사실은 state machine 을 통한 한번의 횡단은 grace
	period 에 충분치 않음을 의미합니다: 여러번의 횡단이 필요합니다.
\iffalse

\item	Because \co{rcu_read_lock()} does not contain any
	memory barriers, the corresponding RCU read-side critical
	sections might be reordered by the CPU to follow the
	\co{rcu_read_unlock()}.
	Therefore, the memory barriers are required to ensure
	that the actions of the RCU read-side critical sections
	have in fact completed.
\item	As we will see, the fact that different CPUs can see the
	counter flip happening at different times means that a
	single trip through the state machine is not sufficient
	for a grace period: multiple trips are required.
\fi
\end{enumerate}

\paragraph{Grace-Period State Machine Walkthrough}
\label{app:rcuimpl:Grace-Period State Machine Walkthrough}

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 void rcu_check_callbacks(int cpu, int user)
  2 {
  3   unsigned long flags;
  4   struct rcu_data *rdp = RCU_DATA_CPU(cpu);
  5
  6   rcu_check_mb(cpu);
  7   if (rcu_ctrlblk.completed == rdp->completed)
  8     rcu_try_flip();
  9   spin_lock_irqsave(&rdp->lock, flags);
 10   RCU_TRACE_RDP(rcupreempt_trace_check_callbacks, rdp);
 11   __rcu_advance_callbacks(rdp);
 12   spin_unlock_irqrestore(&rdp->lock, flags);
 13 }
\end{verbatim}
}
\caption{{\tt rcu\_check\_callbacks()} Implementation}
\label{fig:app:rcuimpl:rcu_check_callbacks() Implementation}
\end{figure}

이 섹션은 scheduling-clock 인터럽트에서 irq (그리고 preemption) 가 비활성화된
채로 \co{rcu_check_callbacks()} 를 호출하는, RCU grace-period state machine 을
구현하는 C 코드를 살펴봅니다.
이 함수는
Figure~\ref{fig:app:rcuimpl:rcu_check_callbacks() Implementation}
에 보여지는 것처럼 구현되어 있습니다.
Line~4 는 현재의 CPU 에 연관된 \co{rcu_data} 구조체를 골라내고 line~6 는 이 CPU
가 state machine 을 \co{rcu_try_flip_waitmb_state} 상태에서 진행시키기 위해
메모리 배리어를 실행해야 하는지를 체크합니다.
Line~7 은 이 CPU 가 이미 현재 grace-period stage number 를 알고 있는지 보고,
그렇다면 line~8 에서 이 state machine 을 진행시킵니다.
Line~9 와 12 는 \co{rcu_data} 의 락을 잡고, line~11 에서는 적절하다면 콜백들을
수행시킵니다.
Line~10 에서는 \co{CONFIG_RCU_TRACE} 가 활성화 되어 있다면 RCU tracing 을 위한
통계들을 업데이트합니다.
\iffalse

This section walks through the C code that implements the RCU
grace-period state machine, which is invoked from the scheduling-clock
interrupt, which invokes \co{rcu_check_callbacks()} with
irqs (and thus also preemption) disabled.
This function is implemented as shown in
Figure~\ref{fig:app:rcuimpl:rcu_check_callbacks() Implementation}.
Line~4 selects the \co{rcu_data} structure corresponding
to the current CPU, and line~6 checks to see if this CPU needs
to execute a memory barrier to advance the state machine out of the
\co{rcu_try_flip_waitmb_state} state.
Line~7 checks to see if this CPU is already aware of the
current grace-period stage number, and line~8 attempts to advance the
state machine if so.
Lines~9 and 12 hold the \co{rcu_data}'s lock, and
line~11 advances callbacks if appropriate.
Line~10 updates RCU tracing statistics, if enabled via
\co{CONFIG_RCU_TRACE}.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 static void rcu_check_mb(int cpu)
  2 {
  3   if (per_cpu(rcu_mb_flag, cpu) == rcu_mb_needed) {
  4     smp_mb();
  5     per_cpu(rcu_mb_flag, cpu) = rcu_mb_done;
  6   }
  7 }
\end{verbatim}
}
\caption{{\tt rcu\_check\_mb()} Implementation}
\label{fig:app:rcuimpl:rcu_check_mb() Implementation}
\end{figure}

\co{rcu_check_mb()} 함수는
Figure~\ref{fig:app:rcuimpl:rcu_check_mb() Implementation}
에 보여진 것처럼 필요하면 메모리 배리어를 수행합니다.
Line~3 는 이 CPU 가 메모리 배리어를 수행해야 하는지 체크하고, 만약 그렇다면
line~4 에서 메모리 배리어를 실행하고 line~5 에서 state machine 을 알립니다.
이 메모리 배리어는 \co{rcu_mb_flag} 의 새로운 값을 보는 모든 CPU 는 이 CPU 에
의해 앞의 RCU read-side 크리티컬 섹션 안에서 수행된 메모리 오퍼레이션들을 보게
될 것을 보장함을 알아두시기 바랍니다.
\iffalse

The \co{rcu_check_mb()} function executes a memory barrier
as needed as shown in
Figure~\ref{fig:app:rcuimpl:rcu_check_mb() Implementation}.
Line~3 checks to see if this CPU needs to execute a memory barrier,
and, if so, line~4 executes one and line~5 informs the state
machine.
Note that this memory barrier ensures that any CPU that sees the new
value of \co{rcu_mb_flag} will also see the memory operations
executed by this CPU in any prior RCU read-side critical section.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 static void rcu_try_flip(void)
  2 {
  3   unsigned long flags;
  4
  5   RCU_TRACE_ME(rcupreempt_trace_try_flip_1);
  6   if (!spin_trylock_irqsave(&rcu_ctrlblk.fliplock, flags)) {
  7     RCU_TRACE_ME(rcupreempt_trace_try_flip_e1);
  8     return;
  9   }
 10   switch (rcu_try_flip_state) {
 11   case rcu_try_flip_idle_state:
 12     if (rcu_try_flip_idle())
 13       rcu_try_flip_state = rcu_try_flip_waitack_state;
 14     break;
 15   case rcu_try_flip_waitack_state:
 16     if (rcu_try_flip_waitack())
 17       rcu_try_flip_state = rcu_try_flip_waitzero_state;
 18     break;
 19   case rcu_try_flip_waitzero_state:
 20     if (rcu_try_flip_waitzero())
 21       rcu_try_flip_state = rcu_try_flip_waitmb_state;
 22     break;
 23   case rcu_try_flip_waitmb_state:
 24     if (rcu_try_flip_waitmb())
 25       rcu_try_flip_state = rcu_try_flip_idle_state;
 26   }
 27   spin_unlock_irqrestore(&rcu_ctrlblk.fliplock, flags);
 28 }
\end{verbatim}
}
\caption{{\tt rcu\_try\_flip()} Implementation}
\label{fig:app:rcuimpl:rcu_try_flip() Implementation}
\end{figure}

\co{rcu_try_flip()} 함수는
Figure~\ref{fig:app:rcuimpl:rcu_try_flip() Implementation}
에 보인 것처럼 RCU grace-period state machine 의 최고단계 구현을 합니다.
Line~6 는 global RCU state-machine lock 을 획득하려 시도하고, 실패하면
리턴합니다.
Line~5 와 7 은 (\co{CONFIG_RCU_TRACE} 가 활성화 되어 있다면) RCU-tracing 통계를
조작합니다.
Line~10 부터 26 은 state machine 을 수행하는데, 각각 해당 state 에 맞는 함수를
수행시킵니다.
그런 함수 각각은 해당 state 가 진행되야 한다면 1을, 그렇지 않다면 0을
리턴합니다.
원칙적으로, 다음 state 를 곧바로 수행될 수 있지만, 실제로는 응답시간을 줄이기
위해 그렇게 하지 않습니다.
마지막으로, line~27 에서는 line~6 에서 획득했던 global RCU state-machine lock
을 해제합니다.
\iffalse

The \co{rcu_try_flip()} function implements the top level of
the RCU grace-period state machine, as shown in
Figure~\ref{fig:app:rcuimpl:rcu_try_flip() Implementation}.
Line~6 attempts to acquire the global RCU state-machine lock,
and returns if unsuccessful.
Lines;~5 and 7 accumulate RCU-tracing statistics (again, if
\co{CONFIG_RCU_TRACE} is enabled).
Lines~10 through 26 execute the state machine,
each invoking a function specific to that state.
Each such function returns 1 if the state needs to be advanced and
0 otherwise.
In principle, the next state could be executed immediately,
but in practice we choose not to do so in order to reduce latency.
Finally, line~27 releases the global RCU state-machine lock
that was acquired by line~6.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 static int rcu_try_flip_idle(void)
  2 {
  3   int cpu;
  4
  5   RCU_TRACE_ME(rcupreempt_trace_try_flip_i1);
  6   if (!rcu_pending(smp_processor_id())) {
  7     RCU_TRACE_ME(rcupreempt_trace_try_flip_ie1);
  8     return 0;
  9   }
 10   RCU_TRACE_ME(rcupreempt_trace_try_flip_g1);
 11   rcu_ctrlblk.completed++;
 12   smp_mb();
 13   for_each_cpu_mask(cpu, rcu_cpu_online_map)
 14     per_cpu(rcu_flip_flag, cpu) = rcu_flipped;
 15   return 1;
 16 }
\end{verbatim}
}
\caption{{\tt rcu\_try\_flip\_idle()} Implementation}
\label{fig:app:rcuimpl:rcu_try_flip_idle() Implementation}
\end{figure}

\co{rcu_try_flip_idle()} 함수는 RCU grace-period state machine 이 idle 상태일
때 호출되며, 따라서 이 state machine 이 필요할 때 시작되도록 해줘야 하는 책임이
있습니다.
그 코드는
Figure~\ref{fig:app:rcuimpl:rcu_try_flip_idle() Implementation}
에 보여져 있습니다.
Line~6 는 이 CPU 에 남아있는 RCU grace-period 작업이 있는지 체크하고, 그렇지
않다면 top-level state machine 에게 idle 상태로 남아있으라고 이야기한채 line~8
에서 빠져나옵니다.
그렇지 않고 할 일이 있다면, line~11 에서 grace-period stage 카운터의 값을
증가시키고, line~12 에서 CPU 들이 새로운 카운터를 보아달라는 요청을 받기 전에
그 카운터를 봄을 보장하기 위해 메모리 배리어를 수행하고, line~13 과 14 에서
모든 online CPU 의 \co{rcu_flip_flag} 를 설정합니다.
마지막으로, line~15 에서 top-level state machine 에게 다음 state 로 넘어가라고
이야기를 합니다.
\iffalse

The \co{rcu_try_flip_idle()} function is called when the
RCU grace-period state machine is idle, and is thus responsible for
getting it started when needed.
Its code is shown in
Figure~\ref{fig:app:rcuimpl:rcu_try_flip_idle() Implementation}.
Line~6 checks to see if there is any RCU grace-period work
pending for this CPU, and if not, line~8 leaves, telling
the top-level state machine to remain in the idle state.
If instead there is work to do, line~11 increments the
grace-period stage counter, line~12 does a memory barrier
to ensure that CPUs see the new counter before they see the
request to acknowledge it, and lines~13 and 14 set all of
the online CPUs' \co{rcu_flip_flag}.
Finally, line~15 tells the top-level state machine to
advance to the next state.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 static int rcu_try_flip_waitack(void)
  2 {
  3   int cpu;
  4
  5   RCU_TRACE_ME(rcupreempt_trace_try_flip_a1);
  6   for_each_cpu_mask(cpu, rcu_cpu_online_map)
  7     if (per_cpu(rcu_flip_flag, cpu) != rcu_flip_seen) {
  8       RCU_TRACE_ME(rcupreempt_trace_try_flip_ae1);
  9       return 0;
 10     }
 11   smp_mb();
 12   RCU_TRACE_ME(rcupreempt_trace_try_flip_a2);
 13   return 1;
 14 }
\end{verbatim}
}
\caption{{\tt rcu\_try\_flip\_waitack()} Implementation}
\label{fig:app:rcuimpl:rcu_try_flip_waitack() Implementation}
\end{figure}

Figure~\ref{fig:app:rcuimpl:rcu_try_flip_waitack() Implementation}
에 보인 \co{rcu_try_flip_waitack()} 함수는 모든 online CPU 들이 카운터 뒤집기
(``값 증가'' 라고도 말할 수 있지만 \co{rcu_read_lock()} 은 \co{rcu_flipctr}
배열을 인덱스 하는데에 사용하는 아래쪽 bit 을 \emph{실제로} 뒤집기에 ``뒤집기''
라고 불립니다) 를 보았는지 체크합니다.
만약 그렇다면, top-level grace-period state machine 에게 다음 state 로
넘어가라고 이야기합니다.

Line~6 는 모든 online CPU 들을 보고, line~7 은 현재의 CPU 가 마지막 카운터
뒤집기를 알아차렸는지 봅니다.
그렇지 않다면, line~9 에서 top-level grace-period state machine 에게 이 state
에 남아있으라고 이야기합니다.
그렇지 않고, 모든 online CPU 들이 알아차렸다면, line~11 에서 마지막 CPU 가
알아아차렸음을 이야기하기 전에 0을 체크하지 않을 것을 보장하기 위해 메모리
배리어를 칩니다.
이는 의심스럽게 보일 수 있습니다만, CPU 설계자들은 가끔 이상한 짓거리를 하기도
합니다.
마지막으로, line~13 은 top-level grace-period state machine 에게 다음 state 로
넘어가라고 이야기합니다.
\iffalse

The \co{rcu_try_flip_waitack()} function, shown in
Figure~\ref{fig:app:rcuimpl:rcu_try_flip_waitack() Implementation},
checks to see
if all online CPUs have acknowledged the counter flip (AKA ``increment'',
but called ``flip'' because the bottom bit, which \co{rcu_read_lock()}
uses to index the \co{rcu_flipctr} array, \emph{does} flip).
If they have, it tells the top-level grace-period state machine to
move to the next state.

Line~6 cycles through all of the online CPUs, and line~7
checks to see if the current such CPU has acknowledged the last counter
flip.
If not, line~9 tells the top-level grace-period state machine to
remain in this state.
Otherwise, if all online CPUs have acknowledged, then line~11
does a memory barrier to ensure that we don't check for zeroes before
the last CPU acknowledges.
This may seem dubious, but CPU designers have sometimes done strange
things.
Finally, line~13 tells the top-level grace-period state machine
to advance to the next state.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 static int rcu_try_flip_waitzero(void)
  2 {
  3   int cpu;
  4   int lastidx = !(rcu_ctrlblk.completed & 0x1);
  5   int sum = 0;
  6
  7   RCU_TRACE_ME(rcupreempt_trace_try_flip_z1);
  8   for_each_possible_cpu(cpu)
  9     sum += per_cpu(rcu_flipctr, cpu)[lastidx];
 10   if (sum != 0) {
 11     RCU_TRACE_ME(rcupreempt_trace_try_flip_ze1);
 12     return 0;
 13   }
 14   smp_mb();
 15   for_each_cpu_mask(cpu, rcu_cpu_online_map)
 16     per_cpu(rcu_mb_flag, cpu) = rcu_mb_needed;
 17   RCU_TRACE_ME(rcupreempt_trace_try_flip_z2);
 18   return 1;
 19 }
\end{verbatim}
}
\caption{{\tt rcu\_try\_flip\_waitzero()} Implementation}
\label{fig:app:rcuimpl:rcu_try_flip_waitzero() Implementation}
\end{figure}

Figure~\ref{fig:app:rcuimpl:rcu_try_flip_waitzero() Implementation}
에 보인 \co{rcu_try_flip_waitzero()} 함수는 모든 이전부터 존재한 RCU read-side
크리티컬 섹션들이 완료되었는지 체크하고, 만약 그렇다면 state machine 에게
진행하라고 이야기합니다.
Line~8 과 9 는 카운터들의 값의 합을 구하고, line~10 은 그 결과가 0인지
확인하고, 만약 그렇지 않다면 line~12 에서 state machine 에게 현재 상태 그대로
유지하라고 이야기합니다.
그렇지 않다면, line~14 에서 어떤 CPU 도 자신이 마지막 RCU read-side 크리티컬
섹션을 빠져나오기 전에 뒤따르는 메모리 배리어 호출을 볼 수 없을 것을 보장하기
위해 메모리 배리어를 호출합니다.
그런 일이 있을 가능성이 희박해 보이겠지만, 다시 말하건대 CPU 설계자들은 좀
이상한 짓을 해왔고, 사실 그것이 빠른 수행 방법입니다.
Line~15 와 16 은 모든 online CPU 의 \co{rcu_mb_flag} 변수의 값을 설정하고,
line~18 에서 state machine 에게 다음 상태로 진행하라고 이야기합니다.
\iffalse

The \co{rcu_try_flip_waitzero()} function, shown in
Figure~\ref{fig:app:rcuimpl:rcu_try_flip_waitzero() Implementation},
checks to see if
all pre-existing RCU read-side critical sections have completed,
telling the state machine to advance if so.
Lines~8 and 9 sum the counters, and line~10 checks
to see if the result is zero, and, if not, line~12 tells
the state machine to stay right where it is.
Otherwise, line~14 executes a memory barrier to ensure that
no CPU sees the subsequent call for a memory barrier before it
has exited its last RCU read-side critical section.
This possibility might seem remote, but again, CPU designers have
done stranger things, and besides, this is anything but a fastpath.
Lines~15 and 16 set all online CPUs' \co{rcu_mb_flag}
variables, and line~18 tells the state machine to advance to
the next state.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 static int rcu_try_flip_waitmb(void)
  2 {
  3   int cpu;
  4
  5   RCU_TRACE_ME(rcupreempt_trace_try_flip_m1);
  6   for_each_cpu_mask(cpu, rcu_cpu_online_map)
  7     if (per_cpu(rcu_mb_flag, cpu) != rcu_mb_done) {
  8       RCU_TRACE_ME(rcupreempt_trace_try_flip_me1);
  9       return 0;
 10     }
 11   smp_mb();
 12   RCU_TRACE_ME(rcupreempt_trace_try_flip_m2);
 13   return 1;
 14 }
\end{verbatim}
}
\caption{{\tt rcu\_try\_flip\_waitmb()} Implementation}
\label{fig:app:rcuimpl:rcu_try_flip_waitmb() Implementation}
\end{figure}

Figure~\ref{fig:app:rcuimpl:rcu_try_flip_waitmb() Implementation}
에 보인 \co{rcu_try_flip_waitmb()} 함수는 모든 online CPU 들이 요청된 메모리
배리어를 수행했는지 체크하고, 만약 그렇다면 state machine 에게 진행하라고
이야기합니다.
Line~6 과 7 은 각각의 online CPU 에 대해 각각 필요한 메모리 배리어를 쳤는지
확인하고, 만약 그렇지 않다면 line~9 에서 state machine 에게 진행하지 말라고
이야기합니다.
그렇지 않고, 모든 CPU 들이 메모리 배리어를 수행했다면, line~11 에서 모든 RCU
콜백 호출이 모든 메모리 배리어들을 뒤따른다는 걸 보장하기 위해 메모리 배리어를
실행하고, line~13 은 state machine 에게 진행하라고 이야기 합니다.
\iffalse

The \co{rcu_try_flip_waitmb()} function, shown in
Figure~\ref{fig:app:rcuimpl:rcu_try_flip_waitmb() Implementation},
checks to see
if all online CPUs have executed the requested memory barrier,
telling the state machine to advance if so.
Lines~6 and 7 check each online CPU to see if it has
done the needed memory barrier, and if not, line~9 tells
the state machine not to advance.
Otherwise, if all CPUs have executed a memory barrier, line~11
executes a memory barrier to ensure that any RCU callback invocation
follows all of the memory barriers, and line~13 tells the
state machine to advance.
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 static void __rcu_advance_callbacks(struct rcu_data *rdp)
  2 {
  3   int cpu;
  4   int i;
  5   int wlc = 0;
  6
  7   if (rdp->completed != rcu_ctrlblk.completed) {
  8     if (rdp->waitlist[GP_STAGES - 1] != NULL) {
  9       *rdp->donetail = rdp->waitlist[GP_STAGES - 1];
 10       rdp->donetail = rdp->waittail[GP_STAGES - 1];
 11       RCU_TRACE_RDP(rcupreempt_trace_move2done, rdp);
 12     }
 13     for (i = GP_STAGES - 2; i >= 0; i--) {
 14       if (rdp->waitlist[i] != NULL) {
 15         rdp->waitlist[i + 1] = rdp->waitlist[i];
 16         rdp->waittail[i + 1] = rdp->waittail[i];
 17         wlc++;
 18       } else {
 19         rdp->waitlist[i + 1] = NULL;
 20         rdp->waittail[i + 1] =
 21           &rdp->waitlist[i + 1];
 22       }
 23     }
 24     if (rdp->nextlist != NULL) {
 25       rdp->waitlist[0] = rdp->nextlist;
 26       rdp->waittail[0] = rdp->nexttail;
 27       wlc++;
 28       rdp->nextlist = NULL;
 29       rdp->nexttail = &rdp->nextlist;
 30       RCU_TRACE_RDP(rcupreempt_trace_move2wait, rdp);
 31     } else {
 32       rdp->waitlist[0] = NULL;
 33       rdp->waittail[0] = &rdp->waitlist[0];
 34     }
 35     rdp->waitlistcount = wlc;
 36     rdp->completed = rcu_ctrlblk.completed;
 37   }
 38   cpu = raw_smp_processor_id();
 39   if (per_cpu(rcu_flip_flag, cpu) == rcu_flipped) {
 40     smp_mb();
 41     per_cpu(rcu_flip_flag, cpu) = rcu_flip_seen;
 42     smp_mb();
 43   }
 44 }
\end{verbatim}
}
\caption{{\tt \_\_rcu\_advance\_callbacks()} Implementation}
\label{fig:app:rcuimpl:__rcu_advance_callbacks() Implementation}
\end{figure}

Figure~\ref{fig:app:rcuimpl:__rcu_advance_callbacks() Implementation}
에 보인 \co{__rcu_advance_callbacks()} 함수는 콜백들을 진행하고 카운터 뒤집기를
확인해줍니다.
Line~7 은 글로벌한 \co{rcu_ctrlblk.completed} 카운터가 마지막의 현재 CPU 에
의한 이 함수의 호출 이후로 값이 증가되었는지 체크합니다.
그렇지 않다면, 콜백들은 진행될 수 (line~8-37) 없습니다.
그렇다면, line~8 부터 37 은 리스트의 콜백들을 진행시킵니다 (비어있지 않은
리스트의 갯수를 \co{wlc} 변수에 관리하면서).
어떤 경우든, line~38 부터 43 은 필요한 경우 카운터 뒤집기를 확인해줍니다.
\iffalse

The \co{__rcu_advance_callbacks()} function, shown in
Figure~\ref{fig:app:rcuimpl:__rcu_advance_callbacks() Implementation},
advances callbacks and acknowledges the counter flip.
Line~7 checks to see if the global \co{rcu_ctrlblk.completed}
counter has advanced since the last call by the current CPU to this
function.
If not, callbacks need not be advanced (lines~8-37).
Otherwise, lines~8 through 37 advance callbacks through the lists
(while maintaining a count of the number of non-empty lists in the
\co{wlc} variable).
In either case, lines~38 through 43 acknowledge the counter flip
if needed.
\fi

\QuickQuiz{}
	\co{__rcu_advance_callbacks()} 의 line~38-43 은 line~7-37 이 수행되지
	않음에도 수행될 수가 있다는 거죠?
	둘 다 카운터 뒤집기 직후에 수행되는데, 다른 시간이 아니지 않아요?
	\iffalse

	How is it possible for lines~38-43 of
	\co{__rcu_advance_callbacks()} to be executed when
	lines~7-37 have not?
	Won't they both be executed just after a counter flip, and
	never at any other time?
	\fi
\QuickQuizAnswer{
	다음과 같은 이벤트들을 생각해 보세요:
	\iffalse

	Consider the following sequence of events:
	\fi
	\begin{enumerate}
	\item	CPU 0 가 \co{rcu_try_flip_idle()} 의 line~5-12 를 수행합니다.
	\item	CPU 1 이 \co{__rcu_advance_callbacks()} 를 수행합니다.
		\co{rcu_ctrlblk.completed} 는 값이 증가되었으므로, line~7-37 이
		수행됩니다.
		하지만, \co{rcu_flip_flag} 변수들 중 어느것도 값이 설정되지
		않았으므로, line~38-43 은 수행되지 \emph{않습니다}.
	\item	CPU 0 가 \co{rcu_try_flip_idle()} 의 line~13-15 를 수행합니다.
	\item	후에, CPU 1 이 다시 \co{__rcu_advance_callbacks()} 를
		수행합니다.
		카운터는 이제 마지막 수행 이후로 값이 증가했습니다만,
		\co{rcu_flip_flag} 변수들은 모두 설정되어있으므로, line~38-43
		만이 수행됩니다.
	\iffalse

	\item	CPU 0 executes lines~5-12 of
		\co{rcu_try_flip_idle()}.
	\item	CPU 1 executes \co{__rcu_advance_callbacks()}.
		Because \co{rcu_ctrlblk.completed} has been
		incremented, lines~7-37 execute.
		However, none of the \co{rcu_flip_flag} variables
		have been set, so lines~38-43 do \emph{not} execute.
	\item	CPU 0 executes lines~13-15 of
		\co{rcu_try_flip_idle()}.
	\item	Later, CPU 1 again executes \co{__rcu_advance_callbacks()}.
		The counter has not been incremented since the earlier
		execution, but the \co{rcu_flip_flag} variables have
		all been set, so only lines~38-43 are executed.
	\fi
	\end{enumerate}
} \QuickQuizEnd


\subsubsection{Read-Side Primitives}
\label{app:rcuimpl:Read-Side Primitives}

이 섹션은 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 기능을 살펴보고,
이어서 어떻게 이 구현이 이 두 기능들이 메모리 배리어를 포함하지 않는다는 점을
어떻게 가능하게 했는지 이야기합니다.
\iffalse

This section examines the \co{rcu_read_lock()} and
\co{rcu_read_unlock()} primitives, followed by a
discussion of how this implementation deals with the fact
that these two primitives do not contain memory barriers.
\fi

\paragraph{{\tt rcu\_read\_lock()}}
\label{app:rcuimpl:rcu_read_lock()}

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 void __rcu_read_lock(void)
  2 {
  3   int idx;
  4   struct task_struct *t = current;
  5   int nesting;
  6
  7   nesting = ACCESS_ONCE(t->rcu_read_lock_nesting);
  8   if (nesting != 0) {
  9     t->rcu_read_lock_nesting = nesting + 1;
 10   } else {
 11     unsigned long flags;
 12
 13     local_irq_save(flags);
 14     idx = ACCESS_ONCE(rcu_ctrlblk.completed) & 0x1;
 15     ACCESS_ONCE(__get_cpu_var(rcu_flipctr)[idx])++;
 16     ACCESS_ONCE(t->rcu_read_lock_nesting) = nesting + 1;
 17     ACCESS_ONCE(t->rcu_flipctr_idx) = idx;
 18     local_irq_restore(flags);
 19   }
 20 }
\end{verbatim}
}
\caption{{\tt \_\_rcu\_read\_lock()} Implementation}
\label{fig:app:rcuimpl:__rcu_read_lock() Implementation}
\end{figure}

\co{rcu_read_lock()} 의 구현은
Figure~\ref{fig:app:rcuimpl:__rcu_read_lock() Implementation}
에 보여져 있습니다.
Line~7 은 이 task 의 RCU read-side 크리티컬 섹션 중첩 카운터를 가져옵니다.
Line~8 에서 이 카운터의 값이 0이 아니란 점이 밝혀지면, 우린 이미 바깥의
\co{rcu_read_lock()} 으로 보호되고 있는 것으로, 이 경우에는 line~9 에서 그냥 이
카운터의 값을 증가시킵니다.

하지만, 이게 가장 바깥의 \co{rcu_read_lock()} 이라면, 더 많은 작업이
필요합니다.
Line~13 과 18 은 그 사이의 코드가 preemption 되지도 않고 (grace period state
machine 을 수행시키는) scheduling-clock 인터럽트로 인터럽트 당하지도 않았다는
것을 보장하기 위해 irq 들을 막고 다시 풀어줍니다.
Line~14 는 grace-period 카운터를 얻어오고, line~15 에서 이 CPU 를 위한 현재
카운터의 값을 증가시키고, line~16 에서 중첩 카운터의 값을 증가시킨 후, line~17
에서 \co{rcu_read_unlock()} 이 연관된 카운터의 값을 감소시킬 수 있도록
기존/새로운 카운터 인덱스를 기록합니다.

\co{ACCESS_ONCE()} 매크로들은 컴파일러가 순서대로 액세스 코드를 만들어 내도록
강제합니다.
비록 이게 CPU 가 액세스들을 다른 CPU 의 관점으로부터 다르게 재배치 하는 것을
막지는 못하지만, 이 CPU에서 수행되는 NMI 와 SMI 핸들러들은 이 액세스들을
순서대로 볼 것을 보장해 줍니다.
이는 상당히 중요합니다:
\iffalse

The implementation of \co{rcu_read_lock()} is as shown in
Figure~\ref{fig:app:rcuimpl:__rcu_read_lock() Implementation}.
Line~7 fetches this task's RCU read-side critical-section nesting
counter.
If line~8 finds that this counter is non-zero,
then we are already protected by an outer
\co{rcu_read_lock()}, in which case line~9 simply increments
this counter.

However, if this is the outermost \co{rcu_read_lock()},
then more work is required.
Lines~13 and 18 suppress and restore irqs to ensure that the
intervening code is neither preempted nor interrupted by a
scheduling-clock interrupt (which runs the grace period state machine).
Line~14 fetches the grace-period counter,
line~15 increments the current counter for
this CPU, line~16 increments the nesting counter,
and line~17 records the old/new counter index so that
\co{rcu_read_unlock()} can decrement the corresponding
counter (but on whatever CPU it ends up running on).

The \co{ACCESS_ONCE()} macros force the compiler to
emit the accesses in order.
Although this does not prevent the CPU from reordering the accesses
from the viewpoint of other CPUs, it does ensure that NMI and
SMI handlers running on this CPU will see these accesses in order.
This is critically important:
\fi

\begin{enumerate}
\item	\co{idx} 로의 값 할당에 \co{ACCESS_ONCE()} 가 없다면, 컴파일러는: (a)
	로컬 변수 \co{idx} 를 삭제하고 (b) line~16 에서의 값 증가를
	fetch-increment-store 로 컴파일해서 \co{rcu_ctrlblk.completed} 에서
	값을 읽어오고 다시 쓰는 두번의 별개의 액세스로 만들어버릴 수 있는
	권리를 갖습니다.
	만약 그 사이에 \co{rcu_ctrlblk.completed} 의 값이 바뀌었다면, 이는
	\co{rcu_flipctr} 값을 잘못되게 만들 수 있습니다.
\item	\co{rcu_read_lock_nesting} 으로의 값 할당 (line~17) 이 \co{rcu_flipctr}
	의 값 할당 (line~16) 앞으로 재배치 된다면, 그리고 NMI 가 이 두 이벤트
	사이에 발생했다면, 해당 NMI 핸들러 안에서의 \co{rcu_read_lock()} 은
	자신이 이미 \co{rcu_read_lock()} 의 보호 아래 있다고 잘못된 결론을 내릴
	겁니다.
\iffalse

\item	In absence of the \co{ACCESS_ONCE()} in the assignment
	to \co{idx}, the compiler would be within its rights
	to: (a) eliminate the local variable \co{idx} and
	(b) compile the increment on line~16 as a
	fetch-increment-store sequence, doing separate accesses to
	\co{rcu_ctrlblk.completed} for the fetch and the
	store.
	If the value of \co{rcu_ctrlblk.completed} had
	changed in the meantime, this would corrupt the
	\co{rcu_flipctr} values.
\item	If the assignment to \co{rcu_read_lock_nesting}
	(line~17) were to be reordered to precede the increment
	of \co{rcu_flipctr} (line~16), and if an
	NMI occurred between these two events, then an
	\co{rcu_read_lock()} in that NMI's handler
	would incorrectly conclude that it was already under the
	protection of \co{rcu_read_lock()}.
\fi
\item	만약 \co{rcu_read_lock_nesting} 으로의 값 할당 (line~17) 이
	\co{rcu_flipctr_idx} 에의 값 할당 (line~18) 뒤로 재배치된다면, 그리고
	NMI 가 이 두 이벤트 사이에 발생한다면, 해당 NMI 핸들러 안에서의
	\co{rcu_read_lock()} 은 \co{rcu_flipctr_idx} 를 망쳐버려서, 짝을 이루는
	\co{rcu_read_unlock()} 이 잘못된 카운터의 값을 감소시키도록 만들 수
	있습니다.
	이는 결국 grace period 가 너무 빨리 끝나거나 grace period 를 무기한
	연장시킬 수도, 두 사건이 모두 일어날 수도 있습니다.
\iffalse

\item	If the assignment to \co{rcu_read_lock_nesting}
        (line~17) were to be reordered to follow the assignment
	to \co{rcu_flipctr_idx} (line~18), and if an
	NMI occurred between these two events, then an
	\co{rcu_read_lock()} in that NMI's handler
	would clobber \co{rcu_flipctr_idx}, possibly
	causing the matching \co{rcu_read_unlock()} to
	decrement the wrong counter.
	This in turn could result in premature ending of a
	grace period, indefinite extension of a grace period,
	or even both.
\fi
\end{enumerate}

\co{nesting} 에의 값 할당 (line~7) 에 \co{ACCESS_ONCE} 가 필요한가는 명확치
않습니다.
또한 \co{smp_read_barrier_depends()} (line~15) 이 필요한지도 명확치 않습니다:
이것들은 인덱스와 값의 변경이 순서가 유지되도록 추가되었습니다.

Line~13 부터 line~19 사이에 irq 가 비활성화 되어야 하는 이유는 다음과 같습니다:
\iffalse

It is not clear that the \co{ACCESS_ONCE} on the assignment to
\co{nesting} (line~7) is required.
It is also unclear whether the \co{smp_read_barrier_depends()}
(line~15) is needed: it was added to ensure that changes to index
and value remain ordered.

The reasons that irqs must be disabled from line~13 through
line~19 are as follows:
\fi

\begin{enumerate}
\item	한 CPU 가 \co{rcu_ctrlblk.completed} 를 읽어왔고 (line~14), 이어서
	두번째 CPU 가 이 카운터의 값을 증가시켰으며, 이어서 첫번째 CPU 가
	scheduling-clock 인터럽트를 받았다고 생각해 봅시다.
	첫번째 CPU 는 이제 이 카운터 뒤집기를 확인해 줘야 함을 보게 되며,
	그렇게 할겁니다.
	이 확인 행위는 새로이 과거의 것이 되는 카운터의 값을 증가시키는 것을
	막을 것이라는 약속인데, 이 CPU 는 이 약속을 깨게 될겁니다.
	더 나쁜건, 이 CPU 가 scheduling-clock 인터럽트로부터의 리턴 직후에
	preemption 당할 수 있고, 따라서 미래의 무작위한 어느 시점에 카운터의
	값을 증가시킬 수 있다는 겁니다.
	두 상황 모두 grace-period 탐지를 망칠 수 있습니다.
\iffalse

\item	Suppose one CPU loaded \co{rcu_ctrlblk.completed}
	(line~14), then a second CPU incremented this counter,
	and then the first CPU took a scheduling-clock interrupt.
	The first CPU would then see that it needed to acknowledge
	the counter flip, which it would do.
	This acknowledgment is a promise to avoid incrementing
	the newly old counter, and this CPU would break this
	promise.
	Worse yet, this CPU might be preempted immediately upon
	return from the scheduling-clock interrupt, and thus
	end up incrementing the counter at some random point
	in the future.
	Either situation could disrupt grace-period detection.
\fi
\item	Irq 들을 비활성화 시키는 것은 preemption 을 비활성화 시키는 side effect
	를 갖습니다.
	만약 이 코드가 \co{rcu_ctrlblk.completed} 를 읽어들이는 것 (line~14) 과
	\co{rcu_flipctr} 의 값을 증기시키는 것 (line~16) 사이에서 preemption 될
	수 있다면, 다른 CPU 에서 동작을 재개할 수 있을 겁니다.
	이는 이 카운터를 다른 CPU 로부터 가져와서는 atomic 하지 않게 값 증가를
	시키는 결과를 낳을 수 있습니다.
	이 CPU 가 바로 그 시점에서 \co{rcu_read_lock()} 또는
	\co{rcu_read_unlock()} 을 수행 중이었다면 하나의 값 증가 또는 감소가
	없던게 되어버려서, 역시 grace-period 탐지를 망칩니다.
	RISC 머신에서는 값 증가 사이에  (기존 카운터의 값 읽기 후 새로이 증가된
	값의 저장 전에) preemption 이 발생하면 같은 결과가 이뤄질 수 있을
	겁니다.
\iffalse

\item	Disabling irqs has the side effect of disabling preemption.
	If this code were to be preempted between fetching
	\co{rcu_ctrlblk.completed} (line~14) and
	incrementing \co{rcu_flipctr} (line~16),
	it might well be migrated to some other CPU.
	This would result in it non-atomically incrementing
	the counter from that other CPU.
	If this CPU happened to be executing in \co{rcu_read_lock()}
	or \co{rcu_read_unlock()} just at that time, one
	of the increments or decrements might be lost, again
	disrupting grace-period detection.
	The same result could happen on RISC machines if the preemption
	occurred in the middle of the increment (after the fetch of
	the old counter but before the store of the newly incremented
	counter).
\fi
\item	line~16 의 중간에, 현재 CPU 의 \co{rcu_flipctr} 배열의 복사본을 고르는
	것과 \co{rcu_flipctr_idx} 로 선택된 원소의 값을 증가시키는 사이에
	preemption 을 허용하는 것은 비슷한 문제를 일으킬 수 있습니다.
	실행은 이번에도 역시 다른 CPU 에서 재개될 수 있습니다.
	이 실행 재개가 원래 CPU 에서 수행중인 \co{rcu_read_lock()} 또는
	\co{rcu_read_unlock()} 과 동시적으로 발생한다면, 하나의 값 증가 또는 값
	감소가 사라질 수 있어서 grace period 의 너무 빠른 종료 또는 무기한
	연장, 또는, 심지어 둘 다를 일으킬 수 있습니다.
\iffalse

\item	Permitting preemption in the midst
	of line~16, between selecting the current CPU's copy
	of the \co{rcu_flipctr} array and the increment of
	the element indicated by \co{rcu_flipctr_idx}, can
	result in a similar failure.
	Execution might well resume on some other CPU.
	If this resumption happened concurrently with an
	\co{rcu_read_lock()} or \co{rcu_read_unlock()}
	running on the original CPU,
	an increment or decrement might be lost, resulting in either
	premature termination of a grace period, indefinite extension
	of a grace period, or even both.
\fi
\item	Preemption 비활성화를 못하게 되는것 역시 특정 task 가 언제 RCU
	read-side 크리티컬 섹션에 있는지 파악하는데 \co{rcu_read_lock_nesting}
	을 사용하는 RCU priority boosting 을 망칠 수 있습니다.
	따라서, 예를 들어, 어떤 task 가 \co{rcu_flipctr} 를 증가시킨 후,
	\co{rcu_read_lock_nesting} 의 값을 업데이트 하기 전에 preemption
	당한다면, preemption 당한 동안 RCU grace period 를 멈춰둘 수 있을
	겁니다.
	하지만, \co{rcu_read_lock_nesting} 은 아직 값이 증가되지 않았으므로,
	RCU priority booster 는 이 boosting 이 필요하다고 말할 수 없습니다.
	따라서, CPU-bound realtime thread 가 존재한다면 이 preemption 당한 task
	는 무기한적으로 grace period 를 멈춰버릴 수 있어서 결국 OOM 이벤트를
	일으킬 겁니다.
\iffalse

\item	Failing to disable preemption can also defeat RCU priority
	boosting, which relies on \co{rcu_read_lock_nesting}
	to determine when a given task is in an RCU read-side
	critical section.
	So, for example, if a given task is indefinitely
	preempted just after incrementing \co{rcu_flipctr},
	but before updating \co{rcu_read_lock_nesting},
	then it will stall RCU grace periods for as long as it
	is preempted.
	However, because \co{rcu_read_lock_nesting} has not
	yet been incremented, the RCU priority booster has no way
	to tell that boosting is needed.
	Therefore, in the presence of CPU-bound realtime threads,
	the preempted task might stall grace periods indefinitely,
	eventually causing an OOM event.
\fi
\end{enumerate}

마지막 세개의 이유는 물론 irq 를 비활성화 하는게 아니라 preemption 만 비활성화
하는 것으로도 해결될 수 있습니다만, 첫번째 이유는 irq 를 비활성화 할 것을
필요로 하기에, 굳이 구분해서 preemption 만 비활성화 할 이유는 없습니다.
첫번째 이유는 추가적인 grace-period stage 를 두어서 해결하는 것도 확실히
가능합니다만, 최근의 CPU 들에서 preemption 을 비활성화 하는 것이 인터럽트를
비활성화 하는것보다 엄청 빠른가는 확실치 않습니다.
\iffalse

The last three reasons could of course be addressed by disabling
preemption rather than disabling of irqs, but given that the first
reason requires disabling irqs in any case, there is little reason
to separately disable preemption.
It is entirely possible that the first reason might be tolerated
by requiring an additional grace-period stage, however, it is not
clear that disabling preemption is much faster than disabling
interrupts on modern CPUs.
\fi

\paragraph{{\tt rcu\_read\_unlock()}}
\label{app:rcuimpl:rcu_read_unlock()}

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 void __rcu_read_unlock(void)
  2 {
  3   int idx;
  4   struct task_struct *t = current;
  5   int nesting;
  6
  7   nesting = ACCESS_ONCE(t->rcu_read_lock_nesting);
  8   if (nesting > 1) {
  9     t->rcu_read_lock_nesting = nesting - 1;
 10   } else {
 11     unsigned long flags;
 12
 13     local_irq_save(flags);
 14     idx = ACCESS_ONCE(t->rcu_flipctr_idx);
 15     ACCESS_ONCE(t->rcu_read_lock_nesting) = nesting - 1;
 16     ACCESS_ONCE(__get_cpu_var(rcu_flipctr)[idx])--;
 17     local_irq_restore(flags);
 18   }
 19 }
\end{verbatim}
}
\caption{{\tt \_\_rcu\_read\_unlock()} Implementation}
\label{fig:app:rcuimpl:__rcu_read_unlock() Implementation}
\end{figure}

Figure~\ref{fig:app:rcuimpl:__rcu_read_unlock() Implementation}
에 \co{rcu_read_unlock()} 의 구현이 보여 있습니다.
Line~7 은 \co{rcu_read_lock_nesting} 캉누터를 읽어오고,
line~8 은 우리가 우리를 둘러싼 \co{rcu_read_lock()} 의 보호 아래 있는지
확인합니다.
만약 그렇다면, line~9 에서 그냥 카운터의 값을 감소시킵니다.

하지만, \co{rcu_read_lock()} 에서와 같이, 그렇지 않다면 더 많은 일을 해야
합니다.
Line~13 과 17 은 \co{rcu_read_unlock()} 처리 과정 중에 scheduling-clock
인터럽트가 grace-period state machine 을 일깨우는 것을 막기 위해 irq 들을 막고
재활성화 시킵니다.
Line~14 는 짝을 맞추는 \co{rcu_read_lock()} 에서 저장된 \co{rcu_flipctr_idx} 를
가져오고, line~15 는 irq 와 NMI/SMI 핸들러들이 앞으로 \co{rcu_flipctr} 를
업데이트할 수 있도록 \co{rcu_read_lock_nesting} 의 값을 감소시키고, line~16 은
카운터의 값을 감소시킵니다.
\iffalse

The implementation of \co{rcu_read_unlock()} is shown in
Figure~\ref{fig:app:rcuimpl:__rcu_read_unlock() Implementation}.
Line~7 fetches the \co{rcu_read_lock_nesting} counter,
which line~8 checks to see if we are under the protection of an
enclosing \co{rcu_read_lock()} primitive.
If so, line~9 simply decrements the counter.

However, as with \co{rcu_read_lock()}, we otherwise must do
more work.
Lines~13 and 17 disable and restore irqs in order to prevent
the scheduling-clock interrupt from invoking the grace-period state machine
while in the midst of \co{rcu_read_unlock()} processing.
Line~14 picks up the \co{rcu_flipctr_idx} that was
saved by the matching \co{rcu_read_lock()},
line~15
decrements \co{rcu_read_lock_nesting} so that irq and
NMI/SMI handlers will henceforth update \co{rcu_flipctr},
line~16 decrements the counter (with the same index as, but possibly
on a different CPU than, that incremented by the matching
\co{rcu_read_lock()}.
\fi

\co{ACCESS_ONCE()} 매크로와 irq 비활성화는 \co{rcu_read_lock()} 에서와 비슷한
이유로 필요합니다.
\iffalse

The \co{ACCESS_ONCE()} macros and irq disabling
are required for similar reasons that they are in
\co{rcu_read_lock()}.
\fi

\QuickQuiz{}
	\co{rcu_read_unlock()} 의 \co{ACCESS_ONCE()} 가 컴파일러에 의해 재배치
	된다면 어떤 문제가 발생할 수 있나요?
	\iffalse

	What problems could arise if the lines containing
	\co{ACCESS_ONCE()} in \co{rcu_read_unlock()}
	were reordered by the compiler?
	\fi
\QuickQuizAnswer{
	\begin{enumerate}
	\item	\co{rcu_flipctr_idx} 를 읽어오는 코드 (line~14) 에
		\co{ACCESS_ONCE()} 가 없어진다면, 컴파일러는 \co{idx} 를 제거할
		수 있습니다.
		또한 \co{rcu_flipctr} 의 값 감소를 읽어오고-감소시키고-저장하기
		로 컴파일 할 수 있어서, 이 읽어오기와 저장하기에 그때마다 각각
		\co{rcu_flipctr_idx} 를 읽어올 수 있습니다.
		만약 이 읽어오기와 저장하기 사이에 NMI 가 발생한다면, 그리고
		해당 NMI 핸들러가 \co{rcu_read_lock()} 을 포함하고 있다면,
		\co{rcu_flipctr_idx} 의 값은 중간에 바뀌어 버릴 것이고,
		\co{rcu_flipctr} 값이 잘못되어버려서, 정확히 grace period 를
		파악하는 능력을 파괴해 버릴 겁니다.
	\iffalse

	\item	If the \co{ACCESS_ONCE()} were omitted from the
		fetch of \co{rcu_flipctr_idx} (line~14), then the compiler
		would be within its rights to eliminate \co{idx}.
		It would also be free to compile the \co{rcu_flipctr}
		decrement as a fetch-increment-store sequence, separately
		fetching \co{rcu_flipctr_idx} for both the fetch and
		the store.
		If an NMI were to occur between the fetch and the store, and
		if the NMI handler contained an \co{rcu_read_lock()},
		then the value of \co{rcu_flipctr_idx} would change
		in the meantime, resulting in corruption of the
		\co{rcu_flipctr} values, destroying the ability
		to correctly identify grace periods.
	\fi
	\item	Line~14 에서 \co{ACCESS_ONCE()} 가 없어질 경우 생길 수 있는
		또다른 문제는 컴파일러기 이 코드를 \co{rcu_read_lock_nesting}
		의 값 감소 (line~16) 뒤로 재배치 할 수 있기 때문에 발생합니다.
		이 경우, 이 두 코드 사이에 NMI 가 발생한다면, 해당 NMI 핸들러
		내에서의 \co{rcu_read_lock()} 은 \co{rcu_flipctr_idx} 의 값을
		망쳐버릴 수 있어서, 잘못된 \co{rcu_flipctr} 가 감소될 수 있게
		할 수 있습니다.
		\co{rcu_read_lock()} 에서의 비슷한 상황에서처럼, 이는 너무 빠른
		grace-period 종료, 무한한 grace period, 또는 둘 다를 일으킬 수
		있습니다.
	\iffalse

	\item	Another failure that could result from omitting the
		\co{ACCESS_ONCE()} from line~14 is due to
		the compiler reordering this statement to follow the
		decrement of \co{rcu_read_lock_nesting}
		(line~16).
		In this case, if an NMI were to occur between these two
		statements, then any \co{rcu_read_lock()} in the
		NMI handler could corrupt \co{rcu_flipctr_idx},
		causing the wrong \co{rcu_flipctr} to be
		decremented.
		As with the analogous situation in \co{rcu_read_lock()},
		this could result in premature grace-period termination,
		an indefinite grace period, or even both.
	\fi
	\item	\co{rcu_read_lock_nesting} 의 업데이트가 컴파일러에 의해
		\co{rcu_flipctr} 의 값 감소와 바쓀 수 있게 \co{ACCESS_ONCE()}
		매크로가 없다면, 그리고 그 사이에 NMI 가 발생한다면, 해당 NMI
		핸들러 내에서의 \co{rcu_read_lock()} 은 옳지 못하게도 자신이
		\co{rcu_read_lock()} 에 의해 보호되고 있다고 착각하고,
		\co{rcu_flipctr} 변수의 값을 증가시키게 될겁니다.
	\iffalse

	\item	If \co{ACCESS_ONCE()} macros were omitted such that
		the update of \co{rcu_read_lock_nesting} could be
		interchanged by the compiler with the decrement of
		\co{rcu_flipctr}, and if an NMI occurred in between,
		any \co{rcu_read_lock()} in the NMI handler would
		incorrectly conclude that it was protected by an enclosing
		\co{rcu_read_lock()}, and fail to increment the
		\co{rcu_flipctr} variables.
	\fi
	\end{enumerate}

	\co{rcu_read_lock_nesting} 을 읽어오는 코드 (line~7) 에서도
	\co{ACCESS_ONCE()} 가 필요한지에 대해서는 명확치 않습니다.
	\iffalse

	It is not clear that the \co{ACCESS_ONCE()} on the
	fetch of \co{rcu_read_lock_nesting} (line~7) is required.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	\co{rcu_read_unlock()} 내의 \co{ACCESS_ONCE()} 를 포함한 코드가 CPU 에
	의해 재배치 되면 어떤 문제가 일어날 수 있을까요?
	\iffalse

	What problems could arise if the lines containing
	\co{ACCESS_ONCE()} in \co{rcu_read_unlock()}
	were reordered by the CPU?
	\fi
\QuickQuizAnswer{
	전혀 없어요!  \co{rcu_read_unlock()} 의 코드는 같은 CPU 에서 돌아가는
	scheduling-clock 인터럽트 핸들러와 상호 동작하며, 따라서 재배치에
	문제가 없는데 이는 CPU 들은 스스로의 액세스에 대해서만큼은 프로그램
	순서대로 보게 되기 때문입니다.
	다른 CPU 들은 \co{rcu_flipctr} 에 액세스 하긴 합니다만, 이 다른 CPU
	들은 다른 변수들에는 접근하지 않기 때문에, 순서는 상관없습니다.
	\iffalse

	Absolutely none!  The code in \co{rcu_read_unlock()}
	interacts with the scheduling-clock interrupt handler
	running on the same CPU, and is thus insensitive to reorderings
	because CPUs always see their own accesses as if they occurred
	in program order.
	Other CPUs do access the \co{rcu_flipctr}, but because these
	other CPUs don't access any of the other variables, ordering is
	irrelevant.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	Irq 들이 비활성화 되어 있지 않다면 \co{rcu_read_unlock()} 에 어떤
	문제가 있을 수 있나요?
	\iffalse

	What problems could arise in
	\co{rcu_read_unlock()} if irqs were not disabled?
	\fi
\QuickQuizAnswer{
	\begin{enumerate}
	\item	Irq 들을 비활성화 하는 것은 preemption 을 비활성화 시키는 추가
		효과를 일으킵니다.
		이 코드가 line~17 의 중간에서 현재 CPU 의 \co{rcu_flipctr}
		배열의 복사본을 고르는 부분과 \co{rcu_flipctr_idx} 로
		가리켜지는 원소의 값의 감소 사이에서 preemption 당한다고 생각해
		보세요.
		프로그램 수행은 어떤 다른 CPU 위에서 재개될 수 있겠습니다.
		만약 이 수행 재개가 원래 CPU 에서 수행되는 \co{rcu_read_lock()}
		또는 \co{rcu_read_unlock()} 과 동시적으로 일어났다면, 하나의 값
		증가나 값 감소가 사라져버리게 되어서 너무 빠른 grace period 의
		종료, 무기한적인 grace period 의 연장, 또는 심지어 둘 다 일어날
		수가 있습니다.
	\iffalse

	\item	Disabling irqs has the side effect of disabling preemption.
		Suppose that this code were to be preempted in the midst
		of line~17 between selecting the current CPU's copy
		of the \co{rcu_flipctr} array and the decrement of
		the element indicated by \co{rcu_flipctr_idx}.
		Execution might well resume on some other CPU.
		If this resumption happened concurrently with an
		\co{rcu_read_lock()} or \co{rcu_read_unlock()}
		running on the original CPU,
		an increment or decrement might be lost, resulting in either
		premature termination of a grace period, indefinite extension
		of a grace period, or even both.
	\fi
	\item	Preemption 을 비활성화 시키는데 실패한다면 어떤 task 의
		우선순위를 높일지 정하는데 \co{rcu_read_lock_nesting} 에
		의존하는 RCU priority boosting 에도 영향을 끼칠 수 있습니다.
		만약 \co{rcu_read_lock_nesting} 의 업데이트 (line~16) 와
		\co{rcu_flipctr} 의 업데이트 (line~17) 사이에서 preemption 이
		일어난다면, grace period 는 이 task 가 재개되기 전까지 멈출
		겁니다.
		하지만 이 RCU priority booster 는 이 특정 task 가 grace period
		를 멈추고 있단 걸 알 수가 없으므로, 필요한 boosting 은 일어날
		수가 없습니다.
		따라서, 만약 CPU-bound realtime task 들이 돌아가고 있다면, 이
		preemption 당한 task 는 결코 수행 재개되지 않을 것이어서 grace
		period 를 무한하게 멈춰있게 하고 결국은 OOM 을 초래할 겁니다.
	\iffalse

	\item	Failing to disable preemption can also defeat RCU priority
		boosting, which relies on \co{rcu_read_lock_nesting}
		to determine which tasks to boost.
		If preemption occurred between the update of
		\co{rcu_read_lock_nesting} (line~16) and of
		\co{rcu_flipctr} (line~17), then a grace
		period might be stalled until this task resumed.
		But because the RCU priority booster has no way of knowing
		that this particular task is stalling grace periods, needed
		boosting will never occur.
		Therefore, if there are CPU-bound realtime tasks running,
		the preempted task might never resume, stalling grace periods
		indefinitely, and eventually resulting in OOM.
	\fi
	\end{enumerate}

	물론, 이런 상황들 모두 irq 를 비활성화 하기보다는 preemption 을
	비활성화 시키는 것으로 해결할 수 있습니다.
	(제가 사용한 CPU 들은 두 방법 사이에서 큰 차이를 보이지 않았습니다만,
	다른 것들은 다를지도 모르지요.)
	\iffalse

	Of course, both of these situations could be handled by disabling
	preemption rather than disabling irqs.
	(The CPUs I have access to do not show much difference between these
	two alternatives, but others might.)
	\fi
} \QuickQuizEnd

\paragraph{Memory-Barrier Considerations}
\label{app:rcuimpl:Memory-Barrier Considerations}

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/RCUrt-MBwaste}}
\caption{Preemptible RCU with Read-Side Memory Barriers}
\label{app:rcuimpl:Preemptible RCU with Read-Side Memory Barriers}
\end{figure}

이 두개의 기능들은 메모리 배리어들을 포함하고 있지 않으며, 따라서
\co{rcu_read_lock()} 을 실행하기 전 또는 \co{rcu_read_unlock()} 을 수행한 후에
크리티컬 섹션을 CPU 가 수행하는 것을 막을 방법이 없다는 것을 알아두시기
바랍니다.
\co{rcu_try_flip_waitmb_state} 의 목적은 이런 가능한 재배치를 처리하기 위한
것입니다만, grace period 의 시작과 끝에서만 그렇습니다.
왜 이 방법이 좋은지 알아보려면, 메모리 배리어를 RCU read-side 크리티컬 섹션의
시작과 끝에 위치시키는 것의 낭비~\cite{PaulEMcKenney2006b}를 보여주는
Figure~\ref{app:rcuimpl:Preemptible RCU with Read-Side Memory Barriers} 를
보시기 바랍니다.
\iffalse

Note that these two primitives contains no memory barriers, so there is
nothing to stop the CPU from executing the critical section
before executing the \co{rcu_read_lock()} or after executing
the \co{rcu_read_unlock()}.
The purpose of the \co{rcu_try_flip_waitmb_state} is to
account for this possible reordering, but only at the beginning or end of
a grace period.
To see why this approach is helpful, consider
Figure~\ref{app:rcuimpl:Preemptible RCU with Read-Side Memory Barriers},
which shows the wastefulness of the conventional approach of placing
a memory barrier at the beginning and end of each RCU read-side critical
section~\cite{PaulEMcKenney2006b}.
\fi

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/RCUrt-MBnowaste}}
\caption{Preemptible RCU with Grace-Period Memory Barriers}
\label{app:rcuimpl:Preemptible RCU with Grace-Period Memory Barriers}
\end{figure}

``MB'' 들은 메모리 배리어들을 의미하며, 굵게 표시된 배리어들만이 필요한데, 각
CPU 의 각 grace period 의 시작과 끝에서의 것들입니다.
따라서 이 perremptible RCU 구현은
Figure~\ref{app:rcuimpl:Preemptible RCU with Grace-Period Memory Barriers}
에 보인 것처럼 grace period 에 메모리 배리어를 연관시킵니다.

리눅스 커널은 말그대로 수백만의 RCU read-side 크리티컬 섹션들을 grace period 당
수행할 수 있다는 점을 놓고 보면, 이 방법은 read-side 비용의 상당한 절감을
가능하게 하는데, 메모리 배리어의 비용을 grace period 내의 모든 read-side
크리티컬 섹션들로 청산하기 때문입니다.
\iffalse

The ``MB''s represent memory barriers, and only the emboldened
barriers are needed, namely the first and last on a given CPU
for each grace period.
This preemptible RCU implementation therefore associates the memory
barriers with the grace period, as shown in
Figure~\ref{app:rcuimpl:Preemptible RCU with Grace-Period Memory Barriers}.

Given that the Linux kernel can execute literally millions of RCU
read-side critical sections per grace period, this latter approach
can result in substantial read-side savings, due to the fact that it
amortizes the cost of the memory barrier over all the read-side critical
sections in a grace period.
\fi

\subsection{Validation of Preemptible RCU}
\label{app:rcuimpl:Validation of Preemptible RCU}

\subsubsection{Testing}
\label{app:rcuimpl:Testing}

Preemptible RCU 는 2단계 grace period 와 함께 완화된 순서 규칙의 POWER4 와
POWER5 CPU 에서 각각 24시간씩 15백만, 2천만 grace period 를 각각 가지고
rcutorture 로 테스트되었으며 어떤 에러도 없었습니다.
물론, 이것만으로는 이 알고리즘이 옳다고 증명하지 못합니다.
여기서 최대한 이야기 할 수 있는건, 이 결과가 이 두개의 기계들은 굉장히 운이
좋았거나 preemptible RCU 에 남아 있는 버그들은 매우 낮은 발생 확률을 가지고
있다는 것입니다.
따라서 우리는 이 알고리즘이 동작한다는 확신이, 또는, 남아있는 버그의 확인이
필요합니다.

이 작업은 개념적 접근방법을 필요로 하는데, 이에 대해 다음 섹션에서 설명합니다.
\iffalse

The preemptible RCU algorithm was tested with a two-stage grace period
on weakly ordered POWER4 and POWER5 CPUs using rcutorture running for
more than 24 hours on each machine, with 15M and 20M grace periods,
respectively, and with no errors.
Of course, this in no way proves that this algorithm is correct.
At most, it shows either that these two machines were extremely
lucky or that any bugs remaining in preemptible RCU have an extremely
low probability of occurring.
We therefore required additional assurance that this algorithm works,
or, alternatively, identification of remaining bugs.

This task requires a conceptual approach,
which is taken in the next section.
\fi

\subsubsection{Conceptual Validation}
\label{app:rcuimpl:Conceptual Validation}

Because neither \co{rcu_read_lock()} nor \co{rcu_read_unlock()}
contain memory barriers, the RCU read-side critical section can bleed
out on weakly ordered machines.
In addition, the relatively loose coupling of this RCU implementation
permits CPUs to disagree on when a given grace period starts and ends.
This leads to the question as to how long a given RCU read-side critical
section can possibly extend relative to the grace-period state machine.

\begin{figure}[htb]
\centering
\resizebox{3in}{!}{\includegraphics{appendix/rcuimpl/RCUpreemptValidation}}
\caption{Preemptible RCU Worst-Case Scenario}
\label{app:rcuimpl:Preemptible RCU Worst-Case Scenario}
\end{figure}

The worst-case scenario is shown in
Figure~\ref{app:rcuimpl:Preemptible RCU Worst-Case Scenario}.
Here, CPU~0 is executing the shortest possible
removal and reclamation sequence,
while CPU~1 executes the longest possible RCU read-side critical
section.
Because the callback queues are advanced just before acknowledging a
counter flip, the latest that CPU~0 can execute its
\co{list_del_rcu()} and \co{call_rcu()} is just before
its scheduling-clock interrupt that acknowledges the counter flip.
The \co{call_rcu()} invocation places the callback on CPU~0's
\co{next} list, and the interrupt will move the callback from
the \co{next} list to the \co{wait[0]} list.
This callback will move again (from the \co{wait[0]} list
to the \co{wait[1]} list) at CPU~0's first scheduling-clock
interrupt following the next counter flip.
Similarly, the callback will move from the \co{wait[1]} list
to the \co{done} list at CPU~0's first scheduling-clock
interrupt following the counter flip resulting in the value 3.
The callback might be invoked immediately afterward.

Meanwhile, CPU~1 is executing an RCU read-side critical section.
Let us assume that the \co{rcu_read_lock()} follows the first
counter flip (the one resulting in the value 1), so that the
\co{rcu_read_lock()} increments CPU~1's
\co{rcu_flipctr[1]} counter.
Note that because \co{rcu_read_lock()} does not contain any
memory barriers, the contents of the critical section might be executed
early by the CPU.
However, this early execution cannot precede the last memory barrier
executed by CPU~1, as shown on the diagram.
This is nevertheless sufficiently early that an \co{rcu_dereference()}
could fetch a pointer to the item being deleted by CPU~0's
\co{list_del_rcu()}.

Because the \co{rcu_read_lock()} incremented an index-1 counter,
the corresponding \co{rcu_read_unlock()} must
precede the ``old counters zero'' event for index 1.
However, because \co{rcu_read_unlock()} contains no memory
barriers, the contents of the corresponding RCU read-side critical
section (possibly including a reference to the item deleted by
CPU~0) can be executed late by CPU~1.
However, it cannot be executed after CPU~1's next memory barrier,
as shown on the diagram.
Because the latest possible reference by CPU~1 precedes the
earliest possible callback invocation by CPU~0, two passes
through the grace-period state machine suffice to constitute
a full grace period, and hence it is safe to do:

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\small
\begin{verbatim}
    #define GP_STAGES 2
\end{verbatim}
\end{minipage}
\vspace{5pt}

\QuickQuiz{}
	Suppose that the irq disabling in
	\co{rcu_read_lock()} was replaced by preemption disabling.
	What effect would that have on \co{GP_STAGES}?
\QuickQuizAnswer{
	No finite value of \co{GP_STAGES} suffices.
	The following scenario, courtesy of Oleg Nesterov, demonstrates this:

	Suppose that low-priority Task~A has executed
	\co{rcu_read_lock()} on CPU 0,
	and thus has incremented \co{per_cpu(rcu_flipctr, 0)[0]},
	which thus has a value of one.
	Suppose further that Task~A is now preempted indefinitely.

	Given this situation, consider the following sequence of events:
	\begin{enumerate}
	\item	Task~B starts executing \co{rcu_read_lock()}, also on
		CPU 0, picking up the low-order bit of
		\co{rcu_ctrlblk.completed}, which is still equal to zero.
	\item	Task~B is interrupted by a sufficient number of scheduling-clock
		interrupts to allow the current grace-period stage to complete,
		and also be sufficient long-running interrupts to allow the
		RCU grace-period state machine to advance the
		\co{rcu_ctrlblk.complete} counter so that its bottom bit
		is now equal to one and all CPUs have acknowledged this
		increment operation.
	\item	CPU 1 starts summing the index==0 counters, starting with
		\co{per_cpu(rcu_flipctr, 0)[0]}, which is equal to one
		due to Task~A's increment.
		CPU 1's local variable \co{sum} is therefore equal to one.
	\item	Task~B returns from interrupt, resuming its execution of
		\co{rcu_read_lock()}, incrementing
		\co{per_cpu(rcu_flipctr, 0)[0]}, which now has a value
		of two.
	\item	Task~B is migrated to CPU 2.
	\item	Task~B completes its RCU read-side critical section, and
		executes \co{rcu_read_unlock()}, which decrements
		\co{per_cpu(rcu_flipctr, 2)[0]}, which is now -1.
	\item	CPU 1 now adds \co{per_cpu(rcu_flipctr, 1)[0]} and
		\co{per_cpu(rcu_flipctr, 2)[0]} to its
		local variable \co{sum}, obtaining the value zero.
	\item	CPU 1 then incorrectly concludes that all prior RCU read-side
		critical sections have completed, and advances to the next
		RCU grace-period stage.
		This means that some other task might well free up data
		structures that Task~A is still using!
	\end{enumerate}

	This sequence of events could repeat indefinitely, so that no finite
	value of \co{GP_STAGES} could prevent disrupting Task~A.
	This sequence of events demonstrates the importance of the promise
	made by CPUs that acknowledge an increment of
	\co{rcu_ctrlblk.completed}, as the problem illustrated by the
	above sequence of events is caused by Task~B's repeated failure
	to honor this promise.

	Therefore, more-pervasive changes to the grace-period state will be
	required in order for \co{rcu_read_lock()} to be able to safely
	dispense with irq disabling.
} \QuickQuizEnd

\QuickQuiz{}
	Why can't the \co{rcu_dereference()}
	precede the memory barrier?
\QuickQuizAnswer{
	Because the memory barrier is being executed in
	an interrupt handler, and interrupts are exact in the sense that
	a single value of the PC is saved upon interrupt, so that the
	interrupt occurs at a definite place in the code.
	Therefore, if the
	\co{rcu_dereference()} were to precede the memory barrier,
	the interrupt would have had to have occurred after the
	\co{rcu_dereference()}, and therefore
	the interrupt would also have had to have occurred after the
	\co{rcu_read_lock()} that begins the RCU read-side critical
	section.
	This would have forced the \co{rcu_read_lock()} to use
	the earlier value of the grace-period counter, which would in turn
	have meant that the corresponding \co{rcu_read_unlock()}
	would have had to precede the first ``Old counters zero [0]'' rather
	than the second one.
	This in turn would have meant that the read-side critical section
	would have been much shorter---which would have been
	counter-productive,
	given that the point of this exercise was to identify the longest
	possible RCU read-side critical section.
} \QuickQuizEnd

\subsubsection{Formal Validation}
\label{app:rcuimpl:Formal Validation}

Formal validation of this algorithm is quite important, but remains
as future work.
One tool for doing this validation is described in
Chapter~\ref{chp:Formal Verification}.

\QuickQuiz{}
	What is a more precise way to say ``CPU~0
	might see CPU~1's increment as early as CPU~1's last previous
	memory barrier''?
\QuickQuizAnswer{
	First, it is important to note that the problem with
	the less-precise statement is that it gives the impression that there
	might be a single global timeline, which there is not, at least not for
	popular microprocessors.
	Second, it is important to note that memory barriers are all about
	perceived ordering, not about time.
	Finally, a more precise way of stating above statement would be as
	follows: ``If CPU~0 loads the value resulting from CPU~1's
	increment, then any subsequent load by CPU~0 will see the
	values from any relevant stores by CPU~1 if these stores
	preceded CPU~1's last prior memory barrier.''

	Even this more-precise version leaves some wiggle room.
	The word ``subsequent'' must be understood to mean ``ordered after'',
	either by an explicit memory barrier or by the CPU's underlying
	memory ordering.
	In addition, the memory barriers must be strong enough to order
	the relevant operations.
	For example, CPU~1's last prior memory barrier must order stores
	(for example, \co{smp_wmb()} or \co{smp_mb()}).
	Similarly, if CPU~0 needs an explicit memory barrier to
	ensure that its later load follows the one that saw the increment,
	then this memory barrier needs to be an \co{smp_rmb()}
	or \co{smp_mb()}.

	In general, much care is required when proving parallel algorithms.
} \QuickQuizEnd
