% intro/intro.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\QuickQuizChapter{chp:Introduction}{Introduction}{qqzintro}
%
\Epigraph{If parallel programming is so hard, why are there so many
	  parallel programs?}{\emph{Unknown}}

병렬 프로그래밍은 해커가 덤빌 수 있는 가장 어려운 영역이라는 평판을 얻었습니다.
논문과 교재들은 데드락, 라이브락, 레이스 컨디션, 비결정성, 암달의 법칙에 의한
확장성 제한, 그리고 지나친 리얼타임 반응시간의 위험을 경고합니다.
그리고 이런 위험들은 진짜입니다; 우리 저자들은 그로 인한 감정적 흉터, 백발,
탈모를 여러해 겪었습니다.

하지만, 처음 소개될 때엔 사용하기 어려웠던 기술들이 언제나 시간의 흐름에 따라
쉬워집니다.
예를 들어, 한때는 희귀했던 자동차 운전이 지금은 많은 나라에서 흔합니다.
이 극적인 변화는 두가지 기본적 이유에서 기인합니다: (1)~자동차가 저렴해지고
쉽게 구매할 수 있게 되어서, 더 많은 사람들이 운전을 배울 기회가 늘었고,
(2)~자동 변속, 자동 초크, 자동 시동, 상당히 개선된 안정성, 그리고 다른 기술적
개선사항의 적용 등으로 자동차를 운영하기가 쉬워졌습니다.

\iffalse

Parallel programming has earned a reputation as one of the most
difficult areas a hacker can tackle.
Papers and textbooks warn of the perils of deadlock, livelock,
race conditions, non-determinism, Amdahl's-Law limits to scaling,
and excessive realtime latencies.
And these perils are quite real; we authors have accumulated uncounted
% 2020:
%	30 for Paul E. McKenney
years of experience along with the resulting emotional scars,
grey hairs, and hair loss.

However, new technologies that are difficult to use at introduction
invariably become easier over time.
For example, the once-rare ability to drive a car is now
commonplace in many countries.
This dramatic change came about for two basic reasons: (1)~cars became
cheaper and more readily available, so that more people had the
opportunity to learn to drive, and (2)~cars became easier to operate
due to automatic transmissions, automatic chokes, automatic starters,
greatly improved reliability,
and a host of other technological improvements.

\fi

컴퓨터를 비롯한 많은 다른 기술들에도 이게 동일하게 적용됩니다.
프로그래밍을 위해 펀칭머신을 사용할 필요가 더이상 없습니다.
스프레드시트는 프로그래머가 아닌 대부분의 사람들도 수십년 전이라면 전문가 팀이
필요했을 것을 컴퓨터에서 얻을 수 있게 합니다.
가장 강력한 예는 웹 서핑과 컨텐츠 작성일 것으로, 이것들은 2000년대 초반 이후로
훈련되지도 교육받지도 않은 사람들이 다양한, 지금은 흔한 소셜 네트워킹 도구들을
이용해서 쉽게 할 수 있게 되었습니다.
1968년만 해도, 그런 컨텐츠 작성은 당시에는 ``백악관 정원에 UFO 가 착륙하는
듯''\cite{ScottGriffen2000} 하다고 묘사되는 전위적 연구
프로젝트였습니다~\cite{DouglasEngelbart1968}.

따라서, 여러분이 병렬 프로그래밍이 현재 많은 사람들에게 인식되듯 어려운
영역으로 남을 거라고 주장하고 싶다면, 많은 노력이 있던 영역들에서 수세기 동안
있었던 반례를 기억하고서 증명을 해야 하는 건 여러분의 몫입니다.

\iffalse

The same is true for many other technologies, including computers.
It is no longer necessary to operate a keypunch in order to program.
Spreadsheets allow most non-programmers to get results from their computers
that would have required a team of specialists a few decades ago.
Perhaps the most compelling example is web-surfing and content creation,
which since the early 2000s has been easily done by
untrained, uneducated people using various now-commonplace
social-networking tools.
As recently as 1968, such content creation was a far-out research
project~\cite{DouglasEngelbart1968}, described at
the time as
``like a UFO landing on the White House lawn''\cite{ScottGriffen2000}.
% http://www.ibiblio.org/pioneers/engelbart.html
% http://www.histech.rwth-aachen.de/www/quellen/engelbart/ahi62index.html

Therefore, if you wish to argue that parallel programming will remain
as difficult as it is currently perceived by many to be, it is you
who bears the burden of proof, keeping in mind the many centuries of
counter-examples in many fields of endeavor.

\fi

\section{Historic Parallel Programming Difficulties}
\label{sec:intro:Historic Parallel Programming Difficulties}
%
\epigraph{Not the power to remember, but its very opposite, the power to
	  forget, is a necessary condition for our existence.}
	 {\emph{Sholem Asch}}

그 제목에서 보여지듯이, 이 책은 다른 접근법을 취합니다.
병렬 프로그래밍의 어려움에 대해 불평을 하기보다는, 병렬 프로그래밍이 어려운
이유를 알아보고, 독자들이 이 어려움들을 극복하는 것을 돕습니다.
이어서 보게 되겠지만, 이런 어려움들은 역사적으로 다음의 것들을 포함하는 몇가지
카테고리로 나뉘었습니다:

\iffalse

As indicated by its title, this book takes a different approach.
Rather than complain about the difficulty of parallel programming,
it instead examines the reasons why parallel programming is
difficult, and then works to help the reader to overcome these
difficulties.
As will be seen, these difficulties have historically fallen into several
categories, including:

\fi

\begin{enumerate}
\item	역사적으로 높은 비용과 상대적으로 희귀한 병렬 시스템의 존재.
\item	일반적인 연구자와 견습자의 병렬 시스템에 대한 경험의 부족.
\item	공개된 병렬 코드의 부재.
\item	병렬 프로그래밍에 대한 널리 알려진 엔지니어링 규칙의 부재.
\item	심지어 강하게 결합된 공유 메모리 컴퓨터에조차 존재하는 작업 대비
	커뮤니케이션의 높은 오버헤드.

\iffalse

\item	The historic high cost and relative rarity of parallel systems.
\item	The typical researcher's and practitioner's lack of experience
	with parallel systems.
\item	The paucity of publicly accessible parallel code.
\item	The lack of a widely understood engineering discipline of
	parallel programming.
\item	The high overhead of communication relative to that of processing,
	even in tightly coupled shared-memory computers.

\fi

\end{enumerate}

이런 역사적 어려움 중 다수는 극복되어 가는 중입니다.
첫째, 지난 수십년간, 병렬 시스템의 가격은 \IX{Moore의 법칙} 덕분에 집 여러채의
가격에서 간단한 식사 값 정도가 되었습니다.
멀티코어 CPU 의 장점을 이야기하는 논문이 1996년부터~\cite{Olukotun96}
출판되었습니다.
IBM 은 고성능 \Power{} 제품군에 2000년에는 동시적 멀티 쓰레딩 (simultaneous
multi-threading) 을, 2001년에는 멀티코어를 도입했습니다.
Intel 은 2000년 11월 하이퍼쓰레드를 Pentium 제품군에 도입했으며, AMD 와 Intel
ahen 2005년에 듀얼코어 CPU 를 소개했습니다.
Sun 은 2005년 말 멀티코어/멀티쓰레드 기능이 도임된 Niagara 를 이어
발표했습니다.
실제로, 2008년에 이르러, 싱글 CPU 데스크탑을 찾기가 어려워졌으며, 싱글코어 CPU
는 넷북과 임베디드 기기에만 주로 사용되게 되었습니다.
2012년에는 스마트폰조차 멀티 CPU 를 사용하기 시작했습니다.
2020년, 안전성이 중요한 소프트웨어 표준들이 동시성을 다루기 시작했습니다.

\iffalse

Many of these historic difficulties are well on the way to being overcome.
First, over the past few decades, the cost of parallel systems
has decreased from many multiples of that of a house to that of a
modest meal, courtesy of \IX{Moore's Law}.
Papers calling out the advantages of multicore CPUs were published
as early as 1996~\cite{Olukotun96}.
IBM introduced simultaneous multi-threading
into its high-end \Power{} family in 2000, and multicore in 2001.
Intel introduced hyperthreading into its commodity Pentium line in
November 2000, and both AMD and Intel introduced
dual-core CPUs in 2005.
Sun followed with the multicore/multi-threaded Niagara in late 2005.
In fact, by 2008, it was becoming difficult
to find a single-CPU desktop system, with single-core CPUs being
relegated to netbooks and embedded devices.
By 2012, even smartphones were starting to sport multiple CPUs.
By 2020, safety-critical software standards started addressing
concurrency.

\fi

둘째로, 비용이 낮고 당장 사용 가능한 멀티코어 시스템의 발전은 한때는 희귀했던
병렬 프로그래밍 경험이 지금은 거의 모든 연구자와 견습자에게 가능해졌음을
의미합니다.
사실, 병렬 시스템은 오랫동안 학생들과 취미가들에게 부담이었습니다.
따라서 우린 병렬 시스템을 둘러싼 발명과 혁신의 상당한 수준 증가를 기대할 수
있고, 그렇게 늘어난 친숙도는 한때는 금지된거나 마찬가지로 금전적 부담이 컸던
병렬 프로그래밍 분야가 훨씬 친숙해지고 일반적이게 만들 겁니다.

셋째로, 20세기에, 고수준 병렬 소프트웨어를 사용하는 거대 시스템은 거의 항상
독점적 보안을 통해 폐쇄적으로 지켜지고 있었습니다.
행복하게도 대조적으로, 21세기는 많은 오픈소스 (따라서 공공적으로 사용이 가능한)
병렬 소프트웨어 프로젝트를 보아왔는데, 리눅스 커널~\cite{Torvalds2.6kernel},
데이터베이스 시스템들~\cite{PostgreSQL2008,MySQL2008}, 그리고 메세지 패싱
시스템들~\cite{OpenMPI2008,BOINC2008} 등이 포함됩니다.
이 책은 리눅스 커널을 기초로 할겁니다만, 사용자 수준 어플리케이션에 사용 가능한
많은 것들을 제공할 겁니다.

\iffalse

Second, the advent of low-cost and readily available multicore systems
means that the once-rare experience of parallel programming is
now available to almost all researchers and practitioners.
In fact, parallel systems have long been within the budget of students
and hobbyists.
We can therefore expect greatly increased levels of invention and
innovation surrounding parallel systems, and that increased familiarity
will over time make the once prohibitively expensive field of parallel
programming much more friendly and commonplace.

Third, in the 20\textsuperscript{th} century, large systems of
highly parallel software were almost always closely guarded proprietary
secrets.
In happy contrast, the 21\textsuperscript{st} century has seen numerous
open-source (and thus publicly available) parallel software projects,
including the Linux kernel~\cite{Torvalds2.6kernel},
database systems~\cite{PostgreSQL2008,MySQL2008},
and message-passing systems~\cite{OpenMPI2008,BOINC2008}.
This book will draw primarily from the Linux kernel, but will
provide much material suitable for user-level applications.

\fi

넷째로, 1980년대와 1990년대의 거대 스케일 병렬 프로그래밍 프로젝트들은 거의
모두 독점 프로젝트였지만, 이 프로젝트들은 제품 품질의 병렬 코드를 개발하는데
필요한 엔지니어링 규칙을 이해하는 개발자들로 핵심그룹이 구성된 커뮤니티들의
씨앗을 뿌렸습니다.
이 책의 주요 목적은 이 엔지니어링 규칙을 제공하는 겁니다.

불행히도, 다섯번째 어려움, 처리 대비 높은 비용의 커뮤니케이션은 여전히
남아있습니다.
이 어려움은 2000년대에 들어 증가된 주목을 받았습니다.
하지만, \ppl{Stephen}{Hawking} 에 따르면, 빛의 제한된 속도와 물질의 원자적
성질이 이 영역에서의 발전을 제한하고
있습니다~\cite{BryanGardiner2007,GordonMoore03a}.
다행히도, 이 어려움은 1980년대 후반부터 드러나기 시작했고, 따라서 앞서 언급한
엔지니어링 규칙은 이를 처리하기에 실용적이고 효과적인 전략으로 발전했습니다.
또한, 하드웨어 설계자들이 이 문제를 더 주목하고 있으므로, 어쩌면 미래의
하드웨어는 \cref{sec:cpu:Hardware Free Lunch?} 에서 이야기하듯 병렬
소프트웨어에 더 친화적이 될수도 있습니다.

\iffalse

Fourth, even though the large-scale parallel\-/programming projects of
the 1980s and 1990s were almost all proprietary projects, these
projects have seeded other communities with cadres of developers who
understand the engineering discipline required to develop production-quality
parallel code.
A major purpose of this book is to present this engineering discipline.

Unfortunately, the fifth difficulty, the high cost of communication
relative to that of processing, remains largely in force.
This difficulty has been receiving increasing attention during
the new millennium.
However, according to \ppl{Stephen}{Hawking},
the finite speed of light and the atomic
nature of matter will limit progress in this
area~\cite{BryanGardiner2007,GordonMoore03a}.
Fortunately, this difficulty has been in force since the late 1980s,
so that the aforementioned engineering discipline has evolved practical
and effective strategies for handling it.
In addition, hardware designers are increasingly aware of these issues,
so perhaps future hardware will be more friendly to parallel software,
as discussed in \cref{sec:cpu:Hardware Free Lunch?}.

\fi

\QuickQuiz{
	이봐요!!!
	병렬 프로그래밍은 수십년동안 엄청나게 어렵다고 알려져왔어요.
	당신은 그게 그렇게 어렵지 않다고 하는 것 같군요.
	뭔가 게임이라도 하는 건가요?

	\iffalse

	Come on now!!!
	Parallel programming has been known to be exceedingly
	hard for many decades.
	You seem to be hinting that it is not so hard.
	What sort of game are you playing?

	\fi

}\QuickQuizAnswer{
	병렬 프로그래밍이 정말 엄청나게 어렵다고 생각한다면, ``왜 병렬
	프로그래밍은 어려운가?'' 라는 질문에 대한 답을 가져야 합니다.
	어떤 사람은 데드락, 레이스 컨디션, 테스트 커버리지 등의 많은 이유를
	이야기 할 수 있겠지만 진짜 답은 {\em 그게 정말로 그렇게 어렵지는 않다}
	입니다.
	무엇보다, 병렬 프로그래밍이 정말 그렇게 소름끼치도록 어렵다면, Apache,
	MySQL, 그리고 리눅스 커널을 포함하는 많은 수의 오픈소스 프로젝트들은
	그걸 해냈겠습니까?

	더 나은 질문은 아마도 이걸겁니다: ``왜 병렬 프로그래밍은 그렇게
	어려울거라 {\em 여겨지는가}?''
	그 답을 알기 위해, 1991년도로 돌아가 봅시다.
	Paul McKenney 는 Sequent 의 벤치마킹 센터로 여섯개의 dual-80486 Sequent
	Symmetry CPU 보드를 들고 주차장을 건너 걸어가고 있었는데, 그는 순간
	자신이 그가 최근 구입한 집보다 몇배가 되는 가격의 물건을 들고 있음을
	깨달았습니다.\footnote{
		그래요, 이 순간적 깨달음은 {\em 정말} 그를 훨씬 조심스럽게 걷게
		만들었습니다.
		왜 묻는 거죠?}
	이런 병렬 시스템의 높은 가격은 병렬 프로그래밍이 \$100,000---1991년 US
	달러--- 까지 달하는 기계를 제조하거나 구매할 수 있는 고용주를 위해
	일하는, 권한을 받은 일부에게로 제한되었음을 의미합니다.

	\iffalse

	If you really believe that parallel programming is exceedingly
	hard, then you should have a ready answer to the question
	``Why is parallel programming hard?''
	One could list any number of reasons, ranging from deadlocks to
	race conditions to testing coverage, but the real answer is that
	{\em it is not really all that hard}.
	After all, if parallel programming was really so horribly difficult,
	how could a large number of open-source projects, ranging from Apache
	to MySQL to the Linux kernel, have managed to master it?

	A better question might be: ``Why is parallel programming {\em
	perceived} to be so difficult?''
	To see the answer, let's go back to the year 1991.
	Paul McKenney was walking across the parking lot to Sequent's
	benchmarking center carrying six dual-80486 Sequent Symmetry CPU
	boards, when he suddenly realized that he was carrying several
	times the price of the house he had just purchased.\footnote{
		Yes, this sudden realization {\em did} cause him to walk quite
		a bit more carefully.
		Why do you ask?}
	This high cost of parallel systems meant that
	parallel programming was restricted to a privileged few who
	worked for an employer who either manufactured or could afford to
	purchase machines costing upwards of \$100,000---in 1991 dollars US.

	\fi

	대조적으로, 2020년, Paul 은 자신이 이 글을 six-core x86 랩톱에서 타이핑
	하고 있음을 압니다.
	그 dual-80486 CPU 보드와 달리, 이 랩톱은 또한 64\,GB 메인 메모리, 1\,TB
	SSD, 디스플레이, 이더넷, USB 포트, 무선인터넷, 블루투스를 포함하고
	있습니다.
	그리고 이 랩톱은 그 dual-80486 CPU 보드들 중 하나보다도 열배 넘게
	쌉니다, 물가 상승을 계산하지 않아도 말이죠.

	병렬 시스템은 정말 도착했습니다.
	그것들은 더이상 선택받은 일부에게만 허용된 도메인이 아니라 거의
	모두에게 사용가능한 무언가입니다.

	\iffalse


	In contrast, in 2020, Paul finds himself typing these words on a
	six-core x86 laptop.
	Unlike the dual-80486 CPU boards, this laptop also contains
	64\,GB of main memory, a 1\,TB solid-state disk, a display, Ethernet,
	USB ports, wireless, and Bluetooth.
	And the laptop is more than an order of magnitude cheaper than
	even one of those dual-80486 CPU boards, even before taking inflation
	into account.

	Parallel systems have truly arrived.
	They are no longer the sole domain of a privileged few, but something
	available to almost everyone.

	\fi

	이전의 병렬 하드웨어의 제한된 접근성이 병렬 프로그래밍은 그렇게
	어렵다고 여겨지게 한 \emph{진짜} 이유입니다.
	어쨌건, 접근할 수가 없다면 가장 간단한 기계조차도 프로그래밍 하는 법을
	배우기가 무척 어렵습니다.
	흔치 않고 비싼 병렬 기계의 시대는 거의 과거가 되고 있으므로, 병렬
	프로그래밍이 미치도록 어렵다고 여겨지던 시대는 끝나가고
	있습니다.\footnote{ 병렬 프로그래밍은 어떤 면에서는 순차적
		프로그래밍보다 어려운데, 예를 들어 병렬 검증은 더 어렵습니다.
		하지만 더이상 미치도록 어렵진 않습니다.}

	\iffalse

	The earlier restricted availability of parallel hardware is
	the \emph{real} reason that parallel programming is considered
	so difficult.
	After all, it is quite difficult to learn to program even the simplest
	machine if you have no access to it.
	Since the age of rare and expensive parallel machines is for the most
	part behind us, the age during which
	parallel programming is perceived to be mind-crushingly difficult is
	coming to a close.\footnote{
		Parallel programming is in some ways more difficult than
		sequential programming, for example, parallel validation
		is more difficult.
		But no longer mind-crushingly difficult.}

	\fi
}\QuickQuizEnd

하지만, 병렬 프로그래밍이 일반적으로 알려진 것만큼 어렵진 않을 수 있다고 쳐도,
많은 경우 순차적 프로그래밍보다는 어렵습니다.

\iffalse

However, even though parallel programming might not be as hard as
is commonly advertised, it is often more work than is sequential
programming.

\fi

\QuickQuiz{
	병렬 프로그래밍이 순차적 프로그래밍만큼 쉬워지는게 \emph{가능은
	할까요}?

	\iffalse

	How could parallel programming \emph{ever} be as easy
	as sequential programming?

	\fi

}\QuickQuizAnswer{
	그건 프로그래밍 환경에 달려 있습니다.
	SQL~\cite{DIS9075SQL92} 은 과소평가된 성공사례로, 병렬성을 전혀 모르는
	프로그래머가 거대한 병렬 시스템을 생산적으로 바쁘게 만들 수 있게
	합니다.
	병렬 컴퓨터가 저렵해지고 더 접근 가능하게 될수록 이런 주제가 다양해질
	거라 예상해 볼 수 있습니다.
	예를 들어, 과학 기술 컴퓨팅 쪽에서의 가능한 대적자는 일반적 행렬 계산을
	자동으로 병렬화 시키는 MATPAB*P 가 될겁니다.

	마지막으로, 리눅스와 유닉스 시스템에서는 다음 셸 커맨드를 생각해
	봅시다:

	\iffalse

	It depends on the programming environment.
	SQL~\cite{DIS9075SQL92} is an underappreciated success
	story, as it permits programmers who know nothing about parallelism
	to keep a large parallel system productively busy.
	We can expect more variations on this theme as parallel
	computers continue to become cheaper and more readily available.
	For example, one possible contender in the scientific and
	technical computing arena is MATLAB*P,
	which is an attempt to automatically parallelize common
	matrix operations.

	Finally, on Linux and UNIX systems, consider the following
	shell command:

	\fi

	\begin{VerbatimU}
	get_input | grep "interesting" | sort
	\end{VerbatimU}

	이 셸 파이프라인은 \co{get_input}, \co{grep}, 그리고 \co{sort} 를
	병렬로 수행합니다.
	봐요, 그렇게 어렵지 않았어요, 이제 어때요?

	짧게 요약해서, 병렬 프로그래밍은 순차적 프로그래밍만큼
	간단합니다---최소한 병렬성을 사용자로부터 감추는 환경에서라면요!

	\iffalse

	This shell pipeline runs the \co{get_input}, \co{grep},
	and \co{sort} processes in parallel.
	There, that wasn't so hard, now was it?

	In short, parallel programming is just as easy as sequential
	programming---at least in those environments that hide the parallelism
	from the user!

	\fi

}\QuickQuizEnd

따라서 병렬 프로그래밍의 대체안을 생각해 보는게 말이 됩니다.
하지만, 병렬 프로그래밍의 목표를 이해하지 못한 채로 병렬 프로그래밍의 합리적
대체안을 생각하는건 불가능합니다.
이 주제는 다음 섹션에서 다룹니다.

\iffalse

It therefore makes sense to consider alternatives to parallel programming.
However, it is not possible to reasonably consider parallel-programming
alternatives without understanding parallel-programming goals.
This topic is addressed in the next section.

\fi

\section{Parallel Programming Goals}
\label{sec:intro:Parallel Programming Goals}
%
\epigraph{If you don't know where you are going, you will end up somewhere
	  else.}{\emph{Yogi Berra}}

병렬 프로그래밍의 (순차적 프로그래밍에 비해 더 나아지고자 하는) 세가지 주요
목표는 다음과 같습니다:

\begin{enumerate}
\item	성능.
\item	생산성.
\item	범용성.
\end{enumerate}

\iffalse

The three major goals of parallel programming (over and above those
of sequential programming) are as follows:

\begin{enumerate}
\item	Performance.
\item	Productivity.
\item	Generality.
\end{enumerate}

\fi

불행히도, 현재 기술로는, 어떤 병렬 프로그램도 이 세가지 목표 중 두개까지만
달성이 가능합니다.
따라서 이 세개의 목표는 \emph{병렬 프로그래밍의 철의 삼각지대} 를 이루는데,
너무 낙관적인 희망은 모두 슬픔으로 끝나고 마는 삼각지대입니다.\footnote{
	철의 삼각지대라는 이름을 지어준 데 대해 Michael Wong 에게 감사를
	드립니다.}

\iffalse

Unfortunately, given the current state of the art, it is possible to
achieve at best two of these three goals for any given parallel program.
These three goals therefore form the \emph{iron triangle of parallel
programming},
a triangle upon which overly optimistic hopes all too often come to
grief.\footnote{
	Kudos to Michael Wong for naming the iron triangle.}

\fi

\QuickQuizSeries{%
\QuickQuizB{
	오, 정말로요???
	정확성, 유지가능성, 견고성, 등등은 어쩌고요?

	\iffalse

	Oh, really???
	What about correctness, maintainability, robustness, and so on?

	\fi

}\QuickQuizAnswerB{

	이것들은 중요한 목표입니다만, 병렬 프로그램에 그렇듯 순차적
	프로그램에도 중요합니다.
	따라서 중요하긴 하지만 병렬 프로그래밍에 국한된 리스트에 들어갈 수는
	없습니다.

	\iffalse

	These are important goals, but they are just as important for
	sequential programs as they are for parallel programs.
	Therefore, important though they are, they do not belong on
	a list specific to parallel programming.

	\fi

}\QuickQuizEndB
%
\QuickQuizM{
	그리고 정확성, 유지가능성, 견고성이 그 리스트에 들어가지 못한다면,
	생산성과 범용성은 왜 들어가는거죠?

	\iffalse

	And if correctness, maintainability, and robustness don't
	make the list, why do productivity and generality?

	\fi

}\QuickQuizAnswerM{
	병렬 프로그래밍이 순차적 프로그래밍에 비해 훨씬 어렵다고 여겨진다는
	점을 고려하면, 생산성 역시 그러하며 따라서 무시되지 말아야 합니다.
	더 나아가서, SQL 과 같은 높은 생산성의 병렬 프로그래밍 환경은 특수
	목적을 처리하며, 따라서 범용성 역시 리스트에 추가되어야 합니다.

	\iffalse

	Given that parallel programming is perceived to be much harder
	than sequential programming, productivity is tantamount and
	therefore must not be omitted.
	Furthermore, high-productivity parallel-programming environments
	such as SQL serve a specific purpose, hence generality must
	also be added to the list.

	\fi

}\QuickQuizEndM
%
\QuickQuizM{
	병렬 프로그램은 순차적 프로그램보다 정확성을 입증하기가 훨씬 어렵다는
	점을 고려하면, 정확성도 \emph{정말} 이 리스트에 들어가야 하지 않습니까?

	\iffalse

	Given that parallel programs are much harder to prove
	correct than are sequential programs, again, shouldn't
	correctness \emph{really} be on the list?

	\fi

}\QuickQuizAnswerM{
	엔지니어링 관점에서 보면, 정식으로든 비정식으로든 정확성을 검증하는데
	드는 어려움은 생산성이라는 주요 목표에 영향 끼치는 만큼만 중요합니다.
	따라서, 정확성 검증이 중요한 경우라면, ``생산성'' 항목에 포함되어
	있습니다.

	\iffalse

	From an engineering standpoint, the difficulty in proving
	correctness, either formally or informally, would be important
	insofar as it impacts the primary goal of productivity.
	So, in cases where correctness proofs are important, they
	are subsumed under the ``productivity'' rubric.

	\fi

}\QuickQuizEndM
%
\QuickQuizE{
	그냥 재미를 목표로 하는건 어때요?

	\iffalse

	What about just having fun?

	\fi

}\QuickQuizAnswerE{
	재미를 주는 것도 물론 중요합니다만, 여러분이 취미가가 아니라면,
	\emph{주요} 목표가 되진 못할 겁니다.
	한편, 여러분이 취미가가 \emph{맞다면}, 날뛰어 보십시오!

	\iffalse

	Having fun is important as well, but, unless you are a hobbyist,
	would not normally be a \emph{primary} goal.
	On the other hand, if you \emph{are} a hobbyist, go wild!

	\fi

}\QuickQuizEndE
}

이 목표들 각각을 다음 섹션들에서 더 설명하겠습니다.

\iffalse

Each of these goals is elaborated upon in the following sections.

\fi

\subsection{Performance}
\label{sec:intro:Performance}

성능은 대부분의 병렬 프로그래밍의 주요 목표입니다.
어쨌건, 성능이 문제가 아니라면, 왜 여러분에게 호의를 베풀지 않습니까:  그냥
순차적 코드를 작성하고, 행복해지는 것 말이예요.
그건 훨씬 쉬울거고 여러분은 훨씬 더 빠르게 일을 끝낼 수 있을 겁니다.

\iffalse

Performance is the primary goal behind most parallel-programming effort.
After all, if performance is not a concern, why not do yourself
a favor:  Just write sequential code, and be happy?
It will very likely be easier
and you will probably get done much more quickly.

\fi

\QuickQuiz{
	병렬 프로그래밍이 성능 외의 것을 위한 경우는 없나요?

	\iffalse

	Are there no cases where parallel programming is about something
	other than performance?

	\fi

}\QuickQuizAnswer{
	해결해야 하는 문제가 본질적으로병렬적인 경우가 있는데, 예를 들어 Monte
	Carlo 방법론과 일부 수학 연산들입니다.
	하지만, 이 경우들에도 병렬성을 관리하기 위한 추가 작업이 일부 있을
	겁니다.

	병렬성은 또한 때로 안전성을 위해 사용됩니다.
	한가지만 예를 들어보자면, triple-modulo redundancy 는 세개의 시스템을
	병렬로 돌리고 그 결과를 투표해서 정합니다.
	극단적 경우에는, 이 세개의 시스템이 다른 알고리즘과 기술을 가지고
	독립적으로 구현될 겁니다.

	\iffalse

	There certainly are cases where the problem to be solved is
	inherently parallel, for example, Monte Carlo methods and
	some numerical computations.
	Even in these cases, however, there will be some amount of
	extra work managing the parallelism.

	Parallelism is also sometimes used for reliability.
	For but one example,
	triple-modulo redundancy has three systems run in parallel
	and vote on the result.
	In extreme cases, the three systems will be independently
	implemented using different algorithms and technologies.

	\fi

}\QuickQuizEnd

여기서 ``성능'' 이란 단어는 넓은 의미를 갖는데, 예를 들어 확장성 (CPU 당 성능)
과 효율성 (watt 당 성능) 을 포함함을 알아두시기 바랍니다.

\iffalse

Note that ``performance'' is interpreted broadly here,
including for example scalability (performance per CPU) and efficiency
(performance per watt).

\fi

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{SMPdesign/clockfreq}}
\caption{MIPS/Clock-Frequency Trend for Intel CPUs}
\label{fig:intro:Clock-Frequency Trend for Intel CPUs}
\end{figure}

그러나, 성능의 포커스는 하드웨어에서 병렬 소프트웨어로 옮겨졌습니다.
이 포커스의 변화는 \IX{Moore 의 법칙} 은 트랜지스터 집적도 증가를 지속하게
함에도, 전통적인 단일 쓰레드 성능 증가는 중단되었다는 사실 때문에
이루어졌습니다.
이는
Figure~\ref{fig:intro:Clock-Frequency Trend for Intel CPUs}\footnote{
	이 그림은 이론적으로 클락당 한개 이상의 인스트럭션을 처리할 수 있는
	신형 CPU 들의 경우 클락 주파수를, 가장 단순한 인스트럭션의 처리에도
	여러 클락을 필요로 하는 구형 CPU 들의 경우에는 MIPS (보통 Dhrystone
	벤치마크를 통해 얻어진, 초당 몇백만개의 인스트럭션이 처리 가능한가를
	나타내는 수) 를 보이고 있습니다.
	두개의 측정을 사용하는 이유는 신형 CPU 의 클락당 여러 인스트럭션을
	처리할 수 있는 능력이 메모리 시스템의 성능으로 인해 제한되곤 하기
	때문입니다.
	뿐만 아니라, 구형 CPU 의 성능 측정에 사용된 벤치마크는 더이상 사용되지
	않고, 신형 벤치마크를 구형 CPU 를 탑재한 시스템에서 돌리는 건 어려운데,
	부분적으로는 동작하는 구형 CPU 를 찾기도 쉽지 않기 때문입니다.}
에 그려져 있는데, 싱글 쓰레드 코드를 작성하고 CPU 가 성능이 좋아지기를 1-2년
기다리는건 더이상 선택지가 아님을 보입니다.
모든 주요 제조사가 멀티코어/멀티쓰레드 시스템으로 방향을 잡은 최근의 트렌드를
놓고 보면, 시스템의 완전한 성능을 내고자 하는 사람에게라면 병렬성이 맞는
방향입니다.

\iffalse

That said, the focus of performance has shifted from hardware to
parallel software.
This change in focus is due to the fact that, although \IX{Moore's Law}
continues to deliver increases in transistor density, it has ceased to
provide the traditional single-threaded performance increases.
This can be seen in
Figure~\ref{fig:intro:Clock-Frequency Trend for Intel CPUs}\footnote{
	This plot shows clock frequencies for newer CPUs theoretically
	capable of retiring one or more instructions per clock, and MIPS
	(millions of instructions per second, usually from the old
	Dhrystone benchmark)
	for older CPUs requiring multiple clocks to execute even the
	simplest instruction.
	The reason for shifting between these two measures is that the
	newer CPUs' ability to retire multiple instructions per clock is
	typically limited by memory-system performance.
	Furthermore, the benchmarks commonly used on the older CPUs
	are obsolete, and it is difficult to run the newer benchmarks
	on systems containing the old CPUs, in part because it is hard
	to find working instances of the old CPUs.},
which shows that writing single-threaded code and simply waiting
a year or two for the CPUs to catch up may no longer be an option.
Given the recent trends on the part of all major manufacturers towards
multicore/multithreaded systems, parallelism is the way to go for
those wanting to avail themselves of the full performance of their
systems.

\fi

\QuickQuiz{
	프로그램을 비효율적인 스크립트 언어에서 C 나 C++ 로 재작성하는 건
	어떨까요?

	\iffalse

	Why not instead rewrite programs from inefficient scripting
	languages to C or C++?

	\fi

}\QuickQuizAnswer{
	그런 재작성을 위한 개발자들, 예산, 그리고 시간이 충분하다면, 그리고
	그게 단일 CPU 에서도 필요한 수준의 성능을 얻을 수 있다면, 합리적
	접근법이 될 수 있습니다.

	\iffalse

	If the developers, budget, and time is available for such a
	rewrite, and if the result will attain the required levels
	of performance on a single CPU, this can be a reasonable
	approach.

	\fi

}\QuickQuizEnd

그렇기는 하나, 첫번째 목표는 확장성보다는 성능인데, 선형적 확장성을 얻는 가장
쉬운 방법은 각 CPU 의 성능을 낮추는 것~\cite{LinusTorvalds2001a} 이라는 점을
놓고 보면 특히 그렇습니다.
네개의 CPU 를 탑재한 시스템이 있다면, 당신이라면 뭘 선호하겠습니까?
단일 CPU 에서 초당 100개의 트랜잭션을 처리하지만 전혀 멀티 CPU 확장성이 없는
프로그램입니까?
아니면 단일 CPU 에서 초당 10개의 트랜잭션만을 처리하지만 CPU 개수를 늘림에 따라
완전하게 확장 가능한 프로그램입니까?
첫번째 프로그램이 더 나은 선택일 겁니다, 32개 CPU 가 탑재된 시스템이라면 답이
달라질 수도 있겠지만요.

\iffalse

Even so, the first goal is performance rather than scalability,
especially given that the easiest way to attain linear scalability
is to reduce the performance of each CPU~\cite{LinusTorvalds2001a}.
Given a four-CPU system, which would you prefer?
A program that provides 100 transactions per second on a single CPU,
but does not scale at all?
Or a program that provides 10 transactions per second on a single CPU,
but scales perfectly?
The first program seems like a better bet, though the answer might
change if you happened to have a 32-CPU system.

\fi

그러나, 여러분이 여러 CPU 를 가졌다는 건 그 자체로 그걸 모두 사용해야만 한다는
이유가 되지 않는데, 특히 최근의 멀티 CPU 시스템의 가격 하락을 놓고 보면
그렇습니다.
핵심은 병렬 프로그래밍은 기본적으로 성능 최적화이며, 그건 여러 잠재적 최적화
방법 중 하나라는 것입니다.
여러분의 프로그램이 현재 작성된 대로도 충분히 빠르다면, 병렬화를 해서든 다른
잠재적 순차적 최족화 방법들을 동원해서든 최적화를 할 이유가 없습니다.\footnote{
	물론, 여러분이 병렬 소프트웨어를 작성하는게 주요 관심사인 취미
	생활자라면 여러분이 관심있는 소프트웨어가 무엇이건 병렬화를 할 충분한
	이유가 됩니다.}
같은 이유로, 순차적 프로그램의 최적화 수단으로 병렬화를 하고자 한다면, 최선의
순차적 알고리즘과 병렬 알고리즘들을 비교해야 합니다.
현재 많은 출판물이 병렬 알고리즘의 성능을 논할 때 순차적 알고리즘의 경우들을
무시하곤 하기 때문에 이 부분에서 주의가 필요합니다.

\iffalse

That said, just because you have multiple CPUs is not necessarily
in and of itself a reason to use them all, especially given the
recent decreases in price of multi-CPU systems.
The key point to understand is that parallel programming is primarily
a performance optimization, and, as such, it is one potential optimization
of many.
If your program is fast enough as currently written, there is no
reason to optimize, either by parallelizing it or by applying any
of a number of potential sequential optimizations.\footnote{
	Of course, if you are a hobbyist whose primary interest is
	writing parallel software, that is more than enough reason to
	parallelize whatever software you are interested in.}
By the same token, if you are looking to apply parallelism as an
optimization to a sequential program, then you will need to compare
parallel algorithms to the best sequential algorithms.
This may require some care, as far too many publications ignore the
sequential case when analyzing the performance of parallel algorithms.

\fi

\subsection{Productivity}
\label{sec:intro:Productivity}

\QuickQuiz{
	왜 이건 기술적이지 않은 문제들에 대해 떠드는 거죠???
	단순히 \emph{아무} 기술적이지 않은 문제가 아니라, \emph{생산성}
	이라구요?
	누가 이걸 신경씁니까?

	\iffalse

	Why all this prattling on about non-technical issues???
	And not just \emph{any} non-technical issue, but \emph{productivity}
	of all things?
	Who cares?

	\fi

}\QuickQuizAnswer{
	여러분이 순수한 취미가라면, 아마 신경쓸 필요 없을 겁니다.
	하지만 순수한 취미가라 할지라도 얼마나 빨리 얼마나 많이 일을 해낼 수
	있는가에 종종 신경씁니다.
	어쨌건, 가장 대중적인 취미가용 도구는 그 일을 하는데 최적인 것들이
	경우가 많고, ``최적'' 의 정의의 중요한 부분은 생산성과 연관되어
	있습니다.
	그리고 만약 누군가가 여러분이 병렬 코드를 작성하는데 대해 돈을 지불하고
	있다면, 그들은 여러분의 생산성에 무척 신경쓰고 있을 가능성이 높습니다.
	그리고 여러분에게 돈을 지불하는 사람이 뭔가에 신경쓰고 있다면, 여러분도
	그것에 최소 어느 정도는 신경을 쓰는게 현명할 겁니다!

	그 외에도, 여러분이 \emph{정말로} 생산성을 신경쓰지 않는다면, 컴퓨터를
	사용하지 않고 수작업으로 직접 일을 하시겠죠!

	\iffalse

	If you are a pure hobbyist, perhaps you don't need to care.
	But even pure hobbyists will often care about how much they
	can get done, and how quickly.
	After all, the most popular hobbyist tools are usually those
	that are the best suited for the job, and an important part of
	the definition of ``best suited'' involves productivity.
	And if someone is paying you to write parallel code, they will
	very likely care deeply about your productivity.
	And if the person paying you cares about something, you would
	be most wise to pay at least some attention to it!

	Besides, if you \emph{really} didn't care about productivity,
	you would be doing it by hand rather than using a computer!

	\fi

}\QuickQuizEnd

최근 수십년간 생산성은 점점 더 중요해졌습니다.
이를 보기 위해, 초기 컴퓨터의 가격은 엔지니어 연봉이 수천달러이던 시절에 수억
달러였음을 생각해 보십시오.
그런 기계를 위해 열명의 엔지니어 팀을 전담시키는 것이 그 성능을 10\,\% 라도
향상시킨다면, 그들의 연봉은 여러번 더 지불될 수 있을 겁니다.

그런 기계 중 하나로 CSIRAC 가 있는데, 가장 오래되었고 여전히 손상되지 않은
stored-program 컴퓨터로, 1949년부터
작동되었습니다~\cite{CSIRACMuseumVictoria,CSIRACUniversityMelbourne}.
이 기계는 트랜지스터 시대 전에 만들어졌으므로, 2,000 개의 진공관으로 만들어졌고
1\,kHz 클락 주파수로 작동하며, 30\,kW 전력을 소비하고, 3 톤의 무게를
가졌습니다.
이 기계가 768 워드 RAM 을 가졌음을 생각해 보면, 이 기계는 오늘날의 거대 규모
소프트웨어 프로젝트가 시달리는 생산성 이슈로 고생하지는 않았을 거라 말할 수
있을 겁니다.

오늘날, 이렇게 작은 컴퓨팅 파워를 가진 기계를 구입하긴 상당히 어려울 겁니다.
가장 비슷한 장비는 아마도 유서 깊은 Z80~\cite{z80Wikipedia} 로 대표되는 8-bit
임베디드 마이크로프로세서가 될 겁니다만, 오래된 Z80 조차도 CSIRAC 보다 1,000
배나 빠른 CPU 클락 주파수를 가졌습니다.
Z80 CPU 는 8,500 개 트랜지스터를 가졌고, 2008년 기준으로 1,000개씩 구매하면
개당 \$2 US 도 하지 않았습니다.
CSIRAC 에 대비되게도, Z80 에 있어 소프트웨어 개발 비용은 중요치 않습니다.

\iffalse

Productivity has been becoming increasingly important in recent decades.
To see this, consider that the price of early computers was tens
of millions of dollars at
a time when engineering salaries were but a few thousand dollars a year.
If dedicating a team of ten engineers to such a machine would improve
its performance, even by only 10\,\%, then their salaries
would be repaid many times over.

One such machine was the CSIRAC, the oldest still-intact stored-program
computer, which was put into operation in
1949~\cite{CSIRACMuseumVictoria,CSIRACUniversityMelbourne}.
Because this machine was built before the transistor era, it was constructed
of 2,000 vacuum tubes, ran with a clock frequency of 1\,kHz,
consumed 30\,kW of power, and weighed more than three metric tons.
Given that this machine had but 768 words of RAM, it is safe to say that
it did not suffer from the productivity issues that often plague
today's large-scale software projects.

Today, it would be quite difficult to purchase a machine with so
little computing power.
Perhaps the closest equivalents
are 8-bit embedded microprocessors exemplified by the venerable
Z80~\cite{z80Wikipedia}, but even the old Z80 had a CPU clock
frequency more than 1,000 times faster than the CSIRAC\@.
The Z80 CPU had 8,500 transistors, and could be purchased in 2008
for less than \$2 US per unit in 1,000-unit quantities.
In stark contrast to the CSIRAC, software-development costs are
anything but insignificant for the Z80.

\fi

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{SMPdesign/mipsperbuck}}
\caption{MIPS per Die for Intel CPUs}
\label{fig:intro:MIPS per Die for Intel CPUs}
\end{figure}

CSIRAC 와 Z80 은 장기적 트렌드 상의 두 지점으로,
Figure~\ref{fig:intro:MIPS per Die for Intel CPUs}
위에서 볼 수 있습니다.
이 그림은 다이당 예상 연산력을 과거 40년의 세월에 걸쳐 그리고 있는데, 40년간
백만배가 넘는 인상적인 향상을 보입니다.
멀티코어 CPU 의 발전은 2003년 이후 마주친 클락 주파수 장벽에도 불구하고 다이당
50개의 하드웨어 쓰레드를 지원함으로써 이 향상을 지속가능하게 했음을 알아두시기
바랍니다.

하드웨어 가격의 가파른 하락의 부정할 수 없는 결론은 소프트웨어 생산성이 갈수록
중요해져 가고 있다는 겁니다.
단순히 하드웨어를 효율적으로 사용하는건 더이상 충분치 않습니다:
이제 소프트웨어 개발자들을 극단적으로 효율성 있게 활용할 필요가 있습니다.
이는 순차적 하드웨어에 있어서 오랫동안 그랬습니다만, 병렬 하드웨어는최근
들어서야 저렴한 일반 상품이 되었습니다.
따라서, 최근에 들어서야 높은 생산성이 병렬 소프트웨어를 만드는 데 있어 크게
중요해 졌습니다.

\iffalse

The CSIRAC and the Z80 are two points in a long-term trend, as can be
seen in
Figure~\ref{fig:intro:MIPS per Die for Intel CPUs}.
This figure plots an approximation to computational power per die
over the past four decades, showing an impressive six-order-of-magnitude
increase over a period of forty years.
Note that the advent of multicore CPUs has permitted this increase to
continue apace despite the clock-frequency wall encountered in 2003,
albeit courtesy of dies supporting more than 50 hardware threads each.

One of the inescapable consequences of the rapid decrease in
the cost of hardware is that software productivity becomes increasingly
important.
It is no longer sufficient merely to make efficient use of the hardware:
It is now necessary to make extremely efficient use of software
developers as well.
This has long been the case for sequential hardware, but
parallel hardware has become a low-cost commodity only recently.
Therefore, only recently has high productivity become critically important
when creating parallel software.

\fi

\QuickQuiz{
	병렬 시스템이 그렇게 싸졌는데, 그걸 프로그램하라고 누가 돈을 줄까요?

	\iffalse

	Given how cheap parallel systems have become, how can anyone
	afford to pay people to program them?

	\fi
}\QuickQuizAnswer{

	이 질문에 여러 답이 가능합니다:
	\begin{enumerate}
	\item	병렬 기계의 클러스터가 있다면, 이 클러스터의 전체 가격은 상당한
		수준의 개발 노력을 정당화 할 수 있을텐데, 개발 비용이 이 많은
		수의 기계들로 나뉘어질 수 있기 때문입니다.
	\item	수천만명의 사용자들에 의해 돌아가는 대중적인 소프트웨어는
		상당한 개발 노력을 쉽게 정당화 할 수 있는데, 이 개발 비용은
		수천만명의 사용자로 나뉘어질 수 있기 때문입니다.
		이는 커널과 시스템 라이브러리 같은 것들을 포함함을
		알아두십시오.
	\item	저렴한 병렬 머신이 중요한 장비의 한 부품의 운영을 조절한다면,
		이 장비의 한 부품의 가격은 상당한 개발 노력을 쉽게 정당화 시킬
		수도 있습니다.
	\item	저렴한 병렬 기계의 소프트웨어가 극단적으로 중요한 결과 (예:
		전력 절약) 를 만들어 낸다면, 이 중요한 결과가 역시 상당한 개발
		비용을 정당화 시킬 수도 있습니다.
	\item	안전성이 중요한 시스템은 목숨을 보호하므로, 분명히 매우 큰 개발
		노력을 정당화 할 수 있습니다.
	\item	취미가들과 연구자들은 대신 지식, 경험, 재미, 그리고 영광을
		추구할 겁니다.
	\end{enumerate}

	그러니 줄어드는 하드웨어 가격이 소프트웨어를 가치없게 하지는 않으며,
	오히려 소프트웨어 개발 비용을 하드웨어 가격 아래 ``감출'' 수
	없어졌습니다, 엄청나게 커다란 하드웨어 단위가 존재하지 않는 이상
	말이죠.

	\iffalse

	There are a number of answers to this question:
	\begin{enumerate}
	\item	Given a large computational cluster of parallel machines,
		the aggregate cost of the cluster can easily justify
		substantial developer effort, because the development
		cost can be spread over the large number of machines.
	\item	Popular software that is run by tens of millions of users
		can easily justify substantial developer effort,
		as the cost of this development can be spread over the tens
		of millions of users.
		Note that this includes things like kernels and system
		libraries.
	\item	If the low-cost parallel machine is controlling the operation
		of a valuable piece of equipment, then the cost of this
		piece of equipment might easily justify substantial
		developer effort.
	\item	If the software for the low-cost parallel machine produces an
		extremely valuable result (e.g., energy savings),
		then this valuable result might again justify substantial
		developer cost.
	\item	Safety-critical systems protect lives, which can clearly
		justify very large developer effort.
	\item	Hobbyists and researchers might instead seek knowledge,
		experience, fun, or glory.
	\end{enumerate}
	So it is not the case that the decreasing cost of hardware renders
	software worthless, but rather that it is no longer possible to
	``hide'' the cost of software development within the cost of
	the hardware, at least not unless there are extremely large
	quantities of hardware.

	\fi

}\QuickQuizEnd

적어도 한때, 병렬 소프트웨어의 단 한가지 목적은 성능이었습니다.
하지만, 지금 생산성은 더 많은 주목을 받고 있습니다.

\iffalse

Perhaps at one time, the sole purpose of parallel software was performance.
Now, however, productivity is gaining the spotlight.

\fi

\subsection{Generality}
\label{sec:intro:Generality}

병렬 소프트웨어 개발의 높은 비용을 정당화 하는 한가지 방법은 최대한의 범용성을
갖추는 것입니다.
다른게 모두 똑같다면, 더 범용적인 소프트웨어는 그 비용이 더 많은 사람들에게
나뉘어 질 수 있을 겁니다.
사실, 이 경제성이 범용성의 중요한 특수 케이스인 이식성에 대한 매니악한 주목을
설명합니다.\footnote{
	이걸 짚어준 Michael Wong 에게 감사의 말씀을 드립니다.}

불행히도, 범용성은 성능, 생산성, 또는 둘 다의 비용을 초래합니다.
예를 들어, 이식성은 적용 레이어를 통해 얻어지는데, 이는 어쩔 수 없이 성능
저하를 일으킵니다.
이를 더 일반적으로 보기 위해, 다음의 유명한 병렬 프로그래밍 환경들을 생각해
봅시다:

\iffalse

One way to justify the high cost of developing parallel software
is to strive for maximal generality.
All else being equal, the cost of a more-general software artifact
can be spread over more users than that of a less-general one.
In fact, this economic force explains much of the maniacal focus
on portability, which can be seen as an important special case
of generality.\footnote{
	Kudos to Michael Wong for pointing this out.}

Unfortunately, generality often comes at the cost of performance,
productivity, or both.
For example, portability is often achieved via adaptation layers,
which inevitably exact a performance penalty.
To see this more generally, consider the following popular parallel
programming environments:

\fi

\begin{description}
\item[C/C++ ``락킹과 쓰레드'':] POSIX 쓰레드
	(pthreads)~\cite{OpenGroup1997pthreads}, Windows 쓰레드, 다양한
	운영체제 커널 환경을 초함하는 이 카테고리는 (적어도 하나의 SMP 시스템
	내에서는) 훌륭한 성능과 좋은 범용성을 제공합니다.
	상대적으로 낮은 생산성이 유감입니다.
\item[Java:] 범용이고 본질적으로 멀티쓰레드 기반인 이 프로그래밍 환경은
	자동화된 가비지 콜렉터와 풍부한 클래스 라이브러리 덕에 C 나 C++ 보다
	훨씬 높은 생산성을 제공한다고 널리 믿어집니다.
	하지만, 그 성능은 2000년대 초반에 상당히 개선되긴 했지만 C 와 C++ 에
	비해선 훨씬 떨어집니다.
\item[MPI:] 이 Message Passing Interface~\cite{MPIForum2008} 는 세계에서 가장
	거대한 과학과 기술 분야 컴퓨팅 클러스터를 굴리며 전대미문의 성능과
	확장성을 제공합니다.
	이론적으로 이건 범용입니다만 과학과 기술 분야 컴퓨팅에 주로 사용됩니다.
	이것의 생산성은 많은 이들에게 C/C++ ``락킹과 쓰레드'' 보다도 낮다고
	여겨집니다.
\iffalse

\item[C/C++ ``Locking Plus Threads'':] This category, which includes
	POSIX Threads (pthreads)~\cite{OpenGroup1997pthreads},
	Windows Threads, and numerous
	operating-system kernel environments, offers excellent performance
	(at least within the confines of a single SMP system)
	and also offers good generality.
	Pity about the relatively low productivity.
\item[Java:] This general purpose and inherently multithreaded
	programming environment	is widely believed to offer much higher
	productivity than C or C++, courtesy of the automatic garbage collector
	and the rich set of class libraries.
	However, its performance, though greatly improved in the early
	2000s, lags that of C and C++.
\item[MPI:] This Message Passing Interface~\cite{MPIForum2008} powers
	the largest scientific and technical computing clusters in
	the world and offers unparalleled performance and scalability.
	In theory, it is general purpose, but it is mainly used
	for scientific and technical computing.
	Its productivity is believed by many to be even lower than that
	of C/C++ ``locking plus threads'' environments.

\fi
\item[OpenMP:] 이 컴파일러 지시어 집합은 반복문을 병렬화 하는데 사용될 수
	있습니다.
	때문에 이 작업에 상당히 특수화 되어 있으며, 이 특수성이 종종 그 성능을
	제한합니다.
	하지만, MPI 나 C/C++ ``락킹과 쓰레드'' 보다 훨씬 사용하기가 쉽습니다.
\item[SQL:] Structured Query Language~\cite{DIS9075SQL92} 는 관계형
	데이터베이스 질의에 특수화 되어 있습니다.
	하지만, Transaction Processing Performance Council (TPC) 벤치마크
	결과~\cite{TPC} 로 측정된 바에 따르면 그 성능은 상당히 좋습니다.
	생산성도 훌륭합니다; 사실, 이 병렬 프로그래밍 환경은 사람들이 병렬
	프로그래밍 개념에 대한 지식이 적거나 아예 없더라도 거대한 병렬 시스템을
	잘 사용할 수 있게 해줍니다.
\iffalse

\item[OpenMP:] This set of compiler directives can be used
	to parallelize loops.  It is thus quite specific to this
	task, and this specificity often limits its performance.
	It is, however, much easier to use than MPI or C/C++
	``locking plus threads.''
\item[SQL:] Structured Query Language~\cite{DIS9075SQL92} is
	specific to relational database queries.
	However, its performance is quite good as measured by the
	Transaction Processing Performance Council (TPC)
	benchmark results~\cite{TPC}.
	Productivity is excellent; in fact, this parallel programming
	environment enables people to make good use of a large parallel
	system despite having little or no knowledge of parallel
	programming concepts.

\fi

\end{description}

\begin{figure}[tb]
\centering
\resizebox{2.5in}{!}{\includegraphics{intro/PPGrelation}}
\caption{Software Layers and Performance, Productivity, and Generality}
\label{fig:intro:Software Layers and Performance, Productivity, and Generality}
\end{figure}

세계급의 성능, 생산성, 그리고 범용성을 제공하는 병렬 프로그래밍 환경의 천국은
아직 존재하지 않습니다.
그런 천국이 나타나기 전까지는, 성능, 생산성, 범용성 사이에서 엔지니어링
트레이드오프를 해야 합니다.
그런 트레이드오프 중 하나가
Figure~\ref{fig:intro:Software Layers and Performance, Productivity, and Generality}
에 보여져 있는데, 생산성이 시스템 스택의 상층부에서 점점 더 중요해지고 있으며,
반면 성능과 범용성은 하층부에서 점점 더 중요해지고 있음을 보입니다.
하층부에서 발생하는 거대한 개발 비용은 많은 수의 사용자로 나누어지며 (따라서
범용성이 중요합니다), 하층부의 성능 저하는 상층부에서 회복시킬 수 없습니다.
이 스택의 상층부는, 해당 어플리케이션의 사용자는 매우 적을수도 있으므로,
생산성에 대한 염려가 주요합니다.
이는 스택의 위쪽으로 갈수록 ``bloatware'' 가 되어가는 경향을 설명합니다:
하드웨어를 추가하는건 종종 개발자를 추가하는 것보다 저렴합니다.
이 책은 이 성능과 범용성이 주요 관심사인, 스택의 바닥 근처에서 일하는 개발자를
위해 쓰였습니다.

\iffalse

The nirvana of parallel programming environments, one that offers
world-class performance, productivity, and generality, simply does
not yet exist.
Until such a nirvana appears, it will be necessary to make engineering
tradeoffs among performance, productivity, and generality.
One such tradeoff is shown in
Figure~\ref{fig:intro:Software Layers and Performance, Productivity, and Generality},
which shows how productivity becomes increasingly important at the upper layers
of the system stack,
while performance and generality become increasingly important at the
lower layers of the system stack.
The huge development costs incurred at the lower layers
must be spread over equally huge numbers of users
(hence the importance of generality), and
performance lost in lower layers cannot easily be
recovered further up the stack.
In the upper layers of the stack, there might be very few users for a given
specific application, in which case productivity concerns are paramount.
This explains the tendency towards ``bloatware'' further up the stack:
Extra hardware is often cheaper than extra developers.
This book is intended for developers working near the bottom
of the stack, where performance and generality are of greatest concern.

\fi

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{intro/Generality}}
\caption{Tradeoff Between Productivity and Generality}
\label{fig:intro:Tradeoff Between Productivity and Generality}
\end{figure}

생산성과 범용성 사이의 트레이드오프는 많은 영역에 수세기동안 존재해 왔음을
알아둘 필요가 있습니다.
한가지만 예를 들어보면, 못박기 기계는 망치보다 못을 박는데는 더 생산적이지만,
망치가 상대적으로 못박기 외의 더 많은 일에 사용될 수 있습니다.
따라서 비슷한 트레이드오프가 병렬 컴퓨팅 분야에서도 발견되는건 놀라운 일이
아닙니다.
Figure~\ref{fig:intro:Tradeoff Between Productivity and Generality}
에 이 점이 간략히 그려져 있습니다.
사용자~1, 2, 3, 그리고~4 는 컴퓨터의 도움을 필요로 하는 일이 있습니다.
해당 사용자를 위해 가장 생산적인 언어나 환경은 프로그래밍, 설정, 또는 다른 셋업
없이도 그 사용자의 일을 하는 것일 겁니다.

\iffalse

It is important to note that a tradeoff between productivity and
generality has existed for centuries in many fields.
For but one example, a nailgun is more productive than a hammer for
driving nails, but in contrast to the nailgun, a hammer can be used for
many things besides driving nails.
It should therefore be no surprise to see similar tradeoffs
appear in the field of parallel computing.
This tradeoff is shown schematically in
Figure~\ref{fig:intro:Tradeoff Between Productivity and Generality}.
Here, users~1, 2, 3, and~4 have specific jobs that they need the computer
to help them with.
The most productive possible language or environment for a given user is one
that simply does that user's job, without requiring any programming,
configuration, or other setup.

\fi

\QuickQuiz{
	이건 이루어질 수 없는 이상이예요!
	왜 실제로 이룰 수 있는 것들에 집중하지 않는 거죠?

	\iffalse

	This is a ridiculously unachievable ideal!
	Why not focus on something that is achievable in practice?

	\fi

}\QuickQuizAnswer{
	이건 대단히 이룰 수 있는 것입니다.
	휴대폰은 최종 사용자 측에서의 프로그래밍이나 설정을 매우 적게 하거나
	아예 없이도 전화를 하고 문자 메세지를 주고받을 수 있는 컴퓨터입니다.

	이는 사소한 예로 보일수도 있겠지만, 주의깊게 들여다보면 이게
	간단하거니와 심오하기도 함을 알게 될겁니다.
	범용성을 희생시키고자 할 때, 우린 상당한 생산성 증가도 얻을 수
	있습니다.
	따라서 지나친 범용성에 빠져든 사람들은 소프트웨어 스택의 꼭대기 근처에
	도달하기 충분한 정도로 생산성 목표를 잡지 못할 겁니다.
	이 사실은 약자도 있습니다: YAGNI, 또는 ``You Ain't Gonna Need It.''

	\iffalse

	This is eminently achievable.
	The cellphone is a computer that can be used to make phone
	calls and to send and receive text messages with little or
	no programming or configuration on the part of the end user.

	This might seem to be a trivial example at first glance,
	but if you consider it carefully you will see that it is
	both simple and profound.
	When we are willing to sacrifice generality, we can achieve
	truly astounding increases in productivity.
	Those who indulge in excessive generality will therefore fail to set
	the productivity bar high enough to succeed near the top of the
	software stack.
	This fact of life even has its own acronym: YAGNI, or ``You
	Ain't Gonna Need It.''

	\fi

}\QuickQuizEnd

불행히도, 사용자~1 에 의해 요청된 일을 하는 시스템은 사용자~2 의 일을 해주진
않을 가능성이 큽니다.
달리 말하자면, 가장 생산적인 언어와 환경은 도메인에 특화되어 있으며, 따라서 그
정의에 따라 범용성이 떨어집니다.

다른 선택지는
Figure~\ref{fig:intro:Tradeoff Between Productivity and Generality}
의 가운데 원으로 보여진 것처럼
주어진 프로그래밍 언어와 환경을 하드웨어 시스템에 맞추거나 (예를 들어,
어셈블리, C, C++, 또는 Java 같은 저수준 언어들) 추상화 계층에 맞추는 (예를
들어, Haskell, Prolog, 또는 Snopbol) 겁니다.
이 언어들은 모두 사용자~1, 2, 3, 그리고~4 에게 필요한 일에 모두 똑같이 특수화
되지 않았다는 점에서 범용적으로 여겨질 수 있습니다.
더 나쁜 건, 특정 추상화 계층에 맞춰진 언어는 그 추상화가 실제 하드웨어에
효율적으로 매핑되지 않는다면 성능과 확장성 문제를 겪을 가능성이 높다는 겁니다.

\iffalse

Unfortunately, a system that does the job required by user~1 is
unlikely to do user~2's job.
In other words, the most productive languages and environments are
domain-specific, and thus by definition lacking generality.

Another option is to tailor a given programming language or environment
to the hardware system (for example, low-level languages such as
assembly, C, C++, or Java) or to some abstraction (for example,
Haskell, Prolog, or Snobol), as is shown by the circular region near
the center of
Figure~\ref{fig:intro:Tradeoff Between Productivity and Generality}.
These languages can be considered to be general in the sense that they
are equally ill-suited to the jobs required by users~1, 2, 3, and~4.
In other words, their generality comes at the expense of
decreased productivity when compared to domain-specific languages
and environments.
Worse yet, a language that is tailored to a given abstraction
is likely to suffer from performance and scalability problems
unless and until it can be efficiently mapped to real hardware.

\fi

성능, 생산성, 그리고 범용성이라는 철의 삼각지대의 상충되는 세가지 목표로부터
벗어날 수는 없을까요?

많은 경우에 탈출구가 존재하는데, 예를 들어 다음 섹션에서 다루어질 병렬
프로그래밍의 대안을 사용하는 것입니다.
어쨌건, 병렬 프로그래밍은 무척 즐거운 선택이 될 수 있지만, 항상 최고의 도구가
되는건 아닙니다.

\iffalse

Is there no escape from iron triangle's three conflicting goals of
performance, productivity, and generality?

It turns out that there often is an escape, for example,
using the alternatives to parallel programming discussed in the next section.
After all, parallel programming can be a great deal of fun, but
it is not always the best tool for the job.

\fi

\section{Alternatives to Parallel Programming}
\label{sec:intro:Alternatives to Parallel Programming}
%
\epigraph{Experiment is folly when experience shows the way.}
	 {\emph{Roger M. Babson}}

병렬 프로그래밍의 대안을 제대로 고려하려면, 먼저 여러분은 병렬성이 여러분에게
뭘 해줄 거라고 생각하고 있는지 정확히 알아야 합니다.
\cref{sec:intro:Parallel Programming Goals} 에서 알아봤듯, 병렬 프로그래밍의
주요 목표는 성능, 생산성, 그리고 범용성입니다.
이 책은 소프트웨어 스택의 바닥 근처에 있는 성능이 중요한 코드를 작업하는
개발자들을 위해 쓰여졌기 때문에, 이 섹션의 나머지는 기본적으로 성능 개선에
주목합니다.

하지만 병렬성은 성능을 개선하는 한가지 방법에 불과할 뿐임을 명심해 두는게
중요합니다.
다른 잘 알려진 방법들로는 어려운 순서대로 대략적으로 나열해 보면 다음과 같은
것들이 있습니다:

\iffalse

In order to properly consider alternatives to parallel programming,
you must first decide on what exactly you expect the parallelism
to do for you.
As seen in \cref{sec:intro:Parallel Programming Goals},
the primary goals of parallel programming are performance, productivity,
and generality.
Because this book is intended for developers working on
performance-critical code near the bottom of the software stack,
the remainder of this section focuses primarily on performance improvement.

It is important to keep in mind that parallelism is but one way to
improve performance.
Other well-known approaches include the following, in roughly increasing
order of difficulty:

\fi

\begin{enumerate}
\item	순차적 어플리케이션의 여러 인스턴스를 돌리기.
\item	이미 존재하는 병렬 소프트웨어를 사용해 어플리케이션을 만들기.
\item	순차적 어플리케이션을 최적화하기.

\iffalse

\item	Run multiple instances of a sequential application.
\item	Make the application use existing parallel software.
\item	Optimize the serial application.

\fi

\end{enumerate}

이 방법들이 다음 섹션에 다뤄집니다.

\iffalse

These approaches are covered in the following sections.

\fi

\subsection{Multiple Instances of a Sequential Application}
\label{sec:intro:Multiple Instances of a Sequential Application}

순차적 어플리케이션의 인스턴스 여러개를 돌리는 것은 병렬 프로그래밍을 정말로
하지는 않으면서 병렬 프로그래밍을 할 수 있도록 해줍니다.
해당 어플리케이션의 구조에 따라, 이 접근법을 위한 여러 방법이 있습니다.

여러분의 프로그램이 여러개의 다양한 시나리오를 분석한다면, 또는 여러개의 독립적
데이터 셋을 분석한다면, 쉽고도 효과적인 방법 중 하나는 하나의 분석을 하는
하나의 순차적 프로그램을 만든 후, 여러 스크립트 환경 (예를 들어 \co{bash} 셸)
중 아무거나 하나를 사용해 이 순차적 프로그램의 여러 인스턴스를 병렬로 수행하는
것입니다.
어떤 경우에는, 이 접근법은 여러 기계의 클러스터로 쉽게 확장될 수도 있습니다.

이 방법은 사기처럼 보일 수도 있겠고, 어떤 사람들은 실제로 그런 프로그램을
``부끄럽게도 병렬적'' 이라며 모욕하기도 합니다.
그리고 실제로, 이 접근법은 메모리 소모량 증가, 공통되는 중간 결과를 재계산하기
위해 낭비되는 CPU 사이클, 데이터 복사의 증가 등의 일부 잠재적 단점이 있습니다.
하지만, 이는 많은 경우 극단적으로 생산적이고, 아주 적은 양의 추가적 노력만으로
극단적 성능 향상을 얻게 해줍니다.

\iffalse

Running multiple instances of a sequential application can allow you
to do parallel programming without actually doing parallel programming.
There are a large number of ways to approach this, depending on the
structure of the application.

If your program is analyzing a large number of different scenarios,
or is analyzing a large number of independent data sets, one easy
and effective approach is to create a single sequential program that
carries out a single analysis, then use any of a number of scripting
environments (for example the \co{bash} shell) to run a number of
instances of that sequential program in parallel.
In some cases, this approach can be easily extended to a cluster of
machines.

This approach may seem like cheating, and in fact some denigrate such
programs as ``embarrassingly parallel''.
And in fact, this approach does have some potential disadvantages,
including increased memory consumption, waste of CPU cycles recomputing
common intermediate results, and increased copying of data.
However, it is often  extremely productive, garnering extreme performance
gains with little or no added effort.

\fi

\subsection{Use Existing Parallel Software}
\label{sec:intro:Use Existing Parallel Software}

관계형 데이터베이스~\cite{Date82}, 웹 어플리케이션 서버, 맵리듀스 환경 등을
포함해 싱글쓰레드 프로그래밍 환경을 제공하는 병렬 소프트웨어 환경은 더이상
부족하지 않습니다.
예를 들어, 흔한 설계 중 하나는 각 사용자를 위해 사용자의 질의들로부터 SQL 을
생성하는 프로세스를 유저별로 제공하는 것입니다.
이 유저별 SQL 은 이 사용자들의 질의들을 자동으로 동시에 수행하는 흔한 관계형
데이터베이스에서 돌아가게 됩니다.
이 유저별 프로그램들은 해당 유저 인터페이스에만 책임이 있으며, 관계형
데이터베이스가 병렬성과 지속성을 둘러싼 어려운 문제들에 대한 모든 책임을
갖습니다.

\iffalse

There is no longer any shortage of parallel software environments that
can present a single-threaded programming environment,
including relational
databases~\cite{Date82},
web-application servers, and map-reduce environments.
For example, a common design provides a separate process for each
user, each of which generates SQL from user queries.
This per-user SQL is run against a common relational database, which
automatically runs the users' queries concurrently.
The per-user programs are responsible only for the user interface,
with the relational database taking full responsibility for the
difficult issues surrounding parallelism and persistence.

\fi

또한, 병렬 라이브러리 함수들이 늘어나고 있는데, 특히 숫자 계산을 위한
것들입니다.
더 나은 것이, 일부 라이브러리는 벡터 유닛과 범용 그래픽 처리 장치 (GPGPU) 와
같은 특수목적 하드웨어를 활용합니다.

이 접근법을 취하는 것은 종종 성능을 일부 희생하는데, 주의깊게 손으로 코딩된
완전한 병렬 어플리케이션에 비해서는 그렇습니다.
하지만, 그런 희생은 많은 경우 개발 노력의 큰 감소로 보상됩니다.

\iffalse

In addition, there are a growing number of parallel library functions,
particularly for numeric computation.
Even better, some libraries take advantage of special\-/purpose
hardware such as vector units and general\-/purpose graphical processing
units (GPGPUs).

Taking this approach often sacrifices some performance, at least when
compared to carefully hand-coding a fully parallel application.
However, such sacrifice is often well repaid by a huge reduction in
development effort.

\fi

\QuickQuiz{
	잠깐만요!
	이 방법은 개발 노력을 당신으로부터 당신이 사용하는 병렬 소프트웨어를
	개발한 누군가에게 떠넘길 뿐인 것 아닌가요?

	\iffalse

	Wait a minute!
	Doesn't this approach simply shift the development effort from
	you to whoever wrote the existing parallel software you are using?

	\fi

}\QuickQuizAnswer{
	바로 그렇습니다!
	그리고 그게 이미 존재하는 소프트웨어를 사용하는 것의 핵심입니다.
	한 팀의 작업물이 다른 여러 팀에 의해 사용될 수 있고, 결국 모든 팀이
	필요없이 바퀴를 재발명하는 것에 비교해 전체적 노력을 크게 줄이게
	됩니다.

	\iffalse

	Exactly!
	And that is the whole point of using existing software.
	One team's work can be used by many other teams, resulting in a
	large decrease in overall effort compared to all teams
	needlessly reinventing the wheel.

	\fi

}\QuickQuizEnd

\subsection{Performance Optimization}
\label{sec:intro:Performance Optimization}

Up through the early 2000s, CPU clock frequencies doubled every 18 months.
It was therefore usually more important to create new functionality than to
carefully optimize performance.
Now that \IX{Moore's Law} is ``only'' increasing transistor density instead
of increasing both transistor density and per-transistor performance,
it might be a good time to rethink the importance of performance
optimization.
After all, new hardware generations no longer bring significant
single-threaded performance improvements.
Furthermore, many performance optimizations can also conserve energy.

From this viewpoint, parallel programming is but another performance
optimization, albeit one that is becoming much more attractive
as parallel systems become cheaper and more readily available.
However, it is wise to keep in mind that the speedup available from
parallelism is limited to roughly the number of CPUs
(but see Section~\ref{sec:SMPdesign:Beyond Partitioning}
for an interesting exception).
In contrast, the speedup available from traditional single-threaded
software optimizations can be much larger.
For example, replacing a long linked list with a hash table
or a search tree can improve performance by many orders of magnitude.
This highly optimized single-threaded program might run much
faster than its unoptimized parallel counterpart, making parallelization
unnecessary.
Of course, a highly optimized parallel program would be even better,
aside from the added development effort required.

Furthermore, different programs might have different performance
bottlenecks.
For example, if your program spends most of its time
waiting on data from your disk drive,
using multiple CPUs will probably just increase the time wasted waiting
for the disks.
In fact, if the program was reading from a single large file laid out
sequentially on a rotating disk, parallelizing your program might
well make it a lot slower due to the added seek overhead.
You should instead optimize the data layout so that
the file can be smaller (thus faster to read), split the file into chunks
which can be accessed in parallel from different drives,
cache frequently accessed data in main memory,
or, if possible,
reduce the amount of data that must be read.

\QuickQuiz{
	What other bottlenecks might prevent additional CPUs from
	providing additional performance?
}\QuickQuizAnswer{
	There are any number of potential bottlenecks:
	\begin{enumerate}
	\item	Main memory.  If a single thread consumes all available
		memory, additional threads will simply page themselves
		silly.
	\item	Cache.  If a single thread's cache footprint completely
		fills any shared CPU cache(s), then adding more threads
		will simply thrash those affected caches, as will be
		seen in \cref{chp:Data Structures}.
	\item	Memory bandwidth.  If a single thread consumes all available
		memory bandwidth, additional threads will simply
		result in additional queuing on the system interconnect.
	\item	I/O bandwidth.  If a single thread is I/O bound,
		adding more threads will simply result in them all
		waiting in line for the affected I/O resource.
	\end{enumerate}

	Specific hardware systems might have any number of additional
	bottlenecks.
	The fact is that every resource which is shared between
	multiple CPUs or threads is a potential bottleneck.
}\QuickQuizEnd

Parallelism can be a powerful optimization technique, but
it is not the only such technique, nor is it appropriate for all
situations.
Of course, the easier it is to parallelize your program, the
more attractive parallelization becomes as an optimization.
Parallelization has a reputation of being quite difficult,
which leads to the question ``exactly what makes parallel
programming so difficult?''

\section{What Makes Parallel Programming Hard?}
\label{sec:intro:What Makes Parallel Programming Hard?}
%
\epigraph{Real difficulties can be overcome; it is only the imaginary
	  ones that are unconquerable.}{\emph{Theodore N.~Vail}}

\OriginallyPublished{Section}{sec:intro:What Makes Parallel Programming Hard?}{What Makes Parallel Programming Hard?}{a Portland State University Technical Report}{PaulEMcKenney2009ProgrammingHard}

It is important to note that the difficulty of parallel programming
is as much a human-factors issue as it is a set of technical properties of the
parallel programming problem.
We do need human beings to be able to tell parallel
systems what to do, otherwise known as programming.
But parallel programming involves two-way communication, with
a program's performance and scalability being the communication from
the machine to the human.
In short, the human writes a program telling the computer what to do,
and the computer critiques this program via the resulting performance and
scalability.
Therefore, appeals to abstractions or to mathematical analyses will
often be of severely limited utility.

In the Industrial Revolution, the interface between human and machine
was evaluated by human-factor studies, then called time-and-motion
studies.
Although there have been a few human-factor studies examining parallel
programming~\cite{RyanEccles2005HPCSNovice,RyanEccles2006HPCSNoviceNeeds,
LorinHochstein2005SC,DuaneSzafron1994PEMPDS}, these studies have
been extremely narrowly focused, and hence unable to demonstrate any
general results.
Furthermore, given that the normal range of programmer productivity
spans more than an order of magnitude, it is unrealistic to expect
an affordable study to be capable of detecting (say) a 10\,\% difference
in productivity.
Although the multiple-order-of-magnitude differences that such studies
\emph{can} reliably detect are extremely valuable, the most impressive
improvements tend to be based on a long series of 10\,\% improvements.

We must therefore take a different approach.

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{intro/FourTaskCategories}}
\caption{Categories of Tasks Required of Parallel Programmers}
\label{fig:intro:Categories of Tasks Required of Parallel Programmers}
\end{figure}

One such approach is to carefully consider the tasks that parallel
programmers must undertake that are not required of sequential programmers.
We can then evaluate how well a given programming language or environment
assists the developer with these tasks.
These tasks fall into the four categories shown in
Figure~\ref{fig:intro:Categories of Tasks Required of Parallel Programmers},
each of which is covered in the following sections.

\subsection{Work Partitioning}
\label{sec:intro:Work Partitioning}

Work partitioning is absolutely required for parallel execution:
if there is but one ``glob'' of work, then it can be executed by at
most one CPU at a time, which is by definition sequential execution.
However, partitioning the code requires great care.
For example, uneven partitioning can result in sequential execution
once the small partitions have completed~\cite{GeneAmdahl1967AmdahlsLaw}.
In less extreme cases, load balancing can be used to fully utilize
available hardware and restore performance and scalabilty.

Although partitioning can greatly improve performance and scalability,
it can also increase complexity.
For example, partitioning can complicate handling of global
errors and events: A parallel
program may need to carry out non-trivial synchronization in order
to safely process such global events.
More generally, each partition requires some sort of communication:
After all, if
a given thread did not communicate at all, it would have no effect and
would thus not need to be executed.
However, because communication incurs overhead, careless partitioning choices
can result in severe performance degradation.

Furthermore, the number of concurrent threads must often be controlled,
as each such thread occupies common resources, for example,
space in CPU caches.
If too many threads are permitted to execute concurrently, the
CPU caches will overflow, resulting in high cache miss rate, which in
turn degrades performance.
Conversely, large numbers of threads are often required to
overlap computation and I/O so as to fully utilize I/O devices.

\QuickQuiz{
	Other than CPU cache capacity, what might require limiting the
	number of concurrent threads?
}\QuickQuizAnswer{
	There are any number of potential limits on the number of
	threads:
	\begin{enumerate}
	\item	Main memory.  Each thread consumes some memory
		(for its stack if nothing else), so that excessive
		numbers of threads can exhaust memory, resulting
		in excessive paging or memory-allocation failures.
	\item	I/O bandwidth.  If each thread initiates a given
		amount of mass-storage I/O or networking traffic,
		excessive numbers of threads can result in excessive
		I/O queuing delays, again degrading performance.
		Some networking protocols may be subject to timeouts
		or other failures if there are so many threads that
		networking events cannot be responded to in a timely
		fashion.
	\item	Synchronization overhead.
		For many synchronization protocols, excessive numbers
		of threads can result in excessive spinning, blocking,
		or rollbacks, thus degrading performance.
	\end{enumerate}

	Specific applications and platforms may have any number of additional
	limiting factors.
}\QuickQuizEnd

Finally, permitting threads to execute concurrently greatly increases
the program's state space, which can make the program difficult to
understand and debug, degrading productivity.
All else being equal, smaller state spaces having more regular structure
are more easily understood, but this is a human-factors statement as much
as it is a technical or mathematical statement.
Good parallel designs might have extremely large state spaces, but
nevertheless be easy to understand due to their regular structure,
while poor designs can be impenetrable despite having a comparatively
small state space.
The best designs exploit embarrassing parallelism, or transform the
problem to one having an embarrassingly parallel solution.
In either case, ``embarrassingly parallel'' is in fact
an embarrassment of riches.
The current state of the art enumerates good designs; more work is
required to make more general judgments on
state-space size and structure.

\subsection{Parallel Access Control}
\label{sec:Parallel Access Control}

Given a single-threaded sequential program, that single
thread has full access to all of the program's resources.
These resources are most often in-memory data structures, but can be CPUs,
memory (including caches), I/O devices, computational accelerators, files,
and much else besides.

The first parallel-access-control issue is whether the form of access to
a given resource depends on that resource's location.
For example, in many message-passing environments, local-variable
access is via expressions and assignments,
while remote-variable access uses an entirely different
syntax, usually involving messaging.
The POSIX Threads environment~\cite{OpenGroup1997pthreads},
Structured Query Language (SQL)~\cite{DIS9075SQL92}, and
partitioned global address-space (PGAS) environments
such as Universal Parallel C (UPC)~\cite{ElGhazawi2003UPC,UPCConsortium2013}
offer implicit access,
while Message Passing Interface (MPI)~\cite{MPIForum2008} offers
explicit access because access to remote data requires explicit
messaging.

The other parallel-access-control issue is how threads coordinate
access to the resources.
This coordination is carried out by
the very large number of synchronization mechanisms
provided by various parallel languages and environments,
including message passing, locking, transactions,
reference counting, explicit timing, shared atomic variables, and data
ownership.
Many traditional parallel-programming concerns such as deadlock,
livelock, and transaction rollback stem from this coordination.
This framework can be elaborated to include comparisons
of these synchronization mechanisms, for example locking vs. transactional
memory~\cite{McKenney2007PLOSTM}, but such elaboration is beyond the
scope of this section.
(See
Sections~\ref{sec:future:Transactional Memory}
and~\ref{sec:future:Hardware Transactional Memory}
for more information on transactional memory.)

\QuickQuiz{
	Just what is ``explicit timing''???
}\QuickQuizAnswer{
	Where each thread is given access to some set of resources during
	an agreed-to slot of time.
	For example, a parallel program with eight threads might be
	organized into eight-millisecond time intervals, so that the
	first thread is given access during the first millisecond of
	each interval, the second thread during the second millisecond,
	and so on.
	This approach clearly requires carefully synchronized clocks
	and careful control of execution times, and therefore should
	be used with considerable caution.

	In fact, outside of hard realtime environments, you almost
	certainly want to use something else instead.
	Explicit timing is nevertheless worth a mention, as it is
	always there when you need it.
}\QuickQuizEnd

\subsection{Resource Partitioning and Replication}
\label{sec:Resource Partitioning and Replication}

The most effective parallel algorithms and systems exploit resource
parallelism, so much so that it is
usually wise to begin parallelization by partitioning your write-intensive
resources and replicating frequently accessed read-mostly resources.
The resource in question is most frequently data, which might be
partitioned over computer systems, mass-storage devices, NUMA nodes,
CPU cores (or dies or hardware threads), pages, cache lines, instances
of synchronization primitives, or critical sections of code.
For example, partitioning over locking primitives is termed
``data locking''~\cite{Beck85}.

Resource partitioning is frequently application dependent.
For example, numerical applications frequently partition matrices
by row, column, or sub-matrix, while commercial applications frequently
partition write-intensive data structures and replicate
read-mostly data structures.
Thus, a commercial application might assign the data for a
given customer to a given few computers out of a large cluster.
An application might statically partition data, or dynamically
change the partitioning over time.

Resource partitioning is extremely effective, but
it can be quite challenging for complex multilinked data
structures.

\subsection{Interacting With Hardware}
\label{sec:Interacting With Hardware}

Hardware interaction is normally the domain of the operating system,
the compiler, libraries, or other software-environment infrastructure.
However, developers working with novel hardware features and components
will often need to work directly with such hardware.
In addition, direct access to the hardware can be required when squeezing
the last drop of performance out of a given system.
In this case, the developer may need to tailor or configure the application
to the cache geometry, system topology, or interconnect protocol of the
target hardware.

In some cases, hardware may be considered to be a resource which
is subject to partitioning or access control, as described in
the previous sections.

\subsection{Composite Capabilities}
\label{sec:Composite Capabilities}

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{intro/FourTaskOrder}}
\caption{Ordering of Parallel-Programming Tasks}
\label{fig:intro:Ordering of Parallel-Programming Tasks}
\end{figure}

Although these four capabilities are fundamental,
good engineering practice uses composites of
these capabilities.
For example, the data-parallel approach first
partitions the data so as to minimize the need for
inter-partition communication, partitions the code accordingly,
and finally maps data partitions and threads so as to maximize
throughput while minimizing inter-thread communication,
as shown in
Figure~\ref{fig:intro:Ordering of Parallel-Programming Tasks}.
The developer can then
consider each partition separately, greatly reducing the size
of the relevant state space, in turn increasing productivity.
Even though some problems are non-partitionable,
clever transformations into forms permitting partitioning can
sometimes greatly enhance
both performance and scalability~\cite{PanagiotisMetaxas1999PDCS}.

\subsection{How Do Languages and Environments Assist With These Tasks?}
\label{sec:intro:How Do Languages and Environments Assist With These Tasks?}

Although many environments require the developer to deal manually
with these tasks, there are long-standing environments that bring
significant automation to bear.
The poster child for these environments is SQL, many implementations
of which automatically parallelize single large queries and also
automate concurrent execution of independent queries and updates.

These four categories of tasks must be carried out in all parallel
programs, but that of course does not necessarily mean that the developer
must manually carry out these tasks.
We can expect to see ever-increasing automation of these four tasks
as parallel systems continue to become cheaper and more readily available.

\QuickQuiz{
	Are there any other obstacles to parallel programming?
}\QuickQuizAnswer{
	There are a great many other potential obstacles to parallel
	programming.
	Here are a few of them:
	\begin{enumerate}
	\item	The only known algorithms for a given project might
		be inherently sequential in nature.
		In this case, either avoid parallel programming
		(there being no law saying that your project \emph{has}
		to run in parallel) or invent a new parallel algorithm.
	\item	The project allows binary-only plugins that share the same
		address space, such that no one developer has access to
		all of the source code for the project.
		Because many parallel bugs, including deadlocks, are
		global in nature, such binary-only plugins pose a severe
		challenge to current software development methodologies.
		This might well change, but for the time being, all
		developers of parallel code sharing a given address space
		need to be able to see \emph{all} of the code running in
		that address space.
	\item	The project contains heavily used APIs that were designed
		without regard to
		parallelism~\cite{HagitAttiya2011LawsOfOrder,Clements:2013:SCR:2517349.2522712}.
		Some of the more ornate features of the System V
		message-queue API form a case in point.
		Of course, if your project has been around for a few
		decades, and its developers did not have access to
		parallel hardware, it undoubtedly has at least
		its share of such APIs.
	\item	The project was implemented without regard to parallelism.
		Given that there are a great many techniques that work
		extremely well in a sequential environment, but that
		fail miserably in parallel environments, if your project
		ran only on sequential hardware for most of its lifetime,
		then your project undoubtably has at least its share of
		parallel-unfriendly code.
	\item	The project was implemented without regard to good
		software-development practice.
		The cruel truth is that shared-memory parallel
		environments are often much less forgiving of sloppy
		development practices than are sequential environments.
		You may be well-served to clean up the existing design
		and code prior to attempting parallelization.
	\item	The people who originally did the development on your
		project have since moved on, and the people remaining,
		while well able to maintain it or add small features,
		are unable to make ``big animal'' changes.
		In this case, unless you can work out a very simple
		way to parallelize your project, you will probably
		be best off leaving it sequential.
		That said, there are a number of simple approaches that
		you might use
		to parallelize your project, including running multiple
		instances of it, using a parallel implementation of
		some heavily used library function, or making use of
		some other parallel project, such as a database.
	\end{enumerate}

	One can argue that many of these obstacles are non-technical
	in nature, but that does not make them any less real.
	In short, parallelization of a large body of code
	can be a large and complex effort.
	As with any large and complex effort, it makes sense to
	do your homework beforehand.
}\QuickQuizEnd

\section{Discussion}
\label{sec:intro:Discussion}
%
\epigraph{Until you try, you don't know what you can't do.}
	 {\emph{Henry James}}

This section has given an overview of the difficulties with, goals of,
and alternatives to parallel programming.
This overview was followed by a discussion of
what can make parallel programming hard, along with a high-level
approach for dealing with parallel programming's difficulties.
Those who still insist that parallel programming is impossibly difficult
should review some of the older guides to parallel
programmming~\cite{SQNTParallel,AndrewDBirrell1989Threads,Beck85,Inman85}.
The following quote from Andrew Birrell's
monograph~\cite{AndrewDBirrell1989Threads} is especially telling:

\begin{quote}
	Writing concurrent programs has a reputation for being exotic
	and difficult. I~believe it is neither. You need a system
	that provides you with good primitives and suitable libraries,
	you need a basic caution and carefulness, you need an armory of
	useful techniques, and you need to know of the common pitfalls.
	I~hope that this paper has helped you towards sharing my belief.
\end{quote}

The authors of these older guides were well up to the parallel programming
challenge back in the 1980s.
As such, there are simply no excuses for refusing to step up to the
parallel-programming challenge here in the 21\textsuperscript{st} century!

We are now ready to proceed to the next chapter, which dives into the
relevant properties of the parallel hardware underlying our parallel
software.

\QuickQuizAnswersChp{qqzintro}
