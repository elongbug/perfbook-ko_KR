% future/htm.tex

\section{Hardware Transactional Memory}
\label{sec:future:Hardware Transactional Memory}

2012 년 초에 이르러, 하드웨어 트랜잭셔널 메모리 (HTM) 이 상품으로 구입할 수
있는 흔한 컴퓨터 시스템들에도 도입되기 시작하고 있습니다.
이 섹션은 병렬 프로그래머의 도구상자에 이 하드웨어 트랜잭셔널 메모리가 위치할
자리를 알아보기 위한 시도를 해 봅니다.

개념적 관점에서, HTM 은 명시된 명령문의 그룹 (하나의 ``트랜잭션'') 을 다른
프로세서에서 수행되는 모든 다른 트랜잭션들의 시야에 원자적으로 보이도록 그
효과를 만들기 위해 프로세서 캐시와 예측적 수행을 사용합니다.
이 트랜잭션은 begin-transaction 기계 인스트럭션을 통해 초기화 되고
commit-transaction 기계 인스트럭션을 통해 완료됩니다.
일반적으로 abort-transaction 기계 인스트럭션도 존재하는데, 이는
(begin-transaction 인스트럭션과 그를 뒤따른 인스트럭션들이 수행되지 않은
것처럼) 예측적 수행 내용을 짓이기고 failure handler 의 수행을 시작합니다.
이 failure handler 의 위치는 begin-transaction 인스트럭션에 의해서 명시적인
failure-handler 의 주소를 통해서든 또는 해당 인스트럭션 자체의 조건적 코드에
의해서든 주어집니다.
각각의 트랜잭션은 모든 다른 트랜잭션에 대해 어토믹하게 수행됩니다.
\iffalse

As of early 2012, hardware transactional memory (HTM) is starting to emerge
into commercially available commodity computer systems.
This section makes a first attempt to find its place in the parallel
programmer's toolbox.

From a conceptual viewpoint, HTM uses processor caches and speculative
execution to make a designated group of statements (a ``transaction'')
take effect atomically
from the viewpoint of any other transactions running on other processors.
This transaction is initiated by a
begin-transaction machine instruction and completed by a commit-transaction
machine instruction.
There is typically also an abort-transaction machine instruction, which
squashes the speculation (as if the begin-transaction instruction and
all following instructions had not executed) and commences execution
at a failure handler.
The location of the failure handler is typically specified by the
begin-transaction instruction, either as an explicit failure-handler
address or via a condition code set by the instruction itself.
Each transaction executes atomically with respect to all other transactions.
\fi

HTM 은 여러가지 중요한 장점을 갖는데, 데이터 구조의 자동적인 동적 분할, 동기화
기능의 캐시 미스의 감소, 그리고 상당수의 실용적 어플리케이션의 지원 등이 이런
장점에 포함됩니다.

하지만, 항상 작은 문자로 인쇄된 부분을 읽어야 하고, HTM 역시 예외가 아닙니다.
이 섹션의 중요한 요점은 어떤 조건 하에서 HTM 의 장점들이 그것의 작은 문자로
인쇄된 내용에 감추어져 있는 복잡성을 앞서는가를 결정하는 것입니다.
이런 결론 아래,
Section~\ref{sec:future:HTM Benefits WRT to Locking}
은 HTM 의 장점을 설명하고
Section~\ref{sec:future:HTM Weaknesses WRT Locking}
은 그 단점들을 설명합니다.
이는 이전의 논문들~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener}
에서 취해진 것과 같은 방법입니다만, 전체적으로 TM 보다는 HTM 에 초점을
맞춥니다.\footnote{
	그리고 저는 다른 저자들인 Maged Michael, Josh Triplett, Jonathan
	Walpole, 그리고 Andi Kleen  과의 자극적인 토론들에 기꺼이 감사를
	드립니다.}
\iffalse

HTM has a number of important benefits, including automatic
dynamic partitioning of data structures, reducing synchronization-primitive
cache misses, and supporting a fair number of practical applications.

However, it always pays to read the fine print, and HTM is no exception.
A major point of this section is determining under what conditions HTM's
benefits outweigh the complications hidden in its fine print.
To this end, Section~\ref{sec:future:HTM Benefits WRT to Locking}
describes HTM's benefits and
Section~\ref{sec:future:HTM Weaknesses WRT Locking} describes its weaknesses.
This is the same approach used in earlier
papers~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener},
but focused on HTM rather than TM as a whole.\footnote{
	And I gratefully acknowledge many stimulating
	discussions with the other authors, Maged Michael, Josh Triplett,
	and Jonathan Walpole, as well as with Andi Kleen.}
\fi

이어서
Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}
은 리눅스 커널에서 (그리고 일부 user-space 어플리케이션에서) 사용되는 동기화
도구들의 조합과 관련해서 HTM 의 단점을 설명합니다.
Section~\ref{sec:future:Where Does HTM Best Fit In?}
은 병렬 프로그래머의 도구상자에서 어다에 HTM 이 가장 잘 어울릴지를 알아보고,
Section~\ref{sec:future:Potential Game Changers}
은 HTM 의 범위와 매력을 상당히 증가시킬 수 있을 몇가지 사건들을 나열합니다.
마지막으로,
Section~\ref{sec:future:Conclusions}
에서는 결론을 내립니다.
\iffalse

Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented} then describes
HTM's weaknesses with respect to the combination of synchronization
primitives used in the Linux kernel (and in some user-space applications).
Section~\ref{sec:future:Where Does HTM Best Fit In?} looks at where HTM
might best fit into the parallel programmer's toolbox, and
Section~\ref{sec:future:Potential Game Changers} lists some events that might
greatly increase HTM's scope and appeal.
Finally, Section~\ref{sec:future:Conclusions}
presents concluding remarks.
\fi

\subsection{HTM Benefits WRT to Locking}
\label{sec:future:HTM Benefits WRT to Locking}

HTM 의 주된 장점들은 (1)~다른 동기화 기능들에 의해 종종 일어나는 캐시 미스의
제거, (2)~동적으로 데이터 구조를 파티셔닝 하는 능력, (3)~상당한 수의 실용적
어플리케이션이 존재한다는 사실입니다.
저는 두가지 이유로 TM 의 전통과 달리 사용의 편의성을 별도로 열거하지 않습니다.
첫째로, 사용의 편의성은 이 섹션이 초점을 맞추고 있는, HTM 의 주요 장점으로부터
기인합니다.
둘째, 날 프로그래밍 재능을 위한 테스트를 하려는 시도를
둘러싼~\cite{RichardBornat2006SheepGoats,SaeedDehnadi2009SheepGoats}, 그리고
심지어 취직을 위한 면접에서의 작은 프로그래밍 연습문제의 사용을
둘러싼~\cite{RegBraithwaite2007FizzBuzz} 상당한 논쟁이 존재했습니다.
이는 우리가 무엇이 프로그래밍을 쉽게 하고 어렵게 하는지에 대한 진정한 이해를
가지고 있지 못함을 의미합니다.
따라서, 이 섹션은 앞서 나열한 세개의 장점에 대해서만, 각각 뒤의 섹션들에서
초점을 맞추도록 하겠습니다.
\iffalse

The primary benefits of HTM are
(1)~its avoidance of the cache misses that are often incurred by
other synchronization primitives,
(2)~its ability to dynamically partition
data structures,
and (3)~the fact that it has
a fair number of practical applications.
I break from TM tradition by not listing ease of use separately
for two reasons.
First, ease of use should stem from HTM's primary benefits,
which this section focuses on.
Second, there has been considerable controversy surrounding attempts to
test for raw programming
talent~\cite{RichardBornat2006SheepGoats,SaeedDehnadi2009SheepGoats}
and even around the use of small programming exercises in job
interviews~\cite{RegBraithwaite2007FizzBuzz}.
This indicates that we really do not have a grasp on what makes
programming easy or hard.
Therefore, this section focuses on the three benefits listed above,
each in one of the following sections.
\fi

\subsubsection{Avoiding Synchronization Cache Misses}
\label{sec:future:Avoiding Synchronization Cache Misses}

대부분의 동기화 메커니즘들은 어토믹 인스트럭션으로 조정되는 데이터 구조에
기반합니다.
일반적으로 이 어토믹 인스트럭션들은 먼저 연관된 캐시 라인이 수행되고 있는 CPU
에 의해 소유되도록 하기 때문에, 다른 CPU 에서 같은 동기화 기능 인스턴스의
수행을 뒤따라 하게 되면, 캐시 미스를 초래하게 됩니다.
이러한 통신으로 인한 캐시 미스 이벤트들은 전통적인 동기화 메커니즘들의 성능과
확장성을 상당히 ㄸ러어뜨립니다~\cite[Section 4.2.3]{Anderson97}.
\iffalse

Most synchronization mechanisms are based on data structures that are
operated on by atomic instructions.
Because these atomic instructions normally operate by first causing
the relevant cache line to be owned by the CPU that they are running on,
a subsequent execution
of the same instance of that synchronization primitive on some other
CPU will result in a cache miss.
These communications cache misses severely degrade both the performance and
scalability of conventional synchronization
mechanisms~\cite[Section 4.2.3]{Anderson97}.
\fi

반면에, HTM 은 CPU 의 캐시를 사용해서 동기화를 하므로 동기화 데이터 구조의
필요와 그로 말미암은 캐시 미스가 없습니다.
HTM 의 장점은 락 데이터 구조가 별개의 캐시 라인에 위치해 있을 때에 극대화
되는데, 크리티컬 섹션을 HTM 트랜잭션으로 변환함으로써 전체 캐시 미스로 인한
크리티컬 섹션의 오버헤드를 줄여주는 경우가 그런 경우입니다.
이런 이득은 짧은 크리티컬 섹션을 갖는 흔한 경우에 특히 클 수 있으며, 최소한
생략된 락이 그 락에 의해 보호되는, 자주 쓰여지는 변수와 캐시 라인을 공유하지
않을 때의 상황에서는 그렇습니다.
\iffalse

In contrast, HTM synchronizes by using the CPU's cache, avoiding the need
for a synchronization data structure and resultant cache misses.
HTM's advantage is greatest in cases where a lock data structure is
placed in a separate cache line, in which case, converting a given
critical section to an HTM transaction can reduce that critical section's
overhead by a full cache miss.
These savings can be quite significant for the common case of short
critical sections, at least for those situations where the elided lock
does not share a cache line with an oft-written variable protected by
that lock.
\fi

\QuickQuiz{}
	해당 락 변수와 캐시 라인을 공유하는, 자주 쓰여지는 변수가 왜
	문제가 될까요?
	\iffalse

	Why would it matter that oft-written variables shared the cache
	line with the lock variable?
	\fi
\QuickQuizAnswer{
	락이 그것이 보호하는 변수와 같은 캐시라인에 있다면, 하나의 CPU 에 의한
	그 변수들로의 쓰기는 모든 다른 CPU 들에 있는 그 캐시 라인을 무효화
	시킵니다.
	이런 무효화는 많은 충돌과 재시도를 만들어내고, 심지어 락킹에 비해
	성능과 확장성을 떨어뜨릴 수도 있을 겁니다.
	\iffalse

	If the lock is in the same cacheline as some of the variables
	that it is protecting, then writes to those variables by one CPU
	will invalidate that cache line for all the other CPUs.
	These invalidations will
	generate large numbers of conflicts and retries, perhaps even
	degrading performance and scalability compared to locking.
	\fi
} \QuickQuizEnd

\subsubsection{Dynamic Partitioning of Data Structures}
\label{sec:future:Dynamic Partitioning of Data Structures}

일부 전통적 동기화 메커니즘의 사용에 대한 주요한 방해는 정적으로 데이터 구조를
분할해야 하는 필요성입니다.
간단하게 분할될 수 있는 데이터 구조들이 여럿 존재하는데, 유명한 예로 해시
테이블이 존재하는데, 여기서는 각각의 해시 체인이 하나의 파티션을 구성하게
됩니다.
각각의 해시 체인을 위한 락을 할당하는 것으로 해시 테이블을 해당 체인에 국한된
오퍼레이션들로 병렬화 시키게 됩니다.\footnote{
	그리고 이 방법을 여러 해시 체인에 접근하는 오퍼레이션들로 그런
	오퍼레이션들이 연관된 체인들을 위한 락들을 해시 순서대로 모두 잡도록
	하는 것으로 쉽게 확장할 수 있습니다.}
배열, radix tree, 그리고 일부 다른 데이터 구조들에 대해서도 파티셔닝은 비슷하게
간단합니다.
\iffalse

A major obstacle to the use of some conventional synchronization mechanisms
is the need to statically partition data structures.
There are a number of data structures that are trivially
partitionable, with the most prominent example being hash tables,
where each hash chain constitutes a partition.
Allocating a lock for each hash chain then trivially parallelizes
the hash table for operations confined to a given chain.\footnote{
	And it is also easy to extend this scheme to operations accessing
	multiple hash chains by having such operations acquire the
	locks for all relevant chains in hash order.}
Partitioning is similarly trivial for arrays, radix trees, and a few
other data structures.
\fi

하지만, 많은 종류의 tree 와 graph 에 있어 파티셔닝은 상당히 어렵고, 그 결과는
종종 복잡합니다~\cite{Ellis80}.
일반적인 데이터 구조를 파티셔닝 하는데에 two-phased 락킹과 해시된 락 배열들을
사용하는 것도 가능하지만, 다른 방법들이 더
선호되었는데~\cite{DavidSMiller2006HashedLocking}, 이것들은
Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}
에서 논의될 겁니다.
동기화 캐시 미스의 제거를 놓고 볼 때, HTM 은 최소한 상대적으로 적은 업데이트를
가정하면 커다란 파티셔닝 불가능한 데이터 구조를 위한 그럴싸한 방법입니다.
\iffalse

However, partitioning for many types of trees and graphs is quite
difficult, and the results are often quite complex~\cite{Ellis80}.
Although it is possible to use two-phased locking and hashed arrays
of locks to partition general data structures, other techniques
have proven preferable~\cite{DavidSMiller2006HashedLocking},
as will be discussed in
Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}.
Given its avoidance of synchronization cache misses,
HTM is therefore a very real possibility for large non-partitionable
data structures, at least assuming relatively small updates.
\fi

\QuickQuiz{}
	HTM 성능과 확장성에 상대적으로 적은 업데이트가 중요한 이유가 뭐죠?
	\iffalse

	Why are relatively small updates important to HTM performance
	and scalability?
	\fi
\QuickQuizAnswer{
	업데이트가 많을수록, 충돌의 가능성이 커지고, 따라서 재시도의 가능성이
	커져서 성능이 하락됩니다.
	\iffalse

	The larger the updates, the greater the probability of conflict,
	and thus the greater probability of retries, which degrade
	performance.
	\fi
} \QuickQuizEnd

\subsubsection{Practical Value}
\label{sec:future:Practical Value}

HTM 의 실질적 가치에 대한 몇몇 증거들이 Sun
Rock~\cite{DaveDice2009ASPLOSRockHTM} 와 Azul Vega~\cite{CliffClick2009AzulHTM}
을 포함한 여러 하드웨어 플랫폼들에서 보여졌습니다.
실질적 이점들이 더 최신의 IBM Blue Gene/Q, Intel Haswell TSX, 그리고 AMD ASF
시스템들에서도 나올 것이라 가정하는 것은 합리적입니다.

예상되는 실질적 이점들은 다음과 같습니다:
\iffalse

Some evidence of HTM's practical value has been demonstrated in a number
of hardware platforms, including
Sun Rock~\cite{DaveDice2009ASPLOSRockHTM} and
Azul Vega~\cite{CliffClick2009AzulHTM}.
It is reasonable to assume that practical benefits will flow from the
more recent IBM Blue Gene/Q, Intel Haswell TSX, and AMD ASF systems.

Expected practical benefits include:
\fi

\begin{enumerate}
\item	In-memory 데이터 액세스와 업데이트를 위한 락
	생략~\cite{Martinez01a,Rajwar02a}.
\item	커다란 파티셔닝 불가능한 데이터 구조로의 동시적인 액세스와 약간의
	무작위적 업데이트들.
\iffalse

\item	Lock elision for in-memory data access and
	update~\cite{Martinez01a,Rajwar02a}.
\item	Concurrent access and small random updates to large non-partitionable
	data structures.
\fi
\end{enumerate}

하지만, HTM 은 또한 실질적인 한계점들도 가지고 있는데, 이에 대해서는 다음
섹션에서 이야기 하겠습니다.
\iffalse

However, HTM also has some very real shortcomings, which will be discussed
in the next section.
\fi

\subsection{HTM Weaknesses WRT Locking}
\label{sec:future:HTM Weaknesses WRT Locking}

HTM 의 컨셉은 상당히 간단합니다: 메모리로의 액세스와 업데이트가 그룹 단위로
어토믹하게 일어난다는 것입니다.
하지만, 많은 간단한 아이디어들이 그러하듯이, 이를 실제 세계의 실제 시스템에
적용할 때에서야 복잡성이 나타납니다.
이 복잡성들은 다음과 같은 것들입니다:
\iffalse

The concept of HTM is quite simple: A group of accesses and updates to
memory occurs atomically.
However, as is the case with many simple ideas, complications arise
when you apply it to real systems in the real world.
These complications are as follows:
\fi

\begin{enumerate}
\item	트랜잭션 크기 한계.
\item	Conflict 처리.
\item	Abort 와 롤백.
\item	진행 보장의 부재.
\item	되돌이킬 수 없는 오퍼레이션들.
\item	Semantic 상의 차이점들.
\iffalse

\item	Transaction-size limitations.
\item	Conflict handling.
\item	Aborts and rollbacks.
\item	Lack of forward-progress guarantees.
\item	Irrevocable operations.
\item	Semantic differences.
\fi
\end{enumerate}

이 각각의 복잡성들은 다음의 섹션들에서 다루어지고, 그 뒤를 이어 요약을 합니다.
\iffalse

Each of these complications is covered in the following sections,
followed by a summary.
\fi

\subsubsection{Transaction-Size Limitations}
\label{sec:future:Transaction-Size Limitations}

현재 HTM 구현들의 트랜잭션 크기 한계점은 그 트랜잭션에 영향받는 데이터를 쥐고
있기 위해 프로세서의 캐시를 사용한다는 데서 나옵니다.
이는 특정 CPU 가 트랜잭션을 자신의 캐시 안에 국한된 채로 수행시켜서 해당
트랜잭션이 다른 CPU 들에게 어토믹 하게 보이도록 하는 것을 가능하게 하지만, 이는
또한 캐시에 들어가지 않는 모든 트랜잭션은 abort 될것을 의미하기도 합니다.
더 나아가서, 인터럽트, 시스템 콜, exception, trap, 그리고 컨텍스트 스위치와
같이 수행 문맥을 바꾸는 이벤트들은 해당 CPU 에서 수행중인 트랜잭션을 모두 abort
시키거나 다른 수행 컨텍스트에 의한 캐시 사용량으로 인해 트랜잭션의 크기를
제한해야만 합니다.

물론, 최신 CPU 들은 커다란 캐시를 갖는 경향이 있고, 많은 트랜잭션들에 필요한
데이터는 1 메가바이트 캐시 안에도 잘 들어갈 겁니다.
불행히도, 캐시에 있어서, 크기만이 모든 문제는 아닙니다.
문제는, 대부분의 캐시들은 하드웨어로 구현된 해시 테이블로 생각될 수 있다는
것입니다.
하지만, 하드웨어 캐시는 (일반적으로 \emph{set} 이라 불리는) 버킷들을 연결시키지
않고, set 당 고정된 수의 캐시라인들을 제공합니다.
특정 캐시에서 각각의 set 에 제공되는 원소들의 수는 해당 캐시의
\emph{associativity} 라고 불립니다.
\iffalse

The transaction-size limitations of current HTM implementations
stem from the use of the processor caches to hold the data
affected by the transaction.
Although this allows a given CPU to make the transaction appear atomic to
other CPUs by executing the transaction within the confines of its cache,
it also means that any transaction that does not fit must be aborted.
Furthermore, events that change execution context, such as interrupts,
system calls, exceptions, traps, and context switches either must
abort any ongoing transaction on the CPU in question or must further
restrict transaction size due to the cache footprint of the other
execution context.

Of course, modern CPUs tend to have large caches, and the data required
for many transactions would fit easily in a one-megabyte cache.
Unfortunately, with caches, sheer size is not all that matters.
The problem is that most caches
can be thought of hash tables implemented in hardware.
However, hardware caches do not chain their buckets (which are normally
called \emph{sets}), but rather
provide a fixed number of cachelines per set.
The number of elements provided for each set in a given cache
is termed that cache's \emph{associativity}.
\fi

Cache associativity 는 다양하지만, 제가 지금 타자를 치고 있는 랩탑의 8-way
associativity level-0 캐시는 흔하지 않습니다.
이게 의미하는바는 특정 트랜잭션이 9개의 캐시 라인을 건드리게 되고, 그 9개의
캐시 라인들이 모두 같은 set 으로 매핑된다면, 그 트랜잭션은 해당 캐시에 얼마나
많은 메가바이트의 용량들이 남아있는가에 관계없이 성공할 수 없다는 것입니다.
그렇습니다, 특정 데이터 구조에서 무작위적으로 골라진 데이터 원소들에 있어서, 그
트랜잭션이 커밋에 성공할 확률은 매우 높긴 합니다만, 어떤 보장사항도 없습니다.

이 한계점을 경감시키기 위한 일부 연구들이 있었습니다.
Fully associative \emph{victim cache} 는 associativity 한계를 경감시킬 수
있습니다만, victim cache 의 성능과 에너지 효율성에 대한 많은 한계가 현재
존재합니다.
그렇다고는 하나, 수정되지 않은 캐시 라인들을 위한 HTM victim cache 는 주소만을
가지고 있을 수도 있으므로, 상당히 작을 수 있습니다:
데이터 주소 자체는 충돌되는 쓰기를 파악하기에 충분하며~\cite{RaviRajwar2012TSX}
데이터 자체는 메모리에 쓰여지거나 다른 캐시에 shadow 될수 있습니다.
\iffalse

Although cache associativity varies, the eight-way associativity of
the level-0 cache on the laptop I am typing this on is not unusual.
What this means is that if a given transaction needed to touch
nine cache lines, and if all nine cache lines mapped to the same
set, then that transaction cannot possibly complete, never mind how
many megabytes of additional space might be available in that cache.
Yes, given randomly selected data elements in a given data structure,
the probability of that transaction being able to commit is quite
high, but there can be no guarantee.

There has been some research work to alleviate this limitation.
Fully associative \emph{victim caches} would alleviate the associativity
constraints, but there are currently stringent performance and
energy-efficiency constraints on the sizes of victim caches.
That said, HTM victim caches for unmodified cache lines can be quite
small, as they need to retain only the address:
The data itself can be written to memory or shadowed by other caches,
while the address itself is sufficient to detect a conflicting
write~\cite{RaviRajwar2012TSX}.
\fi

\emph{Unbounded transactional memory} (UTM)
방법~\cite{CScottAnanian2006,KevinEMoore2006} 은 DRAM 을 극단적으로 커다란
victim cache 로 사용합니다만, 그런 방법을 제품 품질의 캐시 일관성 메커니즘과
결합하는 것은 여전히 해결되지 않은 문제입니다.
또한, DRAM 을 victim cache 로 사용하는 것은 성능과 에너지 효율성의 저하를
가져올 수 있는데, victim cache 가 fully associative 하다면 특히 그렇습니다.
마지막으로, UTM 의 ``unbounded'' 라는 측면은 DRAM 이 모두 victim cache 로
사용될 수 있다는 가정을 합니다만, 실제로는 커다랗긴 하지만 고정된 양의, 해당
CPU 에 주어진 DRAM 의 용량만으로 해당 CPU 의 트랜잭션의 크기가 제한될 겁니다.
다른 방법들은 하드웨어 트랜잭셔널 메모리와 소프트웨어 트랜잭셔널 메모리의
조합을 사용하고~\cite{SanjeevKumar2006}, HTM 의 fallback 메커니즘으로 STM 을
사용하는 방법을 생각해 볼 수도 있을 겁니다.

하지만, 제가 알기로는, 현재로써 사용 가능한 시스템들은 이런 연구 아이디어들을
구현한 바가 없습니다.
\iffalse

\emph{Unbounded transactional memory} (UTM)
schemes~\cite{CScottAnanian2006,KevinEMoore2006}
use DRAM as an extremely large victim cache, but integrating such schemes
into a production-quality cache-coherence mechanism is still an unsolved
problem.
In addition, use of DRAM as a victim cache may have unfortunate
performance and energy-efficiency consequences, particularly
if the victim cache is to be fully associative.
Finally, the ``unbounded'' aspect of UTM assumes that all of DRAM
could be used as a victim cache, while in reality
the large but still fixed amount of DRAM assigned to a given CPU
would limit the size of that CPU's transactions.
Other schemes use a combination of hardware and software transactional
memory~\cite{SanjeevKumar2006} and one could imagine using STM as a
fallback mechanism for HTM.

However, to the best of my knowledge, currently available systems do
not implement any of these research ideas, and perhaps for good reason.
\fi

\subsubsection{Conflict Handling}
\label{sec:future:Conflict Handling}

첫번째 문제는 \emph{conflict} 의 가능성입니다.
예를 들어, transaction~A 와~B 가 다음과 같이 정의되었다고 생각해 봅시다:
\iffalse

The first complication is the possibility of \emph{conflicts}.
For example, suppose that transactions~A and~B are defined as follows:
\fi

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\begin{verbatim}
Transaction A       Transaction B

x = 1;              y = 2;
y = 3;              x = 4;
\end{verbatim}
\end{minipage}
\vspace{5pt}

각각의 트랜잭션이 각자의 프로세서 위에서 동시에 수행된다고 생각해 봅시다.
만약 transaction~A 가 \co{x} 에 쓰기를 하는 동시에 transaction~B 가 \co{y} 에
쓰기를 한다면, 두 트랜잭션 모두 진행될 수 없습니다.
이를 보기 위해, transaction~A 가 \co{y} 로의 쓰기를 수행한다고 생각해 봅시다.
그럼 transaction~A 는 transaction~B 와 섞여들어가게 되는데, 이는 트랜잭션이
상대방의 시점에 어토믹하게 수행되어야 한다는 트랜잭션의 요구사항을 위반하는
것입니다.
Transaction~B 가 \co{x} 로의 저장을 수행하게 허락한다면, 이는 비슷하게 어토믹
수행 요구사항을 위반하는 것입니다.
이 상황은 \emph{conflict} 라 명명되는데, 두개의 동시에 수행되는 트랜잭션들이
똑같은 변수에 접근하게 되며 그 접근들 가운데 최소한 하나는 쓰기인 경우에
발생합니다.
따라서 시스템은 수행이 진행될 수 있도록 하기 위해 이 트랜잭션들 가운데 하나나
두개 모두를 abort 시킬 의무를 갖습니다.
정확히 어떤 트랜잭션을 abort 시킬 것인가에 대한 선택은 Ph.D. 학위논문을 만들
능력이 있을 만큼 흥미로운 주제인데, 그런 예~\cite{EgeAkpinar2011HTM2TLE}도
있으니, 보시기 바랍니다.\footnote{
	``Toxic Transactions'' 라는 제목의 Liu 와 Spear 의
	논문~\cite{YujieLiu2011ToxicTransactions}  은 이런 면에서 특히
	유명합니다.}
이 섹션의 목적을 위해서, 우린 시스템이 무작위적 선택을 한다고 가정하겠습니다.
\iffalse

Suppose that each transaction executes concurrently on its own processor.
If transaction~A stores to \co{x} at the same time that transaction~B
stores to \co{y}, neither transaction can progress.
To see this, suppose that transaction~A executes its store to \co{y}.
Then transaction~A will be interleaved within transaction~B, in violation
of the requirement that transactions execute atomically with respect to
each other.
Allowing transaction~B to execute its store to \co{x} similarly violates
the atomic-execution requirement.
This situation is termed a \emph{conflict}, which happens whenever two
concurrent transactions access the same variable where at least one of
the accesses is a store.
The system is therefore obligated to abort one or both of the transactions
in order to allow execution to progress.
The choice of exactly which transaction to abort is an interesting topic
that will very likely retain the ability to generate Ph.D. dissertations for
some time to come, see for
example~\cite{EgeAkpinar2011HTM2TLE}.\footnote{
	Liu's and Spear's paper entitled ``Toxic
	Transactions''~\cite{YujieLiu2011ToxicTransactions} is
	particularly instructive in this regard.}
For the purposes of this section, we can assume that the system makes
a random choice.
\fi

또하나의 문제는 conflict 파악으로, 적어도 가장 간단한 경우에 있어서는 비교적
간단한 편입니다.
프로세서가 트랜잭션을 수행할 때, 프로세서는 그 트랜잭션에 의해 접근되는 모든
캐시라인을 표시해 둡니다.
만약 이 프로세서의 캐시가 현재 트랜잭션에 의해 접근된 것으로 표시된 캐시라인에
대한 요청을 받게 되면, 잠재적 conflcit 이 일어난 것입니다.
더 세련된 시스템들은 현재 프로세서의 트랜잭션이 그 요청을 보낸 프로세서의
트랜잭션을 앞서도록 순서잡을 것이고, 이 프로세스의 최적화는 또한 Ph.D.
학위논문을 쓰기 위한 능력을 얻을 수 있게 해줄 겁니다.
하지만 이 섹션은 매우 간단한 conflict 파악 전략을 가정합니다.
\iffalse

Another complication is conflict detection, which is comparatively
straightforward, at least in the simplest case.
When a processor is executing a transaction, it marks every cache line
touched by that transaction.
If the processor's cache receives a request involving a cache line that
has been marked as touched by the current transaction, a potential
conflict has occurred.
More sophisticated systems might try to order the current processors'
transaction to precede that of the processor sending the request,
and optimization of this process will likely also retain the ability
to generate Ph.D. dissertations for quite some time.
However this section assumes a very simple conflict-detection strategy.
\fi

하지만, HTM 이 효율적으로 동작하려면 conflict 의 가능성이 충분히 낮아야 하는데,
이는 데이터 구조가 충분히 낮은 conflict 가능성을 유지하도록 구성되어야 할것을
필요로 합니다.
예를 들어, 간단한 삽입, 삭제, 그리고 탐색 오퍼레이션을 제공하는 red-black
트리는 이런 경우에 적합합니다만, 트리의 모든 원소의 정확한 수를 유지해야 하는
red-black 트리는 그렇지 않습니다.\footnote{
	이 수를 업데이트 해야할 필요성이 트리로의 삽입과 트리로부터의 삭제가
	서로 conflict 를 발생시키게 해서 strong non-commutativity 를 초래할
	겁니다~\cite{HagitAttiya2011LawsOfOrder,Attiya:2011:LOE:1925844.1926442,PaulEMcKenney2011SNC}.}
또다른 예로, 트리의 모든 원소를 하나의 트랜잭션에서 열거하는 red-black 트리는
높은 conflict 확률을 가질 것이고, 성능과 확장성을 떨어뜨릴 겁니다.
결과적으로, 많은 순차적 프로그램들은 HTM 이 효과적으로 동작하도록 하기 위해
일부 재구성을 필요로 할 겁니다.
몇몇 경우에 있어서, 실무자들은 그런 추가적 단계를 취하거나 (red-black 트리의
경우에 있어서, radix 트리나 해시 테이블과 같은 파티셔닝 가능한 데이터 구조로의
전환 같은) 그냥 락킹을 사용하는 것을 선호할 수 있는데, HTM 이 모든 관련된
구조에서 사용 가능하기 충분한 시간이 오기 전까지는 특히 그럴 수
있습니다~\cite{CliffClick2009AzulHTM}.
\iffalse

However, for HTM to work effectively, the probability of conflict must
be suitably low, which in turn requires that the data structures
be organized so as to maintain a sufficiently low probability of conflict.
For example, a red-black tree with simple insertion, deletion, and search
operations fits this description, but a red-black
tree that maintains an accurate count of the number of elements in
the tree does not.\footnote{
	The need to update the count would result in additions to and
	deletions from the tree conflicting with each other, resulting
	in strong non-commutativity~\cite{HagitAttiya2011LawsOfOrder,Attiya:2011:LOE:1925844.1926442,PaulEMcKenney2011SNC}.}
For another example, a red-black tree that enumerates all elements in
the tree in a single transaction will have high conflict probabilities,
degrading performance and scalability.
As a result, many serial programs will require some restructuring before
HTM can work effectively.
In some cases, practitioners will prefer to take the extra steps
(in the red-black-tree case, perhaps switching to a partitionable
data structure such as a radix tree or a hash table), and just
use locking, particularly during the time before HTM is readily available
on all relevant
architectures~\cite{CliffClick2009AzulHTM}.
\fi

\QuickQuiz{}
	동기화 메커니즘의 선택에 관계 없이 어떻게 red-black 트리가 트리 내의
	모든 원소의 열거를 효율적으로 할 수 있을까요???
	\iffalse

	How could a red-black tree possibly efficiently enumerate all
	elements of the tree regardless of choice of synchronization
	mechanism???
	\fi
\QuickQuizAnswer{
	많은 경우에, 이 열거는 정확하지 않아도 좋습니다.
	이런 경우들에 있어서, hazard pointer 나 RCU 가 특정한 삽입이나 삭제와의
	낮은 conflict 확률을 유지하면서 읽기 쓰레드들을 보호하는데 사용될 수
	있습니다.
	\iffalse

	In many cases, the enumeration need not be exact.
	In these cases, hazard pointers or RCU may be used to protect
	readers with low probability of conflict with any given insertion
	or deletion.
	\fi
} \QuickQuizEnd

더 나아가서, conflict 이 일어날 수 있다는 사실은 다음 섹션에 이야기되는 것처럼
failure 처리를 어떻게 할 것인지 그림을 가져올 수 있게 해줍니다.
\iffalse

Furthermore, the fact that conflicts can occur brings failure handling
into the picture, as discussed in the next section.
\fi

\subsubsection{Aborts and Rollbacks}
\label{sec:future:Aborts and Rollbacks}

모든 트랜잭션이 언제든 abort 될 수 있으므로, 트랜잭션은 롤백될 수 없는 명령을
포함해선 안된다는 점이 중요합니다.
이 말은 트랜잭션은 I/O, 시스템콜, 또는 디버깅 브레이크포인트 (HTM
트랜잭션에서의 디버거에서의 single step 수행이 안됩니다!!!) 를 가질 수 없음을
의미합니다.
대신, 트랜잭션은 스스로를 평범한 캐시된 메모리에만 접근하도록 국한시켜야만
합니다.
더 나아가서, 일부 시스템에서는, 인터럽트, exception, trap, TLB 미스, 그리고
다른 이벤트들 역시 트랜잭션을 abort 시킵니다.
잘못된 에러 조건의 처리로 초래된 많은 수의 버그들을 생각해보면, 사용성을 위해
abort 와 rollback 이 어떤 효과를 갖는지 알아보는게 좋을 겁니다.
\iffalse

Because any transaction might be aborted at any time, it is important
that transactions contain no statements that cannot be rolled back.
This means that transactions cannot do I/O, system calls, or debugging
breakpoints (no single stepping in the debugger for HTM transactions!!!).
Instead, transactions must confine themselves to accessing normal
cached memory.
Furthermore, on some systems, interrupts, exceptions, traps,
TLB misses, and other events will also abort transactions.
Given the number of bugs that have resulted from improper handling
of error conditions, it is fair to ask what impact aborts and rollbacks
have on ease of use.
\fi

\QuickQuiz{}
	하지만 왜 디버거는 트랜잭션의 앞의 인스턴스의 스텝들을 다시 추적하기
	위해 재시도에 의조하면서 브레이크포인트를 트랜잭션의 성공되는 명령문
	줄에 설정해 두는 것으로 single stepping 을 흉내낼 수 없나요?
	\iffalse

	But why can't a debugger emulate single stepping by setting
	breakpoints at successive lines of the transaction, relying
	on the retry to retrace the steps of the earlier instances
	of the transaction?
	\fi
\QuickQuizAnswer{
	이 방법은 높은 확률로 동작할 수 있을 겁니다만, 대부분의 사용자들에게는
	상당히 놀라운 형태로 실패할 수 있습니다.
	이를 보기 위해, 다음 트랜잭션을 생각해 봅시다:
	\iffalse

	This scheme might work with reasonably high probability, but it
	can fail in ways that would be quite surprising to most users.
	To see this, consider the following transaction:
	\fi

	\vspace{5pt}
	\begin{minipage}[t]{\columnwidth}
	\small
\begin{verbatim}
  1 begin_trans();
  2 if (a) {
  3   do_one_thing();
  4   do_another_thing();
  5 } else {
  6   do_a_third_thing();
  7   do_a_fourth_thing();
  8 }
  9 end_trans();
\end{verbatim}
	\end{minipage}
	\vspace{5pt}

	사용자가 line~3 에 트랜잭션을 abort 시키고 디버거에 들어가게 될
	브레이크포인트를 설정했다고 생각해 봅시다.
	브레이크포인트가 시작되고 디버거가 모든 쓰레드를 정지시키는 사이에,
	어떤 다른 쓰레드가 \co{a} 의 값을 0으로 설정했다고 생각해 봅시다.
	사용자가 이 프로그램을 single-step 하면, 짜잔!
	프로그램은 이제 then-절 대신 else-절에 들어와 있습니다.

	이는 제가 사용성이 좋은 디버거라 부르는 것이 \emph{아닙니다}.
	\iffalse

	Suppose that the user sets a breakpoint at line~3, which triggers,
	aborting the transaction and entering the debugger.
	Suppose that between the time that the breakpoint triggers
	and the debugger gets around to stopping all the threads, some
	other thread sets the value of \co{a} to zero.
	When the poor user attempts to single-step the program, surprise!
	The program is now in the else-clause instead of the then-clause.

	This is \emph{not} what I call an easy-to-use debugger.
	\fi
} \QuickQuizEnd

물론, abort 와 롤백은 HTM 이 real-time 시스템에 유용할 수 있는 것인지라는
질문을 떠올리게 합니다.
HTM 의 성능적 이득이 abort 와 롤백의 비용을 넘을까요, 그리고 그렇다면 어떤 조건
하에서 그럴까요?
트랜잭션은 우선순위 향상 기능을 사용할 수 있을까요?
아니면 높은 우선순위 쓰레드를 위한 트랜잭션은 낮은 우선순위 쓰레드들을
우선적으로 abort 시켜야 할까요?
만약 그렇다면, 하드웨어는 어떻게 효율적으로 우선순위를 알 수 있을까요?
실제 세계에서의 HTM 의 사용에 대한 환경은 협소한데, 연구자들이 트랜잭션들이 비
real-time 환경에서 잘 동작하기에는 충분한 것들보다도 더 많은 문제들을 찾고 있기
때문일 수도 있습니다.
\iffalse

Of course, aborts and rollbacks raise the question of whether HTM can
be useful for hard real-time systems.
Do the performance benefits of HTM outweigh the costs of the aborts
and rollbacks, and if so under what conditions?
Can transactions use priority boosting?
Or should transactions for high-priority threads instead preferentially
abort those of low-priority threads?
If so, how is the hardware efficiently informed of priorities?
The literature on real-time use of HTM is quite sparse, perhaps because
researchers are finding more than enough problems in getting
transactions to work well in non-real-time environments.
\fi

현재의 HTM 구현들은 결정론적으로 특정 트랜잭션을 abort 시킬 수도 있기 때문에,
소프트웨어는 fallback 코드를 제공해야만 합니다.
이 fallback 코드는 예를 들면 락킹과 같은, 어떤 다른 형태의 동기화를 사용해야만
합니다.
만약 이 fallback 이 빈번하게 사용된다면, 데드락의 가능성을 포함한 모든 락킹의
제한점들이 다시 나타납니다.
물론, 이 fallback 이 자주 사용되지 않아서 더 간단하고 디드락이 나타나기 쉽지
않은 설계가 사용될 수 있게 되기를 바랄 수 있습니다.
하지만 이는 시스템은 락 기반의 fallback 에서 트랜잭션으로 어떻게 전환할
것인지에 대한 질문을 떠올리게 합니다.\footnote{
	어플리케이션이 fallback 모드에서 멈춰서게 되는 가능성은 Dave Dice 가
	만드는데 기여한, ``lemming effect'' 라고 명명되었습니다.}
한가지 방법은 test-and-test-and-set 방법~\cite{Martinez02a} 의 사용으로, 모두가
락이 해제될 때까지 기다림으로써 시스템이 트랜잭션적으로 깨끗한 백지 상태에서
시작할 수 있도록 하는 것입니다.
하지만, 이는 상당한 spinning 을 초래할 수 있는데, 이는 락을 쥔 쓰레드가
블락되어 있거나 preemption 당했다면 현명하지 못한 행위일 수 있습니다.
또다른 방법은 트랜잭션이 락을 쥔 쓰레드와 병렬적으로 수행될 수 있도록 하는
것~\cite{Martinez02a} 입니다만, 이 방법은 원자성을 유지하는데에 어려움을
낳으며, 특히 그 쓰레드가 락을 잡고 있는 이유가 연관된 트랜잭션이 캐시에
들어가지 않기 때문이라면 더 그렇습니다.
\iffalse

Because current HTM implementations might deterministically abort a
given transaction, software must provide fallback code.
This fallback code must use some other form of synchronization, for
example, locking.
If the fallback is used frequently, then all the limitations of locking,
including the possibility of deadlock, reappear.
One can of course hope that the fallback isn't used often, which might
allow simpler and less deadlock-prone locking designs to be used.
But this raises the question of how the system transitions from using
the lock-based fallbacks back to transactions.\footnote{
	The possibility of an application getting stuck in fallback
	mode has been termed the ``lemming effect'', a term that
	Dave Dice has been credited with coining.}
One approach is to use a test-and-test-and-set discipline~\cite{Martinez02a},
so that everyone holds off until the lock is released, allowing the
system to start from a clean slate in transactional mode at that point.
However, this could result in quite a bit of spinning, which might not
be wise if the lock holder has blocked or been preempted.
Another approach is to allow transactions to proceed in parallel with
a thread holding a lock~\cite{Martinez02a}, but this raises difficulties
in maintaining atomicity, especially if the reason that the thread is
holding the lock is because the corresponding transaction would not fit
into cache.
\fi

마지막으로, abort 와 롤백 가능성을 처리하는 것은 개발자에게 모든 가능한 에러
조건들의 조합을 올바르게 처리해야 한다는 추가적인 부담을 지우는 것으로 보일 수
있습니다.

HTM 의 사용자들이 fallback 코드 수행경로와 fallback 에서 트랜잭션 코드로의 전환
모두에 상당한 검증을 위한 노력을 기울여야 함은 분명합니다.
\iffalse

Finally, dealing with the possibility of aborts and rollbacks seems to
put an additional burden on the developer, who must correctly handle
all combinations of possible error conditions.

It is clear that users of HTM must put considerable validation effort
into testing both the fallback code paths and transition from fallback
code back to transactional code.
\fi

\subsubsection{Lack of Forward-Progress Guarantees}
\label{sec:future:Lack of Forward-Progress Guarantees}

Even though transaction size, conflicts, and aborts/rollbacks can all
cause transactions to abort, one might hope that sufficiently small and
short-duration transactions could be guaranteed to eventually succeed.
This would permit a transaction to be unconditionally retried, in the
same way that compare-and-swap (CAS) and load-linked/store-conditional
(LL/SC) operations are unconditionally retried in code that uses these
instructions to implement atomic operations.

Unfortunately, most currently available HTM implementation refuse to
make any
sort of forward-progress guarantee, which means that HTM cannot be
used to avoid deadlock on those systems.\footnote{
	HTM might well be used to reduce the probability of deadlock,
	but as long as there is some possibility of the fallback
	code being executed, there is some possibility of deadlock.}
Hopefully future implementations of HTM will provide some sort of
forward-progress guarantees.
Until that time, HTM must be used with extreme caution in real-time
applications.\footnote{
	As of mid-2012, there has been surprisingly little work on
	transactional memory's real-time characteristics.}

The one exception to this gloomy picture as of 2013 is upcoming versions
of the IBM mainframe, which provides a separate instruction that may be
used to start a special
\emph{constrained transaction}~\cite{ChristianJacobi2012MainframeTM}.
As you might guess from the name, such transactions must live within
the following constraints:

\begin{enumerate}
\item	Each transaction's data footprint must be contained within
	four 32-byte blocks of memory.
\item	Each transaction is permitted to execute at most 32 assembler
	instructions.
\item	Transactions are not permitted to have backwards branches
	(e.g., no loops).
\item	Each transaction's code is limited to 256 bytes of memory.
\item	If a portion of a given transaction's data footprint resides
	within a given 4K page, then that 4K page is prohibited from
	containing any of that transaction's instructions.
\end{enumerate}

These constraints are severe, but they nevertheless permit a wide variety
of data-structure updates to be implemented, including stacks, queues,
hash tables, and so on.
These operations are guaranteed to eventually complete, and are free of
deadlock and livelock conditions.

It will be interesting to see how hardware support of forward-progress
guarantees evolves over time.

\subsubsection{Irrevocable Operations}
\label{sec:future:Irrevocable Operations}

Another consequence of aborts and rollbacks is that HTM transactions
cannot accommodate irrevocable operations.
Current HTM implementations typically enforce this limitation by
requiring that all of the accesses in the transaction be to cacheable
memory (thus prohibiting MMIO accesses) and aborting transactions on
interrupts, traps, and exceptions (thus prohibiting system calls).

Note that buffered I/O can be accommodated by HTM transactions as
long as the buffer fill/flush operations occur extra-transactionally.
The reason that this works is that adding data to and removing data
from the buffer is revocable: Only the actual buffer fill/flush
operations are irrevocable.
Of course, this buffered-I/O approach has the effect of including the I/O
in the transaction's footprint, increasing the size of the transaction
and thus increasing the probability of failure.

\subsubsection{Semantic Differences}
\label{sec:future:Semantic Differences}

Although HTM can in many cases be used as a drop-in replacement for locking
(hence the name transactional lock
elision~\cite{DaveDice2008TransactLockElision}),
there are subtle differences in semantics.
A particularly nasty example involving coordinated lock-based critical
sections that results in deadlock or livelock when executed transactionally
was given by Blundell~\cite{Blundell2006TMdeadlock}, but a much simpler
example is the empty critical section.

In a lock-based program, an empty critical section will guarantee
that all processes that had previously been holding that lock have
now released it.
This idiom was used by the 2.4 Linux kernel's networking stack to
coordinate changes in configuration.
But if this empty critical section is translated to a transaction,
the result is a no-op.
The guarantee that all prior critical sections have terminated is
lost.
In other words, transactional lock elision preserves the data-protection
semantics of locking, but loses locking's time-based messaging semantics.

\QuickQuiz{}
	But why would \emph{anyone} need an empty lock-based critical
	section???
\QuickQuizAnswer{
	See the answer to \QuickQuizARef{\QlockingQemptycriticalsection} in
	Section~\ref{sec:locking:Exclusive Locks}.

	However, it is claimed that given a strongly atomic HTM
	implementation without forward-progress guarantees, any
	memory-based locking design based on empty critical sections
	will operate correctly in the presence of transactional
	lock elision.
	Although I have not seen a proof of this statement, there
	is a straightforward rationale for this claim.
	The main idea is that in a strongly atomic HTM implementation,
	the results of a given transaction are not visible until
	after the transaction completes successfully.
	Therefore, if you can see that a transaction has started,
	it is guaranteed to have already completed, which means
	that a subsequent empty lock-based critical section will
	successfully ``wait'' on it---after all, there is no waiting
	required.

	This line of reasoning does not apply to weakly atomic
	systems (including many STM implementation), and it also
	does not apply to lock-based programs that use means other
	than memory to communicate.
	One such means is the passage of time (for example, in
	hard real-time systems) or flow of priority (for example,
	in soft real-time systems).

	Locking designs that rely on priority boosting are of particular
	interest.
} \QuickQuizEnd

\QuickQuiz{}
	Can't transactional lock elision trivially handle locking's
	time-based messaging semantics
	by simply choosing not to elide empty lock-based critical sections?
\QuickQuizAnswer{
	It could do so, but this would be both unnecessary and
	insufficient.

	It would be unnecessary in cases where the empty critical section
	was due to conditional compilation.
	Here, it might well be that the only purpose of the lock was to
	protect data, so eliding it completely would be the right thing
	to do.
	In fact, leaving the empty lock-based critical section would
	degrade performance and scalability.

	On the other hand, it is possible for a non-empty lock-based
	critical section to be relying on both the data-protection
	and time-based and messaging semantics of locking.
	Using transactional lock elision in such a case would be
	incorrect, and would result in bugs.
} \QuickQuizEnd

\QuickQuiz{}
	Given modern hardware~\cite{PeterOkech2009InherentRandomness},
	how can anyone possibly expect parallel software relying
	on timing to work?
\QuickQuizAnswer{
	The short answer is that on commonplace commodity hardware,
	synchronization designs based on any sort of fine-grained
	timing are foolhardy and cannot be expected to operate correctly
	under all conditions.

	That said, there are systems designed for hard real-time use
	that are much more deterministic.
	In the (very unlikely) event that you are using such a system,
	here is a toy example showing how time-based synchronization can
	work.
	Again, do \emph{not} try this on commodity microprocessors,
	as they have highly nondeterministic performance characteristics.

	This example uses multiple worker threads along with a control
	thread.
	Each worker thread corresponds to an outbound data feed, and
	records the current time (for example, from the
	\co{clock_gettime()} system call) in a per-thread
	\co{my_timestamp} variable after executing each unit
	of work.
	The real-time nature of this example results in the following
	set of constraints:

	\begin{enumerate}
	\item	It is a fatal error for a given worker thread to fail
		to update its timestamp for a time period of more than
		\co{MAX_LOOP_TIME}.
	\item	Locks are used sparingly to access and update global
		state.
	item	Locks are granted in strict FIFO order within
		a given thread priority.
	\end{enumerate}

	When worker threads complete their feed, they must disentangle
	themselves from the rest of the application and place a status
	value in a per-thread \co{my_status} variable that is initialized
	to $-1$.
	Threads do not exit; they instead are placed on a thread pool
	to accommodate later processing requirements.
	The control thread assigns (and re-assigns) worker threads as
	needed, and also maintains a histogram of thread statuses.
	The control thread runs at a real-time priority no higher than
	that of the worker threads.

	Worker threads' code is as follows:

	\vspace{5pt}
	\begin{minipage}[t]{\columnwidth}
	\scriptsize
\begin{verbatim}
  1   int my_status = -1;  /* Thread local. */
  2 
  3   while (continue_working()) {
  4     enqueue_any_new_work();
  5     wp = dequeue_work();
  6     do_work(wp);
  7     my_timestamp = clock_gettime(...);
  8   }
  9 
 10   acquire_lock(&departing_thread_lock);
 11 
 12   /*
 13    * Disentangle from application, might
 14    * acquire other locks, can take much longer
 15    * than MAX_LOOP_TIME, especially if many
 16    * threads exit concurrently.
 17    */
 18   my_status = get_return_status();
 19   release_lock(&departing_thread_lock);
 20 
 21   /* thread awaits repurposing. */
\end{verbatim}
	\end{minipage}
	\vspace{5pt}

	The control thread's code is as follows:

	\vspace{5pt}
	\begin{minipage}[t]{\columnwidth}
	\scriptsize
\begin{verbatim}
  1   for (;;) {
  2     for_each_thread(t) {
  3       ct = clock_gettime(...);
  4       d = ct - per_thread(my_timestamp, t);
  5       if (d >= MAX_LOOP_TIME) {
  6         /* thread departing. */
  7         acquire_lock(&departing_thread_lock);
  8         release_lock(&departing_thread_lock);
  9         i = per_thread(my_status, t);
 10         status_hist[i]++; /* Bug if TLE! */
 11       }
 12     }
 13     /* Repurpose threads as needed. */
 14   }
\end{verbatim}
	\end{minipage}
	\vspace{5pt}

	Line~5 uses the passage of time to deduce that the thread
	has exited, executing lines~6-10 if so.
	The empty lock-based critical section on lines~7 and~8
	guarantees that any thread in the process of exiting
	completes (remember that locks are granted in FIFO order!).

	Once again, do not try this sort of thing on commodity
	microprocessors.
	After all, it is difficult enough to get right on systems
	specifically designed for hard real-time use!
} \QuickQuizEnd

One important semantic difference between locking and transactions
is the priority boosting that is used to avoid priority inversion
in lock-based real-time programs.
One way in which priority inversion can occur is when a
low-priority thread holding a lock
is preempted by a medium-priority CPU-bound thread.
If there is at least one such medium-priority thread per CPU, the
low-priority thread will never get a chance to run.
If a high-priority thread now attempts to acquire the lock,
it will block.
It cannot acquire the lock until the low-priority thread releases it,
the low-priority thread cannot release the lock until it gets a chance
to run, and it cannot get a chance to run until one of the medium-priority
threads gives up its CPU.
Therefore, the medium-priority threads are in effect blocking the
high-priority process, which is the rationale for the name ``priority
inversion.''

\begin{figure}[tbp]
{ \scriptsize
\begin{verbbox}
  1 void boostee(void)
  2 {
  3   int i = 0;
  4 
  5   acquire_lock(&boost_lock[i]);
  6   for (;;) {
  7     acquire_lock(&boost_lock[!i]);
  8     release_lock(&boost_lock[i]);
  9     i = i ^ 1;
 10     do_something();
 11   }
 12 }
 13 
 14 void booster(void)
 15 {
 16   int i = 0;
 17 
 18   for (;;) {
 19     usleep(1000); /* sleep 1 ms. */
 20     acquire_lock(&boost_lock[i]);
 21     release_lock(&boost_lock[i]);
 22     i = i ^ 1;
 23   }
 24 }
\end{verbbox}
}
\centering
\theverbbox
\caption{Exploiting Priority Boosting}
\label{fig:future:Exploiting Priority Boosting}
\end{figure}

One way to avoid priority inversion is \emph{priority inheritance},
in which a high-priority thread blocked on a lock temporarily donates
its priority to the lock's holder, which is also called \emph{priority
boosting}.
However, priority boosting can be used for things other than avoiding
priority inversion, as shown in
Figure~\ref{fig:future:Exploiting Priority Boosting}.
Lines~1-12 of this figure show a low-priority process that must
nevertheless run every millisecond or so, while lines~14-24 of
this same figure show a high-priority process that uses priority
boosting to ensure that \co{boostee()} runs periodically as needed.

The \co{boostee()} function arranges this by always holding one of
the two \co{boost_lock[]} locks, so that lines~20-21 of
\co{booster()} can boost priority as needed.

\QuickQuiz{}
	But the \co{boostee()} function in
	Figure~\ref{fig:future:Exploiting Priority Boosting}
	alternatively acquires its locks in reverse order!
	Won't this result in deadlock?
\QuickQuizAnswer{
	No deadlock will result.
	To arrive at deadlock, two different threads must each
	acquire the two locks in oppposite orders, which does not
	happen in this example.
	However, deadlock detectors such as
	lockdep~\cite{JonathanCorbet2006lockdep}
	will flag this as a false positive.
} \QuickQuizEnd

This arrangement requires that \co{boostee()} acquire its first
lock on line~5 before the system becomes busy, but this is easily
arranged, even on modern hardware.

Unfortunately, this arrangement can break down in presence of transactional
lock elision.
The \co{boostee()} function's overlapping critical sections become
one infinite transaction, which will sooner or later abort,
for example, on the first time that the thread running
the \co{boostee()} function is preempted.
At this point, \co{boostee()} will fall back to locking, but given
its low priority and that the quiet initialization period is now
complete (which after all is why \co{boostee()} was preempted),
this thread might never again get a chance to run.

And if the \co{boostee()} thread is not holding the lock, then
the \co{booster()} thread's empty critical section on lines~20 and~21 of
Figure~\ref{fig:future:Exploiting Priority Boosting}
will become an empty transaction that has no effect, so that
\co{boostee()} never runs.
This example illustrates some of the subtle consequences of
transactional memory's rollback-and-retry semantics.

Given that experience will likely uncover additional subtle semantic
differences, application of HTM-based lock elision to large programs
should be undertaken with caution.
That said, where it does apply, HTM-based lock elision can eliminate
the cache misses associated with the lock variable, which has resulted
in tens of percent performance increases in large real-world software
systems as of early 2015.
We can therefore expect to see substantial use of this technique on
hardware supporting it.

\QuickQuiz{}
	So a bunch of people set out to supplant locking, and they
	mostly end up just optimizing locking???
\QuickQuizAnswer{
	At least they accomplished something useful!
	And perhaps there will be additional HTM progress over time.
} \QuickQuizEnd

\subsubsection{Summary}
\label{sec:future:HTM Weaknesses WRT Locking: Summary}

\input{future/HTMtable}

Although it seems likely that HTM will have compelling use cases,
current implementations have serious transaction-size limitations,
conflict-handling complications, abort-and-rollback issues, and
semantic differences that will require careful handling.
HTM's current situation relative to locking is summarized in
Table~\ref{tab:future:Comparison of Locking and HTM}.
As can be seen, although the current state of HTM alleviates some
serious shortcomings of locking,\footnote{
	In fairness, it is important to emphasize that locking's shortcomings
	do have well-known and heavily used engineering solutions, including
	deadlock detectors~\cite{JonathanCorbet2006lockdep}, a wealth
	of data structures that have been adapted to locking, and
	a long history of augmentation, as discussed in
	Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}.
	In addition, if locking really were as horrible as a quick skim
	of many academic papers might reasonably lead one to believe,
	where did all the large lock-based parallel programs (both
	FOSS and proprietary) come from, anyway?}
it does so by introducing a significant
number of shortcomings of its own.
These shortcomings are acknowledged by leaders in the TM
community~\cite{AlexanderMatveev2012PessimisticTM}.\footnote{
	In addition, in early 2011, I was invited to deliver a critique of
	some of the assumptions underlying transactional
	memory~\cite{PaulEMcKenney2011Verico}.
	The audience was surprisingly non-hostile, though perhaps they
	were taking it easy on me due to the fact that I was heavily
	jet-lagged while giving the presentation.}

In addition, this is not the whole story.
Locking is not normally used by itself, but is instead typically
augmented by other synchronization mechanisms,
including reference counting, atomic operations, non-blocking data structures,
hazard pointers~\cite{MagedMichael04a,HerlihyLM02},
and read-copy update (RCU)~\cite{McKenney98,McKenney01a,ThomasEHart2007a,PaulEMcKenney2012ELCbattery}.
The next section looks at how such augmentation changes the equation.

\subsection{HTM Weaknesses WRT to Locking When Augmented}
\label{sec:future:HTM Weaknesses WRT to Locking When Augmented}

\input{future/HTMtableRCU}

Practitioners have long used reference counting, atomic operations,
non-blocking data structures, hazard pointers, and RCU to avoid some
of the shortcomings of locking.
For example, deadlock can be avoided in many cases by using reference
counts, hazard pointers, or RCU to protect data structures,
particularly for read-only critical
sections~\cite{MagedMichael04a,HerlihyLM02,MathieuDesnoyers2012URCU,DinakarGuniguntala2008IBMSysJ,ThomasEHart2007a}.
These approaches also reduce the need to partition data
structures, as was see in Chapter~\ref{chp:Data Structures}.
RCU further provides contention-free wait-free read-side
primitives~\cite{MathieuDesnoyers2012URCU}.
Adding these considerations to
Table~\ref{tab:future:Comparison of Locking and HTM}
results in the updated comparison between augmented locking and HTM
shown in
Table~\ref{tab:future:Comparison of Locking (Augmented by RCU or Hazard Pointers) and HTM}.
A summary of the differences between the two tables is as follows:

\begin{enumerate}
\item	Use of non-blocking read-side mechanisms alleviates deadlock issues.
\item	Read-side mechanisms such as hazard pointers and RCU can operate
	efficiently on non-partitionable data.
\item	Hazard pointers and RCU do not contend with each other or with
	updaters, allowing excellent performance and scalability for
	read-mostly workloads.
\item	Hazard pointers and RCU provide forward-progress guarantees
	(lock freedom and wait-freedom, respectively).
\item	Privatization operations for hazard pointers and RCU are
	straightforward.
\end{enumerate}

Of course, it is also possible to augment HTM,
as discussed in the next section.

\subsection{Where Does HTM Best Fit In?}
\label{sec:future:Where Does HTM Best Fit In?}

Although it will likely be some time before HTM's area of applicability
can be as crisply delineated as that shown for RCU in
Figure~\ref{fig:defer:RCU Areas of Applicability} on
page~\pageref{fig:defer:RCU Areas of Applicability}, that is no reason not to
start moving in that direction.

HTM seems best suited to update-heavy workloads involving relatively
small changes to disparate portions of relatively large in-memory
data structures running on large multiprocessors,
as this meets the size restrictions of current HTM implementations while
minimizing the probability of conflicts and attendant aborts and
rollbacks.
This scenario is also one that is relatively difficult to handle given
current synchronization primitives.

Use of locking in conjunction with HTM seems likely to overcome HTM's
difficulties with irrevocable operations, while use of RCU or
hazard pointers might alleviate HTM's transaction-size limitations
for read-only operations that traverse large fractions of the data
structure.
Current HTM implementations unconditionally abort an update transaction
that conflicts with an RCU or hazard-pointer reader, but perhaps future
HTM implementations will interoperate more smoothly with these
synchronization mechanisms.
In the meantime, the probability of an update conflicting with a
large RCU or hazard-pointer read-side critical section should be
much smaller than the probability of conflicting with the equivalent
read-only transaction.\footnote{
	It is quite ironic that strictly transactional mechanisms are
	appearing in shared-memory systems at just about the time
	that NoSQL databases are relaxing the traditional
	database-application reliance on strict transactions.}
Nevertheless, it is quite possible that a steady stream of RCU or
hazard-pointer readers might starve updaters due to a corresponding
steady stream of conflicts.
This vulnerability could be eliminated (perhaps at significant
hardware cost and complexity) by giving extra-transactional
reads the pre-transaction copy of the memory location being loaded.

The fact that HTM transactions must have fallbacks might in some cases
force static partitionability of data structures back onto HTM.
This limitation might be alleviated if future HTM implementations
provide forward-progress guarantees, which might eliminate the need
for fallback code in some cases, which in turn might allow HTM to
be used efficiently in situations with higher conflict probabilities.

In short, although HTM is likely to have important uses and applications,
it is another tool in the parallel programmer's toolbox, not a replacement
for the toolbox in its entirety.

\subsection{Potential Game Changers}
\label{sec:future:Potential Game Changers}

Game changers that could greatly increase the need for HTM include
the following:

\begin{enumerate}
\item	Forward-progress guarantees.
\item	Transaction-size increases.
\item	Improved debugging support.
\item	Weak atomicity.
\end{enumerate}

These are expanded upon in the following sections.

\subsubsection{Forward-Progress Guarantees}
\label{sec:future:Forward-Progress Guarantees}

As was discussed in
Section~\ref{sec:future:Lack of Forward-Progress Guarantees},
current HTM implementations lack forward-progress guarantees, which requires
that fallback software be available to handle HTM failures.
Of course, it is easy to demand guarantees, but not always easy
to provide them.
In the case of HTM, obstacles to guarantees can include cache size and
associativity, TLB size and associativity, transaction duration and
interrupt frequency, and scheduler implementation.

Cache size and associativity was discussed in
Section~\ref{sec:future:Transaction-Size Limitations},
along with some research intended to work around current limitations.
However, HTM forward-progress guarantees would
come with size limits, large though these limits might one day be.
So why don't current HTM implementations provide forward-progress
guarantees for small transactions, for example, limited to the
associativity of the cache?
One potential reason might be the need to deal with hardware failure.
For example, a failing cache SRAM cell might be handled by deactivating
the failing cell, thus reducing the associativity of the cache and
therefore also the maximum size of transactions that can be guaranteed
forward progress.
Given that this would simply decrease the guaranteed transaction size,
it seems likely that other reasons are at work.
Perhaps providing forward progress guarantees on production-quality
hardware is more difficult than one might think, an entirely plausible
explanation given the difficulty of making forward-progress guarantees
in software.
Moving a problem from software to hardware does not necessarily make
it easier to solve.

Given a physically tagged and indexed cache, it is not enough for the
transaction to fit in the cache.
Its address translations must also fit in the TLB.
Any forward-progress guarantees must therefore also take TLB size
and associativity into account.

Given that interrupts, traps, and exceptions abort transactions in current
HTM implementations, it is necessary that the execution duration of
a given transaction be shorter than the expected interval between
interrupts.
No matter how little data a given transaction touches, if it runs too
long, it will be aborted.
Therefore, any forward-progress guarantees must be conditioned not only
on transaction size, but also on transaction duration.

Forward-progress guarantees depend critically on the ability to determine
which of several conflicting transactions should be aborted.
It is all too easy to imagine an endless series of transactions, each
aborting an earlier transaction only to itself be aborted by a later
transactions, so that none of the transactions actually commit.
The complexity of conflict handling is
evidenced by the large number of HTM conflict-resolution policies
that have been proposed~\cite{EgeAkpinar2011HTM2TLE,YujieLiu2011ToxicTransactions}.
Additional complications are introduced by extra-transactional accesses,
as noted by Blundell~\cite{Blundell2006TMdeadlock}.
It is easy to blame the extra-transactional accesses for all of these
problems, but the folly of this line of thinking is easily demonstrated
by placing each of the extra-transactional accesses into its own
single-access transaction.
It is the pattern of accesses that is the issue, not whether or not they
happen to be enclosed in a transaction.

Finally, any forward-progress guarantees for transactions also
depend on the scheduler, which must let the thread executing the
transaction run long enough to successfully commit.

So there are significant obstacles to HTM vendors offering forward-progress
guarantees.
However, the impact of any of them doing so would be enormous.
It would mean that HTM transactions would no longer need software
fallbacks, which would mean that HTM could finally deliver on the
TM promise of deadlock elimination.

And as of late 2012, the IBM Mainframe announced an HTM
implementation that includes \emph{constrained transactions}
in addition to the usual best-effort HTM
implementation~\cite{ChristianJacobi2012MainframeTM}.
A constrained transaction starts with the \co{tbeginc} instruction
instead of the \co{tbegin} instruction that is used for best-effort
transactions.
Constrained transactions are guaranteed to always complete (eventually),
so if a transaction aborts, rather than branching to a fallback path
(as is done for best-effort transactions), the hardware instead restarts
the transaction at the \co{tbeginc} instruction.

The Mainframe architects needed to take extreme measures to deliver on
this forward-progress guarantee.
If a given constrained transaction repeatedly fails, the CPU
might disable branch prediction, force in-order execution, and even
disable pipelining.
If the repeated failures are due to high contention, the CPU might
disable speculative fetches, introduce random delays, and even
serialize execution of the conflicting CPUs.
``Interesting'' forward-progress scenarios involve as few as two CPUs
or as many as one hundred CPUs.
Perhaps these extreme measures provide some insight as to why other CPUs
have thus far refrained from offering constrained transactions.

As the name implies, constrained transactions are in fact severely constrained:

\begin{enumerate}
\item	The maximum data footprint is four blocks of memory,
	where each block can be no larger than 32 bytes.
\item	The maximum code footprint is 256 bytes.
\item	If a given 4K page contains a constrained transaction's code,
	then that page may not contain that transaction's data.
\item	The maximum number of assembly instructions that may be executed
	is 32.
\item	Backwards branches are forbidden.
\end{enumerate}

Nevertheless, these constraints support a number of important data structures,
including linked lists, stacks, queues, and arrays.
Constrained HTM therefore seems likely to become an important tool in
the parallel programmer's toolbox.

\subsubsection{Transaction-Size Increases}
\label{sec:future:Transaction-Size Increases}

Forward-progress guarantees are important, but as we saw, they will
be conditional guarantees based on transaction size and duration.
It is important to note that even small-sized guarantees will be
quite useful.
For example,
a guarantee of two cache lines is sufficient for a stack, queue, or dequeue.
However, larger data structures require larger guarantees, for example,
traversing a tree in order requires a guarantee equal to the number
of nodes in the tree.

Therefore, increasing the size of the guarantee also increases the
usefulness of HTM, thereby increasing the need for CPUs to either
provide it or provide good-and-sufficient workarounds.

\subsubsection{Improved Debugging Support}
\label{sec:future:Improved Debugging Support}

Another inhibitor to transaction size is the need to debug the transactions.
The problem with current mechanisms is that a single-step exception
aborts the enclosing transaction.
There are a number of workarounds for this issue, including emulating
the processor (slow!), substituting STM for HTM (slow and slightly
different semantics!),
playback techniques using repeated retries to emulate forward
progress (strange failure modes!), and
full support of debugging HTM transactions (complex!).

Should one of the HTM vendors produce an HTM system that allows
straightforward use of classical debugging techniques within
transactions, including breakpoints, single stepping, and
print statements, this will make HTM much more compelling.
Some transactional-memory researchers are starting to recognize this
problem as of 2013, with at least one proposal involving hardware-assisted
debugging facilities~\cite{JustinGottschlich2013TMdebug}.
Of course, this proposal depends on readily available hardware gaining such
facilities.

\subsubsection{Weak Atomicity}
\label{sec:future:Weak Atomicity}

Given that HTM is likely to face some sort of size limitations for the
foreseeable future, it will be necessary for HTM to interoperate
smoothly with other mechanisms.
HTM's interoperability with read-mostly mechanisms such as hazard pointers
and RCU would be improved if extra-transactional reads did not
unconditionally abort transactions with conflicting writes---instead,
the read could simply be provided with the pre-transaction value.
In this way, hazard pointers and RCU could be used to allow HTM to handle
larger data structures and to reduce conflict probabilities.

This is not necessarily simple, however.
The most straightforward way of implementing this requires an additional
state in each cache line and on the bus, which is a non-trivial added
expense.
The benefit that goes along with this expense is permitting
large-footprint readers without the risk of starving updaters due
to continual conflicts.

\subsection{Conclusions}
\label{sec:future:Conclusions}

Although current HTM implementations appear to be poised to deliver real
benefits, they also have significant shortcomings.
The most significant shortcomings appear to be
limited transaction sizes,
the need for conflict handling, the need for aborts and rollbacks,
the lack of forward-progress guarantees,
the inability to handle irrevocable operations,
and subtle semantic differences
from locking.

Some of these shortcomings might be alleviated in future implementations,
but it appears that there will continue to be a strong need to make
HTM work well with the many other types of synchronization mechanisms,
as noted earlier~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener}.

In short, current HTM implementations appear to be welcome and useful
additions to the parallel programmer's toolbox, and much interesting
and challenging work is required to make use of them.
However, they cannot be
considered to be a magic wand with which to wave away all parallel-programming
problems.
