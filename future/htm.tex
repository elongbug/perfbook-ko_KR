% future/htm.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{Hardware Transactional Memory}
\label{sec:future:Hardware Transactional Memory}
%
\epigraph{Make sure your report system is reasonably clean and efficient
	  before you automate.
	  Otherwise, your new computer will just speed up the mess.}
	 {\emph{Robert Townsend}}
% If at first you do succeed---try to hide your astonishment.
% Harry F.~Banks

2021년 기준, 하드웨어 트랜잭셔널 메모리 (HTM) 은 상업적으로 접근 가능한 상품
컴퓨터 시스템의 여러 형태로 수년째
가용해졌습니다~\cite{Yoo:2013:PEI:2503210.2503232,RickMerrit2011PowerTM,ChristianJacobi2012MainframeTM,TimothyHayes2020ARM-HTM}.
이 섹션은 병렬 프로그래머의 도구상자에서 HTM 의 위치를 정의해 보려 합니다.

\iffalse

As of 2021, hardware transactional memory (HTM) has been available for many
years on several types of commercially available commodity computer
systems~\cite{Yoo:2013:PEI:2503210.2503232,RickMerrit2011PowerTM,ChristianJacobi2012MainframeTM,TimothyHayes2020ARM-HTM}.
This section makes an attempt to identify HTM's place in the parallel
programmer's toolbox.

\fi

컨셉적 관점에서, HTM 은 선정된 선언문들이 (``트랜잭션'') 다른 프로세서에서
수행중인 다른 트랜잭션의 관점에서 볼 때 어토믹하게 효과를 발휘하도록 하게 하기
위해 프로세서 캐쉬와 예측적 수행을 사용합니다.
이 트랜잭션은 begin-transaction 기계 명령에 의해 시작되고 commit-transaction
기계 명령에 의해 완료됩니다.
일반적으로 abort-transaction 기계 명령도 존재하는데, 예측을 찌그러뜨리고
(begin-transaction 명령과 뒤따르는 명령들이 수행되지 않은 것처럼) 실패
처리기에서의 수행을 시작합니다.
실패 처리기의 위치는 일반적으로 begin-transaction 명령에 의해 명시되는데,
명시적 실패 처리기 주소가 주어지거나 명령 자체에 의해 설정되는 조건 코드를 통해
주어집니다.
각 트랜잭션은 모든 다른 트랜잭션에 대해 원자적으로 수행됩니다.

HTM 은 여러 중요한 이득을 갖는데, 데이터 구조의 자동화된 동적 파티셔닝, 동기화
기능의 캐쉬 미스 감소, 상당한 수의 실용적 어플리케이션의 지원이 포함됩니다.

\iffalse

From a conceptual viewpoint, HTM uses processor caches and speculative
execution to make a designated group of statements (a ``transaction'')
take effect atomically
from the viewpoint of any other transactions running on other processors.
This transaction is initiated by a
begin-transaction machine instruction and completed by a commit-transaction
machine instruction.
There is typically also an abort-transaction machine instruction, which
squashes the speculation (as if the begin-transaction instruction and
all following instructions had not executed) and commences execution
at a failure handler.
The location of the failure handler is typically specified by the
begin-transaction instruction, either as an explicit failure-handler
address or via a condition code set by the instruction itself.
Each transaction executes atomically with respect to all other transactions.

HTM has a number of important benefits, including automatic
dynamic partitioning of data structures, reducing synchronization-primitive
cache misses, and supporting a fair number of practical applications.

\fi

그러나, 제대로 된 문서를 읽을 것이 항상 필요하며, HTM 도 예외가 아닙니다.
이 섹션의 주요 지점은 어떤 조건에서 HTM 의 이득이 그것의 제대로 된 문서에 숨어
있는 복잡도를 이겨내는가를 알아내는 것입니다.
따라서, \cref{sec:future:HTM Benefits WRT Locking} 는 HTM 의 이득을 이야기하고,
\cref{sec:future:HTM Weaknesses WRT Locking} 는 그 약점을 이야기 합니다.
이는 이전의 섹션들과
논문들에서와~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener} 같은
방법입니다.\footnote{
	다른 저자들, Maged Michael, Josh Triplett, Jonathan Walpole, Andi Kleen
	등과의 많은 자극적 토론에 소중한 감사를 표합니다.}

이어서
\cref{sec:future:HTM Weaknesses WRT Locking When Augmented} 는 리눅스 커널
(그리고 많은 유저 스페이스 어플리케이션) 에서 사용되는 동기화 기능들과의 조합
관점에서의 HTM 의 약점을 설명합니다.
\Cref{sec:future:Where Does HTM Best Fit In?} 는 병렬 프로그래머의 도구상자
내에서 어디에 HTM 이 가장 잘 맞을지 알아보고,
\cref{sec:future:Potential Game Changers} 는 HTM 의 영역과 인상을 크게 개선시킬
수도 있을 이벤트를 일부 나열해 봅니다.
마지막으로, \cref{sec:future:Conclusions} 는 결론을 짓습니다.

\iffalse

However, it always pays to read the fine print, and HTM is no exception.
A major point of this section is determining under what conditions HTM's
benefits outweigh the complications hidden in its fine print.
To this end, \cref{sec:future:HTM Benefits WRT Locking}
describes HTM's benefits and
\cref{sec:future:HTM Weaknesses WRT Locking} describes its weaknesses.
This is the same approach used in earlier
papers~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener}
and also in the previous section.\footnote{
	I gratefully acknowledge many stimulating
	discussions with the other authors, Maged Michael, Josh Triplett,
	and Jonathan Walpole, as well as with Andi Kleen.}

\Cref{sec:future:HTM Weaknesses WRT Locking When Augmented} then describes
HTM's weaknesses with respect to the combination of synchronization
primitives used in the Linux kernel (and in many user-space applications).
\Cref{sec:future:Where Does HTM Best Fit In?} looks at where HTM
might best fit into the parallel programmer's toolbox, and
\cref{sec:future:Potential Game Changers} lists some events that might
greatly increase HTM's scope and appeal.
Finally, \cref{sec:future:Conclusions}
presents concluding remarks.

\fi

\subsection{HTM Benefits WRT Locking}
\label{sec:future:HTM Benefits WRT Locking}

HTM 의 주요 장점은
(1)~다른 동기화 기능에 의해 종종 일어나는 캐쉬 미스의 회피,
(2)~동적으로 데이터 구조를 파티셔닝하는 능력, 그리고
(3)~상당한 수의 실용적 어플리케이션을 갖는다는 사실 입니다.
저는 TM 에 대한 전통과 달리 두가지 이유로 쉬운 사용성을 여기에 포함시키지
않습니다.
첫째로, 쉬운 사용성은 HTM 의 주요 장점으로부터 생겨나는 것인데, 그게 이 섹션이
주목하는 부분입니다.
둘째로, 기본적 프로그래밍 재능에 대한
검사와~\cite{RichardBornat2006SheepGoats,SaeedDehnadi2009SheepGoats,ElizabethPatitsas2020GradesNotBimodal}
심지어 취업 면접에서의 작은 프로그래밍 테스트의 사용에
대한~\cite{RegBraithwaite2007FizzBuzz} 상당한 노란이 있었습니다.
이는 무엇이 프로그래밍을 쉽게 하는지 어렵게 하는지에 대한 확고한 이해를 정말로
갖지 못하고 있음을 보입니다.
따라서, 이 섹션의 나머지 부분은 앞에 나열된 세가지 장점에 집중합니다.

\iffalse

The primary benefits of HTM are
(1)~its avoidance of the cache misses that are often incurred by
other synchronization primitives,
(2)~its ability to dynamically partition
data structures,
and (3)~the fact that it has
a fair number of practical applications.
I break from TM tradition by not listing ease of use separately
for two reasons.
First, ease of use should stem from HTM's primary benefits,
which this section focuses on.
Second, there has been considerable controversy surrounding attempts to
test for raw programming
talent~\cite{RichardBornat2006SheepGoats,SaeedDehnadi2009SheepGoats,ElizabethPatitsas2020GradesNotBimodal}
and even around the use of small programming exercises in job
interviews~\cite{RegBraithwaite2007FizzBuzz}.
This indicates that we really do not have a firm grasp on what makes
programming easy or hard.
Therefore, the remainder of this section focuses on the three benefits
listed above.

\fi

\subsubsection{Avoiding Synchronization Cache Misses}
\label{sec:future:Avoiding Synchronization Cache Misses}

대부분의 동기화 메커니즘은 어토믹 명령에 의해 운영되는 데이터 구조에
기반합니다.
이 어토믹 명령들은 일반적으로 일단 연관된 캐쉬라인이 그들이 수행중인 CPU 에
의해 소유되게 하여, 다른 CPU 에서의 같은 동기화 기능의 사용은 캐쉬 미스를
일으키게 합니다.
이 통신을 위한 캐쉬 미스는 전통적 동기화 메커니즘의 성능과 확장성을 크게
악화시킵니다~\cite[Section 4.2.3]{Anderson97}.

\iffalse

Most synchronization mechanisms are based on data structures that are
operated on by atomic instructions.
Because these atomic instructions normally operate by first causing
the relevant cache line to be owned by the CPU that they are running on,
a subsequent execution
of the same instance of that synchronization primitive on some other
CPU will result in a cache miss.
These communications cache misses severely degrade both the performance and
scalability of conventional synchronization
mechanisms~\cite[Section 4.2.3]{Anderson97}.

\fi

대조적으로, HTM 은 해당 CPU 의 캐쉬를 이용해 동기화를 하므로 별도의 동기화
데이터 구조와 그로 인한 캐쉬 미스를 회피합니다.
HTM 의 장점은 락 데이터 구조가 별도의 캐쉬 라인에 위치하는 경우 가장 커지는데,
이 경우 크리티컬 섹션을 HTM 트랜잭션으로 변환시키는 것은 크리티컬 섹션의 캐쉬
미스로 인한 오버헤드를 완전히 줄일 수 있습니다.
이로 인한 절약은 짧은 크리티컬 섹션이라는 흔한 경우 상당히 클 수 있는데, 최소한
제거된 락이 그 락에 의해 보호되는 변수의 캐쉬 라인을 공유하는 많은 경우가 아닐
경우에는 그렇습니다.

\iffalse

In contrast, HTM synchronizes by using the CPU's cache, avoiding the need
for a separate synchronization data structure and resultant cache misses.
HTM's advantage is greatest in cases where a lock data structure is
placed in a separate cache line, in which case, converting a given
critical section to an HTM transaction can reduce that critical section's
overhead by a full cache miss.
These savings can be quite significant for the common case of short
critical sections, at least for those situations where the elided lock
does not share a cache line with an oft-written variable protected by
that lock.

\fi

\QuickQuiz{
	왜 락 변수와 보호되는 변수가 캐쉬 라인을 공유하는 일반적 경우가
	중요하죠?

	\iffalse

	Why would it matter that oft-written variables shared the cache
	line with the lock variable?

	\fi

}\QuickQuizAnswer{
	그 락이 자신이 보호하는 변수들과 같은 캐쉬라인에 있다면, 한 CPU 에 의한
	이 변수들로의 쓰기는 모든 다른 CPU 의 캐쉬 라인을 무효화 시킬 겁니다.
	이 무효화는 큰 수의 충돌과 재시도를 발생시키는데, 이는 아마 락킹에
	비해서도 성능과 확장성을 더 떨어뜨릴 수도 있습니다.

	\iffalse

	If the lock is in the same cacheline as some of the variables
	that it is protecting, then writes to those variables by one CPU
	will invalidate that cache line for all the other CPUs.
	These invalidations will
	generate large numbers of conflicts and retries, perhaps even
	degrading performance and scalability compared to locking.

	\fi

}\QuickQuizEnd

\subsubsection{Dynamic Partitioning of Data Structures}
\label{sec:future:Dynamic Partitioning of Data Structures}

일부 전통적인 동기화 메커니즘의 사용에 있어서의 주요 장애물은 정적으로 데이터
구조를 분할해야 한다는 필요성입니다.
가장 흔한 예로는 각 해쉬 체인이 하나의 조각이 되는 해쉬 테이블과 같은 쉽게
분할될 수 있는 데이터 구조도 여럿 있습니다.
각 해쉬 체인을 위한 락을 할당하는 것은 간단히 이 해쉬 테이블을 해당 체인으로
국한된 오퍼레이션에 대해 분할할 수 있습니다.\footnote{
	그리고 이 방법을 여러 해쉬 체인을 접근하는 오퍼레이션에 대해서는 연관된
	모든 락을 해쉬 순서로 획득하게 하는 식으로 쉽게 확장할 수 있습니다.}
분할하기는 비슷하게 배열, 래딕스 트리, 스킵리스트, 그리고 여러 다른 데이터
구조에 있어서도 간단합니다.

그러나, 여러 종류의 트리와 그래프에 있어 분할하기는 상당히 어려우며, 그
결과물은 종종 복잡합니다~\cite{Ellis80}.
일반적 데이터 구조를 분할하기 위해선
ㅅwo-phased 락킹과 락의 해슁된 배열을 사용하는게 가능하지만,
\cref{sec:future:HTM Weaknesses WRT Locking When Augmented} 에서 곧 논의할
것이지만 다른 기법이 선호된다는게
밝혀졌습니다~\cite{DavidSMiller2006HashedLocking}.
동기화 캐쉬 미스의 회피 덕에, HTM 은 거대한 분할 불가능한 데이터 구조에 대해
최소한 상대적으로 적은 업데이트를 상정하면 사용 가능성이 있습니다.

\iffalse

A major obstacle to the use of some conventional synchronization mechanisms
is the need to statically partition data structures.
There are a number of data structures that are trivially
partitionable, with the most prominent example being hash tables,
where each hash chain constitutes a partition.
Allocating a lock for each hash chain then trivially parallelizes
the hash table for operations confined to a given chain.\footnote{
	And it is also easy to extend this scheme to operations accessing
	multiple hash chains by having such operations acquire the
	locks for all relevant chains in hash order.}
Partitioning is similarly trivial for arrays, radix trees, skiplists, and
several other data structures.

However, partitioning for many types of trees and graphs is quite
difficult, and the results are often quite complex~\cite{Ellis80}.
Although it is possible to use two-phased locking and hashed arrays
of locks to partition general data structures, other techniques
have proven preferable~\cite{DavidSMiller2006HashedLocking},
as will be discussed in
\cref{sec:future:HTM Weaknesses WRT Locking When Augmented}.
Given its avoidance of synchronization cache misses,
HTM is therefore a very real possibility for large non-partitionable
data structures, at least assuming relatively small updates.

\fi

\QuickQuiz{
	HTM 의 성능과 확장성에 있어 상대적으로 적은 업데이트가 왜 중요한가요?

	\iffalse

	Why are relatively small updates important to HTM performance
	and scalability?

	\fi

}\QuickQuizAnswer{
	업데이트가 클수록, 충돌의 가능성이 커지며, 따라서 재시도의 가능성이
	높아지는데, 이는 성능을 떨어뜨립니다.

	\iffalse

	The larger the updates, the greater the probability of conflict,
	and thus the greater probability of retries, which degrade
	performance.

	\fi

}\QuickQuizEnd

\subsubsection{Practical Value}
\label{sec:future:Practical Value}

HTM 의 실용적 가치에 대한 일부 증거가 여러 하드웨어 플랫폼에서 선보였는데,
Sun Rock~\cite{DaveDice2009ASPLOSRockHTM},
Azul Vega~\cite{CliffClick2009AzulHTM},
IBM Blue Gene/Q~\cite{RickMerrit2011PowerTM},
Intel Haswell TSX~\cite{RaviRajwar2012TSX}, 그리고
IBM System z~\cite{ChristianJacobi2012MainframeTM} 이 포함됩니다.

예상되는 실용적 이득은 다음을 포함합니다:

\iffalse

Some evidence of HTM's practical value has been demonstrated in a number
of hardware platforms, including
Sun Rock~\cite{DaveDice2009ASPLOSRockHTM},
Azul Vega~\cite{CliffClick2009AzulHTM},
IBM Blue Gene/Q~\cite{RickMerrit2011PowerTM},
Intel Haswell TSX~\cite{RaviRajwar2012TSX}, and
IBM System z~\cite{ChristianJacobi2012MainframeTM}.

Expected practical benefits include:

\fi

\begin{enumerate}
\item	메모리 내 데이터 접근과 업데이트 시의 락
	제거~\cite{Martinez01a,Rajwar02a}.
\item	거대한 분할 불가한 데이터 구조로의 동시의 액세스와 작은 무작위
	업데이트.

\iffalse

\item	Lock elision for in-memory data access and
	update~\cite{Martinez01a,Rajwar02a}.
\item	Concurrent access and small random updates to large non-partitionable
	data structures.

\fi

\end{enumerate}

그러나, HTM 은 또한 매우 실제적인 단점을 갖는데, 다음 섹션에서 다룹니다.

\iffalse

However, HTM also has some very real shortcomings, which will be discussed
in the next section.

\fi

\subsection{HTM Weaknesses WRT Locking}
\label{sec:future:HTM Weaknesses WRT Locking}

HTM 의 컨셉은 상당히 간단합니다: 한 그룹의 액세스와 업데이트가 원자적으로
이루어집니다.
그러나, 많은 간단한 아이디어의 경우처럼, 실제 세계의 실제 시스템에 이를 적용할
때 복잡도가 나타납니다.
이 복잡도는 다음과 같습니다:

\iffalse

The concept of HTM is quite simple: A group of accesses and updates to
memory occurs atomically.
However, as is the case with many simple ideas, complications arise
when you apply it to real systems in the real world.
These complications are as follows:

\fi

\begin{enumerate}
\item	트랜잭션 크기 제한.
\item	충돌 처리.
\item	취소하기와 되돌리기.
\item	진행 보장의 부재.
\item	취소 불가한 오퍼레이션.
\item	의미상의 차이.

\iffalse

\item	Transaction-size limitations.
\item	Conflict handling.
\item	Aborts and rollbacks.
\item	Lack of forward-progress guarantees.
\item	Irrevocable operations.
\item	Semantic differences.

\fi

\end{enumerate}

이 복잡성 각각이 다음 섹션에서 다루어지며, 그 뒤에 요약이 나옵니다.

\iffalse

Each of these complications is covered in the following sections,
followed by a summary.

\fi

\subsubsection{Transaction-Size Limitations}
\label{sec:future:Transaction-Size Limitations}

현재 HTM 구현의 트랜잭션 크기 제한은 트랜잭션에 의해 영향받는 데이터를 프로세서
캐쉬에 둔다는 점에서 기인합니다.
이게 특정 CPU 가 트랜잭션을 자신의 캐쉬에 국한시켜서 수행함으로써 이를
원자적으로 행하는 것으로 다른 CPU 에게 보이게 하지만, 이는 또한 여기 들어맞지
않는 트랜잭션은 커밋될 수 없음을 의미합니다.
더 나아가, 인터럽트, 시스템콜, 예외, 트랩, 그리고 컨텍스트 스위치 같은 수행
컨텍스트를 바꾸는 이벤트는 해당 CPU 의 진행중인 트랜잭션을 취소시키거나 이 다른
수행 문맥의 캐쉬 사용량으로 인해 트랜잭션 크기를 더 제한해야 합니다.

\iffalse

The transaction-size limitations of current HTM implementations
stem from the use of the processor caches to hold the data
affected by the transaction.
Although this allows a given CPU to make the transaction appear atomic to
other CPUs by executing the transaction within the confines of its cache,
it also means that any transaction that does not fit cannot commit.
Furthermore, events that change execution context, such as interrupts,
system calls, exceptions, traps, and context switches either must
abort any ongoing transaction on the CPU in question or must further
restrict transaction size due to the cache footprint of the other
execution context.

\fi

물론, 현대의 CPU 는 큰 캐쉬를 갖는 경향을 보이며, 많은 트랜잭션에 필요한
데이터는 쉽게 1 메가바이트 캐쉬에 담길 겁니다.
불행히도, 캐쉬에 있어 작은 크기가 전부는 아닙니다.
문제는 대부분의 캐쉬는 하드웨어로 구현된 해쉬 테이블로 생각될 수 있습니다.
그러나, 하드웨어 캐쉬는 버킷을 (일반적으로 \emph{set} 이라 불립니다) 연결시키지
않고, 고정된 수의 set 별 캐쉬라인을 제공합니다.
각 set 에 의해 제공된 원소의 갯수를 해당 캐쉬의 \emph{associativity} 라
불립니다.

\iffalse

Of course, modern CPUs tend to have large caches, and the data required
for many transactions would fit easily in a one-megabyte cache.
Unfortunately, with caches, sheer size is not all that matters.
The problem is that most caches
can be thought of hash tables implemented in hardware.
However, hardware caches do not chain their buckets (which are normally
called \emph{sets}), but rather
provide a fixed number of cachelines per set.
The number of elements provided for each set in a given cache
is termed that cache's \emph{associativity}.

\fi

캐쉬 associativity 는 다양하지만, 제가 이를 타이핑 하는 랩탑에 있는 8-way
associativity 레벨 0 캐쉬는 드물지 않습니다.
이게 의미하는 바는 특정 트랜잭션이 아홉개의 캐쉬 라인을 건드려야 하며 그
아홉개의 캐쉬 라인이 모두 같은 set 으로 매핑된다면 해당 캐쉬에 얼마나 많은
추가적 공간이 존재하는가와 관계없이 이 트랜잭션은 결코 완료될 수 없다는 겁니다.
그렇습니다, 특정 데이터 구조에서 데이터 원소가 무작위적으로 선택된다면 그
트랜잭션이 커밋될 가능성은 상당히 높습니다, 그러나 보장은
없습니다~\cite{PaulEMcKenney2012HTMCacheGeometry}.

\iffalse

Although cache associativity varies, the eight-way associativity of
the level-0 cache on the laptop I am typing this on is not unusual.
What this means is that if a given transaction needed to touch
nine cache lines, and if all nine cache lines mapped to the same
set, then that transaction cannot possibly complete, never mind how
many megabytes of additional space might be available in that cache.
Yes, given randomly selected data elements in a given data structure,
the probability of that transaction being able to commit is quite
high, but there can be no guarantee~\cite{PaulEMcKenney2012HTMCacheGeometry}.

\fi

이 제한을 완화시키려는 일부 연구가 있었습니다.
완전한 associativity 의 \emph{victim cache} 는 이 ssociativity 제한을 완화시킬
테지만, victim 캐쉬의 크기에 대한 까다로운 성능과 에너지 효율 제한이 있습니다.
그렇다고 하나, 수정되지 않은 캐쉬 라인을 위한 HTM victim 캐쉬는 상당히 작을 수
있는데, 주소만 가지면 되기 때문입니다:
데이터 자체는 메모리에 저장되거나 다른 캐쉬에 의해 따라갈 수 있으며, 주소
자체만으로도 쓰기와의 충돌을 탐지하기 충분합니다~\cite{RaviRajwar2012TSX}.

\iffalse

There has been some research work to alleviate this limitation.
Fully associative \emph{victim caches} would alleviate the associativity
constraints, but there are currently stringent performance and
energy-efficiency constraints on the sizes of victim caches.
That said, HTM victim caches for unmodified cache lines can be quite
small, as they need to retain only the address:
The data itself can be written to memory or shadowed by other caches,
while the address itself is sufficient to detect a conflicting
write~\cite{RaviRajwar2012TSX}.

\fi

\emph{Unbounded transactional memory} (UTM)
방법은~\cite{CScottAnanian2006,KevinEMoore2006}
DRAM 을 극단적으로 큰 victim 캐쉬로 사용합니다만, 그런 방법을 제품 품질의 캐쉬
일관성 메커니즘과 결합하는 것은 여전히 해결되지 않은 문제입니다.
또한, DRAM 을 victim 캐쉬로 사용하는 것은 불행한 성능과 에너지 효율성 결론을
가질 수 있으며, 특히 victim 캐쉬가 완전한 ssociativity 를 갖는다면 그렇습니다.
마지막으로, ``unbounded'' 라는 UTM 의 속성은 모든 DRAM 이 victim 캐쉬로 사용될
수 있음을 가정하는데, 실제로는 크지만 여전히 고정된 양의 DRAM 이 특정 CPU 에
할당되므로 해당 CPU 의 트랜잭션의 크기는 제한될 겁니다.
다른 방법들은 하드웨어와 소프트웨어 트랜잭션 메모리의 결합을
사용하며~\cite{SanjeevKumar2006} 여기서 STM 은 HTM 의 fallback 메커니즘으로
생각될 수 있습니다.

그러나, 제가 알기로는 TM 읽기 집합의 표현의 간략화라는 예외가 있지만 현재 사용
가능한 시스템들은 이런 연구 아이디어들을 구현하지 않았는데, 아마도 좋은 이유가
있었을 겁니다.

\iffalse

\emph{Unbounded transactional memory} (UTM)
schemes~\cite{CScottAnanian2006,KevinEMoore2006}
use DRAM as an extremely large victim cache, but integrating such schemes
into a production-quality cache-coherence mechanism is still an unsolved
problem.
In addition, use of DRAM as a victim cache may have unfortunate
performance and energy-efficiency consequences, particularly
if the victim cache is to be fully associative.
Finally, the ``unbounded'' aspect of UTM assumes that all of DRAM
could be used as a victim cache, while in reality
the large but still fixed amount of DRAM assigned to a given CPU
would limit the size of that CPU's transactions.
Other schemes use a combination of hardware and software transactional
memory~\cite{SanjeevKumar2006} and one could imagine using STM as a
fallback mechanism for HTM\@.

However, to the best of my knowledge, with the exception of abbreviating
representation of TM read sets, currently available systems do not
implement any of these research ideas, and perhaps for good reason.

\fi

\subsubsection{Conflict Handling}
\label{sec:future:Conflict Handling}

첫번째 복잡성은 \emph{충돌} 가능성입니다.
예를 들어, 트랜잭션~A 와~B 가 다음과 같이 정의되었다고 해봅시다.

\iffalse

The first complication is the possibility of \emph{conflicts}.
For example, suppose that transactions~A and~B are defined as follows:

\fi

\begin{VerbatimU}
Transaction A       Transaction B

x = 1;              y = 2;
y = 3;              x = 4;
\end{VerbatimU}

각 트랜잭션이 각자의 프로세서에서 동시에 수행된다고 해봅시다.
트랜잭션~A \co{x} 로의 스토어를 트랜잭션~B 의 \co{y} 스토어와 동시에 행하면,
어떤 트랜잭션도 진행될 수 없습니다.
이를 자세히 보기 위해, 트랜잭션~A 가 \co{y} 로의 스토어를 하는걸 봅시다.
그럼 트랜잭션~A 는 트랜잭션~B 와 엮이게 되어, 각자에 대해 트랜잭션에 원자적으로
수행되어야 한다는 요구사항을 어기게 됩니다.
트랜잭션~B 가 \co{x} 로의 스토어를 하게 하는 것 역시 비슷하게 원자적 수행
요구사항을 어기게 합니다.
이 상황은 \emph{충돌 (conflict)} 라 명명되었는데, 두 동시의 트랜잭션이 같은
변수에 액세스 하며 그 액세스 중 최소 하나는 스토어일 때 발생합니다.
따라서 이 시스템은 수행이 진행될 수 있게 하기 위해 트랜잭션 중 하나 또는 둘
다를 중지시켜야 합니다.
어떤 트랜잭션을 중지시킬지의 선택은 박사 학위논문을 만들기 충분할 만큼의 능력을
얻게 할만큼 흥미로운 주제일텐데 그런 예도
있습니다~\cite{EgeAkpinar2011HTM2TLE}.\footnote{
	Liu 와 Spear 의 ``Toxic
	Transactions''~\cite{YujieLiu2011ToxicTransactions} 는 특히
	교훈적입니다.}
이 섹션의 목표에 집중하기 위해, 우린 시스템이 무작위적 선택을 한다고 가정할 수
있습니다.

\iffalse

Suppose that each transaction executes concurrently on its own processor.
If transaction~A stores to \co{x} at the same time that transaction~B
stores to \co{y}, neither transaction can progress.
To see this, suppose that transaction~A executes its store to \co{y}.
Then transaction~A will be interleaved within transaction~B, in violation
of the requirement that transactions execute atomically with respect to
each other.
Allowing transaction~B to execute its store to \co{x} similarly violates
the atomic-execution requirement.
This situation is termed a \emph{conflict}, which happens whenever two
concurrent transactions access the same variable where at least one of
the accesses is a store.
The system is therefore obligated to abort one or both of the transactions
in order to allow execution to progress.
The choice of exactly which transaction to abort is an interesting topic
that will very likely retain the ability to generate Ph.D. dissertations for
some time to come, see for
example~\cite{EgeAkpinar2011HTM2TLE}.\footnote{
	Liu's and Spear's paper entitled ``Toxic
	Transactions''~\cite{YujieLiu2011ToxicTransactions} is
	particularly instructive.}
For the purposes of this section, we can assume that the system makes
a random choice.

\fi

또다른 복잡성은 충돌 탐지로, 최소한 가장 간단한 경우에는 비교적 간단합니다.
프로세서는 트랜잭션을 수행할 때 이 트랜잭션에 의해 만져진 모든 캐쉬라인을
표시합니다.
만약 이 프로세서의 캐쉬가 현재 트랜잭션에 의해 접촉된 것으로 표시된 캐쉬 라인에
연관된 요청을 받는다면, 잠재적 충돌이 일어난 겁니다.
더 정교한 시스템은 현재 프로세서의 트랜잭션이 그 요청을 보낸 프로세서의 것보다
앞서 수행되도록 노력할 것이고, 이 과정을 최적화 하는 것은 역시나 박사
학위논문을 만들 능력을 얻을 수 있게 할 겁니다.
그러나 이 섹션은 매우 간단한 충돌 탐지 전략을 가정합니다.

\iffalse

Another complication is conflict detection, which is comparatively
straightforward, at least in the simplest case.
When a processor is executing a transaction, it marks every cache line
touched by that transaction.
If the processor's cache receives a request involving a cache line that
has been marked as touched by the current transaction, a potential
conflict has occurred.
More sophisticated systems might try to order the current processors'
transaction to precede that of the processor sending the request, and
optimizing this process will likely also retain the ability to generate
Ph.D. dissertations for quite some time.
However this section assumes a very simple conflict-detection strategy.

\fi

그러나, HTM 이 효과적으로 동작하기 위해선 충돌의 가능성이 상당히 낮아야 하는데,
이는 결국 데이터 구조가 충분히 낮은 충돌 확률을 유지하게끔 짜여져야 할 것을
필요로 합니다.
예를 들어, 간단한 삽입, 삭제, 그리고 탐색을 하는 red-black 트리는 이 경우에
들어맞습니다만, 트리의 원소들의 정확한 수를 유지하는 red-black 트리는 그렇지
않습니다.\footnote{
	이 카운트를 업데이트 해야 한다는 필요성이 트리에의 삽입과 삭제가 서로
	충돌하게 만들어, 강력한 non-commutativity 를
	초래합니다~\cite{HagitAttiya2011LawsOfOrder,Attiya:2011:LOE:1925844.1926442,PaulEMcKenney2011SNC}.}
또다른 예로, 하나의 트랜잭션 내에서 트리의 모든 원소를 접근하는 red-black
트리는 높은 충돌 가능성을 가져서 성능과 확장성을 떨어뜨립니다.
그 결과, 많은 순차적 프로그램들은 HTM 이 효과적으로 동작하기 전에 일부 재구축을
필요로 할 겁니다.
어떤 경우에는, 실무자들은 추가적 단계들을 취하고 (red-black 트리의 경우, radix
트리나 해쉬 테이블 같은 분할 가능한 데이터 구조로의 변경 같은) 간단히 락킹을
하는걸 선호할 텐데, 특히 HTM 이 모든 관련 아키텍쳐에서 사용될 준비가 될
때까지는 그럴 겁니다~\cite{CliffClick2009AzulHTM}.

\iffalse

However, for HTM to work effectively, the probability of conflict must
be quite low, which in turn requires that the data structures
be organized so as to maintain a sufficiently low probability of conflict.
For example, a red-black tree with simple insertion, deletion, and search
operations fits this description, but a red-black
tree that maintains an accurate count of the number of elements in
the tree does not.\footnote{
	The need to update the count would result in additions to and
	deletions from the tree conflicting with each other, resulting
	in strong non-commutativity~\cite{HagitAttiya2011LawsOfOrder,Attiya:2011:LOE:1925844.1926442,PaulEMcKenney2011SNC}.}
For another example, a red-black tree that enumerates all elements in
the tree in a single transaction will have high conflict probabilities,
degrading performance and scalability.
As a result, many serial programs will require some restructuring before
HTM can work effectively.
In some cases, practitioners will prefer to take the extra steps
(in the red-black-tree case, perhaps switching to a partitionable
data structure such as a radix tree or a hash table), and just
use locking, particularly until such time as HTM is readily available
on all relevant
architectures~\cite{CliffClick2009AzulHTM}.

\fi

\QuickQuiz{
	동기화 메커니즘의 선택에 관계 없이 red-black 트리가 어떻게 모든 원소를
	효율적으로 접근할 수 있죠???

	\iffalse

	How could a red-black tree possibly efficiently enumerate all
	elements of the tree regardless of choice of synchronization
	mechanism???

	\fi

}\QuickQuizAnswer{
	많은 경우, 그 접근은 정확할 필요가 없습니다.
	이 경우, 읽기 쓰레드를 보호하기 위해 어떤 삽입이나 삭제와도 낮은 충돌
	확률을 제공하는 해저드 포인터나 RCU 를 사용할 수 있을 겁니다.

	\iffalse

	In many cases, the enumeration need not be exact.
	In these cases, hazard pointers or RCU may be used to protect
	readers, which provides low probability of conflict with any
	given insertion or deletion.

	\fi

}\QuickQuizEnd

더 나아가, 동시의 트랜잭션 사이에서의 충돌하는 액세스의 가능성이 실패를 초래할
수 있습니다.
그런 실패를 처리하는 것에 대해 다음 섹션에서 다룹니다.

\iffalse

Furthermore, the potential for conflicting accesses among concurrent
transactions can result in failure.
Handling such failure is discussed in the next section.

\fi

\subsubsection{Aborts and Rollbacks}
\label{sec:future:Aborts and Rollbacks}

어떤 트랜잭션이든 언제든 중단될 수도 있으므로, 트랜잭션이 취소될 수 없는 문장을
포함하지 않는게 중요합니다.
이는 트랜잭션은 I/O, 시스템콜, 또는 디버깅 브레이크포인트를 수행할 수 없음을
(HTM 트랜잭션을 위한 단계별 디버거가 없습니다!!!) 의미합니다.
대신, 트랜잭션은 스스로를 평범한 캐쉬된 메모리에의 접근으로 국한시켜야 합니다.
더 나아가, 일부 시스템에서는 인터럽트, 예외, 트랩, TLB 미스, 그리고 다른
이벤트들도 트랜잭션을 중단시킬 겁니다.
오류 조건에 대한 적절치 않은 처리로 초래된 수많은 버그를 생각해 보면, 중단과
되돌림이 사용성에 어떤 영향을 주는지 묻는게 공정합니다.

\iffalse

Because any transaction might be aborted at any time, it is important
that transactions contain no statements that cannot be rolled back.
This means that transactions cannot do I/O, system calls, or debugging
breakpoints (no single stepping in the debugger for HTM transactions!!!).
Instead, transactions must confine themselves to accessing normal
cached memory.
Furthermore, on some systems, interrupts, exceptions, traps,
TLB misses, and other events will also abort transactions.
Given the number of bugs that have resulted from improper handling
of error conditions, it is fair to ask what impact aborts and rollbacks
have on ease of use.

\fi

\QuickQuiz{
	하지만 디버거가 트랜잭션의 성공한 라인에 브레이크포인트를 설정하고 앞의
	트랜잭션 수행의 단계를 다시 추적하길 재시도하는 방법으로 단계별 수행을
	에뮬레이션하는 건 왜 안되죠?

	\iffalse

	But why can't a debugger emulate single stepping by setting
	breakpoints at successive lines of the transaction, relying
	on the retry to retrace the steps of the earlier instances
	of the transaction?

	\fi

}\QuickQuizAnswer{
	이 방법은 높은 확률로 동작할 수도 있습니다만, 많은 사용자들에게 무척
	놀라운 방식으로 실패할 수 있습니다.
	이를 자세히 보기 위해, 다음트랜잭션을 생각해 봅시다:

	\iffalse

	This scheme might work with reasonably high probability, but it
	can fail in ways that would be quite surprising to most users.
	To see this, consider the following transaction:

	\fi

\begin{fcvlabel}[ln:future:htm:debug rollbacks]
\begin{VerbatimN}[commandchars=\\\[\]]
begin_trans();
if (a) {
	do_one_thing();
	do_another_thing();	\lnlbl[another]
} else {
	do_a_third_thing();
	do_a_fourth_thing();
}
end_trans();
\end{VerbatimN}
\end{fcvlabel}

	\begin{fcvref}[ln:future:htm:debug rollbacks]
	사용자가 \clnref{another} 에 걸리면 트랜잭션을 중단시키고 디버거에
	진입할 브레이크포인트를 설정했다고 해봅시다.
	\end{fcvref}
	브레이크포인트가 걸린 시각과 디버거가 모든 쓰레드를 중단시키는 시각
	사이에 어떤 다른 쓰레드가 \co{a} 의 값을 0 으로 설정합니다.
	불쌍한 사용자가 이 프로그램을 한단계 더 움직이려 하면, 놀랍게도!
	이 프로그램은 이제 then-절이 아니라 else-절을 수행합니다.

	이는 제가 사용하기 쉬운 디버거라 부르는 게 \emph{아닙니다}.

	\iffalse

	\begin{fcvref}[ln:future:htm:debug rollbacks]
	Suppose that the user sets a breakpoint at \clnref{another},
	which triggers,
	aborting the transaction and entering the debugger.
	\end{fcvref}
	Suppose that between the time that the breakpoint triggers
	and the debugger gets around to stopping all the threads, some
	other thread sets the value of \co{a} to zero.
	When the poor user attempts to single-step the program, surprise!
	The program is now in the else-clause instead of the then-clause.

	This is \emph{not} what I call an easy-to-use debugger.

	\fi

}\QuickQuizEnd

물론, 중단과 되돌리기는 HTM 이 하드 리얼타임 시스템에서 유용할지 질문하게
합니다.
HTM 의 성능 이익은 중단과 되돌리기의 비용을 넘어서며, 그렇다면 어떤 조건에서
그럴까요?
트랜잭션은 우선순위 높이기를 할 수 있을까요?
또는 높은 우선순위 쓰레드를 위한 트랜잭션은 낮은 우선순위 쓰레드를 중단시켜야
할까요?
만약 그렇다면, 하드웨어는 어떻게 효율적으로 우선순위를 전달받나요?
HTM 의 리얼타임에서의 사용에 대한 글들은 상당히 적은데, 아마도 HTM 을 비
리얼타임 환경에서 잘동작하게 만드는데도 충분한 정도를 넘어서는 문제들이
산적했기 때문일 겁니다.

\iffalse

Of course, aborts and rollbacks raise the question of whether HTM can
be useful for hard real-time systems.
Do the performance benefits of HTM outweigh the costs of the aborts
and rollbacks, and if so under what conditions?
Can transactions use priority boosting?
Or should transactions for high-priority threads instead preferentially
abort those of low-priority threads?
If so, how is the hardware efficiently informed of priorities?
The literature on real-time use of HTM is quite sparse, perhaps
because there are more than enough problems in making HTM work well in
non-real-time environments.

\fi

현재의 HTM 구현은 결정론적으로 특정 트랜잭션을 중단시키므로, 소프트웨어는
fallback 코드를 제공해야만 합니다.
이 fallback 코드는 예를 들어 락킹 같은 다른 형태의 동기화를 사용해야만 합니다.
락 기반 fallback 이 사용된다면, 데드락의 가능성을 포함한 모든 락킹의 한계들이
다시 나타납니다.
물론 이 fallback 이 자주 사용되지 않길 바랄 수 있겠는데, 그럼 더 간단하고 덜
데드락에 취약한 락킹 설계가 사용될 수 있을 겁니다.
그러나 이는 시스템이 어떻게 락 기반 fallback 사용에서 트랜잭션으로 전환하는지
질문을 일으킵니다.\footnote{
	Fallback 모드에서 멈춰있는 어플리케이션의 가능성은 ``lemming effect''
	라 명명되었습니다.}
한가지 방법은 test-and-test-and-set 방법~\cite{Martinez02a} 으로, 락이 해제되기
전까지는 모두가 뒤로 물러서서 시스템이 트랜잭션 모드의 깔끔한 상태에서 시작할
수 있게 하는 겁니다.
그러나, 이는 상당한 스피닝을 초래할 수 있는데, 락을 쥔 쓰레드가 블록되거나
preemption 당한다면 현명하지 않은 선택일 수도 있습니다.
또다른 방법은 락을 쥔 쓰레드와 병렬로 트랜잭션이 진행될 수 있게 하는
것인데~\cite{Martinez02a}, 이는 원자성 유지에 어려움을 자아내며, 이 쓰레드가
락을 쥐는 이유가 연관된 트랜잭션이 캐쉬 크기에 맞지 않기 때문이라면 특히
그렇습니다.

\iffalse

Because current HTM implementations might deterministically abort a
given transaction, software must provide fallback code.
This fallback code must use some other form of synchronization, for
example, locking.
If a lock-based fallback is ever used, then all the limitations of locking,
including the possibility of deadlock, reappear.
One can of course hope that the fallback isn't used often, which might
allow simpler and less deadlock-prone locking designs to be used.
But this raises the question of how the system transitions from using
the lock-based fallbacks back to transactions.\footnote{
	The possibility of an application getting stuck in fallback
	mode has been termed the ``lemming effect'', a term that
	Dave Dice has been credited with coining.}
One approach is to use a test-and-test-and-set discipline~\cite{Martinez02a},
so that everyone holds off until the lock is released, allowing the
system to start from a clean slate in transactional mode at that point.
However, this could result in quite a bit of spinning, which might not
be wise if the lock holder has blocked or been preempted.
Another approach is to allow transactions to proceed in parallel with
a thread holding a lock~\cite{Martinez02a}, but this raises difficulties
in maintaining atomicity, especially if the reason that the thread is
holding the lock is because the corresponding transaction would not fit
into cache.

\fi

마지막으로, 중단과 되돌리기의 가능성을 처리하는 것은 가능한 오류 조건을 모두
올바르게 처리해야하는 개발자에게 추가적 짐을 지우는 것으로 보입니다.

HTM 사용자들은 fallback 코드 경로와 fallback 코드에서 트랜잭션 사용 코드로의
전환 두 경우에 상당한 검증 노력을 들여야 함이 분명합니다.
HTM 하드웨어의 검증 요구사항이 덜 힘들 거라 믿을 이유 또한 없습니다.

\iffalse

Finally, dealing with the possibility of aborts and rollbacks seems to
put an additional burden on the developer, who must correctly handle
all combinations of possible error conditions.

It is clear that users of HTM must put considerable validation effort
into testing both the fallback code paths and transition from fallback
code back to transactional code.
Nor is there any reason to believe that the validation requirements of
HTM hardware are any less daunting.

\fi

\subsubsection{Lack of Forward-Progress Guarantees}
\label{sec:future:Lack of Forward-Progress Guarantees}

트랜잭션 크기, 충돌, 그리고 중단/되돌리기가 모두 트랜잭션들을 중단되게 할 수
있지만, 누군가는 충분히 작고 짧은 트랜잭션은 결국 성공할 것이 보장될 것을
희망할 수도 있겠습니다.
이는 어토믹 오퍼레이션을 구현하기 위해 이 명령을 사용하는 코드가
compare-and-swap (CAS) 와 load-linked/store-conditional (LL/SC) 오퍼레이션을
무조건적으로 재시도 하듯 트랜잭션이 무조건적으로 재시도 되는 것을 허용할
겁니다.

불행히도, low-clock-rate 학술 연구
프로토타입~\cite{MartinSchoeberl2010realtimeTM} 외에는 현재 사용 가능한 HTM
구현들은 어떤 종류의 진행 보장도 하지 않습니다.
앞서 언급되었듯, 따라서 HTM 은 시스템의 데드락을 막는데 사용될 수 없습니다.
희망컨대 미래의 HTM 구현은 어떤 종류의 진행 보장을 제공할 겁니다.
그 전까지는, HTM 은 리얼타임 어플리케이션에서 상당한 주의와 함께 사용되어야 할
겁니다.

\iffalse

Even though transaction size, conflicts, and aborts/rollbacks can all
cause transactions to abort, one might hope that sufficiently small and
short-duration transactions could be guaranteed to eventually succeed.
This would permit a transaction to be unconditionally retried, in the
same way that compare-and-swap (CAS) and load-linked/store-conditional
(LL/SC) operations are unconditionally retried in code that uses these
instructions to implement atomic operations.

Unfortunately, other than low-clock-rate academic research
prototypes~\cite{MartinSchoeberl2010realtimeTM},
currently available HTM implementations refuse to make any
sort of forward-progress guarantee.
As noted earlier, HTM therefore cannot be used to avoid deadlock on
those systems.
Hopefully future implementations of HTM will provide some sort of
forward-progress guarantees.
Until that time, HTM must be used with extreme caution in real-time
applications.

\fi

2021년 기준으로 이 암울한 그림에서의 한가지 예외는 \emph{제한된
트랜잭션}~\cite{ChristianJacobi2012MainframeTM} 을 제공하는 IBM
메인프레임입니다.
이 제약은 상당히 강력하며
\cref{sec:future:Forward-Progress Guarantees} 에 보여져 있습니다.
HTM 진행 보장이 메인프레임에서 일반 CPU 제품군까지 퍼질 것인지 보는 것도
흥미롭겠습니다.

\iffalse

The one exception to this gloomy picture as of 2021 is
the IBM mainframe, which provides
\emph{constrained transactions}~\cite{ChristianJacobi2012MainframeTM}.
The constraints are quite severe, and are presented in
\cref{sec:future:Forward-Progress Guarantees}.
It will be interesting to see if HTM forward-progress guarantees migrate
from the mainframe to commodity CPU families.

\fi

\subsubsection{Irrevocable Operations}
\label{sec:future:Irrevocable Operations}

중단과 되돌리기의 또다른 결말은 HTM 트랜잭션은 되돌릴 수 없는 오퍼레이션을
수용할 수 없다는 겁니다.
현재의 HTM 구현은 일반적으로 트랜잭션 내의 모든 액세스가 캐쉬될 수 있는
메모리로의 것일 것으로 (따라서 MMIO 액세스를 금지합니다) 제한하고 인터럽트,
트랩, 그리고 예외의 경우 트랜잭션을 중단시킵니다 (따라서 시스템콜을
금지합니다).

Buffered I/O 는 해당 버퍼 채우기/비우기 오퍼레이션이 트랜잭션 외에서 일어나는
경우 HTM 트랜잭션에 들어갈 수 있음을 알아두시기 바랍니다.
이게 가능한 이유는 데이터를 버퍼에 더하고 제거하는 건 되돌릴 수 있기
때문입니다: 실제 버퍼 채우기/비우기 오퍼레이션만이 취소 불가합니다.
물론, 이 buffered-I/O 방법은 이 I/O 를 트랜잭션의 크기에 포함시켜서 트랜잭션의
크기를 키우고 실패의 가능성을 높이는 효과를 일으킵니다.

\iffalse

Another consequence of aborts and rollbacks is that HTM transactions
cannot accommodate irrevocable operations.
Current HTM implementations typically enforce this limitation by
requiring that all of the accesses in the transaction be to cacheable
memory (thus prohibiting MMIO accesses) and aborting transactions on
interrupts, traps, and exceptions (thus prohibiting system calls).

Note that buffered I/O can be accommodated by HTM transactions as
long as the buffer fill/flush operations occur extra-transactionally.
The reason that this works is that adding data to and removing data
from the buffer is revocable: Only the actual buffer fill/flush
operations are irrevocable.
Of course, this buffered-I/O approach has the effect of including the I/O
in the transaction's footprint, increasing the size of the transaction
and thus increasing the probability of failure.

\fi

\subsubsection{Semantic Differences}
\label{sec:future:Semantic Differences}

HTM 이 많은 경우에 락킹의 즉시 대체제로 사용될 수 있지만 (따라서 Transactional
lock elision~\cite{DaveDice2008TransactLockElision} 이라는 명칭이 나왔습니다),
그 의미에는 작은 차이들이 있습니다.
트랜잭션으로 수행될 때 데드락이나 라이브락을 초래할 수 있는 조합된 락 기반
크리티컬 섹션을 포함시키는 특히 나쁜 예가
Blundell~\cite{Blundell2006TMdeadlock} 에 의해 알려졌습니다만, 훨씬 간단한 예는
텅빈 크리티컬 섹션입니다.

락 기반 프로그램에서, 텅 빈 크리티컬 섹션은 이 락을 잡았던 앞선 프로세스들이
이제 이를 해제했음을 보장합니다.
이 용법은 2.4 리눅스 커널의 네트워킹 스택에서 구성 변경을 처리하기 위해
사용되었습니다.
그러나 이 텅 빈 크리티컬 섹션이 트랜잭션으로 변환된다면, 그 결과는 no-op
입니다.
달리 말하자면, transactional lock elision 은 락킹의 데이터 보호 의미를
유지하나, 락킹의 시간 기반 메세징 의미는 잃습니다.

\iffalse

Although HTM can in many cases be used as a drop-in replacement for locking
(hence the name transactional lock
elision~\cite{DaveDice2008TransactLockElision}),
there are subtle differences in semantics.
A particularly nasty example involving coordinated lock-based critical
sections that results in deadlock or livelock when executed transactionally
was given by Blundell~\cite{Blundell2006TMdeadlock}, but a much simpler
example is the empty critical section.

In a lock-based program, an empty critical section will guarantee
that all processes that had previously been holding that lock have
now released it.
This idiom was used by the 2.4 Linux kernel's networking stack to
coordinate changes in configuration.
But if this empty critical section is translated to a transaction,
the result is a no-op.
The guarantee that all prior critical sections have terminated is
lost.
In other words, transactional lock elision preserves the data-protection
semantics of locking, but loses locking's time-based messaging semantics.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	하지만 \emph{누가} 빈 락 기반 크리티컬 섹션을 필요로 합니까???

	\iffalse

	But why would \emph{anyone} need an empty lock-based critical
	section???

	\fi

}\QuickQuizAnswerB{
	\Cref{sec:locking:Exclusive Locks} 의
	\QuickQuizARef{\QlockingQemptycriticalsection} 의 답을 보시기 바랍니다.

	그러나 진행 보장이 없이 강력한 원자성을 제공하는 HTM 구현 때문에 빈
	크리티컬 섹션에 기반한 모든 메모리 기반 락킹 설계는 transactional lock
	elision 의 존재에도 올바르게 동작할 거라는 주장이 있습니다.
	저는 이 말의 증명을 보지 못했지만, 이 주장에는 단순한 이유가 있습니다.
	요점은 강력하게 원자적인 HTM 구현에서, 특정 트랜잭션의 결과는 이
	트랜잭션이 성공적으로 완료되기 전까지는 보이지 않는다는 겁니다.
	따라서, 여러분이 어떤 트랜잭션이 시작된 걸 본다면, 이는 이미
	완료되었음이 보장되어서 뒤따르는 빈 락 기반 크리티컬 섹션은 그걸
	``기다린다'' 는 겁니다---어쨌건, 기다림이 필요치 않으니까요.

	\iffalse

	See the answer to \QuickQuizARef{\QlockingQemptycriticalsection} in
	\cref{sec:locking:Exclusive Locks}.

	However, it is claimed that given a strongly atomic HTM
	implementation without forward-progress guarantees, any
	memory-based locking design based on empty critical sections
	will operate correctly in the presence of transactional
	lock elision.
	Although I have not seen a proof of this statement, there
	is a straightforward rationale for this claim.
	The main idea is that in a strongly atomic HTM implementation,
	the results of a given transaction are not visible until
	after the transaction completes successfully.
	Therefore, if you can see that a transaction has started,
	it is guaranteed to have already completed, which means
	that a subsequent empty lock-based critical section will
	successfully ``wait'' on it---after all, there is no waiting
	required.

	\fi

	이 근거는 완화된 원자적 시스템에서는 (많은 STM 구현이 포함됩니다)
	성립되지 않으며, 통신에 메모리 이외의 수단을 사용하는 락 기반
	프로그램에도 적용되지 않습니다.
	그런 방법들에는 시간의 흐름 (예를 들어, 하드 리얼타임 시스템) 이나
	우선순위의 흐름이 (예를 들어, 소프트 리얼타임 시스템) 있습니다.

	우선순위 높이기에 기반하는 락킹 설계는 특히 흥미로울 겁니다.

	\iffalse

	This line of reasoning does not apply to weakly atomic
	systems (including many STM implementation), and it also
	does not apply to lock-based programs that use means other
	than memory to communicate.
	One such means is the passage of time (for example, in
	hard real-time systems) or flow of priority (for example,
	in soft real-time systems).

	Locking designs that rely on priority boosting are of particular
	interest.

	\fi

}\QuickQuizEndB
%
\QuickQuizM{
	Transactional lock elision 은 간단히 빈 락 기반 크리티컬 섹션을
	제거하지 않음으로써 락킹의 시간 기반 메세징 의미를 다룰 수 있지
	않을까요?

	\iffalse

	Can't transactional lock elision trivially handle locking's
	time-based messaging semantics
	by simply choosing not to elide empty lock-based critical sections?

	\fi

}\QuickQuizAnswerM{
	그럴 수 있겠습니다만, 이는 불필요하고 불충분할 겁니다.

	이 텅빈 크리티컬 섹션이 조건적 컴파일 때문이었다면 이는 불필요합니다.
	이 락의 목표는 데이터 보호 뿐이었다면 이를 완전히 제거하는게 올바른
	일일 겁니다.
	실제로, 빈 락 기반 크리티컬 섹션을 놔두는 건 성능과 확장성을 떨어뜨릴
	겁니다.

	다른 한편, 비지 않은 락 기반 크리티컬 섹션이 락킹의 데이터 보호와 시간
	기반  메세징 의미에 의존하는 게 가능합니다.
	그런 경우에 transactional lock elision 을 사용하는 것은 올바르지 않으며
	버그를 초래할 겁니다.

	\iffalse

	It could do so, but this would be both unnecessary and
	insufficient.

	It would be unnecessary in cases where the empty critical section
	was due to conditional compilation.
	Here, it might well be that the only purpose of the lock was to
	protect data, so eliding it completely would be the right thing
	to do.
	In fact, leaving the empty lock-based critical section would
	degrade performance and scalability.

	On the other hand, it is possible for a non-empty lock-based
	critical section to be relying on both the data-protection
	and time-based messaging semantics of locking.
	Using transactional lock elision in such a case would be
	incorrect, and would result in bugs.

	\fi

}\QuickQuizEndM
%
\QuickQuizE{
	현대의 하드웨어에서~\cite{PeterOkech2009InherentRandomness} 어떻게
	시간에 기반한 병렬 소프트웨어가 동작할 거라 생각될 수 있습니까?

	\iffalse

	Given modern hardware~\cite{PeterOkech2009InherentRandomness},
	how can anyone possibly expect parallel software relying
	on timing to work?

	\fi

}\QuickQuizAnswerE{
	짧게 답하자면 일반적인 공간의 일반적 하드웨어에서는 모든 세밀한
	타이밍에 기반한 동기화 설계는 무모하며 모든 상황에서 올바르게
	동작할거라 예상될 수 없다는 겁니다.

	그렇다고는 하나, 훨씬 결정론적인 하드 리얼타임에서의 사용을 위해 설계된
	시스템이 있습니다.
	그런 시스템을 사용하는 (매우 드물) 경우, 어떻게 시간 기반 동기화가
	동작할 수 있는지 보이는 작은 예가 있습니다.
	다시 말하지만, 일반적 마이크로프로세서에서는 상당히 비결정적인 성능
	특성이 있으므로 이를 시도하지 \emph{마세요}.

	이 예는 하나의 제어 쓰레드와 여러 일꾼 쓰레드를 사용합니다.
	각 일꾼 쓰레드는 바깥으로의 데이터 넘기기를 하고 각 일단위를 마친 후
	쓰레드별 \co{my_timestamp} 변수에 현재 시간을 (예를 들어,
	\co{clock_gettime()} 시스템콜로부터 얻을 수 있겠습니다) 기록합니다.
	이 예의 리얼타임 특성은 다음과 같은 제한을 초래합니다:

	\iffalse

	The short answer is that on commonplace commodity hardware,
	synchronization designs based on any sort of fine-grained
	timing are foolhardy and cannot be expected to operate correctly
	under all conditions.

	That said, there are systems designed for hard real-time use
	that are much more deterministic.
	In the (very unlikely) event that you are using such a system,
	here is a toy example showing how time-based synchronization can
	work.
	Again, do \emph{not} try this on commodity microprocessors,
	as they have highly nondeterministic performance characteristics.

	This example uses multiple worker threads along with a control
	thread.
	Each worker thread corresponds to an outbound data feed, and
	records the current time (for example, from the
	\co{clock_gettime()} system call) in a per-thread
	\co{my_timestamp} variable after executing each unit
	of work.
	The real-time nature of this example results in the following
	set of constraints:

	\fi

	\begin{enumerate}
	\item	특정 일꾼 쓰레드가 \co{MAX_LOOP_TIME} 이상의 시간동안 이 시간
		기록을 업데이트하지 못한다면 이는 치명적 오류입니다.
	\item	락은 전역 상태를 접근하고 업데이트 하기 위해 아껴서 사용됩니다.
	\item	락은 주어진 쓰레드 우선순위 내에서 엄격한 FIFO 순서로
		얻어집니다.

	\iffalse

	\item	It is a fatal error for a given worker thread to fail
		to update its timestamp for a time period of more than
		\co{MAX_LOOP_TIME}.
	\item	Locks are used sparingly to access and update global
		state.
	\item	Locks are granted in strict FIFO order within
		a given thread priority.

	\fi

	\end{enumerate}

	일꾼 쓰레드가 데이터 넘기기를 완료하면, 이들은 스스로를 이
	어플리케이션의 나머지 부분으로부터 떼어내고 상태 값을 \co{-1} 로 초기화
	되는 쓰레드별 \co{my_status} 변수에 저장합니다.
	쓰레드는 끝나지 않습니다; 대신 이들은 나중의 처리 요구를 위해 쓰레드
	풀에 위치합니다.
	제어 쓰레드는 필요에 따라 일꾼 쓰레드를 할당하고, 또한 쓰레드 상태들의
	히스토그램을 유지합니다.
	이 제어 쓰레드는 일꾼 쓰레드의 그것보다 더 높지 않은 리얼타임
	우선순위로 수행됩니다.

	일꾼 쓰레드의 코드는 다음과 같습니다:

	\iffalse

	When worker threads complete their feed, they must disentangle
	themselves from the rest of the application and place a status
	value in a per-thread \co{my_status} variable that is initialized
	to \co{-1}.
	Threads do not exit; they instead are placed on a thread pool
	to accommodate later processing requirements.
	The control thread assigns (and re-assigns) worker threads as
	needed, and also maintains a histogram of thread statuses.
	The control thread runs at a real-time priority no higher than
	that of the worker threads.

	Worker threads' code is as follows:

	\fi

\begin{VerbatimN}
	int my_status = -1;  /* Thread local. */

	while (continue_working()) {
		enqueue_any_new_work();
		wp = dequeue_work();
		do_work(wp);
		my_timestamp = clock_gettime(...);
	}

	acquire_lock(&departing_thread_lock);

	/*
	 * Disentangle from application, might
	 * acquire other locks, can take much longer
	 * than MAX_LOOP_TIME, especially if many
	 * threads exit concurrently.
	 */
	my_status = get_return_status();
	release_lock(&departing_thread_lock);

	/* thread awaits repurposing. */
\end{VerbatimN}

	제어 쓰레드의 코드는 다음과 같습니다:

	\iffalse

	The control thread's code is as follows:

	\fi

\begin{fcvlabel}[ln:future:htm:control thread]
\begin{VerbatimN}[commandchars=\\\@\$]
	for (;;) {
		for_each_thread(t) {
			ct = clock_gettime(...);
			d = ct - per_thread(my_timestamp, t);
			if (d >= MAX_LOOP_TIME) {	\lnlbl@if$
				/* thread departing. */	\lnlbl@dep:b$
				acquire_lock(&departing_thread_lock); \lnlbl@acq$
				release_lock(&departing_thread_lock); \lnlbl@rel$
				i = per_thread(my_status, t);
				status_hist[i]++; /* Bug if TLE! */ \lnlbl@dep:e$
			}
		}
		/* Repurpose threads as needed. */
	}
\end{VerbatimN}
\end{fcvlabel}

	\begin{fcvref}[ln:future:htm:control thread]
	\Clnref{if} 는 쓰레드가 종료되었는지 추측하기 위해 시간의 흐름을
	사용하며, 그렇다면 \clnref{dep:b,dep:e} 를 수행합니다.
	\Clnref{acq,rel} 의 빈 락 기반 크리티컬 섹션은 종료 중인 모든 쓰레드가
	완료되었길 보장합니다 (락은 FIFO 순서로 주어짐을 기억하세요!).
	\end{fcvref}

	다시 말하지만, 일반 마이크로프로세서에서 이런 일을 하지 마세요.
	어쨌건, 하드 리얼타임 사용처를 위해 특수 설계된 시스템에서도 이를
	올바르게 만들기는 충분히 어렵습니다.

	\iffalse

	\begin{fcvref}[ln:future:htm:control thread]
	\Clnref{if} uses the passage of time to deduce that the thread
	has exited, executing \clnref{dep:b,dep:e} if so.
	The empty lock-based critical section on \clnref{acq,rel}
	guarantees that any thread in the process of exiting
	completes (remember that locks are granted in FIFO order!).
	\end{fcvref}

	Once again, do not try this sort of thing on commodity
	microprocessors.
	After all, it is difficult enough to get this right on systems
	specifically designed for hard real-time use!

	\fi

}\QuickQuizEndE
}

락킹과 트랜잭션 사이의 한가지 중요한 의미상 차이는 락 기반 리얼타임
프로그램에서 우선순위 역전을 막기 위해 사용되는 우선순위 높이기 입니다.
우선순위 역전이 일어날 수 있는 경우 중 하나는 락을 잡은 낮은 우선순위 쓰레드가 
중간 우선순위 CPU 사용 쓰레드에 preemption 당할 때입니다.
그런 중간 우선순위 쓰레드가 CPU 당 최소 하나 있다면, 이 낮은 우선순위 쓰레드는
다시 동작할 기회를 얻지 못합니다.
이제 어떤 높은 우선순위 쓰레드가 이 락을 얻으려 하면 블록됩니다.
이 쓰레드는 이 낮은 운선순위 쓰레드가 이 락을 해제하기 전까지 그 락을 얻을 수
없고, 낮은 우선순위 쓰레드는 동작할 기회를 얻기 전까지는 이 락을 놓을 수
없으며, 중간 우선순위 쓰레드가 CPU 를 놓기 전까지는 동작할 기회를 얻지
못합니다.
따라서, 이 중간 우선순위 쓰레드는 실질적으로 높은 우선순위 프로세스를 블록하고
있으며, 따라서 ``우선순위 역전'' 이라는 이름이 붙었습니다.

\iffalse

One important semantic difference between locking and transactions
is the priority boosting that is used to avoid priority inversion
in lock-based real-time programs.
One way in which priority inversion can occur is when a
low-priority thread holding a lock
is preempted by a medium-priority CPU-bound thread.
If there is at least one such medium-priority thread per CPU, the
low-priority thread will never get a chance to run.
If a high-priority thread now attempts to acquire the lock,
it will block.
It cannot acquire the lock until the low-priority thread releases it,
the low-priority thread cannot release the lock until it gets a chance
to run, and it cannot get a chance to run until one of the medium-priority
threads gives up its CPU\@.
Therefore, the medium-priority threads are in effect blocking the
high-priority process, which is the rationale for the name ``priority
inversion.''

\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:future:Exploiting Priority Boosting]
\begin{VerbatimL}[commandchars=\\\@\$]
void boostee(void)		\lnlbl@low:b$
{
	int i = 0;

	acquire_lock(&boost_lock[i]);	\lnlbl@1stacq$
	for (;;) {
		acquire_lock(&boost_lock[!i]);
		release_lock(&boost_lock[i]);
		i = i ^ 1;
		do_something();
	}
}				\lnlbl@low:e$

void booster(void)		\lnlbl@high:b$
{
	int i = 0;

	for (;;) {
		usleep(500); /* sleep 0.5 ms. */
		acquire_lock(&boost_lock[i]);	\lnlbl@acq$
		release_lock(&boost_lock[i]);	\lnlbl@rel$
		i = i ^ 1;
	}
}                               \lnlbl@high:e$
\end{VerbatimL}
\end{fcvlabel}
\caption{Exploiting Priority Boosting}
\label{lst:future:Exploiting Priority Boosting}
\end{listing}

우선순위 역전을 막는 한가지 방법은 \emph{우선순위 상속} 으로, 락에 블록되는
높은 우선순위 쓰레드가 임시적으로 자신의 우선순위를 락을 쥔 쓰레드에게 주는
것인데, \emph{우선순위 높이기} 라고도 불립니다.
그러나, 우선순위 높이기는
\cref{lst:future:Exploiting Priority Boosting} 에 보인 것처럼 우선순위 역전을
막는 것 이외의 것을 위해서도 사용될 수 있습니다.
\begin{fcvref}[ln:future:Exploiting Priority Boosting]
이 리스트의
\clnrefrange{low:b}{low:e} 는 매 밀리세컨드마다 수행되어야만 하는 낮은 우선순위
프로세스를 보이고, \clnrefrange{high:b}{high:e} 는 \co{boostee()} 가 필요에
따라 주기적으로 수행됨을 보장하기 위해 우선순위 높이기를 사용하는 높은 우선순위
프로세스를 보입니다.

\co{boostee()} 함수는 두개의 \co{boost_lock[]} 락들 중 하나를 항상 잡아서
\co{booster()} 의 \clnrefrange{acq}{rel} 은 필요에 따라 우선순위를 높일 수 있게
함으로써 이를 가능하게 합니다.
\end{fcvref}

\iffalse

One way to avoid priority inversion is \emph{priority inheritance},
in which a high-priority thread blocked on a lock temporarily donates
its priority to the lock's holder, which is also called \emph{priority
boosting}.
However, priority boosting can be used for things other than avoiding
priority inversion, as shown in
\cref{lst:future:Exploiting Priority Boosting}.
\begin{fcvref}[ln:future:Exploiting Priority Boosting]
\Clnrefrange{low:b}{low:e} of this listing show a low-priority process that must
nevertheless run every millisecond or so, while \clnrefrange{high:b}{high:e} of
this same listing show a high-priority process that uses priority
boosting to ensure that \co{boostee()} runs periodically as needed.

The \co{boostee()} function arranges this by always holding one of
the two \co{boost_lock[]} locks, so that \clnrefrange{acq}{rel} of
\co{booster()} can boost priority as needed.
\end{fcvref}

\fi

\QuickQuiz{
	하지만
	\cref{lst:future:Exploiting Priority Boosting}
	의 \co{boostee()} 함수는 그 대신 락을 반대 순서로 잡습니다!
	이는 데드락을 초래할 수 있지 않나요?

	\iffalse

	But the \co{boostee()} function in
	\cref{lst:future:Exploiting Priority Boosting}
	alternatively acquires its locks in reverse order!
	Won't this result in deadlock?

	\fi

}\QuickQuizAnswer{
	데드락은 일어나지 않습니다.
	데드락에 도달하기 위해선, 두개의 다른 쓰레드가 두 락을 반대 순서로
	획득해야 하는데, 이 예에서는 일어나지 않는 일입니다.
	그러나, lockdep~\cite{JonathanCorbet2006lockdep} 같은 데드락 탐지기는
	이를 false positive 로 잡아낼 겁니다.

	\iffalse

	No deadlock will result.
	To arrive at deadlock, two different threads must each
	acquire the two locks in opposite orders, which does not
	happen in this example.
	However, deadlock detectors such as
	lockdep~\cite{JonathanCorbet2006lockdep}
	will flag this as a false positive.

	\fi

}\QuickQuizEnd

\begin{fcvref}[ln:future:Exploiting Priority Boosting]
이 조정은 \co{boostee()} 가 시스템이 바빠지기 전에 \clnref{1stacq} 에서 첫번째
락을 잡을 것을 필요로 하지만, 이는 현대의 하드웨어에서조차 쉽게 해결됩니다.

불행히도, 이 조정은 transactional lock elision 의 존재에서 쉽게 부서질 수
있습니다.
\co{boostee()} 함수의 겹치는 크리티컬 섹션은 하나의 무한한 트랜잭션이 되는데,
이는 언젠가 중단될 것인데, 예를 들어 \co{boostee()} 함수를 수행하는 쓰레드가
preemption 당하는 첫번째 경우가 있겠습니다.
이 시점에서, \co{boostee()} 는 락킹으로 되돌아가지만, 낮은 우선순위와 조용한
초기화 단계는 이미 끝났음을 놓고 보면 (애초에 \co{boostee()} 가 preemption
당한게 그 이유입니다), 이 쓰레드는 다시 수행될 기회를 영원히 잡지 못할 수도
있습니다.

그리고 \co{boostee()} 쓰레드가 락을 잡고 있지 않다면, \co{booster()} 쓰레드의
\cref{lst:future:Exploiting Priority Boosting} 의 \clnref{acq,rel} 에서의 텅 빈
크리티컬 섹션은 이무 효과 없는 텅 빈 트랜잭션이 되어, \co{boostee()} 는 결코
수행되지 않습니다.
이 예는 transactional memory 의 되돌리고 재시도 하기 방법의 미묘한 결과를
보입니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:future:Exploiting Priority Boosting]
This arrangement requires that \co{boostee()} acquire its first
lock on \clnref{1stacq} before the system becomes busy, but this is easily
arranged, even on modern hardware.

Unfortunately, this arrangement can break down in presence of transactional
lock elision.
The \co{boostee()} function's overlapping critical sections become
one infinite transaction, which will sooner or later abort,
for example, on the first time that the thread running
the \co{boostee()} function is preempted.
At this point, \co{boostee()} will fall back to locking, but given
its low priority and that the quiet initialization period is now
complete (which after all is why \co{boostee()} was preempted),
this thread might never again get a chance to run.

And if the \co{boostee()} thread is not holding the lock, then
the \co{booster()} thread's empty critical section on \clnref{acq,rel} of
\cref{lst:future:Exploiting Priority Boosting}
will become an empty transaction that has no effect, so that
\co{boostee()} never runs.
This example illustrates some of the subtle consequences of
transactional memory's rollback-and-retry semantics.
\end{fcvref}

\fi

경험은 추가적인 미묘한 의미적 차이들을 드러낼 거라는 점을 생각해 보면, HTM 기반
락 제거를 거대한 프로그램에 적용하는 것은 주의와 함께 이루어져야 합니다.
그러나, 그게 적용되는 곳에서라면 HTM 기반 락 제거는 락 변수와 연관된 캐쉬
미스를 제거할 수 있으며, 이는 거대한 실제 세계 소프트웨어 시스템에서 2015년 초
기준으로 수십 퍼센트의 성능 향상을 가져왔습니다.
따라서 우리는 안정적인 지원을 제공하는 하드웨어에서의 이 기술의 상당한 사용을
예상할 수 있습니다.

\iffalse

Given that experience will likely uncover additional subtle semantic
differences, application of HTM-based lock elision to large programs
should be undertaken with caution.
That said, where it does apply, HTM-based lock elision can eliminate
the cache misses associated with the lock variable, which has resulted
in tens of percent performance increases in large real-world software
systems as of early 2015.
We can therefore expect to see substantial use of this technique on
hardware providing reliable support for it.

\fi

\QuickQuiz{
	그러니까 여러 사람이 락킹을 대체하려고 했고, 그들은 대부분 그저 락킹을
	최적화 하는데 그치는 건가요???

	\iffalse

	So a bunch of people set out to supplant locking, and they
	mostly end up just optimizing locking???

	\fi

}\QuickQuizAnswer{
	그들은 최소한 무언가 유용한 것을 이루어냈습니다!
	그리고 시간에 따라 추가적인 HTM 쪽 진보가 계속될
	겁니다~\cite{Siakavaras2017CombiningHA,DimitriosSiakavaras2020RCU-HTM-B+Trees,ChristinaGiannoula2018HTM-RCU-graphcoloring,SeongJaePark2020HTMRCUlock}.

	\iffalse

	At least they accomplished something useful!
	And perhaps there will continue to be additional HTM progress
	over time~\cite{Siakavaras2017CombiningHA,DimitriosSiakavaras2020RCU-HTM-B+Trees,ChristinaGiannoula2018HTM-RCU-graphcoloring,SeongJaePark2020HTMRCUlock}.

	\fi

}\QuickQuizEnd

\subsubsection{Summary}
\label{sec:future:HTM Weaknesses WRT Locking: Summary}

\input{future/HTMtable}

HTM 이 강력한 사용처를 가지게 될 것으로 보이긴 합니다만, 현재의 구현은 주의
깊은 처리를 필요로 할 심각한 트랜잭션 크기 제한, 충돌 처리 복잡성, 중단하고
되돌리기 문제, 그리고 의미적 차이를 갖고 있습니다.
락킹 대비 HTM 의 현재 상황은
\cref{tab:future:Comparison of Locking and HTM} 으로 요약될 수 있습니다.
여기서 볼 수 있듯, HTM 의 현재 상황은 락킹의 심각한 단점 일부를
완화시키지만,\footnote{
	공정을 위해, 락킹의 단점들은
	\cref{sec:future:HTM Weaknesses WRT Locking When Augmented} 에서
	논의되듯 데드락 탐지기~\cite{JonathanCorbet2006lockdep}, 락킹을 위해
	조정된 여러 데이터 구조들, 그리고 증강의 긴 역사를 포함해 잘 알려지고
	널리 사용되는 공학적 해결책이 존재함을 강조해 두는게 중요하겠습니다.
	또한, 락킹이 많은 학술 논문을 슬쩍 보는 것만으로도 사람들을 납득시킬 수
	있을만큼 끔찍한 것이었다면, 그 많은 거대한 락 기반 병렬 프로그램은
	(FOSS 와 독점 소프트웨어 양쪽) 어디서 나왔겠습니까?}
이를 위해 그 자체의 상당한 수의 단점을 가져옵니다.
이 단점들은 TM 커뮤니티의 리더에 의해
인정되었습니다~\cite{AlexanderMatveev2012PessimisticTM}.\footnote{
	또한, 2011년 초, 저는 transactional memory 의 기본 가정에 대한 비평을
	전하기 위해 초대된 바 있습니다~\cite{PaulEMcKenney2011Verico}.
	청중들은 놀랍게도 적대적이지 않았지만, 제가 발표 중에도 시차로 인해
	괴로워 하고 있었기 때문에 제게 편하게 대해준 것일 수도 있습니다.}

\iffalse

Although it seems likely that HTM will have compelling use cases,
current implementations have serious transaction-size limitations,
conflict-handling complications, abort-and-rollback issues, and
semantic differences that will require careful handling.
HTM's current situation relative to locking is summarized in
\cref{tab:future:Comparison of Locking and HTM}.
As can be seen, although the current state of HTM alleviates some
serious shortcomings of locking,\footnote{
	In fairness, it is important to emphasize that locking's shortcomings
	do have well-known and heavily used engineering solutions, including
	deadlock detectors~\cite{JonathanCorbet2006lockdep}, a wealth
	of data structures that have been adapted to locking, and
	a long history of augmentation, as discussed in
	\cref{sec:future:HTM Weaknesses WRT Locking When Augmented}.
	In addition, if locking really were as horrible as a quick skim
	of many academic papers might reasonably lead one to believe,
	where did all the large lock-based parallel programs (both
	FOSS and proprietary) come from, anyway?}
it does so by introducing a significant
number of shortcomings of its own.
These shortcomings are acknowledged by leaders in the TM
community~\cite{AlexanderMatveev2012PessimisticTM}.\footnote{
	In addition, in early 2011, I was invited to deliver a critique of
	some of the assumptions underlying transactional
	memory~\cite{PaulEMcKenney2011Verico}.
	The audience was surprisingly non-hostile, though perhaps they
	were taking it easy on me due to the fact that I was heavily
	jet-lagged while giving the presentation.}

\fi

또한, 이게 전부가 아닙니다.
락킹은 보통 그 자체로 사용되지 않고, 일반적으로 레퍼런스 카운팅, 어토믹
오퍼레이션, non-blocking 데이터 구조, 해저드
포인터~\cite{MagedMichael04a,HerlihyLM02}, 그리고 RCU~\cite{McKenney98,
McKenney01a,ThomasEHart2007a,PaulEMcKenney2012ELCbattery} 를 포함한 다른 동기화
메커니즘들과 결합되어 사용됩니다.
다음 섹션은 어떻게 그런 결합이 그림을 바꾸는지 보입니다.

\iffalse

In addition, this is not the whole story.
Locking is not normally used by itself, but is instead typically
augmented by other synchronization mechanisms,
including reference counting, atomic operations, non-blocking data structures,
hazard pointers~\cite{MagedMichael04a,HerlihyLM02},
and RCU~\cite{McKenney98,McKenney01a,ThomasEHart2007a,PaulEMcKenney2012ELCbattery}.
The next section looks at how such augmentation changes the equation.

\fi

\subsection{HTM Weaknesses WRT Locking When Augmented}
\label{sec:future:HTM Weaknesses WRT Locking When Augmented}

\input{future/HTMtableRCU}

실무자들은 락킹의 단점들 중 일부를 회피하기 위해 레퍼런스 카운팅, 어토믹
오퍼레이션, non-blocking 데이터 구조, 해저드 포인터, 그리고 RCU 를 오랫동안
사용해 왔습니다.
예를 들어, 데드락은 레퍼런스 카우트, 해저드 포인터, 또는 RCU 를 데이터 구조
보호에 사용함으로써 막아질 수 있는데, 특히 읽기 전용 크리티컬 섹션의 경우
그렇습니다~\cite{MagedMichael04a,HerlihyLM02,MathieuDesnoyers2012URCU,DinakarGuniguntala2008IBMSysJ,ThomasEHart2007a}.
이 방법은 또한 데이터 구조를 쪼개야 하는 필요를 줄이는데,
\cref{chp:Data Structures} 에서 이를 다루었습니다.
RCU 는 더 나아가 경쟁에서 자유로운 bounded wait-free read-side
기능들~\cite{McKenney98,MathieuDesnoyers2012URCU} 을 제공하며, 해저드 포인터는
lock-free read-side 기능들~\cite{Michael02a,HerlihyLM02,MagedMichael04a} 을
제공합니다.
이 점들을
\cref{tab:future:Comparison of Locking and HTM}
에 더한, 증강된 락킹과 HTM 사이의 비교가
\cref{tab:future:Comparison of Locking (Augmented by RCU or Hazard Pointers) and HTM}
에 있습니다.
두 표 사이의 차이에 대한 요약은 다음과 같습니다:

\iffalse

Practitioners have long used reference counting, atomic operations,
non-blocking data structures, hazard pointers, and RCU to avoid some
of the shortcomings of locking.
For example, deadlock can be avoided in many cases by using reference
counts, hazard pointers, or RCU to protect data structures,
particularly for read-only critical
sections~\cite{MagedMichael04a,HerlihyLM02,MathieuDesnoyers2012URCU,DinakarGuniguntala2008IBMSysJ,ThomasEHart2007a}.
These approaches also reduce the need to partition data
structures, as was seen in \cref{chp:Data Structures}.
RCU further provides contention-free bounded wait-free read-side
primitives~\cite{McKenney98,MathieuDesnoyers2012URCU}, while hazard pointers
provides lock-free read-side
primitives~\cite{Michael02a,HerlihyLM02,MagedMichael04a}.
Adding these considerations to
\cref{tab:future:Comparison of Locking and HTM}
results in the updated comparison between augmented locking and HTM
shown in
\cref{tab:future:Comparison of Locking (Augmented by RCU or Hazard Pointers) and HTM}.
A summary of the differences between the two tables is as follows:

\fi

\begin{enumerate}
\item	Non-blocking read-side 미커니즘의 사용은 데드락 문제를 완화시킵니다.
\item	해저드 포인터와 RCU 같은 read-side 커니즘은 쪼개질 수 없는 데이터에
	효율적으로 사용될 수 있습니다.
\item	해저드 포인터와 RCU 는 서로간이나 업데이트 쓰레드와 경쟁하지 않아서
	읽기가 대부분인 워크로드에 훌륭한 성능과 확장성을 제공합니다.
\item	해저드 포인터와 RCU 는 진행 보장을 제공합니다 (각각 lock freedom 과
	bounded wait-freedom 을).
\item	해저드 포인터와 RCU 를 위한 사설화 오퍼레이션은 간단합니다.

\iffalse

\item	Use of non-blocking read-side mechanisms alleviates deadlock issues.
\item	Read-side mechanisms such as hazard pointers and RCU can operate
	efficiently on non-partitionable data.
\item	Hazard pointers and RCU do not contend with each other or with
	updaters, allowing excellent performance and scalability for
	read-mostly workloads.
\item	Hazard pointers and RCU provide forward-progress guarantees
	(lock freedom and bounded wait-freedom, respectively).
\item	Privatization operations for hazard pointers and RCU are
	straightforward.

\fi

\end{enumerate}

\input{future/HTMtableFull}

시력이 좋은 분들을 위해,
\cref{tab:future:Comparison of Locking (Plain and Augmented) and HTM}
는
\cref{tab:future:Comparison of Locking and HTM,%
tab:future:Comparison of Locking (Augmented by RCU or Hazard Pointers) and HTM}
를 합쳤습니다.

물론, 다음 섹션에서 이야기 하듯 HTM 의 증강도 가능합니다.

\iffalse

For those with good eyesight,
\cref{tab:future:Comparison of Locking (Plain and Augmented) and HTM}
combines
\cref{tab:future:Comparison of Locking and HTM,%
tab:future:Comparison of Locking (Augmented by RCU or Hazard Pointers) and HTM}.

Of course, it is also possible to augment HTM,
as discussed in the next section.

\fi

\subsection{Where Does HTM Best Fit In?}
\label{sec:future:Where Does HTM Best Fit In?}

HTM 의 적용 영역이
page~\pageref{fig:defer:RCU Areas of Applicability} 의
\cref{fig:defer:RCU Areas of Applicability} 에서의 RCU 로 보이는 것처럼 잘
파악되기까지는 시간이 걸릴 것으로 보이지만, 그게 그 방향으로의 이동을 시작하지
않을 이유는 아닙니다.

거대한 멀티프로세서에서 돌아가는 거대한 메모리 상의 데이터 구조에서의
상대적으로 다른 부분들에 상대적으로 작은 변화를 포함하는 업데이트가 많은
워크로드에서 HTM 은 가장 잘 맞을 것으로 보이는데, 이는 현재 HTM 구현의 크기
제한과 맞고 충돌과 그에 따른 중단 및 되돌리기의 가능성을 최소화 하기
때문입니다.
이 시나리오는 현재의 동기화 기능을 가지고는 처리하기가 상대적으로 어려운
것입니다.

\iffalse

Although it will likely be some time before HTM's area of applicability
can be as crisply delineated as that shown for RCU in
\cref{fig:defer:RCU Areas of Applicability} on
page~\pageref{fig:defer:RCU Areas of Applicability}, that is no reason not to
start moving in that direction.

HTM seems best suited to update-heavy workloads involving relatively
small changes to disparate portions of relatively large in-memory
data structures running on large multiprocessors,
as this meets the size restrictions of current HTM implementations while
minimizing the probability of conflicts and attendant aborts and
rollbacks.
This scenario is also one that is relatively difficult to handle given
current synchronization primitives.

\fi

락킹을 HTM 과 함께 사용하는 것은 HTM 의 취소불가 오퍼레이션에서의 문제를 극복할
것으로 보이며, RCU 나 해저드 포인터의 사용은 HTM 의 트랜잭션 크기 제한을 데이터
구조의 큰 부분을 움직이는 읽기 전용 오퍼레이션에서 완화할 수 있을 수도
있습니다~\cite{SeongJaePark2020HTMRCUlock}.
현재의 HTM 구현은 무조건적으로 RCU 나 해저드 포인터 읽기 쓰레드와 충돌하는
업데이트 트랜잭션을 중단시키지만, 미래의 HTM 구현은 이 동기화 메커니즘들과 더
부드럽게 상호작용할지도 모릅니다.
그때까지는, 거대한 RCU 나 해저드 포인터 read-side 크리티컬 섹션과의 업데이트
충돌 확률은 동일한 읽기 전용 트랜잭션과의 충돌의 확률보다 훨씬 작아야 할
겁니다.\footnote{
	NoSQL 데이터베이스가 전통적인 데이터베이스의 엄격한 트랜잭션을
	완화시키는 때에 공유 메모리 시스템에 엄격한 트랜잭션 메커니즘이 나오는
	건 꽤 아이러닉합니다.
	리눅스 커널의 주소 공간 무작위화 방어
	메커니즘~\cite{YeongjinJang2016TSXbreakKASLR,Jang:2016:BKA:2976749.2978321}
	에서의 black-hat 공격에도 불구하고 HTM 은 은 실제로 TM 의 편한 사용성
	약속을 알고 있습니다.}
그러나, RCU 나 해저드 포인터 읽기 쓰레드의 지속적인 등장은 연관된 충돌의 지속적
등장으로 인해 업데이트 쓰레드를 기아에 빠뜨릴 수도 있습니다.
이 취약점은 extra-transactional 읽기에게 로드되는 메모리 위치의 트랜잭션 전
복사본을 제공하는 식으로 제거될 수 있습니다 (상당한 하드웨어 비용과 복잡도가
들겠지만).

\iffalse

Use of locking in conjunction with HTM seems likely to overcome HTM's
difficulties with irrevocable operations, while use of RCU or
hazard pointers might alleviate HTM's transaction-size limitations
for read-only operations that traverse large fractions of the data
structure~\cite{SeongJaePark2020HTMRCUlock}.
Current HTM implementations unconditionally abort an update transaction
that conflicts with an RCU or hazard-pointer reader, but perhaps future
HTM implementations will interoperate more smoothly with these
synchronization mechanisms.
In the meantime, the probability of an update conflicting with a
large RCU or hazard-pointer read-side critical section should be
much smaller than the probability of conflicting with the equivalent
read-only transaction.\footnote{
	It is quite ironic that strictly transactional mechanisms are
	appearing in shared-memory systems at just about the time
	that NoSQL databases are relaxing the traditional
	database-application reliance on strict transactions.
	Nevertheless, HTM has in fact realized the ease-of-use promise
	of TM, albeit for black-hat attacks on the Linux kernel's
	address-space randomization defense
	mechanism~\cite{YeongjinJang2016TSXbreakKASLR,Jang:2016:BKA:2976749.2978321}.}
Nevertheless, it is quite possible that a steady stream of RCU or
hazard-pointer readers might starve updaters due to a corresponding
steady stream of conflicts.
This vulnerability could be eliminated (at significant
hardware cost and complexity) by giving extra-transactional
reads the pre-transaction copy of the memory location being loaded.

\fi

HTM 트랜잭션이 fallback 을 가져야만 한다는 사실은 어떤 경우엔 데이터 구조의
정적 분할 가능성 강요를 HTM 에 다시 불러올수도 있습니다.
미래의 HTM 구현이 진행 보장을 제공한다면 어떤 경우에는 fallback
코드의 필요를 제거할 수도 있으므로 이 한계는 완화될수도 있겠는데, 이는 결국 HTM
이 높은 충돌 확률을 갖는 환경에서 효율적으로 사용될 수 있게 할수도 있습니다.

요약하자면, HTM 은 중요한 사용처와 어플리케이션을 가질 수 있을 것 같지만, 이는
병렬 프로그래머의 도구상자의 또하나의 도구일뿐, 도구상자 전체의 대체제는
아닙니다.

\iffalse

The fact that HTM transactions must have fallbacks might in some cases
force static partitionability of data structures back onto HTM\@.
This limitation might be alleviated if future HTM implementations
provide forward-progress guarantees, which might eliminate the need
for fallback code in some cases, which in turn might allow HTM to
be used efficiently in situations with higher conflict probabilities.

In short, although HTM is likely to have important uses and applications,
it is another tool in the parallel programmer's toolbox, not a replacement
for the toolbox in its entirety.

\fi

\subsection{Potential Game Changers}
\label{sec:future:Potential Game Changers}

HTM 의 필요를 크게 증가시킬 게임 체인저는 다음을 포함합니다:

\begin{enumerate}
\item	진행 보장.
\item	트랜잭션 크기 증가.
\item	디버깅 지원 개선.
\item	완화된 원자성.
\end{enumerate}

이것들이 다음 섹션에서 다루어집니다.

\iffalse

Game changers that could greatly increase the need for HTM include
the following:

\begin{enumerate}
\item	Forward-progress guarantees.
\item	Transaction-size increases.
\item	Improved debugging support.
\item	Weak atomicity.
\end{enumerate}

These are expanded upon in the following sections.

\fi

\subsubsection{Forward-Progress Guarantees}
\label{sec:future:Forward-Progress Guarantees}

\Cref{sec:future:Lack of Forward-Progress Guarantees} 에서 이야기된 것처럼,
현재의 HTM 구현은 진행 보장을 제공하지 않는데, 따라서 HTM 실패를 다루기 위해
fallback 소프트웨어를 필요로 합니다.
물론, 보장을 요구하기는 쉽지만 그걸 제공하기는 항상 쉽지는 않습니다.
HTM 의 경우, 보장에 대한 장애물은 캐쉬 크기와 associativity, TLB 크기와
asociativity, 트랜잭션 길이와 인터럽트 빈번도, 그리고 스케쥴러 구현이 포함될 수
있습니다.

\iffalse

As was discussed in
\cref{sec:future:Lack of Forward-Progress Guarantees},
current HTM implementations lack forward-progress guarantees, which requires
that fallback software is available to handle HTM failures.
Of course, it is easy to demand guarantees, but not always easy
to provide them.
In the case of HTM, obstacles to guarantees can include cache size and
associativity, TLB size and associativity, transaction duration and
interrupt frequency, and scheduler implementation.

\fi

캐쉬 크기와 associativity 는
\cref{sec:future:Transaction-Size Limitations}
에서 현재의 한계를 회피하기 위한 일부 연구와 함께 이야기 되었습니다.
하지만, HTM 진행 보장은 크기 제한과 함께 올 것이며, 그게 크더라도 그 한계는
언젠가 닥칠 겁니다.
그런데 왜 현재의 HTM 구현은 작은 트랜잭션에 대해서는 진행 보장을 제공하지
않을까요, 예를 들면 캐쉬의 associativity 로 제한을 걸어서라도?
한가지 잠재적 이유는 하드웨어 실패 처리 필요일수도 있습니다.
예를 들어, 한 고장난 cache SRAM cell 은 이 고장난 cell 을 비활성화 함으로써
처리될 수 있으며, 따라서 캐쉬의 associativity 를 줄이고 진행 보장이 주어지는
트랜잭션의 최대 크기 또한 줄어듭니다.
이는 보장된 트랜잭션 크기를 줄일 뿐이므로, 다른 이유도 있을 것 같습니다.
아마도 진행 보장을 제품 수준 하드웨어에서 제공하는 것은 사람들이 생각하는
것보다 더 어려울지고 모르고, 소프트웨어에서 진행 보장을 만드는 것의 어려움을
생각하면 완전히 그럴싸한 설명입니다.
문제를 소프트웨어에서 하드웨어로 옮기는 것은 그걸 꼭 쉽게 만드는 것만은
아닙니다~\cite{ChristianJacobi2012MainframeTM}.

\iffalse

Cache size and associativity was discussed in
\cref{sec:future:Transaction-Size Limitations},
along with some research intended to work around current limitations.
However, HTM forward-progress guarantees would
come with size limits, large though these limits might one day be.
So why don't current HTM implementations provide forward-progress
guarantees for small transactions, for example, limited to the
associativity of the cache?
One potential reason might be the need to deal with hardware failure.
For example, a failing cache SRAM cell might be handled by deactivating
the failing cell, thus reducing the associativity of the cache and
therefore also the maximum size of transactions that can be guaranteed
forward progress.
Given that this would simply decrease the guaranteed transaction size,
it seems likely that other reasons are at work.
Perhaps providing forward progress guarantees on production-quality
hardware is more difficult than one might think, an entirely plausible
explanation given the difficulty of making forward-progress guarantees
in software.
Moving a problem from software to hardware does not necessarily make
it easier to solve~\cite{ChristianJacobi2012MainframeTM}.

\fi

물리적으로 태깅되고 인덱싱 된 캐쉬에서라면 트랜잭션이 캐쉬에 들어가는
것만으로는 충분치 않습니다.
그것의 주소 변환 또한 TLB 에 들어맞아야만 합니다.
따라서 모든 진행 보장은 TLB 크기와 associativity 도 계산에 넣어야 합니다.

인터럽트, 트랩, 그리고 예외가 현재의 HTM 구현에서는 트랜잭션을 중단시키므로,
트랜잭션의 수행 시간은 예상되는 인터럽트간 시간 간격보다 짧아야 합니다.
어떤 트랜잭션이 얼마나 작은 데이터를 건드는가와 관계 없이, 이게 너무 오래
돌아간다면, 중단당할 겁니다.
따라서, 모든 진행 보장은 트랜잭션 크기만이 아니라 수행시간에도 조건적이
되어야만 합니다.

\iffalse

Given a physically tagged and indexed cache, it is not enough for the
transaction to fit in the cache.
Its address translations must also fit in the TLB\@.
Any forward-progress guarantees must therefore also take TLB size
and associativity into account.

Given that interrupts, traps, and exceptions abort transactions in current
HTM implementations, it is necessary that the execution duration of
a given transaction be shorter than the expected interval between
interrupts.
No matter how little data a given transaction touches, if it runs too
long, it will be aborted.
Therefore, any forward-progress guarantees must be conditioned not only
on transaction size, but also on transaction duration.

\fi

진행 보장은 여러 충돌하는 트랜잭션 중 어느 것을 중단시킬지 결정하는 능력에
치명적으로 의존합니다.
앞의 트랜잭션을 중단시키고는 나중의 트랜잭션에 스스로가 중단당하는, 따라서 어떤
트랜잭션도 실제로 커밋하지 못하는 끝없는 트랜잭션의 연속을 상상하기는 너무
쉽습니다.
충돌 처리의 복잡성은 많은 HTM 충돌 처리 정책
제안들~\cite{EgeAkpinar2011HTM2TLE,YujieLiu2011ToxicTransactions} 에 의해
증명되었습니다.
추가적인 복잡도가 Blundell 에 의해 이야기 되었듯~\cite{Blundell2006TMdeadlock}
트랜잭션 외 액세스에 의해 더해집니다.
트랜잭션 외 액세스를 이 모든 문제에 대해 비난하기는 쉬우나, 이런 생각의
어리석음은 트랜잭션 외 액세스 각각을 각자의 단일 액세스 트랜잭션에
위치시킴으로써 쉽게 선보여질 수 있습니다.
문제는 액세스의 패턴이지, 그것이 트랜잭션에 감싸여서 수행되는가가 아닙니다.

마지막으로, 모든 트랜잭션 진행 보장은 트랜잭션을 수행하는 쓰레드가 성공적으로
커밋하기 충분하게 오래 수행되게 허용해야 하는 스케쥴러에 의존적입니다. 

\iffalse

Forward-progress guarantees depend critically on the ability to determine
which of several conflicting transactions should be aborted.
It is all too easy to imagine an endless series of transactions, each
aborting an earlier transaction only to itself be aborted by a later
transactions, so that none of the transactions actually commit.
The complexity of conflict handling is
evidenced by the large number of HTM conflict-resolution policies
that have been proposed~\cite{EgeAkpinar2011HTM2TLE,YujieLiu2011ToxicTransactions}.
Additional complications are introduced by extra-transactional accesses,
as noted by Blundell~\cite{Blundell2006TMdeadlock}.
It is easy to blame the extra-transactional accesses for all of these
problems, but the folly of this line of thinking is easily demonstrated
by placing each of the extra-transactional accesses into its own
single-access transaction.
It is the pattern of accesses that is the issue, not whether or not they
happen to be enclosed in a transaction.

Finally, any forward-progress guarantees for transactions also
depend on the scheduler, which must let the thread executing the
transaction run long enough to successfully commit.

\fi

따라서 HTM 제조사가 진행 보장을 제공하는데에는 상당한 장애물이 존재합니다.
그러나, 그것들 중 하나라도 처리하는 것의 효과는 거대할 겁니다.
이는 HTM 트랜잭션은 더이상 소프트웨어 fallback 을 필요로 하지 않을 것을
의미하는데, 이는 HTM 이 마침내 TM 의 데드락 제거 약속을 지키는 것을 의미합니다.

그러나, 2012 년 말, IBM Mainframe 은 일반적인 best-effort HTM
구현~\cite{ChristianJacobi2012MainframeTM} 에 더해 \emph{제한된 트랜잭션} 을
포함하는 HTM 구현을 발표했습니다.
제한된 트랜잭션은 best-effort 트랜잭션에 사용되었던 \co{tbegin} 을 대신해
\co{tbeginc} 명령으로 시작합니다.
제한된 트랜잭션은 항상 (결국은) 완료될 것이 보장되어서, 트랜잭션이 중단되면
fallback 경로로 분기하는 대신 (best-effort 트랜잭션에선 이렇게 되었습니다),
하드웨어가 \co{tbeginc} 명령부터 트랜잭션을 재시작 합니다.

\iffalse

So there are significant obstacles to HTM vendors offering forward-progress
guarantees.
However, the impact of any of them doing so would be enormous.
It would mean that HTM transactions would no longer need software
fallbacks, which would mean that HTM could finally deliver on the
TM promise of deadlock elimination.

However, in late 2012, the IBM Mainframe announced an HTM implementation
that includes \emph{constrained transactions} in addition to the usual
best-effort HTM
implementation~\cite{ChristianJacobi2012MainframeTM}.
A constrained transaction starts with the \co{tbeginc} instruction
instead of the \co{tbegin} instruction that is used for best-effort
transactions.
Constrained transactions are guaranteed to always complete (eventually),
so if a transaction aborts, rather than branching to a fallback path
(as is done for best-effort transactions), the hardware instead restarts
the transaction at the \co{tbeginc} instruction.

\fi

Mainframe 설계자는 이 진행 보장을 위한 극한적인 측정을 해야 했습니다.
만약 제한된 트랜잭션이 반복적으로 실패한다면, CPU 는 분기 예측을 비활성화 하고,
순차적 수행을 강제하고, 파이프라이닝을 비활성화하기까지 할수도 있습니다.
반복된 실패가 높은 경쟁 때문이라면, CPU 는 예측적 읽기를 비활성화하고, 무작위적
지연을 넣고, 충돌하는 CPU 의 순차적 수행을 시킬 수조차 있습니다.
``흥미로운'' 진행 시나리오는 최소 두개의 CPU 로부터 백개의 CPU 까지 포함시킬 수
있습니다.
이 극한의 측정은 왜 다른 CPU 들이 지금껏 제한된 트랜잭션을 제공하는 것을
자제했는지 어떤 통찰을 제공합니다.

이름이 의미하듯, 제한된 트랜잭션은 실제로 상당히 제한되어 있습니다:

\iffalse

The Mainframe architects needed to take extreme measures to deliver on
this forward-progress guarantee.
If a given constrained transaction repeatedly fails, the CPU
might disable branch prediction, force in-order execution, and even
disable pipelining.
If the repeated failures are due to high contention, the CPU might
disable speculative fetches, introduce random delays, and even
serialize execution of the conflicting CPUs.
``Interesting'' forward-progress scenarios involve as few as two CPUs
or as many as one hundred CPUs.
Perhaps these extreme measures provide some insight as to why other CPUs
have thus far refrained from offering constrained transactions.

As the name implies, constrained transactions are in fact severely constrained:

\fi

\begin{enumerate}
\item	최대 데이터 사용량은 메모리의 네개 블록으로, 각 블록은 32 바이트가
	최대입니다.
\item	최대 코드 사용량은 256 바이트입니다.
\item	만약 4K 페이지가 제한된 트랜잭션의 코드를 포함한다면, 그 페이지는 그
	트랜잭션의 데이터를 포함하지 않습니다.
\item	수행될 수 있는 어셈블리 명령의 최대 수는 32 입니다.
\item	후방으로의 분기는 금지되어 있습니다.

\iffalse

\item	The maximum data footprint is four blocks of memory,
	where each block can be no larger than 32 bytes.
\item	The maximum code footprint is 256 bytes.
\item	If a given 4K page contains a constrained transaction's code,
	then that page may not contain that transaction's data.
\item	The maximum number of assembly instructions that may be executed
	is 32.
\item	Backwards branches are forbidden.

\fi

\end{enumerate}

그러나, 이 제약들은 링크드 리스트, 스택, 큐, 그리고 배열 같은 많은 중요한
데이터 구조들을 지원합니다.
따라서 제약된 HTM 은 병렬 프로그래머의 도구상자에 중요한 도구가 될 것 같습니다.

이 진행 보장은 절대적일 필요는 없음을 알아두십시오.
예를 들어, 어떤 HTM 의 사용이 fallback 으로 전역 락을 사용한다고 해봅시다.
이 fallback 메커니즘은
\cref{sec:future:Aborts and Rollbacks}
에서 설명된 ``lemming effect'' 를 막게끔 조심스레 설계되었다 가정하면, HTM
되돌리기가 충분히 빈번하지 않을 경우, 이 전역 락은 병목이 되지 않을 겁니다.
그렇다고는 하나, 시스템이 거대할수록, 크리티컬 섹션이 길수록, 그리고 ``lemming
effect'' 로부터 회복되는데 필요한 시간이 길수록, ``충분히 빈번하지 않음'' 음 더
드물어져야 할 겁니다.

\iffalse

Nevertheless, these constraints support a number of important data structures,
including linked lists, stacks, queues, and arrays.
Constrained HTM therefore seems likely to become an important tool in
the parallel programmer's toolbox.

Note that these forward-progress guarantees need not be absolute.
For example, suppose that a use of HTM uses a global lock as fallback.
Assuming that the fallback mechanism has been carefully designed to
avoid the ``lemming effect'' discussed in
\cref{sec:future:Aborts and Rollbacks},
then if HTM rollbacks are sufficiently infrequent, the global lock
will not be a bottleneck.
That said, the larger the system, the longer the critical sections,
and the longer the time required to recover from the ``lemming effect'',
the more rare ``sufficiently infrequent'' needs to be.

\fi

\subsubsection{Transaction-Size Increases}
\label{sec:future:Transaction-Size Increases}

진행 보장은 중요하지만, 앞서 봤듯 그건 트랜잭션 크기와 시간에 기반한 조건적
보장일 겁니다.
거기에 일부 진보가 있었는데, 예를 들어 어떤 상용 HTM 구현은 극단적으로 큰 HTM
읽기 집합을 지원하기 위한 추정 기법을 사용합니다~\cite{RaviRajwar2012TSX}.
또다른 예로, \Power{8} HTM 은 중단된 트랜잭션을 지원하는데, 이는 관계 없는
액세스를 중단된 트랜잭션의 읽기와 쓰기 집합에 넣는 것을
막습니다~\cite{Le:2015:TMS:3266491.3266500}.
이 능력은 고성능 reader-writer 락을 만드는데
사용되었습니다~\cite{PascalFelber2016rwlockElision}.

\iffalse

Forward-progress guarantees are important, but as we saw, they will
be conditional guarantees based on transaction size and duration.
There has been some progress, for example, some commercially available
HTM implementations use approximation techniques to support extremely
large HTM read sets~\cite{RaviRajwar2012TSX}.
For another example, \Power{8} HTM supports suspended transations, which
avoid adding irrelevant accesses to the suspended transation's read and
write sets~\cite{Le:2015:TMS:3266491.3266500}.
This capability has been used to produce a high performance
reader-writer lock~\cite{PascalFelber2016rwlockElision}.

\fi

작은 크기에 대한 보장조차도 굉장히 유용할 것을 알아두는 게 중요합니다.
예를 들어, 두개 캐쉬 라인에 대한 보장은 스택, 큐, 또는 dequeue 를 지원하는데
충분합니다.
그러나, 더 큰 데이터 구조는 더 큰 보장을 필요로 하는데, 예를 들어 트리를
순서대로 순회하는 것은 트리의 노드 수만큼의 크기에 대한 보장을 필요로 합니다.
따라서, 보장되는 크기의 약간의 증가라도 HTM 의 유용성을 증가시킬 수 있으며,
이는 CPU 가 그걸 제공하거나 충분히 좋은 대안을 제공할 필요를 증가시킵니다.

\iffalse

It is important to note that even small-sized guarantees will be
quite useful.
For example,
a guarantee of two cache lines is sufficient for a stack, queue, or dequeue.
However, larger data structures require larger guarantees, for example,
traversing a tree in order requires a guarantee equal to the number
of nodes in the tree.
Therefore, even modest increases in the size of the guarantee also
increases the usefulness of HTM, thereby increasing the need for CPUs
to either provide it or provide good-and-sufficient workarounds.

\fi

\subsubsection{Improved Debugging Support}
\label{sec:future:Improved Debugging Support}

트랜잭션 크기에의 또다른 억제자는 트랜잭션 디버깅의 필요입니다.
현재 메커니즘의 문제는 단계별 수행 예외가 이를 감싼 트랜잭션을 중단시킨다는
겁니다.
이 문제를 회피하는 여러 방법이 있는데, 프로세서를 에뮬레이션 하는 것 (느려요!),
HTM 을 대체하는 STM 의 사용 (느리고 약간 다른 의미를 가져옵니다!), 진행을
에뮬레이션하기 위한 반복된 재시도를 사용하는 재생 기법 (이상한 실패 모드!),
그리고 HTM 트랜잭션 디버깅의 완전한 지원 (복잡해요!) 등이 포함됩니다.

브레이크포인트, 단계별 수행, 그리고 문자 출력 등을 포함하는 고전적 디버깅
기법의 간단한 사용을 허용하는 HTM 시스템을 만드는 HTM 제조사는 HTM 을 훨씬 더
강력하게 만들 겁니다.
일부 트랜잭션 메모리 연구자들은 이 문제를 2013년에 알아차리기 시작했는데,
최소한 하드웨어가 돕는 디버깅 장치를 포함하는 제안 한가지를
냈습니다~\cite{JustinGottschlich2013TMdebug}.
물론, 이 제안은 사용 가능한 하드웨어가 그런 장치를 얻는 것에
의존적입니다~\cite{TimothyHayes2020ARM-HTM,Intel2020TSXdevguide}.
더 나쁜게, 일부 최첨단 디버깅 기능은 HTM 과 호환되지
않습니다~\cite{RobertOCallahan2020DebuggingHTM}.

\iffalse

Another inhibitor to transaction size is the need to debug the transactions.
The problem with current mechanisms is that a single-step exception
aborts the enclosing transaction.
There are a number of workarounds for this issue, including emulating
the processor (slow!), substituting STM for HTM (slow and slightly
different semantics!),
playback techniques using repeated retries to emulate forward
progress (strange failure modes!), and
full support of debugging HTM transactions (complex!).

Should one of the HTM vendors produce an HTM system that allows
straightforward use of classical debugging techniques within
transactions, including breakpoints, single stepping, and
print statements, this will make HTM much more compelling.
Some transactional-memory researchers started to recognize this
problem in 2013, with at least one proposal involving hardware-assisted
debugging facilities~\cite{JustinGottschlich2013TMdebug}.
Of course, this proposal depends on readily available hardware gaining such
facilities~\cite{TimothyHayes2020ARM-HTM,Intel2020TSXdevguide}.
Worse yet, some cutting-edge debugging facilities are incompatible
with HTM~\cite{RobertOCallahan2020DebuggingHTM}.

\fi

\subsubsection{Weak Atomicity}
\label{sec:future:Weak Atomicity}

Given that HTM is likely to face some sort of size limitations for the
foreseeable future, it will be necessary for HTM to interoperate
smoothly with other mechanisms.
HTM's interoperability with read-mostly mechanisms such as hazard pointers
and RCU would be improved if extra-transactional reads did not
unconditionally abort transactions with conflicting writes---instead,
the read could simply be provided with the pre-transaction value.
In this way, hazard pointers and RCU could be used to allow HTM to handle
larger data structures and to reduce conflict probabilities.

This is not necessarily simple, however.
The most straightforward way of implementing this requires an additional
state in each cache line and on the bus, which is a non-trivial added
expense.
The benefit that goes along with this expense is permitting
large-footprint readers without the risk of starving updaters due
to continual conflicts.
An alternative approach, applied to great effect to binary search trees
by Siakavaras et al.~\cite{Siakavaras2017CombiningHA},
is to use RCU for read-only traversals and HTM
only for the actual updates themselves.
This combination outperformed other transactional-memory techniques by
up to 220\,\%, a speedup similar to that observed by
Howard and Walpole~\cite{PhilHoward2011RCUTMRBTree}
when they combined RCU with STM\@.
In both cases, the weak atomicity is implemented in software rather than
in hardware.
It would nevertheless be interesting to see what additional speedups
could be obtained by implementing weak atomicity in both hardware and
software.

\subsection{Conclusions}
\label{sec:future:Conclusions}

Although current HTM implementations have delivered real performance
benefits in some situations, they also have significant shortcomings.
The most significant shortcomings appear to be
limited transaction sizes,
the need for conflict handling, the need for aborts and rollbacks,
the lack of forward-progress guarantees,
the inability to handle irrevocable operations,
and subtle semantic differences
from locking.

Some of these shortcomings might be alleviated in future implementations,
but it appears that there will continue to be a strong need to make
HTM work well with the many other types of synchronization mechanisms,
as noted earlier~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener}.
Although there has been some work using HTM with
RCU~\cite{Siakavaras2017CombiningHA,DimitriosSiakavaras2020RCU-HTM-B+Trees,ChristinaGiannoula2018HTM-RCU-graphcoloring,SeongJaePark2020HTMRCUlock},
there has been little evidence of progress towards HTM work better with
RCU and with other deferred-reclamation mechanisms.

In short, current HTM implementations appear to be welcome and useful
additions to the parallel programmer's toolbox, and much interesting
and challenging work is required to make use of them.
However, they cannot be
considered to be a magic wand with which to wave away all parallel-programming
problems.
