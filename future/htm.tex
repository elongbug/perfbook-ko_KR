% future/htm.tex

\section{Hardware Transactional Memory}
\label{sec:future:Hardware Transactional Memory}

2017 년에 이르러, 하드웨어 트랜잭셔널 메모리 (HTM) 이 상품으로 구입할 수
있는 흔한 컴퓨터 시스템들 일부에도 도입되기 시작하고 있습니다.
이 섹션은 병렬 프로그래머의 도구상자에 이 하드웨어 트랜잭셔널 메모리가 위치할
자리를 알아보기 위한 시도를 해 봅니다.

개념적 관점에서, HTM 은 명시된 명령문의 그룹 (하나의 ``트랜잭션'') 을 다른
프로세서에서 수행되는 모든 다른 트랜잭션들의 시야에 원자적으로 보이도록 그
효과를 만들기 위해 프로세서 캐시와 예측적 수행을 사용합니다.
이 트랜잭션은 begin-transaction 기계 인스트럭션을 통해 초기화 되고
commit-transaction 기계 인스트럭션을 통해 완료됩니다.
일반적으로 abort-transaction 기계 인스트럭션도 존재하는데, 이는
(begin-transaction 인스트럭션과 그를 뒤따른 인스트럭션들이 수행되지 않은
것처럼) 예측적 수행 내용을 짓이기고 failure handler 의 수행을 시작합니다.
이 failure handler 의 위치는 begin-transaction 인스트럭션에 의해서 명시적인
failure-handler 의 주소를 통해서든 또는 해당 인스트럭션 자체의 조건적 코드에
의해서든 주어집니다.
각각의 트랜잭션은 모든 다른 트랜잭션에 대해 어토믹하게 수행됩니다.
\iffalse

As of 2017, hardware transactional memory (HTM) is available on several
types of commercially available commodity computer systems.
This section makes a first attempt to find its place in the parallel
programmer's toolbox.

From a conceptual viewpoint, HTM uses processor caches and speculative
execution to make a designated group of statements (a ``transaction'')
take effect atomically
from the viewpoint of any other transactions running on other processors.
This transaction is initiated by a
begin-transaction machine instruction and completed by a commit-transaction
machine instruction.
There is typically also an abort-transaction machine instruction, which
squashes the speculation (as if the begin-transaction instruction and
all following instructions had not executed) and commences execution
at a failure handler.
The location of the failure handler is typically specified by the
begin-transaction instruction, either as an explicit failure-handler
address or via a condition code set by the instruction itself.
Each transaction executes atomically with respect to all other transactions.
\fi

HTM 은 여러가지 중요한 장점을 갖는데, 데이터 구조의 자동적인 동적 분할, 동기화
기능의 캐시 미스의 감소, 그리고 상당수의 실용적 어플리케이션의 지원 등이 이런
장점에 포함됩니다.

하지만, 항상 작은 문자로 인쇄된 부분을 읽어야 하고, HTM 역시 예외가 아닙니다.
이 섹션의 중요한 요점은 어떤 조건 하에서 HTM 의 장점들이 그것의 작은 문자로
인쇄된 내용에 감추어져 있는 복잡성을 앞서는가를 결정하는 것입니다.
이런 결론 아래,
Section~\ref{sec:future:HTM Benefits WRT to Locking}
은 HTM 의 장점을 설명하고
Section~\ref{sec:future:HTM Weaknesses WRT Locking}
은 그 단점들을 설명합니다.
이는 이전의 논문들~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener}
에서 취해진 것과 같은 방법입니다만, 전체적으로 TM 보다는 HTM 에 초점을
맞춥니다.\footnote{
	그리고 저는 다른 저자들인 Maged Michael, Josh Triplett, Jonathan
	Walpole, 그리고 Andi Kleen  과의 자극적인 토론들에 기꺼이 감사를
	드립니다.}
\iffalse

HTM has a number of important benefits, including automatic
dynamic partitioning of data structures, reducing synchronization-primitive
cache misses, and supporting a fair number of practical applications.

However, it always pays to read the fine print, and HTM is no exception.
A major point of this section is determining under what conditions HTM's
benefits outweigh the complications hidden in its fine print.
To this end, Section~\ref{sec:future:HTM Benefits WRT to Locking}
describes HTM's benefits and
Section~\ref{sec:future:HTM Weaknesses WRT Locking} describes its weaknesses.
This is the same approach used in earlier
papers~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener},
but focused on HTM rather than TM as a whole.\footnote{
	And I gratefully acknowledge many stimulating
	discussions with the other authors, Maged Michael, Josh Triplett,
	and Jonathan Walpole, as well as with Andi Kleen.}
\fi

이어서
Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}
은 리눅스 커널에서 (그리고 일부 user-space 어플리케이션에서) 사용되는 동기화
도구들의 조합과 관련해서 HTM 의 단점을 설명합니다.
Section~\ref{sec:future:Where Does HTM Best Fit In?}
은 병렬 프로그래머의 도구상자에서 어다에 HTM 이 가장 잘 어울릴지를 알아보고,
Section~\ref{sec:future:Potential Game Changers}
은 HTM 의 범위와 매력을 상당히 증가시킬 수 있을 몇가지 사건들을 나열합니다.
마지막으로,
Section~\ref{sec:future:Conclusions}
에서는 결론을 내립니다.
\iffalse

Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented} then describes
HTM's weaknesses with respect to the combination of synchronization
primitives used in the Linux kernel (and in some user-space applications).
Section~\ref{sec:future:Where Does HTM Best Fit In?} looks at where HTM
might best fit into the parallel programmer's toolbox, and
Section~\ref{sec:future:Potential Game Changers} lists some events that might
greatly increase HTM's scope and appeal.
Finally, Section~\ref{sec:future:Conclusions}
presents concluding remarks.
\fi

\subsection{HTM Benefits WRT to Locking}
\label{sec:future:HTM Benefits WRT to Locking}

HTM 의 주된 장점들은 (1)~다른 동기화 기능들에 의해 종종 일어나는 캐시 미스의
제거, (2)~동적으로 데이터 구조를 파티셔닝 하는 능력, (3)~상당한 수의 실용적
어플리케이션이 존재한다는 사실입니다.
저는 두가지 이유로 TM 의 전통과 달리 사용의 편의성을 별도로 열거하지 않습니다.
첫째로, 사용의 편의성은 이 섹션이 초점을 맞추고 있는, HTM 의 주요 장점으로부터
기인합니다.
둘째, 날 프로그래밍 재능을 위한 테스트를 하려는 시도를
둘러싼~\cite{RichardBornat2006SheepGoats,SaeedDehnadi2009SheepGoats}, 그리고
심지어 취직을 위한 면접에서의 작은 프로그래밍 연습문제의 사용을
둘러싼~\cite{RegBraithwaite2007FizzBuzz} 상당한 논쟁이 존재했습니다.
이는 우리가 무엇이 프로그래밍을 쉽게 하고 어렵게 하는지에 대한 진정한 이해를
가지고 있지 못함을 의미합니다.
따라서, 이 섹션은 앞서 나열한 세개의 장점에 대해서만, 각각 뒤의 섹션들에서
초점을 맞추도록 하겠습니다.
\iffalse

The primary benefits of HTM are
(1)~its avoidance of the cache misses that are often incurred by
other synchronization primitives,
(2)~its ability to dynamically partition
data structures,
and (3)~the fact that it has
a fair number of practical applications.
I break from TM tradition by not listing ease of use separately
for two reasons.
First, ease of use should stem from HTM's primary benefits,
which this section focuses on.
Second, there has been considerable controversy surrounding attempts to
test for raw programming
talent~\cite{RichardBornat2006SheepGoats,SaeedDehnadi2009SheepGoats}
and even around the use of small programming exercises in job
interviews~\cite{RegBraithwaite2007FizzBuzz}.
This indicates that we really do not have a grasp on what makes
programming easy or hard.
Therefore, this section focuses on the three benefits listed above,
each in one of the following sections.
\fi

\subsubsection{Avoiding Synchronization Cache Misses}
\label{sec:future:Avoiding Synchronization Cache Misses}

대부분의 동기화 메커니즘들은 어토믹 인스트럭션으로 조정되는 데이터 구조에
기반합니다.
일반적으로 이 어토믹 인스트럭션들은 먼저 연관된 캐시 라인이 수행되고 있는 CPU
에 의해 소유되도록 하기 때문에, 다른 CPU 에서 같은 동기화 기능 인스턴스의
수행을 뒤따라 하게 되면, 캐시 미스를 초래하게 됩니다.
이러한 통신으로 인한 캐시 미스 이벤트들은 전통적인 동기화 메커니즘들의 성능과
확장성을 상당히 ㄸ러어뜨립니다~\cite[Section 4.2.3]{Anderson97}.
\iffalse

Most synchronization mechanisms are based on data structures that are
operated on by atomic instructions.
Because these atomic instructions normally operate by first causing
the relevant cache line to be owned by the CPU that they are running on,
a subsequent execution
of the same instance of that synchronization primitive on some other
CPU will result in a cache miss.
These communications cache misses severely degrade both the performance and
scalability of conventional synchronization
mechanisms~\cite[Section 4.2.3]{Anderson97}.
\fi

반면에, HTM 은 CPU 의 캐시를 사용해서 동기화를 하므로 동기화 데이터 구조의
필요와 그로 말미암은 캐시 미스가 없습니다.
HTM 의 장점은 락 데이터 구조가 별개의 캐시 라인에 위치해 있을 때에 극대화
되는데, 크리티컬 섹션을 HTM 트랜잭션으로 변환함으로써 전체 캐시 미스로 인한
크리티컬 섹션의 오버헤드를 줄여주는 경우가 그런 경우입니다.
이런 이득은 짧은 크리티컬 섹션을 갖는 흔한 경우에 특히 클 수 있으며, 최소한
생략된 락이 그 락에 의해 보호되는, 자주 쓰여지는 변수와 캐시 라인을 공유하지
않을 때의 상황에서는 그렇습니다.
\iffalse

In contrast, HTM synchronizes by using the CPU's cache, avoiding the need
for a synchronization data structure and resultant cache misses.
HTM's advantage is greatest in cases where a lock data structure is
placed in a separate cache line, in which case, converting a given
critical section to an HTM transaction can reduce that critical section's
overhead by a full cache miss.
These savings can be quite significant for the common case of short
critical sections, at least for those situations where the elided lock
does not share a cache line with an oft-written variable protected by
that lock.
\fi

\QuickQuiz{}
	해당 락 변수와 캐시 라인을 공유하는, 자주 쓰여지는 변수가 왜
	문제가 될까요?
	\iffalse

	Why would it matter that oft-written variables shared the cache
	line with the lock variable?
	\fi
\QuickQuizAnswer{
	락이 그것이 보호하는 변수와 같은 캐시라인에 있다면, 하나의 CPU 에 의한
	그 변수들로의 쓰기는 모든 다른 CPU 들에 있는 그 캐시 라인을 무효화
	시킵니다.
	이런 무효화는 많은 충돌과 재시도를 만들어내고, 심지어 락킹에 비해
	성능과 확장성을 떨어뜨릴 수도 있을 겁니다.
	\iffalse

	If the lock is in the same cacheline as some of the variables
	that it is protecting, then writes to those variables by one CPU
	will invalidate that cache line for all the other CPUs.
	These invalidations will
	generate large numbers of conflicts and retries, perhaps even
	degrading performance and scalability compared to locking.
	\fi
} \QuickQuizEnd

\subsubsection{Dynamic Partitioning of Data Structures}
\label{sec:future:Dynamic Partitioning of Data Structures}

일부 전통적 동기화 메커니즘의 사용에 대한 주요한 방해는 정적으로 데이터 구조를
분할해야 하는 필요성입니다.
간단하게 분할될 수 있는 데이터 구조들이 여럿 존재하는데, 유명한 예로 해시
테이블이 존재하는데, 여기서는 각각의 해시 체인이 하나의 파티션을 구성하게
됩니다.
각각의 해시 체인을 위한 락을 할당하는 것으로 해시 테이블을 해당 체인에 국한된
오퍼레이션들로 병렬화 시키게 됩니다.\footnote{
	그리고 이 방법을 여러 해시 체인에 접근하는 오퍼레이션들로 그런
	오퍼레이션들이 연관된 체인들을 위한 락들을 해시 순서대로 모두 잡도록
	하는 것으로 쉽게 확장할 수 있습니다.}
배열, radix tree, 그리고 일부 다른 데이터 구조들에 대해서도 파티셔닝은 비슷하게
간단합니다.
\iffalse

A major obstacle to the use of some conventional synchronization mechanisms
is the need to statically partition data structures.
There are a number of data structures that are trivially
partitionable, with the most prominent example being hash tables,
where each hash chain constitutes a partition.
Allocating a lock for each hash chain then trivially parallelizes
the hash table for operations confined to a given chain.\footnote{
	And it is also easy to extend this scheme to operations accessing
	multiple hash chains by having such operations acquire the
	locks for all relevant chains in hash order.}
Partitioning is similarly trivial for arrays, radix trees, and a few
other data structures.
\fi

하지만, 많은 종류의 tree 와 graph 에 있어 파티셔닝은 상당히 어렵고, 그 결과는
종종 복잡합니다~\cite{Ellis80}.
일반적인 데이터 구조를 파티셔닝 하는데에 two-phased 락킹과 해시된 락 배열들을
사용하는 것도 가능하지만, 다른 방법들이 더
선호되었는데~\cite{DavidSMiller2006HashedLocking}, 이것들은
Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}
에서 논의될 겁니다.
동기화 캐시 미스의 제거를 놓고 볼 때, HTM 은 최소한 상대적으로 적은 업데이트를
가정하면 커다란 파티셔닝 불가능한 데이터 구조를 위한 그럴싸한 방법입니다.
\iffalse

However, partitioning for many types of trees and graphs is quite
difficult, and the results are often quite complex~\cite{Ellis80}.
Although it is possible to use two-phased locking and hashed arrays
of locks to partition general data structures, other techniques
have proven preferable~\cite{DavidSMiller2006HashedLocking},
as will be discussed in
Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}.
Given its avoidance of synchronization cache misses,
HTM is therefore a very real possibility for large non-partitionable
data structures, at least assuming relatively small updates.
\fi

\QuickQuiz{}
	HTM 성능과 확장성에 상대적으로 적은 업데이트가 중요한 이유가 뭐죠?
	\iffalse

	Why are relatively small updates important to HTM performance
	and scalability?
	\fi
\QuickQuizAnswer{
	업데이트가 많을수록, 충돌의 가능성이 커지고, 따라서 재시도의 가능성이
	커져서 성능이 하락됩니다.
	\iffalse

	The larger the updates, the greater the probability of conflict,
	and thus the greater probability of retries, which degrade
	performance.
	\fi
} \QuickQuizEnd

\subsubsection{Practical Value}
\label{sec:future:Practical Value}

HTM 의 실질적 가치에 대한 몇몇 증거들이 Sun
Rock~\cite{DaveDice2009ASPLOSRockHTM} 와 Azul Vega~\cite{CliffClick2009AzulHTM}
을 포함한 여러 하드웨어 플랫폼들에서 보여졌습니다.
실질적 이점들이 더 최신의 IBM Blue Gene/Q, Intel Haswell TSX, 그리고 AMD ASF
시스템들에서도 나올 것이라 가정하는 것은 합리적입니다.

예상되는 실질적 이점들은 다음과 같습니다:
\iffalse

Some evidence of HTM's practical value has been demonstrated in a number
of hardware platforms, including
Sun Rock~\cite{DaveDice2009ASPLOSRockHTM} and
Azul Vega~\cite{CliffClick2009AzulHTM}.
It is reasonable to assume that practical benefits will flow from the
more recent IBM Blue Gene/Q, Intel Haswell TSX, and AMD ASF systems.

Expected practical benefits include:
\fi

\begin{enumerate}
\item	In-memory 데이터 액세스와 업데이트를 위한 락
	생략~\cite{Martinez01a,Rajwar02a}.
\item	커다란 파티셔닝 불가능한 데이터 구조로의 동시적인 액세스와 약간의
	무작위적 업데이트들.
\iffalse

\item	Lock elision for in-memory data access and
	update~\cite{Martinez01a,Rajwar02a}.
\item	Concurrent access and small random updates to large non-partitionable
	data structures.
\fi
\end{enumerate}

하지만, HTM 은 또한 실질적인 한계점들도 가지고 있는데, 이에 대해서는 다음
섹션에서 이야기 하겠습니다.
\iffalse

However, HTM also has some very real shortcomings, which will be discussed
in the next section.
\fi

\subsection{HTM Weaknesses WRT Locking}
\label{sec:future:HTM Weaknesses WRT Locking}

HTM 의 컨셉은 상당히 간단합니다: 메모리로의 액세스와 업데이트가 그룹 단위로
어토믹하게 일어난다는 것입니다.
하지만, 많은 간단한 아이디어들이 그러하듯이, 이를 실제 세계의 실제 시스템에
적용할 때에서야 복잡성이 나타납니다.
이 복잡성들은 다음과 같은 것들입니다:
\iffalse

The concept of HTM is quite simple: A group of accesses and updates to
memory occurs atomically.
However, as is the case with many simple ideas, complications arise
when you apply it to real systems in the real world.
These complications are as follows:
\fi

\begin{enumerate}
\item	트랜잭션 크기 한계.
\item	Conflict 처리.
\item	Abort 와 롤백.
\item	진행 보장의 부재.
\item	되돌이킬 수 없는 오퍼레이션들.
\item	Semantic 상의 차이점들.
\iffalse

\item	Transaction-size limitations.
\item	Conflict handling.
\item	Aborts and rollbacks.
\item	Lack of forward-progress guarantees.
\item	Irrevocable operations.
\item	Semantic differences.
\fi
\end{enumerate}

이 각각의 복잡성들은 다음의 섹션들에서 다루어지고, 그 뒤를 이어 요약을 합니다.
\iffalse

Each of these complications is covered in the following sections,
followed by a summary.
\fi

\subsubsection{Transaction-Size Limitations}
\label{sec:future:Transaction-Size Limitations}

현재 HTM 구현들의 트랜잭션 크기 한계점은 그 트랜잭션에 영향받는 데이터를 쥐고
있기 위해 프로세서의 캐시를 사용한다는 데서 나옵니다.
이는 특정 CPU 가 트랜잭션을 자신의 캐시 안에 국한된 채로 수행시켜서 해당
트랜잭션이 다른 CPU 들에게 어토믹 하게 보이도록 하는 것을 가능하게 하지만, 이는
또한 캐시에 들어가지 않는 모든 트랜잭션은 abort 될것을 의미하기도 합니다.
더 나아가서, 인터럽트, 시스템 콜, exception, trap, 그리고 컨텍스트 스위치와
같이 수행 문맥을 바꾸는 이벤트들은 해당 CPU 에서 수행중인 트랜잭션을 모두 abort
시키거나 다른 수행 컨텍스트에 의한 캐시 사용량으로 인해 트랜잭션의 크기를
제한해야만 합니다.

물론, 최신 CPU 들은 커다란 캐시를 갖는 경향이 있고, 많은 트랜잭션들에 필요한
데이터는 1 메가바이트 캐시 안에도 잘 들어갈 겁니다.
불행히도, 캐시에 있어서, 크기만이 모든 문제는 아닙니다.
문제는, 대부분의 캐시들은 하드웨어로 구현된 해시 테이블로 생각될 수 있다는
것입니다.
하지만, 하드웨어 캐시는 (일반적으로 \emph{set} 이라 불리는) 버킷들을 연결시키지
않고, set 당 고정된 수의 캐시라인들을 제공합니다.
특정 캐시에서 각각의 set 에 제공되는 원소들의 수는 해당 캐시의
\emph{associativity} 라고 불립니다.
\iffalse

The transaction-size limitations of current HTM implementations
stem from the use of the processor caches to hold the data
affected by the transaction.
Although this allows a given CPU to make the transaction appear atomic to
other CPUs by executing the transaction within the confines of its cache,
it also means that any transaction that does not fit must be aborted.
Furthermore, events that change execution context, such as interrupts,
system calls, exceptions, traps, and context switches either must
abort any ongoing transaction on the CPU in question or must further
restrict transaction size due to the cache footprint of the other
execution context.

Of course, modern CPUs tend to have large caches, and the data required
for many transactions would fit easily in a one-megabyte cache.
Unfortunately, with caches, sheer size is not all that matters.
The problem is that most caches
can be thought of hash tables implemented in hardware.
However, hardware caches do not chain their buckets (which are normally
called \emph{sets}), but rather
provide a fixed number of cachelines per set.
The number of elements provided for each set in a given cache
is termed that cache's \emph{associativity}.
\fi

Cache associativity 는 다양하지만, 제가 지금 타자를 치고 있는 랩탑의 8-way
associativity level-0 캐시는 흔하지 않습니다.
이게 의미하는바는 특정 트랜잭션이 9개의 캐시 라인을 건드리게 되고, 그 9개의
캐시 라인들이 모두 같은 set 으로 매핑된다면, 그 트랜잭션은 해당 캐시에 얼마나
많은 메가바이트의 용량들이 남아있는가에 관계없이 성공할 수 없다는 것입니다.
그렇습니다, 특정 데이터 구조에서 무작위적으로 골라진 데이터 원소들에 있어서, 그
트랜잭션이 커밋에 성공할 확률은 매우 높긴 합니다만, 어떤 보장사항도 없습니다.

이 한계점을 경감시키기 위한 일부 연구들이 있었습니다.
Fully associative \emph{victim cache} 는 associativity 한계를 경감시킬 수
있습니다만, victim cache 의 성능과 에너지 효율성에 대한 많은 한계가 현재
존재합니다.
그렇다고는 하나, 수정되지 않은 캐시 라인들을 위한 HTM victim cache 는 주소만을
가지고 있을 수도 있으므로, 상당히 작을 수 있습니다:
데이터 주소 자체는 충돌되는 쓰기를 파악하기에 충분하며~\cite{RaviRajwar2012TSX}
데이터 자체는 메모리에 쓰여지거나 다른 캐시에 shadow 될수 있습니다.
\iffalse

Although cache associativity varies, the eight-way associativity of
the level-0 cache on the laptop I am typing this on is not unusual.
What this means is that if a given transaction needed to touch
nine cache lines, and if all nine cache lines mapped to the same
set, then that transaction cannot possibly complete, never mind how
many megabytes of additional space might be available in that cache.
Yes, given randomly selected data elements in a given data structure,
the probability of that transaction being able to commit is quite
high, but there can be no guarantee.

There has been some research work to alleviate this limitation.
Fully associative \emph{victim caches} would alleviate the associativity
constraints, but there are currently stringent performance and
energy-efficiency constraints on the sizes of victim caches.
That said, HTM victim caches for unmodified cache lines can be quite
small, as they need to retain only the address:
The data itself can be written to memory or shadowed by other caches,
while the address itself is sufficient to detect a conflicting
write~\cite{RaviRajwar2012TSX}.
\fi

\emph{Unbounded transactional memory} (UTM)
방법~\cite{CScottAnanian2006,KevinEMoore2006} 은 DRAM 을 극단적으로 커다란
victim cache 로 사용합니다만, 그런 방법을 제품 품질의 캐시 일관성 메커니즘과
결합하는 것은 여전히 해결되지 않은 문제입니다.
또한, DRAM 을 victim cache 로 사용하는 것은 성능과 에너지 효율성의 저하를
가져올 수 있는데, victim cache 가 fully associative 하다면 특히 그렇습니다.
마지막으로, UTM 의 ``unbounded'' 라는 측면은 DRAM 이 모두 victim cache 로
사용될 수 있다는 가정을 합니다만, 실제로는 커다랗긴 하지만 고정된 양의, 해당
CPU 에 주어진 DRAM 의 용량만으로 해당 CPU 의 트랜잭션의 크기가 제한될 겁니다.
다른 방법들은 하드웨어 트랜잭셔널 메모리와 소프트웨어 트랜잭셔널 메모리의
조합을 사용하고~\cite{SanjeevKumar2006}, HTM 의 fallback 메커니즘으로 STM 을
사용하는 방법을 생각해 볼 수도 있을 겁니다.

하지만, 제가 알기로는, 현재로써 사용 가능한 시스템들은 이런 연구 아이디어들을
구현한 바가 없습니다.
\iffalse

\emph{Unbounded transactional memory} (UTM)
schemes~\cite{CScottAnanian2006,KevinEMoore2006}
use DRAM as an extremely large victim cache, but integrating such schemes
into a production-quality cache-coherence mechanism is still an unsolved
problem.
In addition, use of DRAM as a victim cache may have unfortunate
performance and energy-efficiency consequences, particularly
if the victim cache is to be fully associative.
Finally, the ``unbounded'' aspect of UTM assumes that all of DRAM
could be used as a victim cache, while in reality
the large but still fixed amount of DRAM assigned to a given CPU
would limit the size of that CPU's transactions.
Other schemes use a combination of hardware and software transactional
memory~\cite{SanjeevKumar2006} and one could imagine using STM as a
fallback mechanism for HTM.

However, to the best of my knowledge, currently available systems do
not implement any of these research ideas, and perhaps for good reason.
\fi

\subsubsection{Conflict Handling}
\label{sec:future:Conflict Handling}

첫번째 문제는 \emph{conflict} 의 가능성입니다.
예를 들어, transaction~A 와~B 가 다음과 같이 정의되었다고 생각해 봅시다:
\iffalse

The first complication is the possibility of \emph{conflicts}.
For example, suppose that transactions~A and~B are defined as follows:
\fi

\vspace{5pt}
\begin{minipage}[t]{\columnwidth}
\begin{verbatim}
Transaction A       Transaction B

x = 1;              y = 2;
y = 3;              x = 4;
\end{verbatim}
\end{minipage}
\vspace{5pt}

각각의 트랜잭션이 각자의 프로세서 위에서 동시에 수행된다고 생각해 봅시다.
만약 transaction~A 가 \co{x} 에 쓰기를 하는 동시에 transaction~B 가 \co{y} 에
쓰기를 한다면, 두 트랜잭션 모두 진행될 수 없습니다.
이를 보기 위해, transaction~A 가 \co{y} 로의 쓰기를 수행한다고 생각해 봅시다.
그럼 transaction~A 는 transaction~B 와 섞여들어가게 되는데, 이는 트랜잭션이
상대방의 시점에 어토믹하게 수행되어야 한다는 트랜잭션의 요구사항을 위반하는
것입니다.
Transaction~B 가 \co{x} 로의 저장을 수행하게 허락한다면, 이는 비슷하게 어토믹
수행 요구사항을 위반하는 것입니다.
이 상황은 \emph{conflict} 라 명명되는데, 두개의 동시에 수행되는 트랜잭션들이
똑같은 변수에 접근하게 되며 그 접근들 가운데 최소한 하나는 쓰기인 경우에
발생합니다.
따라서 시스템은 수행이 진행될 수 있도록 하기 위해 이 트랜잭션들 가운데 하나나
두개 모두를 abort 시킬 의무를 갖습니다.
정확히 어떤 트랜잭션을 abort 시킬 것인가에 대한 선택은 Ph.D. 학위논문을 만들
능력이 있을 만큼 흥미로운 주제인데, 그런 예~\cite{EgeAkpinar2011HTM2TLE}도
있으니, 보시기 바랍니다.\footnote{
	``Toxic Transactions'' 라는 제목의 Liu 와 Spear 의
	논문~\cite{YujieLiu2011ToxicTransactions}  은 이런 면에서 특히
	유명합니다.}
이 섹션의 목적을 위해서, 우린 시스템이 무작위적 선택을 한다고 가정하겠습니다.
\iffalse

Suppose that each transaction executes concurrently on its own processor.
If transaction~A stores to \co{x} at the same time that transaction~B
stores to \co{y}, neither transaction can progress.
To see this, suppose that transaction~A executes its store to \co{y}.
Then transaction~A will be interleaved within transaction~B, in violation
of the requirement that transactions execute atomically with respect to
each other.
Allowing transaction~B to execute its store to \co{x} similarly violates
the atomic-execution requirement.
This situation is termed a \emph{conflict}, which happens whenever two
concurrent transactions access the same variable where at least one of
the accesses is a store.
The system is therefore obligated to abort one or both of the transactions
in order to allow execution to progress.
The choice of exactly which transaction to abort is an interesting topic
that will very likely retain the ability to generate Ph.D. dissertations for
some time to come, see for
example~\cite{EgeAkpinar2011HTM2TLE}.\footnote{
	Liu's and Spear's paper entitled ``Toxic
	Transactions''~\cite{YujieLiu2011ToxicTransactions} is
	particularly instructive in this regard.}
For the purposes of this section, we can assume that the system makes
a random choice.
\fi

또하나의 문제는 conflict 파악으로, 적어도 가장 간단한 경우에 있어서는 비교적
간단한 편입니다.
프로세서가 트랜잭션을 수행할 때, 프로세서는 그 트랜잭션에 의해 접근되는 모든
캐시라인을 표시해 둡니다.
만약 이 프로세서의 캐시가 현재 트랜잭션에 의해 접근된 것으로 표시된 캐시라인에
대한 요청을 받게 되면, 잠재적 conflcit 이 일어난 것입니다.
더 세련된 시스템들은 현재 프로세서의 트랜잭션이 그 요청을 보낸 프로세서의
트랜잭션을 앞서도록 순서잡을 것이고, 이 프로세스의 최적화는 또한 Ph.D.
학위논문을 쓰기 위한 능력을 얻을 수 있게 해줄 겁니다.
하지만 이 섹션은 매우 간단한 conflict 파악 전략을 가정합니다.
\iffalse

Another complication is conflict detection, which is comparatively
straightforward, at least in the simplest case.
When a processor is executing a transaction, it marks every cache line
touched by that transaction.
If the processor's cache receives a request involving a cache line that
has been marked as touched by the current transaction, a potential
conflict has occurred.
More sophisticated systems might try to order the current processors'
transaction to precede that of the processor sending the request,
and optimization of this process will likely also retain the ability
to generate Ph.D. dissertations for quite some time.
However this section assumes a very simple conflict-detection strategy.
\fi

하지만, HTM 이 효율적으로 동작하려면 conflict 의 가능성이 충분히 낮아야 하는데,
이는 데이터 구조가 충분히 낮은 conflict 가능성을 유지하도록 구성되어야 할것을
필요로 합니다.
예를 들어, 간단한 삽입, 삭제, 그리고 탐색 오퍼레이션을 제공하는 red-black
트리는 이런 경우에 적합합니다만, 트리의 모든 원소의 정확한 수를 유지해야 하는
red-black 트리는 그렇지 않습니다.\footnote{
	이 수를 업데이트 해야할 필요성이 트리로의 삽입과 트리로부터의 삭제가
	서로 conflict 를 발생시키게 해서 strong non-commutativity 를 초래할
	겁니다~\cite{HagitAttiya2011LawsOfOrder,Attiya:2011:LOE:1925844.1926442,PaulEMcKenney2011SNC}.}
또다른 예로, 트리의 모든 원소를 하나의 트랜잭션에서 열거하는 red-black 트리는
높은 conflict 확률을 가질 것이고, 성능과 확장성을 떨어뜨릴 겁니다.
결과적으로, 많은 순차적 프로그램들은 HTM 이 효과적으로 동작하도록 하기 위해
일부 재구성을 필요로 할 겁니다.
몇몇 경우에 있어서, 실무자들은 그런 추가적 단계를 취하거나 (red-black 트리의
경우에 있어서, radix 트리나 해시 테이블과 같은 파티셔닝 가능한 데이터 구조로의
전환 같은) 그냥 락킹을 사용하는 것을 선호할 수 있는데, HTM 이 모든 관련된
구조에서 사용 가능하기 충분한 시간이 오기 전까지는 특히 그럴 수
있습니다~\cite{CliffClick2009AzulHTM}.
\iffalse

However, for HTM to work effectively, the probability of conflict must
be suitably low, which in turn requires that the data structures
be organized so as to maintain a sufficiently low probability of conflict.
For example, a red-black tree with simple insertion, deletion, and search
operations fits this description, but a red-black
tree that maintains an accurate count of the number of elements in
the tree does not.\footnote{
	The need to update the count would result in additions to and
	deletions from the tree conflicting with each other, resulting
	in strong non-commutativity~\cite{HagitAttiya2011LawsOfOrder,Attiya:2011:LOE:1925844.1926442,PaulEMcKenney2011SNC}.}
For another example, a red-black tree that enumerates all elements in
the tree in a single transaction will have high conflict probabilities,
degrading performance and scalability.
As a result, many serial programs will require some restructuring before
HTM can work effectively.
In some cases, practitioners will prefer to take the extra steps
(in the red-black-tree case, perhaps switching to a partitionable
data structure such as a radix tree or a hash table), and just
use locking, particularly during the time before HTM is readily available
on all relevant
architectures~\cite{CliffClick2009AzulHTM}.
\fi

\QuickQuiz{}
	동기화 메커니즘의 선택에 관계 없이 어떻게 red-black 트리가 트리 내의
	모든 원소의 열거를 효율적으로 할 수 있을까요???
	\iffalse

	How could a red-black tree possibly efficiently enumerate all
	elements of the tree regardless of choice of synchronization
	mechanism???
	\fi
\QuickQuizAnswer{
	많은 경우에, 이 열거는 정확하지 않아도 좋습니다.
	이런 경우들에 있어서, hazard pointer 나 RCU 가 특정한 삽입이나 삭제와의
	낮은 conflict 확률을 유지하면서 읽기 쓰레드들을 보호하는데 사용될 수
	있습니다.
	\iffalse

	In many cases, the enumeration need not be exact.
	In these cases, hazard pointers or RCU may be used to protect
	readers with low probability of conflict with any given insertion
	or deletion.
	\fi
} \QuickQuizEnd

더 나아가서, conflict 이 일어날 수 있다는 사실은 다음 섹션에 이야기되는 것처럼
failure 처리를 어떻게 할 것인지 그림을 가져올 수 있게 해줍니다.
\iffalse

Furthermore, the fact that conflicts can occur brings failure handling
into the picture, as discussed in the next section.
\fi

\subsubsection{Aborts and Rollbacks}
\label{sec:future:Aborts and Rollbacks}

모든 트랜잭션이 언제든 abort 될 수 있으므로, 트랜잭션은 롤백될 수 없는 명령을
포함해선 안된다는 점이 중요합니다.
이 말은 트랜잭션은 I/O, 시스템콜, 또는 디버깅 브레이크포인트 (HTM
트랜잭션에서의 디버거에서의 single step 수행이 안됩니다!!!) 를 가질 수 없음을
의미합니다.
대신, 트랜잭션은 스스로를 평범한 캐시된 메모리에만 접근하도록 국한시켜야만
합니다.
더 나아가서, 일부 시스템에서는, 인터럽트, exception, trap, TLB 미스, 그리고
다른 이벤트들 역시 트랜잭션을 abort 시킵니다.
잘못된 에러 조건의 처리로 초래된 많은 수의 버그들을 생각해보면, 사용성을 위해
abort 와 rollback 이 어떤 효과를 갖는지 알아보는게 좋을 겁니다.
\iffalse

Because any transaction might be aborted at any time, it is important
that transactions contain no statements that cannot be rolled back.
This means that transactions cannot do I/O, system calls, or debugging
breakpoints (no single stepping in the debugger for HTM transactions!!!).
Instead, transactions must confine themselves to accessing normal
cached memory.
Furthermore, on some systems, interrupts, exceptions, traps,
TLB misses, and other events will also abort transactions.
Given the number of bugs that have resulted from improper handling
of error conditions, it is fair to ask what impact aborts and rollbacks
have on ease of use.
\fi

\QuickQuiz{}
	하지만 왜 디버거는 트랜잭션의 앞의 인스턴스의 스텝들을 다시 추적하기
	위해 재시도에 의조하면서 브레이크포인트를 트랜잭션의 성공되는 명령문
	줄에 설정해 두는 것으로 single stepping 을 흉내낼 수 없나요?
	\iffalse

	But why can't a debugger emulate single stepping by setting
	breakpoints at successive lines of the transaction, relying
	on the retry to retrace the steps of the earlier instances
	of the transaction?
	\fi
\QuickQuizAnswer{
	이 방법은 높은 확률로 동작할 수 있을 겁니다만, 대부분의 사용자들에게는
	상당히 놀라운 형태로 실패할 수 있습니다.
	이를 보기 위해, 다음 트랜잭션을 생각해 봅시다:
	\iffalse

	This scheme might work with reasonably high probability, but it
	can fail in ways that would be quite surprising to most users.
	To see this, consider the following transaction:
	\fi

	\vspace{5pt}
	\begin{minipage}[t]{\columnwidth}
	\small
\begin{verbatim}
  1 begin_trans();
  2 if (a) {
  3   do_one_thing();
  4   do_another_thing();
  5 } else {
  6   do_a_third_thing();
  7   do_a_fourth_thing();
  8 }
  9 end_trans();
\end{verbatim}
	\end{minipage}
	\vspace{5pt}

	사용자가 line~3 에 트랜잭션을 abort 시키고 디버거에 들어가게 될
	브레이크포인트를 설정했다고 생각해 봅시다.
	브레이크포인트가 시작되고 디버거가 모든 쓰레드를 정지시키는 사이에,
	어떤 다른 쓰레드가 \co{a} 의 값을 0으로 설정했다고 생각해 봅시다.
	사용자가 이 프로그램을 single-step 하면, 짜잔!
	프로그램은 이제 then-절 대신 else-절에 들어와 있습니다.

	이는 제가 사용성이 좋은 디버거라 부르는 것이 \emph{아닙니다}.
	\iffalse

	Suppose that the user sets a breakpoint at line~3, which triggers,
	aborting the transaction and entering the debugger.
	Suppose that between the time that the breakpoint triggers
	and the debugger gets around to stopping all the threads, some
	other thread sets the value of \co{a} to zero.
	When the poor user attempts to single-step the program, surprise!
	The program is now in the else-clause instead of the then-clause.

	This is \emph{not} what I call an easy-to-use debugger.
	\fi
} \QuickQuizEnd

물론, abort 와 롤백은 HTM 이 real-time 시스템에 유용할 수 있는 것인지라는
질문을 떠올리게 합니다.
HTM 의 성능적 이득이 abort 와 롤백의 비용을 넘을까요, 그리고 그렇다면 어떤 조건
하에서 그럴까요?
트랜잭션은 우선순위 향상 기능을 사용할 수 있을까요?
아니면 높은 우선순위 쓰레드를 위한 트랜잭션은 낮은 우선순위 쓰레드들을
우선적으로 abort 시켜야 할까요?
만약 그렇다면, 하드웨어는 어떻게 효율적으로 우선순위를 알 수 있을까요?
실제 세계에서의 HTM 의 사용에 대한 환경은 협소한데, 연구자들이 트랜잭션들이 비
real-time 환경에서 잘 동작하기에는 충분한 것들보다도 더 많은 문제들을 찾고 있기
때문일 수도 있습니다.
\iffalse

Of course, aborts and rollbacks raise the question of whether HTM can
be useful for hard real-time systems.
Do the performance benefits of HTM outweigh the costs of the aborts
and rollbacks, and if so under what conditions?
Can transactions use priority boosting?
Or should transactions for high-priority threads instead preferentially
abort those of low-priority threads?
If so, how is the hardware efficiently informed of priorities?
The literature on real-time use of HTM is quite sparse, perhaps because
researchers are finding more than enough problems in getting
transactions to work well in non-real-time environments.
\fi

현재의 HTM 구현들은 결정론적으로 특정 트랜잭션을 abort 시킬 수도 있기 때문에,
소프트웨어는 fallback 코드를 제공해야만 합니다.
이 fallback 코드는 예를 들면 락킹과 같은, 어떤 다른 형태의 동기화를 사용해야만
합니다.
만약 이 fallback 이 빈번하게 사용된다면, 데드락의 가능성을 포함한 모든 락킹의
제한점들이 다시 나타납니다.
물론, 이 fallback 이 자주 사용되지 않아서 더 간단하고 디드락이 나타나기 쉽지
않은 설계가 사용될 수 있게 되기를 바랄 수 있습니다.
하지만 이는 시스템은 락 기반의 fallback 에서 트랜잭션으로 어떻게 전환할
것인지에 대한 질문을 떠올리게 합니다.\footnote{
	어플리케이션이 fallback 모드에서 멈춰서게 되는 가능성은 Dave Dice 가
	만드는데 기여한, ``lemming effect'' 라고 명명되었습니다.}
한가지 방법은 test-and-test-and-set 방법~\cite{Martinez02a} 의 사용으로, 모두가
락이 해제될 때까지 기다림으로써 시스템이 트랜잭션적으로 깨끗한 백지 상태에서
시작할 수 있도록 하는 것입니다.
하지만, 이는 상당한 spinning 을 초래할 수 있는데, 이는 락을 쥔 쓰레드가
블락되어 있거나 preemption 당했다면 현명하지 못한 행위일 수 있습니다.
또다른 방법은 트랜잭션이 락을 쥔 쓰레드와 병렬적으로 수행될 수 있도록 하는
것~\cite{Martinez02a} 입니다만, 이 방법은 원자성을 유지하는데에 어려움을
낳으며, 특히 그 쓰레드가 락을 잡고 있는 이유가 연관된 트랜잭션이 캐시에
들어가지 않기 때문이라면 더 그렇습니다.
\iffalse

Because current HTM implementations might deterministically abort a
given transaction, software must provide fallback code.
This fallback code must use some other form of synchronization, for
example, locking.
If the fallback is used frequently, then all the limitations of locking,
including the possibility of deadlock, reappear.
One can of course hope that the fallback isn't used often, which might
allow simpler and less deadlock-prone locking designs to be used.
But this raises the question of how the system transitions from using
the lock-based fallbacks back to transactions.\footnote{
	The possibility of an application getting stuck in fallback
	mode has been termed the ``lemming effect'', a term that
	Dave Dice has been credited with coining.}
One approach is to use a test-and-test-and-set discipline~\cite{Martinez02a},
so that everyone holds off until the lock is released, allowing the
system to start from a clean slate in transactional mode at that point.
However, this could result in quite a bit of spinning, which might not
be wise if the lock holder has blocked or been preempted.
Another approach is to allow transactions to proceed in parallel with
a thread holding a lock~\cite{Martinez02a}, but this raises difficulties
in maintaining atomicity, especially if the reason that the thread is
holding the lock is because the corresponding transaction would not fit
into cache.
\fi

마지막으로, abort 와 롤백 가능성을 처리하는 것은 개발자에게 모든 가능한 에러
조건들의 조합을 올바르게 처리해야 한다는 추가적인 부담을 지우는 것으로 보일 수
있습니다.

HTM 의 사용자들이 fallback 코드 수행경로와 fallback 에서 트랜잭션 코드로의 전환
모두에 상당한 검증을 위한 노력을 기울여야 함은 분명합니다.
\iffalse

Finally, dealing with the possibility of aborts and rollbacks seems to
put an additional burden on the developer, who must correctly handle
all combinations of possible error conditions.

It is clear that users of HTM must put considerable validation effort
into testing both the fallback code paths and transition from fallback
code back to transactional code.
\fi

\subsubsection{Lack of Forward-Progress Guarantees}
\label{sec:future:Lack of Forward-Progress Guarantees}

트랜잭션 크기, conflict, 그리고 abort/rollback 이 모두 트랜잭션을 abort 되게
만들 수 있다고는 하지만, 충분히 작고 짧은 기간동안 수행되는 트랜잭션은 결국은
성공할 것이라 보장된다고 희망할 수 있을 것입니다.
이는 compare-and-swap (CAS) 와 load-linked/store-conditional (LL/SC)
오퍼레이션들이 이 인스트럭션들을 어토믹 오퍼레이션을 구현하는데에 사용하는
코드에서 무조건적으로 재시도 되는 것과 똑같이 트랜잭션이 무조건적으로 재시도
되도록 허용하도록 할 수 있을 것입니다.

불행히도, 대부분의 현재 사용 가능한 HTM 구현들은 어떤 종류의 진행 보장도
제공하지 않는데, 이는 HTM 은 시스템의 데드락을 막는데에 사용될 수 없음을
의미합니다.\footnote{
	HTM 은 데드락의 가능성을 줄이는데 사용될 수는 있습니다만, fallback
	코드가 수행될 가능성이 존재하는한, 데드락의 가능성은 존재합니다.}
미래의 HTM 구현은 어떤 진행 보장을 제공할 수도 있을 겁니다.
그러기 전까지는, HTM 은 real-time 어플리케이션은 상당한 주의 아래 사용되어야만
합니다.\footnote{
	2012년 중반까지는, 트랜잭셔널 메모리의 real-time 특성에 대해서는
	놀라만큼 적은 작업만이 있었습니다.}
\iffalse

Even though transaction size, conflicts, and aborts/rollbacks can all
cause transactions to abort, one might hope that sufficiently small and
short-duration transactions could be guaranteed to eventually succeed.
This would permit a transaction to be unconditionally retried, in the
same way that compare-and-swap (CAS) and load-linked/store-conditional
(LL/SC) operations are unconditionally retried in code that uses these
instructions to implement atomic operations.

Unfortunately, most currently available HTM implementation refuse to
make any
sort of forward-progress guarantee, which means that HTM cannot be
used to avoid deadlock on those systems.\footnote{
	HTM might well be used to reduce the probability of deadlock,
	but as long as there is some possibility of the fallback
	code being executed, there is some possibility of deadlock.}
Hopefully future implementations of HTM will provide some sort of
forward-progress guarantees.
Until that time, HTM must be used with extreme caution in real-time
applications.\footnote{
	As of mid-2012, there has been surprisingly little work on
	transactional memory's real-time characteristics.}
\fi

2013년에 있어 이 우울한 그림에 대한 한가지 예외는 특수한 \emph{제약된
트랜잭션}~\cite{ChristianJacobi2012MainframeTM} 을 시작하는데 사용되는 별도의
인스트럭션을 제공하는 IBM 메인프레임의 차기 버전들입니다.
이름에서 추측할 수 있듯이, 그런 트랜잭션은 다음과 같은 제약 아래에 살아남을 수
있어야만 합니다:
\iffalse

The one exception to this gloomy picture as of 2013 is upcoming versions
of the IBM mainframe, which provides a separate instruction that may be
used to start a special
\emph{constrained transaction}~\cite{ChristianJacobi2012MainframeTM}.
As you might guess from the name, such transactions must live within
the following constraints:
\fi

\begin{enumerate}
\item	각각의 트랜잭션의 데이터 사용량은 4개의 32-byte 메모리 블락 안에 들어갈
	수 있어야만 합니다.
\item	각각의 트랜잭션은 최대 32 개의 어셈블러 인스트럭션을 수행하도록
	허용됩니다.
\item	트랜잭션은 뒤로 돌아가는 브랜치 (e.x: 루프를 가질 수 없음) 를 가질 수
	없습니다.
\item	각각의 트랜잭션의 코드는 256 바이트의 메모리로 제한됩니다.
\item	특정 트랜잭션의 데이터 사용량의 한 부분이 4K 페이지 안에 위치한다면, 그
	4K 페이지는 트랜잭션의 인스트럭션을 담을 수 없습니다.
\iffalse

\item	Each transaction's data footprint must be contained within
	four 32-byte blocks of memory.
\item	Each transaction is permitted to execute at most 32 assembler
	instructions.
\item	Transactions are not permitted to have backwards branches
	(e.g., no loops).
\item	Each transaction's code is limited to 256 bytes of memory.
\item	If a portion of a given transaction's data footprint resides
	within a given 4K page, then that 4K page is prohibited from
	containing any of that transaction's instructions.
\fi
\end{enumerate}

이런 제약은 가혹합니다만, 이는 더도 아니고 덜도 아니고 스택, 큐, 해시 테이블,
등등을 포함해서 다양한 데이터 구조의 업데이트가 구현될 수 있도록 합니다.
이런 오퍼레이션들은 결국은 완료될 것이 보장되고, 따라서 데드락과 라이브락
조건으로부터 자유롭습니다.

시간의 흐름에 따라 하드웨어의 진행 보장이 얼마나 지우너될 것인지 보는 것은 꽤
흥미로울 것입니다.
\iffalse

These constraints are severe, but they nevertheless permit a wide variety
of data-structure updates to be implemented, including stacks, queues,
hash tables, and so on.
These operations are guaranteed to eventually complete, and are free of
deadlock and livelock conditions.

It will be interesting to see how hardware support of forward-progress
guarantees evolves over time.
\fi

\subsubsection{Irrevocable Operations}
\label{sec:future:Irrevocable Operations}

Abort 와 롤백의 또다른 결론은 HTM 트랜잭션은 되돌이켜질 수 없는 오퍼레이션들을
담을 수 없다는 것입니다.
현재의 HTM 구현들은 일반적으로 트랜잭션 안에서의 모든 액세스가 캐시될 수 있는
메모리 안으로만 국한되도록 하고 (따라서 MMIO 액세스를 금지하고) 인터럽트, trap,
그리고 exception 시에는 트랜잭션을 어보팅 시키는 것으로 (따라서 시스템콜을
금지시키는 것으로) 이 제한을 강제합니다.

HTM 트랜잭션은 buffered I/O 역시 버퍼의 fill/flush 오퍼레이션이 트랜잭션 외에서
일어나는 한은 담겨질 수 있음을 알아두시기 바랍니다.
이게 동작하는 이유는 버퍼에 데이터를 넣고 빼는 것은 되돌이켜질 수 있기
때문입니다: 실제 버퍼 fill/flush 오퍼레이션들만이 되돌이켜질 수 없습니다.
물론, 이 buffered-I/O 방법은 I/O 를 트랜잭션의 흔적에 포함시키는 효과를 내서,
트랜잭션의 크기를 키우고 그로 인해 트랜잭션 실패 확률을 증가시킵니다.
\iffalse

Another consequence of aborts and rollbacks is that HTM transactions
cannot accommodate irrevocable operations.
Current HTM implementations typically enforce this limitation by
requiring that all of the accesses in the transaction be to cacheable
memory (thus prohibiting MMIO accesses) and aborting transactions on
interrupts, traps, and exceptions (thus prohibiting system calls).

Note that buffered I/O can be accommodated by HTM transactions as
long as the buffer fill/flush operations occur extra-transactionally.
The reason that this works is that adding data to and removing data
from the buffer is revocable: Only the actual buffer fill/flush
operations are irrevocable.
Of course, this buffered-I/O approach has the effect of including the I/O
in the transaction's footprint, increasing the size of the transaction
and thus increasing the probability of failure.
\fi

\subsubsection{Semantic Differences}
\label{sec:future:Semantic Differences}

HTM 이 많은 경우에 락킹의 대체제로 사용될 수 있기는 하지만 (그래서
transactional lock elision~\cite{DaveDice2008TransactLockElision} 이란 명칭이
있습니다), semantic 상에 약간의 차이가 있습니다.
트랜잭션으로 수행되면 deadlock 이나 livelock 을 초래할 수 있는, 락 기반의
크리티컬 섹션과 연관된 특히 골치아픈 예가 Blundell 에 의해
알려졌습니다만~\cite{Blundell2006TMdeadlock}, 훨씬 간단한 예는 텅 빈 크리티컬
섹션입니다.

락 기반의 프로그램에서, 텅 빈 크리티컬 섹션은 기존에 그 락을 쥐고 있던 모든
프로세스들이 지금은 그것을 해제한 상태일 것을 보장합니다.
이 idiom 은 2.4 리눇 크너러의 네트워킹 스택에서 설정 변경을 조정하기 위해
사용되었습니다.
하지만 이 텅 빈 크리티컬 섹션이 트랜잭션으로 변환된다면, 그 결과는 no-op
입니다.
모든 앞의 크리티컬 섹션들이 종료되었을 것이라는 보장은 사라집니다.
달리 말해서, transactional lock elision 은 락킹의 데이터 보호 semantic 을
유지하지만 락킹의 시간에 기반한 메세지 semantic 은 잃어버립니다.
\iffalse

Although HTM can in many cases be used as a drop-in replacement for locking
(hence the name transactional lock
elision~\cite{DaveDice2008TransactLockElision}),
there are subtle differences in semantics.
A particularly nasty example involving coordinated lock-based critical
sections that results in deadlock or livelock when executed transactionally
was given by Blundell~\cite{Blundell2006TMdeadlock}, but a much simpler
example is the empty critical section.

In a lock-based program, an empty critical section will guarantee
that all processes that had previously been holding that lock have
now released it.
This idiom was used by the 2.4 Linux kernel's networking stack to
coordinate changes in configuration.
But if this empty critical section is translated to a transaction,
the result is a no-op.
The guarantee that all prior critical sections have terminated is
lost.
In other words, transactional lock elision preserves the data-protection
semantics of locking, but loses locking's time-based messaging semantics.
\fi

\QuickQuiz{}
	하지만 \emph{누가} 텅 빈 락 기반의 크리티컬 섹션을 필요로 하나요???
	\iffalse

	But why would \emph{anyone} need an empty lock-based critical
	section???
	\fi
\QuickQuizAnswer{
	Section~\ref{sec:locking:Exclusive Locks}
	의 \QuickQuizARef{\QlockingQemptycriticalsection} 의 답을 보시기 바랍니다.

	하지만, 진행 보장이 없는 강력한 어토믹 HTM 구현들에 대해서, 텅 빈
	크리티컬 섹션에 기반한 메모리 기반의 락킹 설계는 transactional lock
	elision 의 존재에도 올바르게 동작할 거라는 주장이 있습니다.
	비록 저는 이 주장에 대한 증명을 보지는 못했습니다만, 이 주장에는
	직선적인 합리성이 존재합니다.
	주요 아이디어는, 강력한 어토믹 HTM 구현에 있어서, 특정 트랜잭션의
	결과는 그 트랜잭션이 성공적으로 완료되기 전까지는 보여지지 않는다는
	것입니다.
	따라서, 트랜잭션이 시작된 것을 볼 수 있다면, 그것이 이미 완료되었음이
	보장되는데, 이 말은 뒤따르는 텅 빈 락 기반의 크리티컬 섹션은 성공적으로
	그것을 ``기다릴'' 것을 의미합니다---무엇보다도, 기다림이 요구되지
	않습니다.
	\iffalse

	See the answer to \QuickQuizARef{\QlockingQemptycriticalsection} in
	Section~\ref{sec:locking:Exclusive Locks}.

	However, it is claimed that given a strongly atomic HTM
	implementation without forward-progress guarantees, any
	memory-based locking design based on empty critical sections
	will operate correctly in the presence of transactional
	lock elision.
	Although I have not seen a proof of this statement, there
	is a straightforward rationale for this claim.
	The main idea is that in a strongly atomic HTM implementation,
	the results of a given transaction are not visible until
	after the transaction completes successfully.
	Therefore, if you can see that a transaction has started,
	it is guaranteed to have already completed, which means
	that a subsequent empty lock-based critical section will
	successfully ``wait'' on it---after all, there is no waiting
	required.
	\fi

	이 이야기는 (많은 STM 구현을 포함하는) weakly atomic 시스템에는
	적용되지 않고, 통신에 메모리 이외의 수단을 사용하는 락 기반의
	프로그램들에는 적용되지 않습니다.
	그런 수단으로는 시간의 흐름 (예를 들어, hard real-time 시스템)
	이나 우선순위의 흐름 (예를 들어, soft real-time 시스템) 이 있습니다.

	Priority boosting 에 의존하는 락킹 설계는 특히 흥미로운 경우입니다.
	\iffalse

	This line of reasoning does not apply to weakly atomic
	systems (including many STM implementation), and it also
	does not apply to lock-based programs that use means other
	than memory to communicate.
	One such means is the passage of time (for example, in
	hard real-time systems) or flow of priority (for example,
	in soft real-time systems).

	Locking designs that rely on priority boosting are of particular
	interest.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	락 기반의 텅 빈 크리티컬 섹션들을 생략하지 않는 방법으로 간단하게
	락킹의 시간 기반 메세징 semantic 을 transactional lock elision 에서
	처리할 수는 없을까요?
	\iffalse
	
	Can't transactional lock elision trivially handle locking's
	time-based messaging semantics
	by simply choosing not to elide empty lock-based critical sections?
	\fi
\QuickQuizAnswer{
	그럴수도 있습니다만, 이는 불필요하고 불충분할 겁니다.

	텅 빈 크리티컬 섹션이 조건적 컴파일에 의한 것이라면 이 방법은 필요가
	없습니다.
	여기서는, 해당 락의 유일한 목적은 데이터를 보호하는 것이므로, 이를
	생략시키는 것이 해야할 옳은 일일 것입니다.
	실제로, 락 기반의 텅 빈 크리티컬 섹션을 남겨두는 것은 성능과 확장성을
	떨어뜨릴 수 있습니다.

	또다른 한편, 락 기반의 비어있지 않은 크리티컬 섹션이 락킹의 데이터
	보호화 시간 기반의 메세징 semantic 에 의존하고 있을 수도 있습니다.
	그런 경우에 transactional lock elision 을 사용하는 것은 올바르지 않고,
	버그를 초래할 수 있습니다.
	\iffalse

	It could do so, but this would be both unnecessary and
	insufficient.

	It would be unnecessary in cases where the empty critical section
	was due to conditional compilation.
	Here, it might well be that the only purpose of the lock was to
	protect data, so eliding it completely would be the right thing
	to do.
	In fact, leaving the empty lock-based critical section would
	degrade performance and scalability.

	On the other hand, it is possible for a non-empty lock-based
	critical section to be relying on both the data-protection
	and time-based and messaging semantics of locking.
	Using transactional lock elision in such a case would be
	incorrect, and would result in bugs.
	\fi
} \QuickQuizEnd

\QuickQuiz{}
	최신 하드웨어~\cite{PeterOkech2009InherentRandomness} 에서, 누가 병렬
	소프트웨어가 타이밍에 의존해서 동작할 거라고 기대할 수 있겠습니까?
	\iffalse

	Given modern hardware~\cite{PeterOkech2009InherentRandomness},
	how can anyone possibly expect parallel software relying
	on timing to work?
	\fi
\QuickQuizAnswer{
	짧게 답하자면 일반적으로 구할수 있는 하드웨어에서, 짧은 시간 단위의
	타이밍에 기반한 동기화 설계들은 무모하고 모든 조건 하에서 올바르게
	동작할 거라고 예상될 수 없습니다.

	그렇다고는 하나, 훨씬 더 결정론적인, hard real-time 에서의 사용을 위해
	설계된 시스템들이 있습니다.
	여러분이 그런 시스템을 사용하게 되는 (있을 수 없을법한) 상황이라면 여기
	시간 기반의 동기화가 동작할 수 있는지 보이는 예가 있습니다.
	다시 말하지만, 일반적인 마이크로프로세서는 매우 비결정론적인 성능
	특성들을 가지고 있으므로, 이를 일반적인 마이크로프로세서 위에서는
	시도하지 \emph{마세요}.
	\iffalse

	The short answer is that on commonplace commodity hardware,
	synchronization designs based on any sort of fine-grained
	timing are foolhardy and cannot be expected to operate correctly
	under all conditions.

	That said, there are systems designed for hard real-time use
	that are much more deterministic.
	In the (very unlikely) event that you are using such a system,
	here is a toy example showing how time-based synchronization can
	work.
	Again, do \emph{not} try this on commodity microprocessors,
	as they have highly nondeterministic performance characteristics.
	\fi

	이 예는 하나의 제어 쓰레드와 함께 복수개의 worker 쓰레드를 사용합니다.
	각각의 worker 쓰레드는 외부로 나가는 데이터에 연관되고, 각 단위의 일을
	수행한 후에 (예를 들어, \co{clock_gettime()} 시스템콜로 얻어오는) 현재
	시간을 per-thread \co{my_timestamp} 변수에 저장합니다.
	이 예의 real-time 특성은 다음과 같은 제한을 갖습니다:
	\iffalse

	This example uses multiple worker threads along with a control
	thread.
	Each worker thread corresponds to an outbound data feed, and
	records the current time (for example, from the
	\co{clock_gettime()} system call) in a per-thread
	\co{my_timestamp} variable after executing each unit
	of work.
	The real-time nature of this example results in the following
	set of constraints:
	\fi

	\begin{enumerate}
	\item	특정 worker 쓰레드가 자신의 타임스탬프를 \co{MAX_LOOP_TIME}
		기간이 넘도록 업데이트 하지 못하는 것은 치명적인 에러입니다.
	\item	락들은 글로벌 상태에 접근하고 업데이트하는데 절약적으로
		사용되어야 합니다.
	\item	락들은 각각의 쓰레드 우선순위 내에서는 엄격한 FIFO 순서로
		얻어집니다.
	\iffalse

	\item	It is a fatal error for a given worker thread to fail
		to update its timestamp for a time period of more than
		\co{MAX_LOOP_TIME}.
	\item	Locks are used sparingly to access and update global
		state.
	\item	Locks are granted in strict FIFO order within
		a given thread priority.
	\fi
	\end{enumerate}

	Worker 쓰레드들이 일을 받는걸 완료하면, 이들은 어플리케이션의 다른
	부분들로부터 그들을 풀어내고 $-1$ 로 초기화 한 per-thread
	\co{my_status} 변수의 상태값을 설정해야 합니다.
	쓰레드들은 종료되지 않습니다; 그대신 뒤이어 처리해야할 것들을
	처리해주기 위해 쓰레드 풀에 들어갑니다.
	제어 쓰레드는 필요한 만큼 worker 쓰레드를 할당 (그리고 재할당) 하고,
	또한 쓰레드 상태들의 히스토그램을 관리합니다.
	제어 쓰레드는 worker 쓰레드보다 높지는 않은 real-time 우선순위로
	동작합니다.

	Worker 쓰레드의 코드는 다음과 같습니다:
	\iffalse

	When worker threads complete their feed, they must disentangle
	themselves from the rest of the application and place a status
	value in a per-thread \co{my_status} variable that is initialized
	to $-1$.
	Threads do not exit; they instead are placed on a thread pool
	to accommodate later processing requirements.
	The control thread assigns (and re-assigns) worker threads as
	needed, and also maintains a histogram of thread statuses.
	The control thread runs at a real-time priority no higher than
	that of the worker threads.

	Worker threads' code is as follows:
	\fi

	\vspace{5pt}
	\begin{minipage}[t]{\columnwidth}
	\scriptsize
\begin{verbatim}
  1   int my_status = -1;  /* Thread local. */
  2 
  3   while (continue_working()) {
  4     enqueue_any_new_work();
  5     wp = dequeue_work();
  6     do_work(wp);
  7     my_timestamp = clock_gettime(...);
  8   }
  9 
 10   acquire_lock(&departing_thread_lock);
 11 
 12   /*
 13    * Disentangle from application, might
 14    * acquire other locks, can take much longer
 15    * than MAX_LOOP_TIME, especially if many
 16    * threads exit concurrently.
 17    */
 18   my_status = get_return_status();
 19   release_lock(&departing_thread_lock);
 20 
 21   /* thread awaits repurposing. */
\end{verbatim}
	\end{minipage}
	\vspace{5pt}

	제어 쓰레드의 코드는 다음과 같습니다:
	\iffalse

	The control thread's code is as follows:
	\fi

	\vspace{5pt}
	\begin{minipage}[t]{\columnwidth}
	\scriptsize
\begin{verbatim}
  1   for (;;) {
  2     for_each_thread(t) {
  3       ct = clock_gettime(...);
  4       d = ct - per_thread(my_timestamp, t);
  5       if (d >= MAX_LOOP_TIME) {
  6         /* thread departing. */
  7         acquire_lock(&departing_thread_lock);
  8         release_lock(&departing_thread_lock);
  9         i = per_thread(my_status, t);
 10         status_hist[i]++; /* Bug if TLE! */
 11       }
 12     }
 13     /* Repurpose threads as needed. */
 14   }
\end{verbatim}
	\end{minipage}
	\vspace{5pt}

	Line~5 는 해당 쓰레드가 종료되었는지를 추론하는데에 시간의 흐름을
	사용하고, 만약 그렇다면 line~6-10 을 수행합니다.
	Line~7 과~8 의 락 기반의 텅 빈 크리티컬 섹션은 종료되는 프로세스의 모든
	쓰레드는 완료되었음을 보장합니다 (락은 FIFO 순서로 얻어짐을
	기억하세요!).

	다시 말하건대, 이것들을 일반적인 마이크로프로세서 위에서 수행하려
	시도하지 마세요.
	무엇보다도, hard real-time 사용을 위해 설계된 시스템을 사용할 권한을
	얻기도 충분히 어렵습니다!
	\iffalse

	Line~5 uses the passage of time to deduce that the thread
	has exited, executing lines~6-10 if so.
	The empty lock-based critical section on lines~7 and~8
	guarantees that any thread in the process of exiting
	completes (remember that locks are granted in FIFO order!).

	Once again, do not try this sort of thing on commodity
	microprocessors.
	After all, it is difficult enough to get right on systems
	specifically designed for hard real-time use!
	\fi
} \QuickQuizEnd

락킹과 트랜잭션 사이의 중요한 semantic 상의 차이 하나는 락 기반의 real-time
프로그램에서 우선순위 역전을 막기 위해 상요되는 priority boosting 입니다.
우선순위 역전이 일어날 수 있는 한가지 경우는 락을 쥐고 있는 낮은 우선순위의
쓰레드가 중간 우선순위의 CPU 를 많이 사용하는 쓰레드에 의해 preemption 당하는
경우입니다.
만약 CPU 마다 그런 중간 우선순위 쓰레드가 최소 하나씩은 있다면, 낮은 우선순위
쓰레드는 수행될 기회를 결코 얻지 못할 겁니다.
만약 높은 우선순위 쓰레드가 이제 그 락을 얻으려 시도하면, 이 쓰레드는 블록될
겁니다.
이 쓰레드는 낮은 우선순위 쓰레드가 락을 놓기 전까지는 그 락을 얻지 못할 것이고,
이 낮은 우선순위 쓰레드는 수행될 기회를 얻기 전까지는 그 락을 해제하지를 못할
것이며, 낮은 우선순위 쓰레드는 중간 우선순위 쓰레드가 CPU 를 놓기 전까지는
수행될 기회를 얻지를 못할 겁니다.
따라서, 중간 우선순위 쓰레드는 실질적으로 높은 우선순위 프로세스를 블록하고
있는 셈인데, 이게 바로 ``우선순위 역전'' 이라 불리는 이유입니다.
\iffalse

One important semantic difference between locking and transactions
is the priority boosting that is used to avoid priority inversion
in lock-based real-time programs.
One way in which priority inversion can occur is when a
low-priority thread holding a lock
is preempted by a medium-priority CPU-bound thread.
If there is at least one such medium-priority thread per CPU, the
low-priority thread will never get a chance to run.
If a high-priority thread now attempts to acquire the lock,
it will block.
It cannot acquire the lock until the low-priority thread releases it,
the low-priority thread cannot release the lock until it gets a chance
to run, and it cannot get a chance to run until one of the medium-priority
threads gives up its CPU.
Therefore, the medium-priority threads are in effect blocking the
high-priority process, which is the rationale for the name ``priority
inversion.''
\fi

\begin{figure}[tbp]
{ \scriptsize
\begin{verbbox}
  1 void boostee(void)
  2 {
  3   int i = 0;
  4 
  5   acquire_lock(&boost_lock[i]);
  6   for (;;) {
  7     acquire_lock(&boost_lock[!i]);
  8     release_lock(&boost_lock[i]);
  9     i = i ^ 1;
 10     do_something();
 11   }
 12 }
 13 
 14 void booster(void)
 15 {
 16   int i = 0;
 17 
 18   for (;;) {
 19     usleep(1000); /* sleep 1 ms. */
 20     acquire_lock(&boost_lock[i]);
 21     release_lock(&boost_lock[i]);
 22     i = i ^ 1;
 23   }
 24 }
\end{verbbox}
}
\centering
\theverbbox
\caption{Exploiting Priority Boosting}
\label{fig:future:Exploiting Priority Boosting}
\end{figure}

우선순위 역전을 막기 위한 한가지 방법은 \emph{priority inheritance} 로, 락에
의해 블록된 높은 우선순위 쓰레드가 임시적으로 자신의 우선순위를 락을 쥔
쓰레드에게 넘겨주는 것인데, \emph{priority boosting} 이라고도 불립니다.
하지만, priority boosting 은 우선순위 역전을 막는것 외에도
Figure~\ref{fig:future:Exploiting Priority Boosting} 에 보여진 것처럼도 사용될
수 있습니다.
이 그림의 line~1-12 는 매 밀리세컨드마다 수행되어야 하는 낮은 우선순위
프로세스를 보이고 있고, line~14-24 는 \co{boostee()} 가 주기적으로 필요한 만큼
수행되는 것을 보장하기 위해 priority boosting 을 사용하는 높은 우선순위
프로세스를 보입니다.

\co{boostee()} 함수는 두개의 \co{boost_lock[]} 락들 가운데 하나를 항상 쥐고
있어서 \co{booster()} 의 line~20-21 이 우선순위를 필요한만큼 증폭시킬 수 있게
함으로써 이를 가능하게 합니다.
\iffalse

One way to avoid priority inversion is \emph{priority inheritance},
in which a high-priority thread blocked on a lock temporarily donates
its priority to the lock's holder, which is also called \emph{priority
boosting}.
However, priority boosting can be used for things other than avoiding
priority inversion, as shown in
Figure~\ref{fig:future:Exploiting Priority Boosting}.
Lines~1-12 of this figure show a low-priority process that must
nevertheless run every millisecond or so, while lines~14-24 of
this same figure show a high-priority process that uses priority
boosting to ensure that \co{boostee()} runs periodically as needed.

The \co{boostee()} function arranges this by always holding one of
the two \co{boost_lock[]} locks, so that lines~20-21 of
\co{booster()} can boost priority as needed.
\fi

\QuickQuiz{}
	하지만
	Figure~\ref{fig:future:Exploiting Priority Boosting}
	의 \co{boostee()} 함수는 그 락을 반대 순서로 잡고 있어요!
	이는 deadlock 을 초래할 수 있지 않을까요?
	\iffalse

	But the \co{boostee()} function in
	Figure~\ref{fig:future:Exploiting Priority Boosting}
	alternatively acquires its locks in reverse order!
	Won't this result in deadlock?
	\fi
\QuickQuizAnswer{
	Deadlock 은 일어나지 않을 겁니다.
	Deadlock 이 일어나려면, 두개의 다른 쓰레드가 각각 두개의 락을 반대
	순서로 잡아야 하는데, 이 예에서는 그런 일은 없습니다.
	하지만, lockdep~\cite{JonathanCorbet2006lockdep} 과 같은 deadlock
	detector 들은 이에 거짓 양성 반응을 보일 수 있습니다.
	\iffalse

	No deadlock will result.
	To arrive at deadlock, two different threads must each
	acquire the two locks in oppposite orders, which does not
	happen in this example.
	However, deadlock detectors such as
	lockdep~\cite{JonathanCorbet2006lockdep}
	will flag this as a false positive.
	\fi
} \QuickQuizEnd

이 구조는 \co{boostee()} 가 시스템이 바빠지기 전에 line~5 에서 첫번째 락을 잡을
것을 필요로 합니다만, 이는 최신 하드웨어에서조차도 쉽게 가능합니다.

안타깝게도, 이 구조는 transactional lock elision 의 존재 하에서는 깨질 수
있습니다.
\co{boostee()} 함수의 겹쳐지는 크리티컬 섹션들은 잠시후든 나중이든 abort 될
하나의 무한한 트랜잭션이 되어버리는데,  예를 들면 \co{boostee()} 함수를
수행하는 쓰레드가 preemption 당하는 첫번째 시점이 되겠습니다.
이 시점에서, \co{boostee()} 는 락킹으로 물러나게 됩니다만, 그 낮은 우선순위와
초기화 단계가 완료되었다는 사실 때문에 (이게 바로 \co{boostee()} 가 preemption
을 당한 이유입니다), 이 쓰레드는 다시 수행될 기회를 얻지 못하게 됩니다.

그리고 만약 \co{boostee()} 쓰레드가 락을 잡고 있지 않다면, \co{booster()}
쓰레드의
Figure~\ref{fig:future:Exploiting Priority Boosting}
line~20 과~21 에서의 텅빈 크리티컬 섹션은 아무런 효과를 갖지 못하는 텅빈
트랜잭션이 되어서, \co{boostee()} 는 결코 수행되지 않을 겁니다.
이 예는 트랜잭셔널 메모리의 rollback-and-retry 시맨틱의 미묘한 결론을 그리고
있습니다.
\iffalse

This arrangement requires that \co{boostee()} acquire its first
lock on line~5 before the system becomes busy, but this is easily
arranged, even on modern hardware.

Unfortunately, this arrangement can break down in presence of transactional
lock elision.
The \co{boostee()} function's overlapping critical sections become
one infinite transaction, which will sooner or later abort,
for example, on the first time that the thread running
the \co{boostee()} function is preempted.
At this point, \co{boostee()} will fall back to locking, but given
its low priority and that the quiet initialization period is now
complete (which after all is why \co{boostee()} was preempted),
this thread might never again get a chance to run.

And if the \co{boostee()} thread is not holding the lock, then
the \co{booster()} thread's empty critical section on lines~20 and~21 of
Figure~\ref{fig:future:Exploiting Priority Boosting}
will become an empty transaction that has no effect, so that
\co{boostee()} never runs.
This example illustrates some of the subtle consequences of
transactional memory's rollback-and-retry semantics.
\fi

경험이 추가적인 묘한 semantic 상의 차이를 더 드러낼 것인데, HTM 기반의 lock
elision 의 커다란 프로그램으로의 적용은 주의 하에 이루어져야 합니다.
그렇다곤 하나, 적용이 되는 곳이라면, HTM 기반 lock elision 은 해당 락 변수에
연관된 캐시 미스들을 제거할 수 있어서 2015년 초에 있어서 실제 세계의 커다란
소프트웨어 시스템들에서는 수십 퍼센트의 성능 향상을 가져옵니다.
따라서 우리는 이 기술을 지원하는 하드웨어에서의 이 테크닉의 상당한 사용을
기대합니다.
\iffalse

Given that experience will likely uncover additional subtle semantic
differences, application of HTM-based lock elision to large programs
should be undertaken with caution.
That said, where it does apply, HTM-based lock elision can eliminate
the cache misses associated with the lock variable, which has resulted
in tens of percent performance increases in large real-world software
systems as of early 2015.
We can therefore expect to see substantial use of this technique on
hardware supporting it.
\fi

\QuickQuiz{}
	그래서 많은 사람들이 락킹을 대신하는 작업을 시작하고는 대부분은 락킹을
	최적화 하는 것으로 결론을 내리나요???
	\iffalse

	So a bunch of people set out to supplant locking, and they
	mostly end up just optimizing locking???
	\fi
\QuickQuizAnswer{
	그들은 최소한 어떤 유용한 것을 얻습니다!
	그리고 시간이 흐름에 따라 HTM 에 추가적인 진보가 있을 수 있습니다.
	\iffalse

	At least they accomplished something useful!
	And perhaps there will be additional HTM progress over time.
	\fi
} \QuickQuizEnd

\subsubsection{Summary}
\label{sec:future:HTM Weaknesses WRT Locking: Summary}

\input{future/HTMtable}

HTM 이 강력한 사용 예들을 갖는 것처럼 보이긴 하지만, 현재의 구현들은 주의깊은
처리를 필요로 하는, 트랜잭션 크기, conflict 처리의 복잡성, abort-and-rollback
이슈, 그리고 semantic 상의 차이와 같은 심각한 한계들을 가지고 있습니다.  HTM 의
현재 상황이 락킹과 비교해서
Table~\ref{tab:future:Comparison of Locking and HTM} 에 요약되어 있습니다.
보여지듯이, HTM 의 현재 상황이 락킹의 일부 심각한
단점들을 경감시키긴 하지만,\footnote{
	공정성을 위해 말해두자면, 락킹의 단점들은 잘 알려져 있고 널리 사용되고
	있는, deadlock detector~\cite{JonathanCorbet2006lockdep}, 락킹에 적용된
	데이터 구조의 풍부함, 그리고
	Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}
	에서 이야기한 것과 같이 결합되어 사용되어온 긴 역사를 포함한,
	엔지니어링 단계에서의 해결책들이 있음을 강조해둘 필요가 있습니다.
	한가지 더 말하자면, 락킹이 정말로 많은 학계의 논문들을 살짝만 보아도
	믿어질 만큼 끔찍한 것이었다면, 그 수많은 락 기반의 (FOSS 와 독점의)
	병렬 프로그램들은 대체 어디서 나왔을까요?}
HTM 역시 그 자체의 상당히 많은 단점들을 포함하고 있습니다.  이러한 단점들은 TM
커뮤니티의 리더들에 의해서도 인정된 바
있습니다~\cite{AlexanderMatveev2012PessimisticTM}.\footnote{
	또한, 2011년 초에, 저는 트랜잭셔널 메모리를 둘러싼 일부 가정에 대한
	비평을 하도록 초대된 바 있습니다~\cite{PaulEMcKenney2011Verico}.
	제가 발표를 하기 위해 시차에 매우 시달렸기 때문에 저를 편하게 해주기
	위해서였을지는 몰라도, 청중은 놀라우리만큼 적대적이지 않았습니다.}
\iffalse

Although it seems likely that HTM will have compelling use cases,
current implementations have serious transaction-size limitations,
conflict-handling complications, abort-and-rollback issues, and
semantic differences that will require careful handling.
HTM's current situation relative to locking is summarized in
Table~\ref{tab:future:Comparison of Locking and HTM}.
As can be seen, although the current state of HTM alleviates some
serious shortcomings of locking,\footnote{
	In fairness, it is important to emphasize that locking's shortcomings
	do have well-known and heavily used engineering solutions, including
	deadlock detectors~\cite{JonathanCorbet2006lockdep}, a wealth
	of data structures that have been adapted to locking, and
	a long history of augmentation, as discussed in
	Section~\ref{sec:future:HTM Weaknesses WRT to Locking When Augmented}.
	In addition, if locking really were as horrible as a quick skim
	of many academic papers might reasonably lead one to believe,
	where did all the large lock-based parallel programs (both
	FOSS and proprietary) come from, anyway?}
it does so by introducing a significant
number of shortcomings of its own.
These shortcomings are acknowledged by leaders in the TM
community~\cite{AlexanderMatveev2012PessimisticTM}.\footnote{
	In addition, in early 2011, I was invited to deliver a critique of
	some of the assumptions underlying transactional
	memory~\cite{PaulEMcKenney2011Verico}.
	The audience was surprisingly non-hostile, though perhaps they
	were taking it easy on me due to the fact that I was heavily
	jet-lagged while giving the presentation.}
\fi

또한, 이게 전부가 아닙니다.
락킹은 일반적으로 그 자체만으로 사용되지 않고, 보통 레퍼런스 카운팅, 어토믹
오퍼레이션, non-blocking 데이터 구조, 해저드
포인터~\cite{MagedMichael04a,HerlihyLM02}, 그리고 read-copy update
(RCU)~\cite{McKenney98,McKenney01a,ThomasEHart2007a,PaulEMcKenney2012ELCbattery}
등과 같은 다른 동기화 메커니즘들과 결합되어 사용됩니다.
다음 섹션은 그러한 결합이 이 수식을 어떻게 바꾸어놓는지 봅니다.
\iffalse

In addition, this is not the whole story.
Locking is not normally used by itself, but is instead typically
augmented by other synchronization mechanisms,
including reference counting, atomic operations, non-blocking data structures,
hazard pointers~\cite{MagedMichael04a,HerlihyLM02},
and RCU~\cite{McKenney98,McKenney01a,ThomasEHart2007a,PaulEMcKenney2012ELCbattery}.
The next section looks at how such augmentation changes the equation.
\fi

\subsection{HTM Weaknesses WRT to Locking When Augmented}
\label{sec:future:HTM Weaknesses WRT to Locking When Augmented}

\input{future/HTMtableRCU}

실무자들은 락킹의 일부 단점들을 막기 위해 오랫동안 레퍼런스 카운팅, 어토믹
오퍼레이션, non-blocking 데이터 구조, 해저드 포인터, 그리고 RCU 를 사용해
왔습니다.
예를 들어, deadlock 은 많은 경우에 레퍼런스 카운트, 해저드 포인터, 또는 RCU 를
데이터 구조를 보호하는데에 사용함으로써 막아질 수 있고, 특히나 read-only
크리티컬 섹션에서는
그렇습니다~\cite{MagedMichael04a,HerlihyLM02,MathieuDesnoyers2012URCU,DinakarGuniguntala2008IBMSysJ,ThomasEHart2007a}.
이 방법은 또한
Chapter~\ref{chp:Data Structures} 에서 봤던 것처럼 데이터 구조를 분할할 필요를
줄여줍니다.
RCU 는 더 나아가서 contention 에서 자유로운 wait-free read-side 기능들을
제공합니다~\cite{MathieuDesnoyers2012URCU}.
이런 점을
Table~\ref{tab:future:Comparison of Locking and HTM} 에 추가하면
Table~\ref{tab:future:Comparison of Locking (Augmented by RCU or Hazard Pointers) and HTM}
에 보인, augmented locking 과 HTM 사이의 업데이트된 비교가 나옵니다.
두개의 표간의 차이점을 요약해보면 다음과 같습니다:
\iffalse

Practitioners have long used reference counting, atomic operations,
non-blocking data structures, hazard pointers, and RCU to avoid some
of the shortcomings of locking.
For example, deadlock can be avoided in many cases by using reference
counts, hazard pointers, or RCU to protect data structures,
particularly for read-only critical
sections~\cite{MagedMichael04a,HerlihyLM02,MathieuDesnoyers2012URCU,DinakarGuniguntala2008IBMSysJ,ThomasEHart2007a}.
These approaches also reduce the need to partition data
structures, as was see in Chapter~\ref{chp:Data Structures}.
RCU further provides contention-free wait-free read-side
primitives~\cite{MathieuDesnoyers2012URCU}.
Adding these considerations to
Table~\ref{tab:future:Comparison of Locking and HTM}
results in the updated comparison between augmented locking and HTM
shown in
Table~\ref{tab:future:Comparison of Locking (Augmented by RCU or Hazard Pointers) and HTM}.
A summary of the differences between the two tables is as follows:
\fi

\begin{enumerate}
\item	Non-blocking read-side 메커니즘의 사용은 deadlock 문제를 줄여줍니다.
\item	해저드 포인터와 RCU 와 같은 Read-side 메커니즘들은 분할이 불가능한
	데이터에서 효과적으로 동작할 수 있습니다.
\item	해저드 포인터와 RCU 는 서로간에 또는 업데이트 쓰레드와 충돌하지 않아서,
	읽기가 대부분인 워크로드에서는 훌륭한 성능과 확장성을 제공합니다.
\item	해저드 포인터와 RCU 는 진행 보장을 제공합니다 (각각 lock freedom 과
	wait-freedom 을 제공합니다).
\item	해저드 포인터와 RCU 에서의 privatization 오퍼레이션들은 간단합니다.
\iffalse

\item	Use of non-blocking read-side mechanisms alleviates deadlock issues.
\item	Read-side mechanisms such as hazard pointers and RCU can operate
	efficiently on non-partitionable data.
\item	Hazard pointers and RCU do not contend with each other or with
	updaters, allowing excellent performance and scalability for
	read-mostly workloads.
\item	Hazard pointers and RCU provide forward-progress guarantees
	(lock freedom and wait-freedom, respectively).
\item	Privatization operations for hazard pointers and RCU are
	straightforward.
\fi
\end{enumerate}

물론, 다음 섹션에서 논의하듯이 HTM 을 다른 기능들과 결합하는 것도 가능합니다.
\iffalse

Of course, it is also possible to augment HTM,
as discussed in the next section.
\fi

\subsection{Where Does HTM Best Fit In?}
\label{sec:future:Where Does HTM Best Fit In?}

HTM 의 적용 영역이
page~\pageref{fig:defer:RCU Areas of Applicability} 의
Figure~\ref{fig:defer:RCU Areas of Applicability} 에 보여진 RCU 처럼 그려지기
전인 것 같긴 하지만, 그런 방향으로 움직이기 시작하지 않을 이유는 없습니다.

HTM 은 커다란 멀티프로세서에서 돌아가는 상대적으로 커다란 in-memory 데이터
구조의 겹치지 않는 영역에 대한 상대적으로 작은 변경에 연관된 업데이트 위주의
워크로드에 들어맞을 텐데, 이런 워크로드는 현재 HTM 구현의 크기 제약을 맞출 수
있고 conflict 과 그로인한 abort 와 롤백의 확률을 최소화 시켜줄 것이기
때문입니다.
이 시나리오는 현재의 동기화 도구들을 가지고는 처리하기가 상대적으로 어려운
시나리오이기도 합니다.
\iffalse

Although it will likely be some time before HTM's area of applicability
can be as crisply delineated as that shown for RCU in
Figure~\ref{fig:defer:RCU Areas of Applicability} on
page~\pageref{fig:defer:RCU Areas of Applicability}, that is no reason not to
start moving in that direction.

HTM seems best suited to update-heavy workloads involving relatively
small changes to disparate portions of relatively large in-memory
data structures running on large multiprocessors,
as this meets the size restrictions of current HTM implementations while
minimizing the probability of conflicts and attendant aborts and
rollbacks.
This scenario is also one that is relatively difficult to handle given
current synchronization primitives.
\fi

HTM 과 함께 락킹을 사용하는 것은 돌이킬 수 없는 오퍼레이션들에 대한 HTM 의
어려움을 극복해줄 수 있을 것으로 보이며, RCU 나 해저드 포인터의 사용은 데이터
구조의 커다란 부분을 횡단하는, read-only 오퍼레이션들에 대해서 HTM 의 트랜잭션
크기 제한을 해결해 줄 수 있을 것입니다.
현재의 HTM 구현들은 RCU 나 해저드 포인터 읽기 쓰레드와 conflict 나는 업데이트
트랜잭션을 무조건적으로 abort 시키고 있지만, 미래의 HTM 구현들은 이런 동기화
메커니즘들과 더 부드럽게 작용할 것입니다.
그전까지는, 커다란 RCU 나 해저드 포인터 read-side 크리티컬 섹션과 conflict 나는
업데이트의 확률은 동일한 read-only 트랜잭션과 conflict 날 확률에 비해 훨씬
작아야 합니다.\footnote{
	NoSQL 데이터베이스들이 데이터베이스 어플리케이션의 엄격한 트랜잭션에의
	의존도를 완화시키고 있는 상황에서 shared-memory 시스템에서는 엄격한
	트랜잭션 메커니즘이 떠오르는 것은 상당히 아이러닉합니다.}
더도 아니고 덜도 아니고, RCU 나 해저드 포인터 읽기 쓰레드들의 느린 흐름이
연관된 conflict 의 느린 흐름으로 인해 업데이트 쓰레드를 starve 시킬 수도
있습니다.
이런 취약점은 앞의 트랜잭션의 로드된 메모리 로케이션의 복사본에 대한 트랜잭션
외적인 읽기 방법을 제공하는 것으로 (상당한 하드웨어 비용과 복잡성을 요하겠지만)
제거될 수도 있습니다.
\iffalse

Use of locking in conjunction with HTM seems likely to overcome HTM's
difficulties with irrevocable operations, while use of RCU or
hazard pointers might alleviate HTM's transaction-size limitations
for read-only operations that traverse large fractions of the data
structure.
Current HTM implementations unconditionally abort an update transaction
that conflicts with an RCU or hazard-pointer reader, but perhaps future
HTM implementations will interoperate more smoothly with these
synchronization mechanisms.
In the meantime, the probability of an update conflicting with a
large RCU or hazard-pointer read-side critical section should be
much smaller than the probability of conflicting with the equivalent
read-only transaction.\footnote{
	It is quite ironic that strictly transactional mechanisms are
	appearing in shared-memory systems at just about the time
	that NoSQL databases are relaxing the traditional
	database-application reliance on strict transactions.}
Nevertheless, it is quite possible that a steady stream of RCU or
hazard-pointer readers might starve updaters due to a corresponding
steady stream of conflicts.
This vulnerability could be eliminated (perhaps at significant
hardware cost and complexity) by giving extra-transactional
reads the pre-transaction copy of the memory location being loaded.
\fi

HTM 트랜잭션들이 fallback 을 가져야만 한다는 사실로 인해 어떤 경우에는 데이터
구조들의 정적 분할 가능성을 강제해야만 할수도 있습니다.
이 제약점은 미래의 HTM 구현들이 진행 보장을 제공한다면 어떤 경우에는 fallback
코드의 필요성을 제거할 것이므로 없어질 수 있을 것인데, 이는 HTM 이 높은
conflict 확률 아래의 환경에서도 효과적으로 사용될 수 있을 것입니다.

요약하자면, HTM 이 중요한 사용과 응용 분야를 가질 수 있을 것이지만, 병렬
프로그래머의 도구상자의 또다른 도구일 뿐이지, 도구상자 전체의 대체제는
아닙니다.
\iffalse

The fact that HTM transactions must have fallbacks might in some cases
force static partitionability of data structures back onto HTM.
This limitation might be alleviated if future HTM implementations
provide forward-progress guarantees, which might eliminate the need
for fallback code in some cases, which in turn might allow HTM to
be used efficiently in situations with higher conflict probabilities.

In short, although HTM is likely to have important uses and applications,
it is another tool in the parallel programmer's toolbox, not a replacement
for the toolbox in its entirety.
\fi

\subsection{Potential Game Changers}
\label{sec:future:Potential Game Changers}

HTM 의 필요성을 상당히 증가시킬 Game changer 들은 다음과 같은 것들이 있습니다:
\iffalse

Game changers that could greatly increase the need for HTM include
the following:
\fi

\begin{enumerate}
\item	진행 보장.
\item	트랜잭션 크기 증가.
\item	개선된 디버깅 지원.
\item	완화된 원자성.
\iffalse

\item	Forward-progress guarantees.
\item	Transaction-size increases.
\item	Improved debugging support.
\item	Weak atomicity.
\fi
\end{enumerate}

이것들은 다음 섹션들에서 확장되어 설명됩니다.
\iffalse

These are expanded upon in the following sections.
\fi

\subsubsection{Forward-Progress Guarantees}
\label{sec:future:Forward-Progress Guarantees}

Section~\ref{sec:future:Lack of Forward-Progress Guarantees} 에서 논의한 것과
같이, 현재의 HTM 구현들은 진행 보장을 갖지 않아서 HTM 의 실패된 트랜잭션을
처리하기 위한 fallback 소프트웨어를 필요로 합니다.
물론, 보장을 추가하는 건 쉽습니다만, 그걸 제공하는건 항상 쉽지는 않습니다.
HTM 의 경우에, 보장을 제공하는데 걸리는 문제는 캐시 크기와 캐시 associativity,
TLB 크기와 TLB asociativity, 트랜잭션의 시간적 길이와 인터럽트 빈도, 그리고
스케쥴러 구현 등이 포함됩니다.
\iffalse

As was discussed in
Section~\ref{sec:future:Lack of Forward-Progress Guarantees},
current HTM implementations lack forward-progress guarantees, which requires
that fallback software be available to handle HTM failures.
Of course, it is easy to demand guarantees, but not always easy
to provide them.
In the case of HTM, obstacles to guarantees can include cache size and
associativity, TLB size and associativity, transaction duration and
interrupt frequency, and scheduler implementation.
\fi

캐시 크기와 캐시 associativity 는
Section~\ref{sec:future:Transaction-Size Limitations} 에서 현재의 한계점들을
우회하기 위한 일부 연구 작업들과 함께 논의된 바 있습니다.
하지만, HTM 의 진행 보장은 크기에 대하 한계와 함께 제공될 겁니다.
그런데 현재의 HTM 구현들은, 예를 들자면 캐시의 associativity 의 한계에 맞춰진
작은 트랜잭션들에 대해서는 진행 보장을 제공하지 않는 걸까요?
한가지 잠재적인 이유는 하드웨어 failure를 처리해야 하는 필요성일 수 있습니다.
예를 들어, 문제가 생긴 캐시의 SRAM 셀은 해당 문제가 생긴 셀을 비활성화 시키는
것으로 처리될 수 있는데, 이는 캐시의 associativity 를 줄이게 되고 따라서 진행
보장이 제공될 수 있ㄴ느 트랜잭션의 최대 크기 역시 줄이게 됩니다.
이는 단순히 보장된 트랜잭션 크기를 줄일 뿐이란 점을 생각해 보면, 실제로는 다른
이유들도 있을 것으로 보입니다.
제품 수준의 하드웨어에서 진행 보장을 제공하는 것은 아마도 소프트웨어에서 진행
보장을 제공하는데 걸리는 어려움보다도 더 어려울 수 있습니다.
따라서 문제를 더 쉽게 풀기 위해, 문제를 소프트웨어에서 하드웨어로 옮기는 게
필요합니다.
\iffalse

Cache size and associativity was discussed in
Section~\ref{sec:future:Transaction-Size Limitations},
along with some research intended to work around current limitations.
However, HTM forward-progress guarantees would
come with size limits, large though these limits might one day be.
So why don't current HTM implementations provide forward-progress
guarantees for small transactions, for example, limited to the
associativity of the cache?
One potential reason might be the need to deal with hardware failure.
For example, a failing cache SRAM cell might be handled by deactivating
the failing cell, thus reducing the associativity of the cache and
therefore also the maximum size of transactions that can be guaranteed
forward progress.
Given that this would simply decrease the guaranteed transaction size,
it seems likely that other reasons are at work.
Perhaps providing forward progress guarantees on production-quality
hardware is more difficult than one might think, an entirely plausible
explanation given the difficulty of making forward-progress guarantees
in software.
Moving a problem from software to hardware does not necessarily make
it easier to solve.
\fi

물리적으로 tag 되고 index 되는 캐시에 있어서는 트랜잭션이 캐시 안에 들어간다는
것만으로는 충분치 않습니다.
여기서는 주소변환이 TLB 에 들어 맞기도 해야 합니다.
따라서 모든 진행 보장은 TLB 크기와 TLB associativity 도 신경을 써야 합니다.

현재의 HTM 구현들에서는 인터럽트, trap, 그리고 exception 이 트랜잭션을 abort
시킨다는 점을 생각해 보면, 특정 트랜잭션의 수행 시간 길이가 인터럽트 간의
예상되는 시간 간격보다 짧아야 할 필요가 있습니다.
특정 트랜잭션이 얼마나 적은 데이터만 건드리는가와는 관계 없이, 너무 오랫동안
수행된다면, 해당 트랜잭션은 abort 될겁니다.
따라서, 모든 진행 보장은 트랜잭션 크기만이 아니라 트랜잭션 수행시간에 대해서도
조정되어야만 합니다.
\iffalse

Given a physically tagged and indexed cache, it is not enough for the
transaction to fit in the cache.
Its address translations must also fit in the TLB.
Any forward-progress guarantees must therefore also take TLB size
and associativity into account.

Given that interrupts, traps, and exceptions abort transactions in current
HTM implementations, it is necessary that the execution duration of
a given transaction be shorter than the expected interval between
interrupts.
No matter how little data a given transaction touches, if it runs too
long, it will be aborted.
Therefore, any forward-progress guarantees must be conditioned not only
on transaction size, but also on transaction duration.
\fi

진행 보장은 conflict 되는 여러개의 트랜잭션들 가운데 어떤 트랜잭션이 aobrt
되어야 하는지 결정하는 능력에도 특히 의존적입니다.
각각 앞의 트랜잭션을 aobrt 시키고 자기 자신도 뒤의 트랜잭션에 의해서 aobrt
되어서 어떤 트랜잭션도 실질적으로 커밋하지 못하는 무한한 트랜잭션의 연속을 쉽게
생각해 볼 수 있습니다.
Conflict 처리의 복잡성은 제안된 바 있는 많은 수의 HTM conflict 해결
정책들~\cite{EgeAkpinar2011HTM2TLE,YujieLiu2011ToxicTransactions} 로 알 수
있습니다.
트랜잭션 외적인 액세스들로 인해 추가적인 복잡성들이 나타나는데, Blundell에 의해
알려졌습니다~\cite{Blundell2006TMdeadlock}.
이런 모든 문제들에 대해서 트랜잭션 외적인 액세스들을 탓하기는 쉽습니다만, 이런
생각의 어리석음은 각각의 트랜잭션 외적인 액세슫르을 그 자신만의 하나의 액세스로
구성된 트랜잭션으로 교체함으로써 쉽게 드러납니다.
이는 그 자체로 문제인 액세스 패턴이지, 그것들이 트랜잭션 안에서 일어나느냐
아니냐의 문제가 아닙니다.
\iffalse

Forward-progress guarantees depend critically on the ability to determine
which of several conflicting transactions should be aborted.
It is all too easy to imagine an endless series of transactions, each
aborting an earlier transaction only to itself be aborted by a later
transactions, so that none of the transactions actually commit.
The complexity of conflict handling is
evidenced by the large number of HTM conflict-resolution policies
that have been proposed~\cite{EgeAkpinar2011HTM2TLE,YujieLiu2011ToxicTransactions}.
Additional complications are introduced by extra-transactional accesses,
as noted by Blundell~\cite{Blundell2006TMdeadlock}.
It is easy to blame the extra-transactional accesses for all of these
problems, but the folly of this line of thinking is easily demonstrated
by placing each of the extra-transactional accesses into its own
single-access transaction.
It is the pattern of accesses that is the issue, not whether or not they
happen to be enclosed in a transaction.
\fi

마지막으로, 트랜잭션을 위한 모든 진행 보장은 해당 트랜잭션을 수행하는 쓰레드가
커밋을 성공하기에 충분할 만큼 길게 수행될 수 있도록 해줄 수 있는 스케쥴러에
의존적입니다.

따라서 진행 보장을 제공하는 HTM 제작사들에게는 상당한 문제가 존재합니다.
하지만, 그것들을 해결하면 얻을 수 있는 효과는 대단합니다.
그렇게 되면 HTM 트랜잭션은 소프트웨어 fallback 이 더이상 필요없어지는데, 이는
HTM 은 마침내 TM 의 deadlock 제거의 약속을 선사하게 됨을 의미합니다.

그리고 2012년 말, IBM Mainframe 은 일반적인 최선의 HTM 구현에 더해서
\emph{constrained transaction} 을 포함하는 HTM 구현을
발표했습니다~\cite{ChristianJacobi2012MainframeTM}.
constrained transaction 은 best-effort 트랜잭션을 시작하는데 사용되는
\co{tbegin} 명령과 달리 \co{tbeginc} 명령으로 시작됩니다.
Constrained transaction 은 항상 (결국은) 성공할 것이 보장되어 있으며, 따라서
만약 어떤 트랜잭션이 abort 된다면, (best-effort 트랜잭션이 그렇듯이) fallback
path 로 분기되기 보다는 하드웨어가 그 트랜잭션을 \co{tbeginc} 명령으로부터
재시작 시킵니다.
\iffalse

Finally, any forward-progress guarantees for transactions also
depend on the scheduler, which must let the thread executing the
transaction run long enough to successfully commit.

So there are significant obstacles to HTM vendors offering forward-progress
guarantees.
However, the impact of any of them doing so would be enormous.
It would mean that HTM transactions would no longer need software
fallbacks, which would mean that HTM could finally deliver on the
TM promise of deadlock elimination.

And as of late 2012, the IBM Mainframe announced an HTM
implementation that includes \emph{constrained transactions}
in addition to the usual best-effort HTM
implementation~\cite{ChristianJacobi2012MainframeTM}.
A constrained transaction starts with the \co{tbeginc} instruction
instead of the \co{tbegin} instruction that is used for best-effort
transactions.
Constrained transactions are guaranteed to always complete (eventually),
so if a transaction aborts, rather than branching to a fallback path
(as is done for best-effort transactions), the hardware instead restarts
the transaction at the \co{tbeginc} instruction.
\fi

이 Mainframe 구조는 이 진행 보장을 위해서 상당한 측정을 해야 했습니다.
특정 constrained transaction 이 반복적으로 실패한다면, 이 CPU 는 branch
prediction 을 비활성화 하고, in-order execution 을 강제하고, 심지어 pipelining
을 비활성화 시킬 수도 있습니다.
만약 반복된 failure 가 높은 contention 때문이라면, CPU 는 speculative fetche 를
비활성화 하고, 무작위적 delay 를 집어넣고, 심지어 충돌하는 CPU 들의 수행을
직렬화 시킬 수조차 있습니다.
``흥미로운'' 진행 보장 시나리오는 두개의 CPU 만이 관여될수도, 백개의 CPU 들이
관여될 수도 있습니다.
아마도 이런 상당한 측정은 왜 다른 CPU 들이 constrained transaction 을 제공하는
것을 그렇게도 자제했는지에 대한 이해를 일부 제공합니다.

그 이름이 이야기 하듯이, constrained transaction 은 실제로 상당히 제약되어
있습니다:
\iffalse

The Mainframe architects needed to take extreme measures to deliver on
this forward-progress guarantee.
If a given constrained transaction repeatedly fails, the CPU
might disable branch prediction, force in-order execution, and even
disable pipelining.
If the repeated failures are due to high contention, the CPU might
disable speculative fetches, introduce random delays, and even
serialize execution of the conflicting CPUs.
``Interesting'' forward-progress scenarios involve as few as two CPUs
or as many as one hundred CPUs.
Perhaps these extreme measures provide some insight as to why other CPUs
have thus far refrained from offering constrained transactions.

As the name implies, constrained transactions are in fact severely constrained:
\fi

\begin{enumerate}
\item	최대 데이터 사용량은 메모리의 4개 블럭으로 제한되는데, 각각의 블럭은 32
	바이트 이상이 될 수 없습니다.
\item	최대 코드 크기는 256 바이트 입니다.
\item	만약 특정 4K 페이지가 constrained transaction 의 코드를 담고 있다면,
	해당 페이지는 그 트랜잭션의 데이터를 담고 있을 수 없습니다.
\item	실행될 수 있는 assembly 인스트럭션의 최대 갯수는 32 입니다.
\item	뒤 방향으로의 분기는 금지됩니다.
\iffalse

\item	The maximum data footprint is four blocks of memory,
	where each block can be no larger than 32 bytes.
\item	The maximum code footprint is 256 bytes.
\item	If a given 4K page contains a constrained transaction's code,
	then that page may not contain that transaction's data.
\item	The maximum number of assembly instructions that may be executed
	is 32.
\item	Backwards branches are forbidden.
\fi
\end{enumerate}

더도 아니고 덜도 아니고, 이러한 제약들은 링크드 리스트, 스택, 큐, 그리고 배열과
같은 여러개의 중요한 데이터 구조들을 지원합니다.
따라서 constrained HTM 은 병렬 프로그래머의 도구상자에서 중요한 도구가 될 수
있을 것으로 보입니다.

이런 진행 보장성은 절대적일 필요는 없다는 것을 알아두시기 바랍니다.
예를 들어, HTM 의 사용이 fallback 으로 global lock 을 사용한다고 생각해 봅시다.
이 fallback 메카니즘이
Section~\ref{sec:future:Aborts and Rollbacks} 에서 이야기된 ``lemming effect''
를 피할 수 있도록 잘 설계되었다고 하면, HTM 롤백들이 충분히 드물게 일어난다면,
이 global lock 은 병목이 되지 않을 겁니다.
그렇다곤 하나, 시스템이 커질수록, 크리티컬 섹션이 길어질수록, ``lemming
effect'' 로부터 회복되는데 필요한 시간이 길어질수록, 더욱 드문 ``충분한
드물음'' 이 필요해질 겁니다.
\iffalse

Nevertheless, these constraints support a number of important data structures,
including linked lists, stacks, queues, and arrays.
Constrained HTM therefore seems likely to become an important tool in
the parallel programmer's toolbox.

Note that these forward-progress guarantees need not be absolute.
For example, suppose that a use of HTM uses a global lock as fallback.
Assuming that the fallback mechanism has been carefully designed to
avoid the ``lemming effect'' discussed in
Section~\ref{sec:future:Aborts and Rollbacks},
then if HTM rollbacks are sufficiently infrequent, the global lock
will not be a bottleneck.
That said, the larger the system, the longer the critical sections,
and the longer the time required to recover from the ``lemming effect'',
the more rare ``sufficiently infrequent'' needs to be.
\fi

\subsubsection{Transaction-Size Increases}
\label{sec:future:Transaction-Size Increases}

진행 보장은 중요하지만, 우리가 봤듯이, 트랜잭션 크기와 시간에 기반한 조건적
보장이 될 겁니다.
작은 크기의 트랜잭션에 대한 보장도 상당히 유용함을 알아둘 것이 필요합니다.
예를 들어, 두개의 캐시 라인 크기에 대한 보장은 스택, 큐, dequeue 에 충분합니다.
하지만, 더 큰 데이터 구조는 더 큰 트랜잭션에 대한 보장을 필요로 하는데, 예를
들어 tree 를 순서대로 횡단하는데에는 tree 의 노드의 수만큼의 크기에 대한 보장이
필요합니다.

따라서, 보장의 크기를 늘리는 것은 HTM 의 유용성 역시 늘려주고, 따라서 CPU 들이
HTM 을 제공하거나 훌륭하고 충분한 우회적 해결방법을 제공할 필요를 증가시킵니다.
\iffalse

Forward-progress guarantees are important, but as we saw, they will
be conditional guarantees based on transaction size and duration.
It is important to note that even small-sized guarantees will be
quite useful.
For example,
a guarantee of two cache lines is sufficient for a stack, queue, or dequeue.
However, larger data structures require larger guarantees, for example,
traversing a tree in order requires a guarantee equal to the number
of nodes in the tree.

Therefore, increasing the size of the guarantee also increases the
usefulness of HTM, thereby increasing the need for CPUs to either
provide it or provide good-and-sufficient workarounds.
\fi

\subsubsection{Improved Debugging Support}
\label{sec:future:Improved Debugging Support}

트랜잭션 크기에 대한 또다른 억제 요소는 트랜잭션을 디버깅 해야할 필요입니다.
현재 메커니즘에서의 문제는 single-step exception 이 자신을 둘러싼 트랜잭션을
abort 시킨다는 것입니다.
이 문제를 위한 우회적 해결 방법으로 프로세서 에뮬레이션 (느려요!), HTM 을 STM
으로의 대체 (느리고 시맨틱이 약간 다릅니다!), 진행을 에뮬레이션 하기 위한
반복적 재시도를 사용한 playback 테크닉 (이상한 failure 모드가 존재합니다!),
그리고 HTM 트랜잭션에서의 디버깅 지원 (복잡해요!) 등의 여러가지 방버들이
있습니다.

HTM 제조사들 가운데 누군가는 브레이크포인트, single stepping, 그리고 print
명령을 포함한 고전적인 디버깅 방법을 트랜잭션 안에서 사용할 수 있는 간단한
방법을 가능하게 하는 HTM 시스템을 제공해야 하며, 이는 HTM 을 더욱 강력하게
만들어줄 겁니다.
2013년에 이르러, 일부 트랜잭셔널 메모리 연구자들은 이 문제를 인식하고 있으며
하드웨어가 돕는 디버깅 기능들에 관한 제안도
있습니다~\cite{JustinGottschlich2013TMdebug}.
물론, 이 제안은 그런 기능들을 실제로 가지고 있고 사용할 수 있는 하드웨어에
의존적입니다.
\iffalse

Another inhibitor to transaction size is the need to debug the transactions.
The problem with current mechanisms is that a single-step exception
aborts the enclosing transaction.
There are a number of workarounds for this issue, including emulating
the processor (slow!), substituting STM for HTM (slow and slightly
different semantics!),
playback techniques using repeated retries to emulate forward
progress (strange failure modes!), and
full support of debugging HTM transactions (complex!).

Should one of the HTM vendors produce an HTM system that allows
straightforward use of classical debugging techniques within
transactions, including breakpoints, single stepping, and
print statements, this will make HTM much more compelling.
Some transactional-memory researchers are starting to recognize this
problem as of 2013, with at least one proposal involving hardware-assisted
debugging facilities~\cite{JustinGottschlich2013TMdebug}.
Of course, this proposal depends on readily available hardware gaining such
facilities.
\fi

\subsubsection{Weak Atomicity}
\label{sec:future:Weak Atomicity}

HTM 이 가까운 미래에 어떤 종류의 크기 제한을 갖게 될 것이라는 점을 놓고 보면,
HTM 은 다른 메커니즘들과 부드럽게 연동될 수 있어야 할겁니다.
해저드 포인터와 RCU 같은 읽기가 대부분인 경우를 위한 메커니즘들과 HTM 의 연동
능력은 트랜잭션 외적인 읽기가 같은 목적지에 쓰기를 하는 트랜잭션을 무조건적으로
abort 시키지 않는다면 개선될 수 있을 겁니다---대신, 해당 읽기는 간단히 해당
트랜잭션 전의 값을 얻어올 수 있을 겁니다.
이런 방식으로, 해저드 포인터와 RCU 는 HTM 이 커다란 데이터 구조를 처리하고
conflict 확률을 줄이는데 사용될 수 있을 겁니다.

하지만, 이는 간단하지가 않습니다.
이 방법을 구현하는 가장 간단한 방법은 각각의 캐시라인과 bus 에 추가적인 상태를
가질 것을 필요로 하는데, 이는 추가적 비용을 필요로 합니다.
이 비용과 함께 생기는 장점은 커다란 영역을 접근하는 읽기 쓰레드들이 연속된
conflict 로 인해 업데이트 쓰레드들이 starve 하게 되는 문제 없이 수행될 수 있게
해준다는 것입니다.
Binary search tree 에 큰 효과를 가져다준 Siakvaras 등의 대안적인
방법~\cite{Siakavaras2017CombiningHA} 은 read-only traversal 에만 RCU 를
사용하고 실제 업데이트에는 HTM 만 사용합니다.
이 조합은 다른 transactional-memory 기법들을 220\% 가량 상회하는 성능을
보이는데, Howard 와 Walpole~\cite{PhilHoward2011RCUTMRBTree} 이 RCU 와 STM 을
조합해서 보인 것과 비슷한 성능 향상입니다.
두 경우 모두, 이 완화된 atomicity 는 하드웨어가 아니라 소프트웨어로
구현되었습니다.
하지만 완화된 aotmicity 를 하드웨어와 소프트웨어 모두로 구현해서 추가적인
성능향상을 보는 것도 흥미로울 겁니다.
\iffalse

Given that HTM is likely to face some sort of size limitations for the
foreseeable future, it will be necessary for HTM to interoperate
smoothly with other mechanisms.
HTM's interoperability with read-mostly mechanisms such as hazard pointers
and RCU would be improved if extra-transactional reads did not
unconditionally abort transactions with conflicting writes---instead,
the read could simply be provided with the pre-transaction value.
In this way, hazard pointers and RCU could be used to allow HTM to handle
larger data structures and to reduce conflict probabilities.

This is not necessarily simple, however.
The most straightforward way of implementing this requires an additional
state in each cache line and on the bus, which is a non-trivial added
expense.
The benefit that goes along with this expense is permitting
large-footprint readers without the risk of starving updaters due
to continual conflicts.
An alternative approach, applied to great effect to binary search trees
by Siakavaras et al.~\cite{Siakavaras2017CombiningHA},
is to use RCU for read-only traversals and HTM
only for the actual updates themselves.
This combination outperformed other transactional-memory techniques by
up to 220\,\%, a speedup similar to that observed by
Howard and Walpole~\cite{PhilHoward2011RCUTMRBTree}
when they combined RCU with STM.
In both cases, the weak atomicity is implemented in software rather than
in hardware.
It would nevertheless be interesting to see what additional speedups
could be obtained by implementing weak atomicity in both hardware and
software.
\fi

\subsection{Conclusions}
\label{sec:future:Conclusions}

현재의 HTM 구현들이 일부 경우에 대해서는 실질적인 이득을 가져다 주긴 했지만,
또한 상당한 단점들을 가지고 있기도 합니다.
가장 심각한 단점은 제한적인 트랜잭션 사이즈, conflict 처리, abort 와 롤백의
필요, 진행 보장의 부재, 되돌이켜질 수 없는 오퍼레이션들의 처리 불가능성, 그리고
락킹과의 미묘한 semantic 상의 차이입니다.
\iffalse

Although current HTM implementations have delivered real performance
benefits in some situations, they also have significant shortcomings.
The most significant shortcomings appear to be
limited transaction sizes,
the need for conflict handling, the need for aborts and rollbacks,
the lack of forward-progress guarantees,
the inability to handle irrevocable operations,
and subtle semantic differences
from locking.
\fi

이러한 단점들 가운데 일부는 미래의 구현들에서는 줄어들 수 있겠습니다만, 기존에
언급된 바~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener} 와 같이
많은 다른 종류의 동기화 메커니즘들과 함께 동작할 수 있어야 할 필요성은 계속될
것으로 보입니다.

요약해서, 현재의 HTM 구현들은 병렬 프로그래머의 도구박스에 들어오면 좋은,
그리고 유용한 추가적 도구가 되겠고, 그것들을 사용하기 위해서는 많은 흥미롭고
도전적인 작업들을 필요로 합니다.
하지만, 그것들은 모든 병렬 프로그래밍에서의 문제들을 모두 한번에 처리해줄
마법봉으로 여겨질 수는 없습니다.
\iffalse

Some of these shortcomings might be alleviated in future implementations,
but it appears that there will continue to be a strong need to make
HTM work well with the many other types of synchronization mechanisms,
as noted earlier~\cite{McKenney2007PLOSTM,PaulEMcKenney2010OSRGrassGreener}.

In short, current HTM implementations appear to be welcome and useful
additions to the parallel programmer's toolbox, and much interesting
and challenging work is required to make use of them.
However, they cannot be
considered to be a magic wand with which to wave away all parallel-programming
problems.
\fi
