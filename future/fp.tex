% future/fp.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{Functional Programming for Parallelism}
\label{sec:future:Functional Programming for Parallelism}
%
\epigraph{The curious failure of functional programming for parallel
	  applications.}
	 {\emph{Malte Skarupke}}

1980년대 초에 제가 처음으로 함수형 프로그래밍 수업을 들었을 때, 교수님은
부작용으로부터 자유로운 함수형 프로그래밍 스타일은 사소한 병렬화와 분석에 잘
맞는다고 단정하셨습니다.
30년 후, 이 단정은 남아있습니다만, 주류 제작사에서의 병렬 함수형 언어의 사용은
매우 적으며, 이는 교수님의 프로그램은 상태를 유지하지 않고 I/O 를 하지 않아야
한다고 하셨던 추가적인 말씀과 관계가 아주 없지는 않을 겁니다.
Erlang 과 같은 함수형 언어의 틈색에서의 사용이 있고, 여러 다른 함수형 언어에
멀티쓰레드 지원이 추가되었습니다만, 주류 제조 환경은 C, C++, Java, 그리고
Fortran 같은 절차형 언어의 (보통 OpenMP, MPI, 또는 coarrays 와 증간된 형태의)
영역으로 남아 있습니다.

이 상황은 자연스레 ``분석이 목표라면, 분석 전에 왜 이 절차형 언어를 함수형
언어로 변환하면 어떨까?'' 라는 질문을 일으키게 합니다.
이 방법에 대한 여러 반대들이 물론 존재하는데, 이 중 세개만 나열하자면:

\iffalse

When I took my first-ever functional-programming class in the early 1980s,
the professor asserted that the side-effect-free functional-programming
style was well-suited to trivial parallelization and analysis.
Thirty years later, this assertion remains, but mainstream production
use of parallel functional languages is minimal, a state of affairs that
might not be entirely unrelated to professor's additional
assertion that programs should neither maintain state nor do I/O\@.
There is niche use of functional languages such as Erlang, and
multithreaded support has been added to several other functional languages,
but mainstream production usage remains the province of procedural
languages such as C, C++, Java, and Fortran (usually augmented with
OpenMP, MPI, or coarrays).

This situation naturally leads to the question ``If analysis is the goal,
why not transform the procedural language into a functional language before
doing the analysis?''
There are of course a number of objections to this approach, of which
I list but three:

\fi

\begin{enumerate}
\item	절차형 언어는 다른 독립된 함수들에 의해, 또는 더 나쁘게도 여러 쓰레드에
	의해 수정될 수 있는 전역 변수들을 종종 많이 사용합니다.
	Haskell 의 \emph{monads} 는 싱글 쓰레드 전역 상태를 처리하기 위해
	발명되었으며, 전역 상태로의 멀티 쓰레드에 의한 액세스는 함수형 모델에
	추가적인 위반을 가함을 알아 두시기 바랍니다.
\item	멀티쓰레드 기반 절차형 언어는 종종 락, 어토믹 오퍼레이션, 그리고
	트랜잭션 같은 동기화 기능을 사용하는데, 이는 함수형 모델에 위반을
	더합니다.
\item	절차형 언어는 함수 인자에 \emph{별명을 붙일 (alias)} 수 있는데, 예를
	들어 같은 구조체로의 포인터를 어떤 함수의 같은 호출에 두개의 다른
	인자로 넘길 수 있습니다.
	이는 이 함수가 이 구조체를 두개의 다른 (그리고 아마도 겹치는) 코드
	순서에서 알지 못한 업데이트를 만들 수 있게 하는데, 이는 분석을 무척
	복잡하게 만듭니다.

\iffalse

\item	Procedural languages often make heavy use of global variables,
	which can be updated independently by different
	functions, or, worse yet, by multiple threads.
	Note that Haskell's \emph{monads} were invented to deal with
	single-threaded global state, and that multi-threaded access to
	global state inflicts additional violence on the functional model.
\item	Multithreaded procedural languages often use synchronization
	primitives such as locks, atomic operations, and transactions,
	which inflict added violence upon the functional model.
\item	Procedural languages can \emph{alias} function arguments,
	for example, by passing a pointer to the same structure via two
	different arguments to the same invocation of a given function.
	This can result in the function unknowingly updating that
	structure via two different (and possibly overlapping) code
	sequences, which greatly complicates analysis.

\fi

\end{enumerate}

Of course, given the importance of global state, synchronization
primitives, and aliasing, clever functional-programming experts have
proposed any number of attempts to reconcile the function programming
model to them, monads being but one case in point.

Another approach is to compile the parallel procedural program into
a functional program, then to use functional-programming tools to analyze
the result.
But it is possible to do much better than this, given that any real
computation is a large finite-state machine with finite input that
runs for a finite time interval.
This means that any real program can be transformed into an expression,
possibly albeit an impractically large one~\cite{VijayDSilva2012-sas}.

However, a number of the low-level kernels of parallel algorithms transform
into expressions that are small enough to fit easily into the memories
of modern computers.
If such an expression is coupled with an assertion, checking to see if
the assertion would ever fire becomes a satisfiability problem.
Even though satisfiability problems are NP-complete, they can often
be solved in much less time than would be required to generate the
full state space.
In addition, the solution time appears to be only weakly dependent on
the underlying memory model, so that algorithms running on weakly ordered
systems can also be checked~\cite{JadeAlglave2013-cav}.

The general approach is to transform the program into single-static-assignment
(SSA) form, so that each assignment to a variable creates a separate
version of that variable.
This applies to assignments from all the active threads, so that the
resulting expression embodies all possible executions of the code
in question.
The addition of an assertion entails asking whether any combination of
inputs and initial values can result in the assertion firing, which,
as noted above, is exactly the satisfiability problem.

One possible objection is that it does not gracefully handle arbitrary
looping constructs.
However, in many cases, this can be handled by unrolling the loop a
finite number of times.
In addition, perhaps some loops will also prove amenable to collapse
via inductive methods.

Another possible objection is that spinlocks involve arbitrarily long
loops, and any finite unrolling would fail to capture the full behavior
of the spinlock.
It turns out that this objection is easily overcome.
Instead of modeling a full spinlock, model a trylock that attempts to
obtain the lock, and aborts if it fails to immediately do so.
The assertion must then be crafted so as to avoid firing in cases
where a spinlock aborted due to the lock not being immediately available.
Because the logic expression is independent of time, all possible
concurrency behaviors will be captured via this approach.

A final objection is that this technique is unlikely to be able to handle
a full-sized software artifact such as the millions of lines of code making
up the Linux kernel.
This is likely the case, but the fact remains that exhaustive validation
of each of the much smaller parallel primitives within the Linux kernel
would be quite valuable.
And in fact the researchers spearheading this approach have applied it
to non-trivial real-world code, including the Tree RCU implementation in
the Linux
kernel~\cite{LihaoLiang2016VerifyTreeRCU,MichalisKokologiannakis2017NidhuggRCU}.

It remains to be seen how widely applicable this technique is, but
it is one of the more interesting innovations in the field of
formal verification.
Although it might well be that the functional-programming advocates
are at long last correct in their assertion of the inevitable
dominance of functional programming, it is clearly the case
that this long-touted methodology is starting to see credible
competition on its formal-verification home turf.
There is therefore continued reason to doubt the inevitability of
functional-programming dominance.
