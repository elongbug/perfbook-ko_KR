% together/applyrcu.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{RCU Rescues}
\label{sec:together:RCU Rescues}
%
\epigraph{With great doubts comes great understanding, with little doubts
	  comes little understanding.}
	 {\emph{Chinese proverb}}

이 섹션은 이 책의 앞부분에서 이야기된 일부 예제들에 RCU 를 어떻게 적용할 수
있는지 보입니다.
어떤 경우, RCU 는 더 간단한 코드를 제공하고 어떤 경우에는 더 나은 성능과
확장성을 제공하며, 또다른 경우에는 이를 모두 제공합니다.

\iffalse

This section shows how to apply RCU to some examples discussed earlier
in this book.
In some cases, RCU provides simpler code, in other cases better
performance and scalability, and in still other cases, both.

\fi

\subsection{RCU and Per-Thread-Variable-Based Statistical Counters}
\label{sec:together:RCU and Per-Thread-Variable-Based Statistical Counters}

\Cref{sec:count:Per-Thread-Variable-Based Implementation}
는 단순한 값 증가의 (C 의 \co{++} 연산자) 것만큼이나 훌륭한 성능과 선형적
확장성을 제공하는---그러나 \co{inc_count()} 를 통한 값 증가 시에만---통계적
카운터의 구현을 보였습니다.
불행히도, \co{read_count()} 를 통해 값을 읽어야 하는 쓰레드는 전역 락을
획득해야 했으며, 따라서 높은 오버헤드를 일으키고 낮은 확장성으로 고통받아야
했습니다.
이 락 기반의 구현 코드는
Page~\pageref{lst:count:Per-Thread Statistical Counters} 의
\cref{lst:count:Per-Thread Statistical Counters} 에 있습니다.

\iffalse

\Cref{sec:count:Per-Thread-Variable-Based Implementation}
described an implementation of statistical counters that provided
excellent
performance, roughly that of simple increment (as in the C \co{++}
operator), and linear scalability---but only for incrementing
via \co{inc_count()}.
Unfortunately, threads needing to read out the value via \co{read_count()}
were required to acquire a global
lock, and thus incurred high overhead and suffered poor scalability.
The code for the lock-based implementation is shown in
\cref{lst:count:Per-Thread Statistical Counters} on
Page~\pageref{lst:count:Per-Thread Statistical Counters}.

\fi

\QuickQuiz{
	대체 왜 우린 전역 락을 필요로 했죠?

	\iffalse

	Why on earth did we need that global lock in the first place?

	\fi

}\QuickQuizAnswer{
	특정 쓰레드의 \co{__thread} 변수는 그 쓰레드가 종료될 때 사라집니다.
	따라서 다른 쓰레드의 \co{__thread} 변수에 접근하는 모든 오퍼레이션을
	쓰레드 종료와 동기화 시킬 필요가 있었습니다.
	그런 동기화가 없다면 금방 종료된 쓰레드의 \co{__thread} 변수로의 접근은
	segmentation fault 를 초래합니다.

	\iffalse

	A given thread's \co{__thread} variables vanish when that
	thread exits.
	It is therefore necessary to synchronize any operation that
	accesses other threads' \co{__thread} variables with
	thread exit.
	Without such synchronization, accesses to \co{__thread} variable
	of a just-exited thread will result in segmentation faults.

	\fi

}\QuickQuizEnd

\subsubsection{Design}

여기서 우리가 원하는건 \co{inc_count()} 만이 아니라 \co{read_count()} 에서도
훌륭한 성능과 확장성을 얻기 위해 \co{read_count()} 에서 순회를 하는 쓰레드를
\co{final_mutex} 가 아닌 RCU 를 사용하게 하는 겁니다.
그러나, 계산된 값에 대한 정확도를 놓치고 싶지도 않습니다.
특히, 특정 쓰레드가 종료될 때, 우린 분명 이 종료되는 쓰레드의 값을 잃고 싶지
않고, 그걸 중복해 셀수도 없습니다.
그런 오류는 결과의 완전한 예측과 동일한 비정확성을 초래한느데 달리 말하면 그런
오류는 그 결과를 완전히 쓸모없게 만들 겁니다.
그리고 실제로, \co{final_mutex} 의 목적 중 하나는 쓰레드가 \co{read_count()}
수행 중간에 왔다가 갔다가 하지 않음을 보장하는 겁니다.

따라서, \co{final_mutex} 를 제거하고자 한다면, 일관성을 보장하는 어떤 다른
방법을 사용해야 합니다.
한가지 방법은 앞서 종료된 모든 쓰레드를 위한 전체 카운트와 쓰레드별 카운터로의
포인터들의 배열을 하나의 구조체에 두는 겁니다.
그런 구조체는 일단 \co{read_count()} 에서 사용 가능하게 하고 일관성을
유지한다면 \co{read_count()} 가 일관된 데이터를 볼 수 있게 합니다.

\iffalse

The hope is to use RCU rather than \co{final_mutex} to protect the
thread traversal in \co{read_count()} in order to obtain excellent
performance and scalability from \co{read_count()}, rather than just
from \co{inc_count()}.
However, we do not want to give up any accuracy in the computed sum.
In particular, when a given thread exits, we absolutely cannot
lose the exiting thread's count, nor can we double-count it.
Such an error could result in inaccuracies equal to the full
precision of the result, in other words, such an error would
make the result completely useless.
And in fact, one of the purposes of \co{final_mutex} is to
ensure that threads do not come and go in the middle of \co{read_count()}
execution.

Therefore, if we are to dispense with \co{final_mutex}, we will need
to come up with some other method for ensuring consistency.
One approach is to place the total count for all previously exited
threads and the array of pointers to the per-thread counters into a single
structure.
Such a structure, once made available to \co{read_count()}, is
held constant, ensuring that \co{read_count()} sees consistent data.

\fi

\subsubsection{Implementation}

\begin{fcvref}[ln:count:count_end_rcu:whole]
\Cref{lst:together:RCU and Per-Thread Statistical Counters}
의 \clnrefrange{struct:b}{struct:e} 는 \co{countarray} 구조체를 보이는데, 이
구조체는 앞서 종료된 쓰레드들로부터의 카운트를 위한 \co{->total} 필드와 현재
수행 중인 쓰레드 각각으로의 쓰레드별 \co{counter} 로의 포인터 배열인
\co{counterp[]} 를 갖습니다.
이 구조체는 특정 \co{read_count()} 수행이 파악된 수행중인 쓰레드 집합에 일관된
전체를 볼 수 있게 합니다.

\iffalse

\begin{fcvref}[ln:count:count_end_rcu:whole]
\Clnrefrange{struct:b}{struct:e} of
\cref{lst:together:RCU and Per-Thread Statistical Counters}
show the \co{countarray} structure, which contains a
\co{->total} field for the count from previously exited threads,
and a \co{counterp[]} array of pointers to the per-thread
\co{counter} for each currently running thread.
This structure allows a given execution of \co{read_count()}
to see a total that is consistent with the indicated set of running
threads.

\fi

\begin{listing}[bp]
\input{CodeSamples/count/count_end_rcu@whole.fcv}
\caption{RCU and Per-Thread Statistical Counters}
\label{lst:together:RCU and Per-Thread Statistical Counters}
\end{listing}

\Clnrefrange{perthread:b}{perthread:e} 는 쓰레드별 \co{counter} 변수, 현재
\co{countarray} 구조체를 참조하는 전역 포인터 \co{countarrayp}, 그리고
\co{final_mutex} 스핀락의 정의를 답고 있습니다.

\Clnrefrange{inc:b}{inc:e} 는
\cref{lst:count:Per-Thread Statistical Counters} 에서 달라지지 않은
\co{inc_count()} 를 보입니다.
\end{fcvref}

\iffalse

\Clnrefrange{perthread:b}{perthread:e}
contain the definition of the per-thread \co{counter}
variable, the global pointer \co{countarrayp} referencing
the current \co{countarray} structure, and
the \co{final_mutex} spinlock.

\Clnrefrange{inc:b}{inc:e} show \co{inc_count()}, which is unchanged from
\cref{lst:count:Per-Thread Statistical Counters}.
\end{fcvref}

\fi

\begin{fcvref}[ln:count:count_end_rcu:whole:read]
\Clnrefrange{b}{e} 는 \co{read_count()} 를 보이는데, 상당히 달라졌습니다.
\Clnref{rrl,rru} 는 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 을 사용해
\co{final_mutex} 의 획득과 해제를 대체합니다.
\Clnref{deref} 는 현재 \co{countarray} 구조체를 지역 변수 \co{cap} 으로 스냅샷
하기 위해 \co{rcu_dereference()} 를 사용합니다.
RCU 의 올바른 사용은 이 \co{countarray} 구조체가 \clnref{rru} 에서의 현재 RCU
read-side 크리티컬 섹션의 종료까지는 남아 있을 것을 보장합니다.
\Clnref{init} 는 \co{sum} 을 \co{cap->total} 로 초기화하는데, 이는 앞서 종료된
쓰레드의 카운트의 합입니다.
\Clnrefrange{add:b}{add:e} 는 현재 수행중인 쓰레드들에 연관된 쓰레드별 카운터를
더하며, 마지막으로 \clnref{ret} 에서 이 합을 리턴합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:count:count_end_rcu:whole:read]
\Clnrefrange{b}{e} show \co{read_count()}, which has changed significantly.
\Clnref{rrl,rru} substitute \co{rcu_read_lock()} and
\co{rcu_read_unlock()} for acquisition and release of \co{final_mutex}.
\Clnref{deref} uses \co{rcu_dereference()} to snapshot the
current \co{countarray} structure into local variable \co{cap}.
Proper use of RCU will guarantee that this \co{countarray} structure
will remain with us through at least the end of the current RCU
read-side critical section at \clnref{rru}.
\Clnref{init} initializes \co{sum} to \co{cap->total}, which is the
sum of the counts of threads that have previously exited.
\Clnrefrange{add:b}{add:e} add up the per-thread counters corresponding
to currently
running threads, and, finally, \clnref{ret} returns the sum.
\end{fcvref}

\fi

\begin{fcvref}[ln:count:count_end_rcu:whole:init]
\co{countarrayp} 의 초기 값은 \clnrefrange{b}{e} 에서의 \co{count_init()} 을
통해 제공됩니다.
이 함수는 첫번째 쓰레드가 생성되기 전에 수행되어, 초기 구조체를 할당하고 0으로
초기화 하며 \co{countarrayp} 로 그 포인터를 할당합니다.
\end{fcvref}

\begin{fcvref}[ln:count:count_end_rcu:whole:reg]
\Clnrefrange{b}{e} 는 \co{count_register_thread()} 함수를 보이는데, 이 함수는
새로 생성된 쓰레드 각각에 의해 호출됩니다.
\Clnref{idx} 는 현재 쓰레드의 인덱스를 얻어오고, \clnref{acq} 는
\co{final_mutex} 를 획득하며, \clnref{set} 은 이 쓰레드의 \co{counter} 로의
포인터를 설치하고 \clnref{rel} 은 \co{final_mutex} 를 해제합니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:count:count_end_rcu:whole:init]
The initial value for \co{countarrayp} is
provided by \co{count_init()} on \clnrefrange{b}{e}.
This function runs before the first thread is created, and its job
is to allocate
and zero the initial structure, and then assign it to \co{countarrayp}.
\end{fcvref}

\begin{fcvref}[ln:count:count_end_rcu:whole:reg]
\Clnrefrange{b}{e} show the \co{count_register_thread()} function, which
is invoked by each newly created thread.
\Clnref{idx} picks up the current thread's index, \clnref{acq} acquires
\co{final_mutex}, \clnref{set} installs a pointer to this thread's
\co{counter}, and \clnref{rel} releases \co{final_mutex}.
\end{fcvref}

\fi

\QuickQuiz{
	\begin{fcvref}[ln:count:count_end_rcu:whole:reg]
	여보세요!!!
	\Cref{lst:together:RCU and Per-Thread Statistical Counters}
	의 \clnref{set} 은 앞서서부터 존재한 \co{countarray} 구조의 값을
	수정하잖아요!
	이 구조체는 일단 \co{read_count()} 에게 접근 가능해지면 일관적인 상태로
	남는다고 하지 않았나요???
	\end{fcvref}

	\iffalse

	\begin{fcvref}[ln:count:count_end_rcu:whole:reg]
	Hey!!!
	\Clnref{set} of
	\cref{lst:together:RCU and Per-Thread Statistical Counters}
	modifies a value in a pre-existing \co{countarray} structure!
	Didn't you say that this structure, once made available to
	\co{read_count()}, remained constant???
	\end{fcvref}

	\fi

}\QuickQuizAnswer{
	실제로 그렇게 말씀드렸습니다.
	그리고 \co{count_register_thread()} 가 \co{count_unregister_thread()}
	처럼 새 구조체를 할당받게 하는 것도 가능할 겁니다.

	하지만 이는 불필요합니다.
	\co{read_count()} 의 오류 범위의 유도는 메모리의 스냅샷에서 기초함을
	기억하시기 바랍니다.
	새 쓰레드는 값 0인 초기 \co{counter} 값으로 시작하므로,
	\co{read_count()} 의 수행 도중에 새 쓰레드를 넣는다 해도 그 유도식은
	유지됩니다.
	따라서, 흥미롭게도 새 쓰레드를 더할 때, 이 구현은 실제로 할당을 하지는
	않지만 새 구조체를 할당하는 것과 같은 효과를 냅니다.

	\begin{fcvref}[ln:count:count_end_rcu:whole:unreg]
	다른 한편, \co{count_unregister_thread()} 는 빠져나가는 쓰레드의 일이
	중복으로 카운트 되게 할 수 있습니다.
	이는 \co{read_count()} 가 라인~\clnref{add} 와~\clnref{null} 사이에서
	호출될 때 발생 가능합니다.
	이 중복 카운트를 막는 효율적인 방법들이 있습니다만, 그건 독자 여러분의
	연습문제로 남겨두겠습니다.
	\end{fcvref}

	\iffalse

	Indeed I did say that.
	And it would be possible to make \co{count_register_thread()}
	allocate a new structure, much as \co{count_unregister_thread()}
	currently does.

	But this is unnecessary.
	Recall the derivation of the error bounds of \co{read_count()}
	that was based on the snapshots of memory.
	Because new threads start with initial \co{counter} values of
	zero, the derivation holds even if we add a new thread partway
	through \co{read_count()}'s execution.
	So, interestingly enough, when adding a new thread, this
	implementation gets the effect of allocating a new structure,
	but without actually having to do the allocation.

	\begin{fcvref}[ln:count:count_end_rcu:whole:unreg]
	On the other hand, \co{count_unregister_thread()} can result
	in the outgoing thread's work being double counted.
	This can happen when \co{read_count()} is invoked between
	lines~\Clnref{add} and~\Clnref{null}.
	There are efficient ways of avoiding this double-counting, but
	these are left as an exercise for the reader.
	\end{fcvref}

	\fi

}\QuickQuizEnd

\begin{fcvref}[ln:count:count_end_rcu:whole:unreg]
\Clnrefrange{b}{e} 는 \co{count_unregister_thread()} 를 보이는데, 이 함수는 각
쓰레드가 종료되기 직전에 호출됩니다.
\Clnrefrange{alloc:b}{alloc:e} 는 새 \co{countarray} 구조체를 할당하고,
\clnref{acq} 는 \co{final_mutex} 를 획득하고 \clnref{rel} 에서 해제합니다.
\Clnref{copy} 는 현재 \co{countarray} 의 내용을 새로 할당된 버전에 복사하며,
\clnref{add} 는 종료되고 있는 쓰레드의 \co{counter} 를 새 구조체의 \co{->total}
에 더하며, \clnref{null} 은 이 종료되는 중인 쓰레드의 \co{counterp[]} 배열
원소를 \co{NULL} 로 만듭니다.
\Clnref{retain} 은 이어서 현재 (곧 과거 버전이 될) \co{countarray} 구조체로의
포인터를 보존하고, \clnref{assign} 은 \co{countarray} 구조체의 새 버전을
설치하기 위해 \co{rcu_assign_pointer()} 를 사용합니다.
\Clnref{sync} 는 하나의 grace period 가 지나가길, 그래서 동시에
\co{read_count()} 를 수행 중일 수 있는, 따라서 기존 \co{countarray} 구조체로의
참조를 가지고 있을 수도 있는 쓰레드들이 각자의 RCU read-side 크리티컬 섹션을
빠져나와 모든 그런 참조를 내려놓을 때까지 기다립니다.
\Clnref{free} 는 이제 기존의 \co{countarray} 구조체를 안전하게 메모리 해제할 수
있습니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:count:count_end_rcu:whole:unreg]
\Clnrefrange{b}{e} show \co{count_unregister_thread()}, which is invoked
by each thread just before it exits.
\Clnrefrange{alloc:b}{alloc:e} allocate a new \co{countarray} structure,
\clnref{acq} acquires \co{final_mutex} and \clnref{rel} releases it.
\Clnref{copy} copies the contents of the current \co{countarray} into
the newly allocated version, \clnref{add} adds the exiting thread's \co{counter}
to new structure's \co{->total}, and \clnref{null} \co{NULL}s the exiting thread's
\co{counterp[]} array element.
\Clnref{retain} then retains a pointer to the current (soon to be old)
\co{countarray} structure, and \clnref{assign} uses \co{rcu_assign_pointer()}
to install the new version of the \co{countarray} structure.
\Clnref{sync} waits for a grace period to elapse, so that any threads that
might be concurrently executing in \co{read_count()}, and thus might
have references to the old \co{countarray} structure, will be allowed
to exit their RCU read-side critical sections, thus dropping any such
references.
\Clnref{free} can then safely free the old \co{countarray} structure.
\end{fcvref}

\fi

\QuickQuiz{
	고정된 크기의 \co{counterp} 배열을 가지고, 이 코드는 어떻게 쓰레드의
	수의 고정된 최대 한계 문제를 어떻게 회피하나요?

	\iffalse

	Given the fixed-size \co{counterp} array, exactly how does this
	code avoid a fixed upper bound on the number of threads???

	\fi

}\QuickQuizAnswer{
	맞아요, 그 배열은 실제로 고정된 최대 한계를 만듭니다.
	이 한계는 쓰레드들을 userspace RCU~\cite{MathieuDesnoyers2012URCU} 에서
	그러는 것처럼 링크드 리스트를 사용해 쓰레드를 추적하는 것으로 회피될 수
	있습니다.
	그와 비슷한 일을 하는건 독자 여러분의 연습문제로 남겨둡니다.

	\iffalse

	You are quite right, that array does in fact reimpose the fixed
	upper limit.
	This limit may be avoided by tracking threads with a linked list,
	as is done in userspace RCU~\cite{MathieuDesnoyers2012URCU}.
	Doing something similar for this code is left as an exercise for
	the reader.

	\fi

}\QuickQuizEnd

\subsubsection{Discussion}

\QuickQuiz{
	와!
	\Cref{lst:count:Per-Thread Statistical Counters} 의 42 라인 코드에 비해
	\cref{lst:together:RCU and Per-Thread Statistical Counters}
	는 70 라인 코드를 갖는군요.
	이 여분의 복잡도는 그럴만한 가치가 있나요?

	\iffalse

	Wow!
	\cref{lst:together:RCU and Per-Thread Statistical Counters}
	contains 70 lines of code, compared to only 42 in
	\cref{lst:count:Per-Thread Statistical Counters}.
	Is this extra complexity really worth it?

	\fi

}\QuickQuizAnswer{
	이는 물론 경우에 따라 결정되어야 합니다.
	여러분이 선형적으로 확장되는 \co{read_count()} 구현을 필요로 한다면,
	\cref{lst:count:Per-Thread Statistical Counters}
	에 보인 락 기반 구현은 여러분에게 적합치 않을 겁니다.
	그러나, \co{read_count()} 호출이 충분히 드물다면 락 기반 버전이 더
	간단하고 따라서 더 나을 수도 있는데, 이 코드 크기 차이는 구조체 정의,
	메모리 할당, 그리고 \co{NULL} 반환값 검사 때문이긴 합니다.

	물론, 더 나은 질문은 ``왜 언어 자체적으로 쓰레드간 \co{__thread} 변수
	접근을 지원하지 않나요?'' 일 겁니다.
	어쨌건, 그런 구현은 락킹과 RCU 의 사용 모두를 불필요하게 할 겁니다.
	이는 결국
	\cref{lst:count:Per-Thread Statistical Counters} 에 보인 것보다도 더
	간단한, 그러면서도
	\cref{lst:together:RCU and Per-Thread Statistical Counters} 에 보인
	구현의 확장성과 성능 이익을 유지한 구현을 가능하게 할 겁니다!

	\iffalse

	This of course needs to be decided on a case-by-case basis.
	If you need an implementation of \co{read_count()} that
	scales linearly, then the lock-based implementation shown in
	\cref{lst:count:Per-Thread Statistical Counters}
	simply will not work for you.
	On the other hand, if calls to \co{read_count()} are sufficiently
	rare, then the lock-based version is simpler and might thus be
	better, although much of the size difference is due
	to the structure definition, memory allocation, and \co{NULL}
	return checking.

	Of course, a better question is ``Why doesn't the language
	implement cross-thread access to \co{__thread} variables?''
	After all, such an implementation would make both the locking
	and the use of RCU unnecessary.
	This would in turn enable an implementation that
	was even simpler than the one shown in
	\cref{lst:count:Per-Thread Statistical Counters}, but
	with all the scalability and performance benefits of the
	implementation shown in
	\cref{lst:together:RCU and Per-Thread Statistical Counters}!

	\fi

}\QuickQuizEnd

RCU 의 사용은 종료되는 쓰레드가 다른 쓰레드가 종료되는 쓰레드의 \co{__thread}
변수 사용을 마쳤음이 보장될 때까지 기다리는 것을 가능하게 해줍니다.
이는 \co{read_count()} 함수가 락킹을 제거할 수 있게 해주며, 따라서
\co{inc_count()} 와 \co{read_count()} 함수 모두에 훌륭한 성능과 확장성을
제공하게 해줍니다.
그러나, 이 성능과 확장성은 코드 복잡도의 약간의 증가의 비용을 갖습니다.
컴파일러와 라이브러리 개발자들이 안전한 쓰레드간 \co{__thread} 변수 접근을 위해
user-level RCU~\cite{MathieuDesnoyers2009URCU} 를 채택해서 \co{__thread}
변수들의 사용자들에게 보여지는 복잡도를 낮출 수 있기를 희망합니다.

\iffalse

Use of RCU enables exiting threads to wait until other threads are
guaranteed to be done using the exiting threads' \co{__thread} variables.
This allows the \co{read_count()} function to dispense with locking,
thereby providing
excellent performance and scalability for both the \co{inc_count()}
and \co{read_count()} functions.
However, this performance and scalability come at the cost of some increase
in code complexity.
It is hoped that compiler and library writers employ user-level
RCU~\cite{MathieuDesnoyers2009URCU} to provide safe cross-thread
access to \co{__thread} variables, greatly reducing the
complexity seen by users of \co{__thread} variables.

\fi

\subsection{RCU and Counters for Removable I/O Devices}
\label{sec:together:RCU and Counters for Removable I/O Devices}

\Cref{sec:count:Applying Exact Limit Counters}
는 제거 가능한 기기로의 I/O 액세스를 세기 위한 한쌍의 코드 조각을 보였습니다.
이 코드 조각들은 reader-writer 락을 획득함으로써 생기는 fastpath (I/O 시작)
에서의 높은 오버헤드로 고통받았습니다.

이 섹션은 이 오버헤드를 막기 위해 RCU 가 어떻게 사용될 수 있는지 보입니다.

I/O 를 수행하는 코드는 원래의 것과 상당히 비슷한데 원본에서의 reader-writer 락
read-side 크리티컬 섹션이 RCU read-side 크리티컬 섹션으로 대체되었습니다:

\iffalse

\Cref{sec:count:Applying Exact Limit Counters}
showed a fanciful pair of code fragments for dealing with counting
I/O accesses to removable devices.
These code fragments suffered from high overhead on the fastpath
(starting an I/O) due to the need to acquire a reader-writer
lock.

This section shows how RCU may be used to avoid this overhead.

The code for performing an I/O is quite similar to the original, with
an RCU read-side critical section being substituted for the reader-writer
lock read-side critical section in the original:

\fi

\begin{VerbatimN}[tabsize=8]
rcu_read_lock();
if (removing) {
	rcu_read_unlock();
	cancel_io();
} else {
	add_count(1);
	rcu_read_unlock();
	do_io();
	sub_count(1);
}
\end{VerbatimN}
\vspace{5pt}

이 RCU read-side 기능들은 최소한의 오버헤드를 가지며, 따라서 희망한대로
fastpath 속도를 증가시킵니다.

기기를 제거하는 코드 조각의 업데이트된 버전은 다음과 같습니다:

\iffalse

The RCU read-side primitives have minimal overhead, thus speeding up
the fastpath, as desired.

The updated code fragment removing a device is as follows:

\fi

\begin{fcvlabel}[ln:together:applyrcu:Removing Device]
\begin{VerbatimN}[tabsize=8,commandchars=\\\[\]]
spin_lock(&mylock);
removing = 1;
sub_count(mybias);
spin_unlock(&mylock);
synchronize_rcu();
while (read_count() != 0) {	\lnlbl[nextofsync]
	poll(NULL, 0, 1);
}
remove_device();
\end{VerbatimN}
\end{fcvlabel}

\begin{fcvref}[ln:together:applyrcu:Removing Device]
여기서 우리는 reader-writer 락을 배타적 스핀락으로 교체하고 모든 RCU read-side
크리티컬 섹션이 완료되기를 기다리기 위해 \co{synchronize_rcu()} 를 추가합니다.
\co{synchronize_rcu()} 때문에, 우리가 일단 \clnref{nextofsync} 에 다다르면 모든
남아있는 I/O 는 세어졌음을 압니다.

물론, \co{synchronize_rcu()} 의 오버헤드는 클 수 있으나, 기기의 제거가 상당히
드물게 이어질 것이란 걸 생각하면 이는 좋은 트레이드오프입니다.
\end{fcvref}

\iffalse

\begin{fcvref}[ln:together:applyrcu:Removing Device]
Here we replace the reader-writer lock with an exclusive spinlock and
add a \co{synchronize_rcu()} to wait for all of the RCU read-side
critical sections to complete.
Because of the \co{synchronize_rcu()},
once we reach \clnref{nextofsync},
we know that all remaining I/Os have been accounted for.

Of course, the overhead of \co{synchronize_rcu()} can be large,
but given that device removal is quite rare, this is usually a good
tradeoff.
\end{fcvref}

\fi

\FloatBarrier
\subsection{Array and Length}
\label{sec:together:Array and Length}

\Cref{lst:together:RCU-Protected Variable-Length Array} 에 보인 것과 같은
RCU 로 보호되는 유동 길이 배열이 있다고 해봅시다.
배열 \co{->a[]} 의 길이는 언제든 동적으로 변화할 수 있고, 그 길이는
\co{->length} 필드에 의해 주어집니다.
물론, 이는 다음과 같은 race condition 을 만듭니다:

\iffalse

Suppose we have an RCU-protected variable-length array, as shown in
\cref{lst:together:RCU-Protected Variable-Length Array}.
The length of the array \co{->a[]} can change dynamically, and at any
given time, its length is given by the field \co{->length}.
Of course, this introduces the following race condition:

\fi

\begin{listing}[tbp]
\begin{VerbatimL}[tabsize=8]
struct foo {
	int length;
	char *a;
};
\end{VerbatimL}
\caption{RCU-Protected Variable-Length Array}
\label{lst:together:RCU-Protected Variable-Length Array}
\end{listing}

\begin{enumerate}
\item	이 배열은 초기엔 16 캐릭터 길이이며, 따라서 \co{->length} 는 16 입니다.
\item	CPU~0 이 \co{->length} 의 값을 읽어와 16을 얻습니다.
\item	CPU~1 이 이 배열의 길이를 8로 줄이고, 이 새 8-캐릭터 블록 메모리로의
	포인터를 \co{->a[]} 에 할당합니다.
\item	CPU~0 이 \co{->a[]} 로의 새 포인터를 가져오고 새 값을 원소 12 에
	저장합니다.
	이 원소는 8개 캐릭터만 가지므로 이는 SEGV 또는 (더 나쁜) 메모리 오염을
	일으킵니다.

\iffalse

\item	The array is initially 16 characters long, and thus \co{->length}
	is equal to 16.
\item	CPU~0 loads the value of \co{->length}, obtaining the value 16.
\item	CPU~1 shrinks the array to be of length 8, and assigns a pointer
	to a new 8-character block of memory into \co{->a[]}.
\item	CPU~0 picks up the new pointer from \co{->a[]}, and stores a
	new value into element 12.
	Because the array has only 8 characters, this results in
	a SEGV or (worse yet) memory corruption.

\fi

\end{enumerate}

이걸 어떻게 막을 수 있을까요?

한가지 방법은
\cref{chp:Advanced Synchronization: Memory Ordering} 에서 다룬 메모리 배리어를
주의 깊게 사용하는 겁니다.
이는 동작하지만, 읽기 쪽의 오버헤드를 일으키며, 어쩌면 더 나쁘게도 명시적
메모리 배리어의 사용을 핑료로 합니다.

\iffalse

How can we prevent this?

One approach is to make careful use of memory barriers, which are
covered in \cref{chp:Advanced Synchronization: Memory Ordering}.
This works, but incurs read-side overhead and, perhaps worse, requires
use of explicit memory barriers.

\fi

\begin{listing}[tbp]
\begin{VerbatimL}[tabsize=8]
struct foo_a {
	int length;
	char a[0];
};

struct foo {
	struct foo_a *fa;
};
\end{VerbatimL}
\caption{Improved RCU-Protected Variable-Length Array}
\label{lst:together:Improved RCU-Protected Variable-Length Array}
\end{listing}

더 나은 방법은
\cref{lst:together:Improved RCU-Protected Variable-Length Array}~\cite{Arcangeli03}
에 보인 것처럼 값과 배열을 같은 구조체에 넣는 것입니다.
그러면 새 배열을 (\co{foo_a} 구조체) 할당하는 것은 자동적으로 그 배열의 길이를
위한 공간을 제공합니다.
이는 어떤 CPU 가 \co{->fa} 로의 참조를 얻으면 \co{->length} 는 \co{->a[]} 에
맞을 것이 보장됨을 의미합니다.

\iffalse

A better approach is to put the value and the array into the same structure,
as shown in
\cref{lst:together:Improved RCU-Protected Variable-Length Array}~\cite{Arcangeli03}.
Allocating a new array (\co{foo_a} structure) then automatically provides
a new place for the array length.
This means that if any CPU picks up a reference to \co{->fa}, it is
guaranteed that the \co{->length} will match the \co{->a[]}.

\fi

\begin{enumerate}
\item	이 배열은 초기에 16 캐릭터 길이이므로, \co{->length} 는 16 입니다.
\item	CPU~0 이 \co{->fa} 의 값을 읽어 값 16 과 16 바이트 배열을 갖는
	구조체로의 포인터를 얻어옵니다.
\item	CPU~0 이 \co{->fa->length} 를 읽어 값 16을 얻습니다.
\item	CPU~1 이 이 배열을 길이 8로 줄이고, 8 캐릭터 메모리 블록을 에 담고 있는
	새로운 \co{foo_a} 구조체로의 포인터를 \co{->fa} 에 할당합니다.
\item	CPU~0 이 \co{->a[]} 로부터 새로운 포인터를 가져오고, 새 값을 원소 12 에
	저장합니다.
	하지만 CPU~0 은 여전히 16 바이트 배열을 갖는 기존의 \co{foo_a} 구조체를
	참조하고 있으므로 아무 문제 없습니다.

\iffalse

\item	The array is initially 16 characters long, and thus \co{->length}
	is equal to 16.
\item	CPU~0 loads the value of \co{->fa}, obtaining a pointer to
	the structure containing the value 16 and the 16-byte array.
\item	CPU~0 loads the value of \co{->fa->length}, obtaining the value 16.
\item	CPU~1 shrinks the array to be of length 8, and assigns a pointer
	to a new \co{foo_a} structure containing an 8-character block
	of memory into \co{->fa}.
\item	CPU~0 picks up the new pointer from \co{->a[]}, and stores a
	new value into element 12.
	But because CPU~0 is still referencing the old \co{foo_a}
	structure that contains the 16-byte array, all is well.

\fi

\end{enumerate}

물론, 두 경우 모두 CPU~1 은 기존 배열을 메모리 해제하기 전에 하나의 grace
period 를 기다려야만 합니다.
이 방법의 더 범용적인 버전을 다음 섹션에서 보입니다.

\iffalse

Of course, in both cases, CPU~1 must wait for a grace period before
freeing the old array.

A more general version of this approach is presented in the next section.

\fi

\subsection{Correlated Fields}
\label{sec:together:Correlated Fields}
\OriginallyPublished{Section}{sec:together:Correlated Fields}{Correlated Fields}{Oregon Graduate Institute}{PaulEdwardMcKenneyPhD}

Suppose that each of Sch\"odinger's animals is represented by the
data element shown in
\cref{lst:together:Uncorrelated Measurement Fields}.
The \co{meas_1}, \co{meas_2}, and \co{meas_3} fields are a set
of correlated measurements that are updated periodically.
It is critically important that readers see these three values from
a single measurement update: If a reader sees an old value of
\co{meas_1} but new values of \co{meas_2} and \co{meas_3}, that
reader will become fatally confused.
How can we guarantee that readers will see coordinated sets of these
three values?\footnote{
	This situation is similar to that described in
	\cref{sec:together:Correlated Data Elements},
	except that here readers need only see a consistent view of a
	given single data element, not the consistent view of a
	group of data elements that was required in that earlier
	\lcnamecref{sec:together:Correlated Data Elements}.}

\begin{listing}[tbp]
\begin{VerbatimL}[tabsize=8]
struct animal {
	char name[40];
	double age;
	double meas_1;
	double meas_2;
	double meas_3;
	char photo[0]; /* large bitmap. */
};
\end{VerbatimL}
\caption{Uncorrelated Measurement Fields}
\label{lst:together:Uncorrelated Measurement Fields}
\end{listing}

One approach would be to allocate a new \co{animal} structure,
copy the old structure into the new structure, update the new
structure's \co{meas_1}, \co{meas_2}, and \co{meas_3} fields,
and then replace the old structure with a new one by updating
the pointer.
This does guarantee that all readers see coordinated sets of
measurement values, but it requires copying a large structure due
to the \co{->photo[]} field.
This copying might incur unacceptably large overhead.

\begin{listing}[tbp]
\begin{VerbatimL}[tabsize=8]
struct measurement {
	double meas_1;
	double meas_2;
	double meas_3;
};

struct animal {
	char name[40];
	double age;
	struct measurement *mp;
	char photo[0]; /* large bitmap. */
};
\end{VerbatimL}
\caption{Correlated Measurement Fields}
\label{lst:together:Correlated Measurement Fields}
\end{listing}

Another approach is to impose a level of indirection, as shown in
\cref{lst:together:Correlated Measurement Fields}~\cite[Section 5.3.4]{PaulEdwardMcKenneyPhD}.
When a new measurement is taken, a new \co{measurement} structure
is allocated, filled in with the measurements, and the \co{animal}
structure's \co{->mp} field is updated to point to this new
\co{measurement} structure using \co{rcu_assign_pointer()}.
After a grace period elapses, the old \co{measurement} structure
can be freed.

\QuickQuiz{
	But cant't the approach shown in
	\cref{lst:together:Correlated Measurement Fields}
	result in extra cache misses, in turn resulting in additional
	read-side overhead?
}\QuickQuizAnswer{
	Indeed it can.

\begin{listing}[tbp]
\begin{VerbatimL}[tabsize=8]
struct measurement {
	double meas_1;
	double meas_2;
	double meas_3;
};

struct animal {
	char name[40];
	double age;
	struct measurement *mp;
        struct measurement meas;
	char photo[0]; /* large bitmap. */
};
\end{VerbatimL}
\caption{Localized Correlated Measurement Fields}
\label{lst:together:Localized Correlated Measurement Fields}
\end{listing}

	One way to avoid this cache-miss overhead is shown in
	\cref{lst:together:Localized Correlated Measurement Fields}:
	Simply embed an instance of a \co{measurement} structure
	named \co{meas}
	into the \co{animal} structure, and point the \co{->mp}
	field at this \co{->meas} field.

	Measurement updates can then be carried out as follows:

	\begin{enumerate}
	\item	Allocate a new \co{measurement} structure and place
		the new measurements into it.
	\item	Use \co{rcu_assign_pointer()} to point \co{->mp} to
		this new structure.
	\item	Wait for a grace period to elapse, for example using
		either \co{synchronize_rcu()} or \co{call_rcu()}.
	\item	Copy the measurements from the new \co{measurement}
		structure into the embedded \co{->meas} field.
	\item	Use \co{rcu_assign_pointer()} to point \co{->mp}
		back to the old embedded \co{->meas} field.
	\item	After another grace period elapses, free up the
		new \co{measurement} structure.
	\end{enumerate}

	This approach uses a heavier weight update procedure to eliminate
	the extra cache miss in the common case.
	The extra cache miss will be incurred only while an update is
	actually in progress.
}\QuickQuizEnd

This approach enables readers to see correlated values for selected
fields, but while incurring minimal read-side overhead.
This per-data-element consistency suffices in the common case where
a reader looks only at a single data element.

% @@@ Birthstone/tombstone for moving records when readers cannot be permitted
% to see extraneous records.
% Flag for deletion (if not already covered in the defer chapter).
% @@@ Issaquah Challenge.
% @@@ RLU & MV-RLU (Eventually the corresponding patents.)

\subsection{Update-Friendly Traversal}
\label{sec:together:Update-Friendly Traversal}

Suppose that a statistical scan of all elements in a hash table is
required.
For example, Schr\"odinger might wish to compute the average
length-to-weight ratio over all of his animals.\footnote{
	Why would such a quantity be useful?
	Beats me!
	But group statistics are often useful.}
Suppose further that Schr\"odinger is willing to ignore slight
errors due to animals being added to and removed from the hash
table while this statistical scan is being carried out.
What should Schr\"odinger do to control concurrency?

One approach is to enclose the statistical scan in an RCU read-side
critical section.
This permits updates to proceed concurrently without unduly impeding
the scan.
In particular, the scan does not block the updates and vice versa,
which allows scan of hash tables containing very large numbers of
elements to be supported gracefully, even in the face of very high
update rates.

\QuickQuiz{
	But how does this scan work while a resizable hash table
	is being resized?
	In that case, neither the old nor the new hash table is
	guaranteed to contain all the elements in the hash table!
}\QuickQuizAnswer{
	True, resizable hash tables as described in
	\cref{sec:datastruct:Non-Partitionable Data Structures}
	cannot be fully scanned while being resized.
	One simple way around this is to acquire the
	\co{hashtab} structure's \co{->ht_lock} while scanning,
	but this prevents more than one scan from proceeding
	concurrently.

	Another approach is for updates to mutate the old hash
	table as well as the new one while resizing is in
	progress.
	This would allow scans to find all elements in the old
	hash table.
	Implementing this is left as an exercise for the reader.
}\QuickQuizEnd

\subsection{Scalable Reference Count Two}
\label{sec:together:Scalable Reference Count Two}

Suppose a reference count is becoming a performance or scalability
bottleneck.
What can you do?

Another approach is to use per-CPU counters for each reference count,
somewhat similar to the algorithms in \cref{chp:Counting}, in particular,
the exact limit counters described in
\cref{sec:count:Exact Limit Counters}.
The need to switch between per-CPU and global modes for these counters
results either in expensive increments and decrements on the one hand
(\cref{sec:count:Atomic Limit Counter Implementation})
or in the use of POSIX signals on the other
(\cref{sec:count:Signal-Theft Limit Counter Design}).

Another alternative is to use RCU to mediate the switch between per-CPU
and global counting modes.
Each update is carried out within an RCU read-side critical section,
and each update checks a flag to determine whether to update the
per-CPU counters on the one hand or the global on the other.
To switch modes, update the flag, wait for a grace period, and then
move any remaining counts from the per-CPU counters to the global
counter or vice versa.

The Linux kernel uses this approach in its \co{percpu_ref} style of
reference counter, to which interested readers are referred.

% @@@ RCU link counts
% @@@ Minimize memory footprint, for example, SRCU.
% @@@ Dealing with too-long readers.  Drop anchor, use refcnt, shard
% @@@	the list, use iterator that takes one of these approaches, ...
