% defer/whichtochoose.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{Which to Choose?}
\label{sec:defer:Which to Choose?}

\begin{table*}
\small
\centering
\begin{tabular}{p{1.5in}||p{1.5in}|p{0.8in}|p{0.8in}|p{1.0in}}
	~ ~ ~ ~ ~ ~ ~ ~ ~
		& Reference Counting
			& Hazard Pointers
				& Sequence Locks
					& RCU \\
	\hline
%		  RC	  HP	  SL	  RCU \\
	\hline
	Existence Guarantees
		& Complex
			& Yes
				& No
					& Yes \\
	\hline
	Updates and Readers Progress Concurrently
		& Yes
			& Yes
				& No
					& Yes \\
	\hline
	Contention Among Readers
		& High
			& None
				& None
					& None \\
	\hline
	Reader Per-Critical-Section Overhead
		& N/A
			& N/A
				& Two \co{smp_mb()}
					& Ranges from none to two
					  \co{smp_mb()} \\
	\hline
	Reader Per-Object Traversal Overhead
		& Read-modify-write atomic operations, memory-barrier
		  instructions, and cache misses
			& \co{smp_mb()}
				& None, but unsafe
					& None (volatile accesses) \\
	\hline
	Reader Forward Progress Guarantee
		& Lock free
			& Lock free
				& Blocking
					& Bounded wait free \\
	\hline
	Reader Reference Acquisition
		& Can fail (conditional)
			& Can fail (conditional)
				& Unsafe
					& Cannot fail (unconditional) \\
	\hline
	Memory Footprint
		& Bounded
			& Bounded
				& Bounded
					& Unbounded \\
	\hline
	Reclamation Forward Progress
		& Lock free
			& Lock free
				& N/A
					& Blocking \\
	\hline
	Automatic Reclamation
		& Yes
			& No
				& N/A
					& No \\
	\hline
	Lines of Code
		& 94
			& 79
				& 79
					& 73 \\
\end{tabular}
\caption{Which Deferred Technique to Choose?}
\label{tab:defer:Which Deferred Technique to Choose?}
\end{table*}

Table~\ref{tab:defer:Which Deferred Technique to Choose?}
provides some rough rules of thumb that can help you choose among the
four deferred-processing techniques presented in this chapter.

As shown in the ``Existence Guarantee'' row,
if you need existence guarantees for linked
data elements, you must use reference counting, hazard pointers, or RCU.
Sequence locks do not provide existence guarantees, instead providing
detection of updates, retrying any read-side critical sections
that do encounter an update.

Of course, as shown in the ``Updates and Readers Progress Concurrently''
row, this detection of updates implies
that sequence locking does not permit updaters and readers to make forward
progress concurrently.
After all, preventing such forward progress is the whole point of using
sequence locking in the first place!
This situation points the way to using sequence locking in conjunction
with reference counting, hazard pointers, or RCU in order to provide
both existence guarantees and update detection.
In fact, the Linux kernel combines RCU and sequence locking in
this manner during pathname lookup.

The ``Contention Among Readers'', ``Reader Per-Critical-Section Overhead'',
and ``Reader Per-Object Traversal Overhead'' rows give a rough sense of
the read-side overhead of these techniques.
The overhead of reference counting can be quite large, with
contention among readers along with a fully ordered read-modify-write
atomic operation required for each and every object traversed.
Hazard pointers incur the overhead of a memory barrier for each data element
traversed, and sequence locks incur the overhead of a pair of memory barriers
for each attempt to execute the critical section.
The overhead of RCU implementations vary from nothing to that of a pair of
memory barriers for each read-side critical section, thus providing RCU
with the best performance, particularly for read-side critical sections
that traverse many data elements.

The ``Reader Forward Progress Guarantee'' row shows that only RCU
has a bounded wait-free forward-progress guarantee, which means that
it can carry out a finite traversal by executing a bounded number of
instructions.

The ``Reader Reference Acquisition'' rows indicates that only RCU is
capable of unconditionally acquiring references.
The entry for sequence locks is ``N/A'' because, again, sequence locks
detect updates rather than acquiring references.
Reference counting and hazard pointers require that traversals be
restarted from the beginning if a given acquisition fail because
the currrent object might be removed and all of its
possible successsors might be not only be removed, but also freed.
For example, when using reference counting or hazard pointers to
protect a tree traversal, any reference-acquisition failure requires
that the traversal be restarted from the root of the tree.
This situation gives RCU a significant ease-of-use advantage.

However, RCU's ease-of-use advantage does not come
for free, as can be seen in the ``Memory Footprint'' row.
RCU's support of unconditional reference acquisition means that
it must avoid freeing any object visible to a given RCU reader
until that reader completes.
RCU therefore has an unbounded footprint, at least unless updates
are artificially throttled.
In contrast, reference counting and hazard pointers would retain only
those specific data elements actually referenced by concurrent readers.

This tension between memory footprint and acquisition
failures is sometimes resolved within the Linux kernel by combining use
of RCU and reference counters.
RCU is used for short-lived references, which means that RCU read-side
critical sections can be short.
These short RCU read-side critical sections in turn mean that the corresponding
RCU grace periods can also be short, limiting the memory footprint.
For the few data elements that need longer-lived references, reference
counting is used.
This means that the complexity of reference-acquisition failure only
needs to be dealt with for those few data elements:  The bulk of
the reference acquisitions are unconditional, courtesy of RCU.
See Section~\ref{sec:together:Refurbish Reference Counting}
for more information on combining reference counting with other
synchronization mechanisms.

The ``Reclamation Forward Progress'' row shows that hazard pointers
can provide non-blocking updates~\cite{MagedMichael04a,HerlihyLM02}.
Reference counting might or might not, depending on the implementation.
However, sequence locking cannot provide non-blocking updates, courtesy
of its update-side lock.
RCU updaters must wait on readers, which also rules out fully non-blocking
updates.
However, there are situations in which the only blocking operation is
a wait to free memory, which results in an situation that, for many
purposes, is as good as non-blocking~\cite{MathieuDesnoyers2012URCU}.

As shown in the ``Automatic Reclamation'' row, only reference
counting can automate freeing of memory, at least assuming non-cyclic
data structures.

Finally, the ``Lines of Code'' row shows the size of the Pre-BSD
Routing Table implementations, giving a rough idea of relative ease of use.
That said, it is important to note that the reference-counting and
sequence-locking implementations are buggy, and that a correct
reference-counting implementation is considerably more complex.

As more experience is gained using these techniques, both separately
and in combination, the rules of thumb laid out in this section will
need to be refined.
However, this section does reflect the current state of the art.
