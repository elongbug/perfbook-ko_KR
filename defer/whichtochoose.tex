% defer/whichtochoose.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{Which to Choose?}
\label{sec:defer:Which to Choose?}
%
\epigraph{Choose always the way that seems the best, however rough it
	  may be; custom will soon render it easy and agreeable.}
	  {\emph{Pythagoras}}

Section~\ref{sec:defer:Which to Choose? (Overview)}
은 높은 수준에서의 개론을 제공하고
Section~\ref{sec:defer:Which to Choose? (Details)}
에서는 이 챕터에서 소개된 미뤄서 처리하기 테크닉들 사이의 차이점을 알아봅니다.
이 해설은 충분히 커서 읽기 쓰레드가 하나의 횡단에서 다른 곳으로 레퍼런스를
가져가지 않고, 원소들이 언제든지 어디에든지 추가되고 삭제될 수 있는 링크된
데이터 구조를 가정합니다.
Section~\ref{sec:defer:Which to Choose? (Production Use)}
은 이어서 해저드 포인터, 시퀀스 락킹, 그리고 RCU 의 제품 단계에서의 사용을
짚어봅니다.
이 해설은 여러분이 이 기술들 중에서 어떤 걸 골라야 할지 선택하는데 도움을 줄 수
있을 겁니다.
\iffalse

Section~\ref{sec:defer:Which to Choose? (Overview)}
provides a high-level overview and then
Section~\ref{sec:defer:Which to Choose? (Details)}
provides a more detailed view
of the differences between the deferred-processing techniques presented
in this chapter.
This discussion assumes a linked data structure that is large enough
that readers do not hold references from one traversal to another,
and where elements might be added to and removed from the structure
at any location and at any time.
Section~\ref{sec:defer:Which to Choose? (Production Use)}
then points out a few publicly visible production uses of
hazard pointers, sequence locking, and RCU.
This discussion should help you to make an informed choice between
these techniques.
\fi

\subsection{Which to Choose? (Overview)}
\label{sec:defer:Which to Choose? (Overview)}

\begin{table*}
\rowcolors{1}{}{lightgray}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering\OneColumnHSpace{-.3in}
\begin{tabularx}{5.3in}{>{\raggedright\arraybackslash}p{1.1in}
    >{\raggedright\arraybackslash}p{1.0in}
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}p{.9in}}
	\toprule
	Property
		& Reference Counting
			& Hazard Pointers
				& Sequence Locks
					& RCU \\
%		  RC	  HP	  SL	  RCU \\
	\midrule
	Readers
		& Slow and unscalable
			& Fast and scalable
				& Fast and scalable
					& Fast and scalable \\
	Number of Protected Objects
		& Scalable
			& Unscalable
				& No protection
					& Scalable \\
	Duration of Protection
		& Can be long
			& Can be long
				& No protection
					& User must bound duration \\
	Need for Traversal Retries
		& If race with object deletion
			& If race with object deletion
				& If race with any update
					& Never \\
	\bottomrule
\end{tabularx}
\caption{Which Deferred Technique to Choose? (Overview)}
\label{tab:defer:Which Deferred Technique to Choose? (Overview)}
\end{table*}

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Overview)}
이 deferred-reclamation 기술을 다른 것들과 차별화 시키는 높은 단계에서의
속성들을 일부 보입니다.

``Readers'' 행은
Figure~\ref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR}
에 보인 결과들을 요약하는데, 레퍼런스 카운팅을 제외한 모든 것이 합리적인 속도와
확장 가능한 읽기 쓰레드를 가짐을 보입니다.
\iffalse

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Overview)}
shows a few high-level properties that distinguish the deferred-reclamation
techniques from one another.

The ``Readers'' row summarizes the results presented in
Figure~\ref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR},
which shows that all but reference counting are enjoy reasonably
fast and scalable readers.
\fi

``Number of Protected Objects'' 행은 각 기술의 읽기 쓰레드의 보호를 기록하는
외부 저장소 필요를 평가합니다.
RCU 는 quiescent state 에 기반하며, 따라서 읽기 쓰레드를 표현하는 저장소를
오브젝트 내에도 외부에도 필요로 하지 않습니다.
레퍼런스 카운팅은 각 오브젝트 구조체 내에 하나의 정수를 사용할 수 있으며,
추가적인 저장소는 필요로 하지 않습니다.
해저드 포인터는 외부에서 오브젝트로의 포인터들이 준비될 것을 필요로 하며,
주어진 CPU 나 쓰레드가 동시에 레퍼런스 할 수 있는 최대 갯수의 오브젝트를 다룰
수 있기에 충분한 포인터가 있을 것을 필요로 합니다.
물론, 시퀀스 락은 포인터 횡단 보호를 제공하지 않는데, 이게 일반적으로 정적
데이터에 사용되는 이유입니다.
\iffalse

The ``Number of Protected Objects'' row evaluates each technique's need
for external storage with which to record reader protection.
RCU relies on quiescent states, and thus needs no storage to represent
readers, whether within or outside of the object.
Reference counting can use a single integer within each object in the
structure, and no additional storage is required.
Hazard pointers requires external-to-object pointers be provisioned,
and that there be sufficient pointers to handle the maximum number of
objects that a given CPU or thread might need to reference simultaneously.
Of course, sequence locks provides no pointer-traversal protection,
which is why it is normally used on static data.
\fi

\QuickQuiz{}
	왜 사용자들이 필요할 때마다 해저드 포인터들을 동적으로 할당하면
	안되나요?
	\iffalse

	Why can't users dynamically allocate the hazard pointers as they
	are needed?
	\fi
\QuickQuizAnswer{
	그럴 수 있습니다만 추가적인 읽기 쓰레드의 횡단 오버헤드를 필요로 하며,
	어떤 환경에서는 메모리 할당 실패에 대한 처리도 해야합니다.
	\iffalse

	They can, but at the expense of additional reader-traversal
	overhead and, in some environments, the need to handle
	memory-allocation failure.
	\fi
} \QuickQuizEnd

``Duration of Protection'' 은 얼마나 긴 시간동안 사용자가 특정 오브젝트를
보호할 수 있는지에 대한 제약을 (존재한다면) 보이고 있습니다.
레퍼런스 카운팅과 해저드 포인터는 둘 다 오브젝트를 별다른 사이드 이펙트 없이
확장된 시간 동안 보호할 수 있습니다만, 하나의 오브젝트를 위한 것이라도 RCU
레퍼런스를 유지하는건 모든 다른 RCU 가 메모리 해제를 행하는 걸 막습니다.
따라서 RCU 읽기 쓰레드는 시스템이 메모리 부족 현상을 겪는 걸 막기 위해
상대적으로 짧게 수행되어야 합니다.
다시 말하지만, 시퀀스 락은 포인터 횡단 보호를 제공하지 않으며, 이게 일반적으로
정적 데이터에 사용되는 이유입니다.
\iffalse

The ``Duration of Protection'' describes constraints (if any) on how
long a period of time a user may protect a given object.
Reference counting and hazard pointers can both protect objects for
extended time periods with no untoward side effects, but
maintaining an RCU reference to even one object prevents all other RCU
from being freed.
RCU readers must therefore be relatively short in order to avoid running
the system out of memory.
Again, sequence locks provides no pointer-traversal protection,
which is why it is normally used on static data.
\fi

``Need for Traversal Retries'' 행은 특정 오브젝트로의 새로운 레퍼런스가 RCU
에서와 같이 조건 없이 얻어질 수 있는지, 또는 레퍼런스 카운팅, 해저드 포인터,
그리고 시퀀스 락의 경우와 같이 레퍼런스 획득이 실패할 수 있어서 재시도
오퍼레이션을 초래하는지를 이야기 합니다.
레퍼런스 카운팅과 해저드 포인터의 경우, 재시도는 특정 오브젝트로의 레퍼런스의
획득 시도가 해당 프로세스가 삭제되는 과정 중에 있었다면 필요시 되는데, 이
주제는 다음 섹션에서 더 자세히 다뤄집니다.
시퀀스 락킹은 물론 업데이트와 동시에 수행되었을 때 그 크리티컬 섹션을 재시도
해야 합니다.
\iffalse

The ``Need for Traversal Retries'' row tells whether a new reference to
a given object may be acquired unconditionally, as it can with RCU, or
whether the reference acquisition can fail, resulting in a retry
operation, which is the case for reference counting, hazard pointers,
and sequence locks.
In the case of reference counting and hazard pointers, retries are only
required if an attempt to acquire a reference to a given object while
that object is in the processof being deleted, a topic covered in more
detail in the next section.
Sequence locking must of course retry its critical section should it
run concurrently with any update.
\fi

\QuickQuiz{}
	하지만 리눅스 커널의 \co{kref} 레퍼런스 카운터는 무조건적인 레퍼런스
	획득을 보장하지 않던가요?
	\iffalse

	But don't Linux-kernel \co{kref} reference counters allow
	guaranteed unconditional reference acquisition?
	\fi
\QuickQuizAnswer{
	맞습니다, 하지만 그 보장은 레퍼런스가 이미 잡혀 있을 때에만
	무조건적으로 적용됩니다.
	이를 명심하고,
	Section~\ref{sec:defer:Which to Choose?} 의 시작 부분의 문단을 다시
	읽어보시기 바랍니다, 특히 ``읽기 쓰레드들이 하나의 횡단에서 다른
	횡단으로 레퍼런스를 쥐지 못할 정도로 충분히 크다면'' 부분을요.
	\iffalse

	Yes they do, but the guarantee only applies unconditionally
	in cases where a reference is already held.
	With this in mind, please review the paragraph at the beginning of
	Section~\ref{sec:defer:Which to Choose?}, especially the part
	saying ``large enough that readers do not hold references from
	one traversal to another''.
	\fi
} \QuickQuizEnd

물론, 다른 열은 다른 상황에서 다른 중요도를 가질 겁니다.
예를 들어, 여러분의 현재 코드가 해저드 포인터를 사용해서 읽기 쪽 확장성 문제를
가지고 있다면, 해저드 포인터가 레퍼런스 획득 재시도를 필요로 한다는 건 문제가
되지 않는데 여러분의 현재 코드가 이미 이를 다루고 있기 때문입니다.
비슷하게, 만약 응답시간 고려사항이 이미 읽기 쓰레드의 횡단 기간을 제한하고
있다면, 커널과 낮은 단계 어플리케이션들이 이 경우죠, RCU 가 기간 제한을
요구한다는 건 문제가 되지 않는데, 여러분의 코드가 이미 그 필요성을 만족하고
있기 때문입니다.
같은 맥락에서, 만약 읽기 쓰레드가 자신이 횡단 중인 오브젝트에 쓰기를 해야만
하는 상황이라면, 레퍼런스 카운터의 읽기 쪽 오버헤드는 그렇게 중요하지 않을 수
있습니다.
마지막으로, 만약 보호되어야 하는 데이터가 정적으로 할당된 변수라면, 시퀀스
락킹의 포인터 보호 기능 부족은 큰 문제가 되지 않습니다.
\iffalse

Of course, different rows will have different levels of importance in
different situations.
For example, if your current code is having read-side scalability problems
with hazard pointers, then it does not matter that hazard pointers can require
retrying reference acquisition because your current code already handles
this.
Similarly, if response-time considerations already limit the duration
of reader traversals, as is often the case in kernels and low-level
applications, then it does not matter that RCU has duration-limit
requirements because your code already meets them.
In the same vein, if readers must already write to the objects that they
are traversing, the read-side overhead of reference counters might
not be so important.
Finally, if the data to be protected is in statically allocated variables,
then sequence locking's inability to protect pointers is irrelevant.
\fi

그러나, 이 표는 이 기술들 중 하나를 고를 때 큰 도움이 될 겁니다.
하지만 더 자세한 내용은 다음 섹션으로 이어집니다.
\iffalse

Nevertheless, this table should be of great help when choosing between
these techniques.
But those wishing more detail should continue on to the next section.
\fi

\subsection{Which to Choose? (Details)}
\label{sec:defer:Which to Choose? (Details)}

\begin{table*}
\rowcolors{1}{}{lightgray}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering\OneColumnHSpace{-.3in}
\begin{tabularx}{5.3in}{>{\raggedright\arraybackslash}p{1.1in}
    >{\raggedright\arraybackslash}p{1.2in}
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}p{.9in}}
	\toprule
	Property
		& Reference Counting
			& Hazard Pointers
				& Sequence Locks
					& RCU \\
%		  RC	  HP	  SL	  RCU \\
	\midrule
	Existence Guarantees
		& Complex
			& Yes
				& No
					& Yes \\
	Updates and Readers Progress Concurrently
		& Yes
			& Yes
				& No
					& Yes \\
	Contention Among Readers
		& High
			& None
				& None
					& None \\
	Reader Per\-/Critical\-/Section Overhead
		& N/A
			& N/A
				& Two \tco{smp_mb()}
					& Ranges from none to two
					  \tco{smp_mb()} \\
	Reader Per-Object Traversal Overhead
		& Read-modify-write atomic operations, memory\-/barrier
		  instructions, and cache misses
			& \tco{smp_mb()}
				& None, but unsafe
					& None (volatile accesses) \\
	Reader Forward Progress Guarantee
		& Lock free
			& Lock free
				& Blocking
					& Bounded wait free \\
	Reader Reference Acquisition
		& Can fail (conditional)
			& Can fail (conditional)
				& Unsafe
					& Cannot fail (unconditional) \\
	Memory Footprint
		& Bounded
			& Bounded
				& Bounded
					& Unbounded \\
	Reclamation Forward Progress
		& Lock free
			& Lock free
				& N/A
					& Blocking \\
	Automatic Reclamation
		& Yes
			& No
				& N/A
					& No \\
	Lines of Code
		& 94
			& 79
				& 79
					& 73 \\
	\bottomrule
\end{tabularx}
\caption{Which Deferred Technique to Choose?  (Details)}
\label{tab:defer:Which Deferred Technique to Choose?  (Details)}
\end{table*}

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Details)}
는 이 챕터에서 소개한 네개의 미뤄두고 처리하기 테크닉들 중 무엇을
선택해야할지를 돕는 간단한 경험적 법칙을 제공합니다.

``Existence Guarantee'' 열에서 보인 것처럼, 링크된 데이터 원소들에 대한 존재
보장이 필요하다면 레퍼런스 카운팅, 해저드 포인터, 또는 RCU 를 사용해야 합니다.
시퀀스 락은 존재 보장을 제공하지 않고, 업데이트의 발견과 업데이트를 마주한
read-side 크리티컬 섹션의 재시도 기능을 제공합니다.
\iffalse

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Details)}
provides more-detailed rules of thumb that can help you choose among the
four deferred-processing techniques presented in this chapter.

As shown in the ``Existence Guarantee'' row,
if you need existence guarantees for linked
data elements, you must use reference counting, hazard pointers, or RCU.
Sequence locks do not provide existence guarantees, instead providing
detection of updates, retrying any read-side critical sections
that do encounter an update.
\fi

물론, ``Updates and Readers Progress Concurrently'' 열에서 보인 것처럼, 이런
업데이트의 발견은 시퀀스 락킹이 업데이트 쓰레드와 읽기 쓰레드가 동시에 진행할
수는 없게 만듭니다.
무엇보다, 그런 진행을 방지하는 것이 시퀀스 락킹을 사용하는 첫번째 이유입니다!
이런 상황은 존재 보장과 업데이트 발견을 제공하기 위해서 시퀀스 락킹을 레퍼런스
카운팅, 해저드 포인터, 또는 RCU 와 함께 사용하는 방법을 보입니다.
실제로, 리눅스 커널은 경로 탐색을 할 때에 RCU 와 시퀀스 락킹을 함께 사용합니다.
\iffalse

Of course, as shown in the ``Updates and Readers Progress Concurrently''
row, this detection of updates implies
that sequence locking does not permit updaters and readers to make forward
progress concurrently.
After all, preventing such forward progress is the whole point of using
sequence locking in the first place!
This situation points the way to using sequence locking in conjunction
with reference counting, hazard pointers, or RCU in order to provide
both existence guarantees and update detection.
In fact, the Linux kernel combines RCU and sequence locking in
this manner during pathname lookup.
\fi

``Contention Among Readers'', ``Reader Per-Critical-Section Overhead'',
그리고 ``Reader Per-Object Traversal Overhead'' 열은 이 테크닉들의 대략적인
read-side 오버헤드를 보입니다.
레퍼런스 카운팅의 오버헤드는 읽기 쓰레드간의 완전히 순서 맞춰진
read-modify-write 어토믹 오퍼레이션이 각각의 모든 오브젝트 방문에 필요하기
때문에 상당히 클 수 있습니다.
해저드 포인터는 마주치는 각각의 데이터 원소에 메모리 배리어 오버헤드를 끼치고
시퀀스 락은 크리티컬 섹션을 실행하고자 하는 각 시도마다 두개의 메모리 배리어
오버헤드를 만듭니다.
RCU 구현의 오버헤드는 아예 없는 경우부터 각각의 read-side 크리티컬 섹션에서의
한쌍의 메모리 배리어까지 다양하고, 따라서 RCU 는 최고의 성능을 제공하는데, 많은
데이터 원소들을 마주치게 되는 read-side 크리티컬 섹션들에 대해서는 특히
그렇습니다.
물론, 모든 deferred-processing 변종의 이 읽기쪽 오버헤드는 batching 을 통해 각
읽기쪽 오퍼레이션이 더 많은 데이터를 다루게 함으로써 줄일 수 있습니다.
\iffalse

The ``Contention Among Readers'', ``Reader Per-Critical-Section Overhead'',
and ``Reader Per-Object Traversal Overhead'' rows give a rough sense of
the read-side overhead of these techniques.
The overhead of reference counting can be quite large, with
contention among readers along with a fully ordered read-modify-write
atomic operation required for each and every object traversed.
Hazard pointers incur the overhead of a memory barrier for each data element
traversed, and sequence locks incur the overhead of a pair of memory barriers
for each attempt to execute the critical section.
The overhead of RCU implementations vary from nothing to that of a pair of
memory barriers for each read-side critical section, thus providing RCU
with the best performance, particularly for read-side critical sections
that traverse many data elements.
Of course, the read-side overhead of all deferred-processing variants can
be reduced by batching, so that each read-side operation covers more data.
\fi

\QuickQuiz{}
	하지만 Section~\ref{sec:defer:Hazard Pointers}
	의 quick quizz 중 하나의 답은 해저드 포인터에서 읽기쪽의 \co{smp_mb()}
	를 비대칭적인 배리어 짝으로 없앨 수 있다고 하지 않았나요?
	\iffalse

	But didn't the answer to one of the quick quizzes in
	Section~\ref{sec:defer:Hazard Pointers}
	say that pairwise asymmetric barriers could eliminate the
	read-side \co{smp_mb()} from hazard pointers?
	\fi
\QuickQuizAnswer{
	맞아요, 그랬습니다.
	하지만, 그렇게 하는건 해저드 포인터의 (뒤에서 다루어질) ``Reclamation
	Forward Progress'' 행을 lock-free 에서 blocking 으로 바꿔야 한다는
	의견을 가능하게 할텐데, 인터럽트가 불능화 된 채 커널에서 스피닝 하는
	CPU 는 업데이트쪽 비대칭 배리어가 완료되는 걸 막을 것이기 때문입니다.
	리눅스 커널에서, 그런 블록킹은 이론적으로 커널을 \co{CONFIG_NO_HZ_FULL}
	로 빌드하고 관련된 CPU 들을 부팅 시점에 \co{nohz_full} 로 지정함으로써
	하나의 쓰레드만이 하나의 CPU 에서 한번에 돌아갈 수 있음을 보장하고 커널
	내로 호출하는 것을 방지함으로써 막을 수 있습니다.
	대안적으로, 커널이 인터럽트가 불능화 된 채 CPU 스피닝을 유발하는 모든
	버그로부터 안전하다는 것을 보장해 볼 수도 있습니다.
	\iffalse

	Yes, it did.
	However, doing this could be argued to change hazard pointers's
	``Reclamation Forward Progress'' row (discussed later) from
	lock-free to blocking because a CPU spinning with interrupts
	disabled in the kernel would prevent the update-side portion of
	the asymmetric barrier from completing.
	In the Linux kernel, such blocking could in theory be prevented
	by building the kernel with \co{CONFIG_NO_HZ_FULL}, designating
	the relevant CPUs as \co{nohz_full} at boot time, ensuring that
	only one thread was ever runnable on a given CPU at a given
	time, and avoiding ever calling into the kernel.
	Alternatively, you could ensure that the kernel was free of any
	bugs that might cause CPUs to spin with interrupts disabled.
	\fi

	인터럽트가 불능화 된 채 리눅스 커널 내에서 스피닝하는 CPU 는 드물다는
	걸 놓고 볼 때, 비대칭 배리어 해저드 포인터 업데이트는 이론 외적으로
	보면 실질적으로 non-blocking 이라고 말할 수도 있겠습니다.
	\iffalse

	Given that CPUs spinning in the Linux kernel with interrupts
	disabled seems to be rather rare, one might counter-argue that
	asymmetric-barrier hazard-pointer updates are non-blocking
	in practice, if not in theory.
	\fi
} \QuickQuizEnd

``Reader Forward Progress Guarantee'' 열은 RCU 만이 bounded wait-free
forward-progress 보장을 가짐을 보이는데, 이는 유한한 갯수의 인스트럭션들을
수행하는 것으로 유한한 방문을 할 수 있음을 의미합니다.

``Reader Reference Acquisition'' 열은 RCU 만이 무조건적으로 레퍼런스를 얻어오는
것이 가능함을 알립니다.
시퀀스 락의 항목은 ``Unsafe'' 라 표기되어 있는데, 다시 말하지만 시퀀스 락은
레퍼런스를 얻는게 아니라 업데이트를 발견하기 때문입니다.
\iffalse

The ``Reader Forward Progress Guarantee'' row shows that only RCU
has a bounded wait-free forward-progress guarantee, which means that
it can carry out a finite traversal by executing a bounded number of
instructions.

The ``Reader Reference Acquisition'' rows indicates that only RCU is
capable of unconditionally acquiring references.
The entry for sequence locks is ``Unsafe'' because, again, sequence locks
detect updates rather than acquiring references.
\fi

레퍼런스 카운팅과 해저드 포인터 둘 다 특정 레퍼런스 획득에 실패했을 때에는
횡단을 처음부터 다시 시작할 것이 요구됩니다.
이를 자세히 보기 위해, 오브젝트~A, B, C, 그리고~D 가 순서대로 담겨 있는 링크드
리스트에 다음과 같은 이벤트들이 발생한다고 생각해 봅시다:
\iffalse

Reference counting and hazard pointers both require that traversals be
restarted from the beginning if a given acquisition fails.
To see this, consider a linked list containing objects~A, B, C, and~D,
in that order, and the following series of events:
\fi

\begin{enumerate}
\item	한 읽기 쓰레드가 오브젝트~B 로의 레퍼런스를 얻습니다.
\item	업데이트 쓰레드가 오브젝트~B 를 제거하지만, 읽기 쓰레드가 레퍼런스를
	잡고 있으므로 해제하지는 않습니다.
	이 리스트는 이제 오브젝트~A, C, 그리고~D 를 가지고 있고, 오브젝트~B 의
	\co{->next} 포인터는 \co{HAZPTR_POISON} 으로 설정되어 있습니다.
\item	앞의 업데이트 쓰레드는 오브젝트~C 를 제거하고, 이에 의해 리스트는
	오브젝트~A 와~D 만 가지고 있게 됩니다.
	오브젝트~C 에는 레퍼런스가 잡혀 있지 않으므로, 곧바로 해제됩니다.
\item	앞의 읽기 쓰레드는 이제는 삭제된 오브젝트~B 의 다음 오브젝트로 넘어가려
	하지만, poison 값을 가지고 있는 \co{->next} 포인터는 이를 못하게
	합니다.
	이는 좋은 일인데, 이렇게 되지 않으면 오브젝트~B 의 \co{->next} 포인터는
	이미 해제된 메모리 영역을 가리킬 수도 있기 때문입니다.
\item	이 읽기 쓰레드는 따라서 리스트의 헤드부터 횡단을 다시 시작해야 합니다.
\iffalse

\item	A reader acquires a reference to object~B.
\item	An updater removes~object B, but refrains from freeing it because
	the reader holds a reference.
	The list now contains objects~A, C, and~D, and
	object~B's \co{->next} pointer is set to \co{HAZPTR_POISON}.
\item	The updater removes object~C, so that the list now contains
	objects~A and~D.
	Because there is no reference to object~C, it is immediately freed.
\item	The reader tries to advance to the successor of the object
	following the now-removed object~B, but the poisoned
	\co{->next} pointer prevents this.
	Which is a good thing, because object~B's \co{->next} pointer
	would otherwise point to the freelist.
\item	The reader must therefore restart its traversal from the head
	of the list.
\fi
\end{enumerate}

따라서, 레퍼런스를 획득하는데 실패했다면, 해저드 포인터나 레퍼런스 카운터를
사용하는 횡단은 처음부터 그 횡단을 재시작해야 합니다.
예를 들어 링크드 리스트를 담고 있는 트리와 같이 중첩된 링크드 데이터 구조의
경우 이 횡단은 가장 바깥의 데이터 구조로부터 재시작되어야 합니다.
이런 상황은 RCU 에 훨씬 사용하기 쉬운 이점을 가져다 줍니다.
\iffalse

Thus, when failing to acquire a reference, a hazard-pointer or
reference-counter traversal must restart that traversal from the
beginning.
In the case of nested linked data structures, for example, a
tree containing linked lists, the traversal must be restarted from
the outermost data structure.
This situation gives RCU a significant ease-of-use advantage.
\fi

하지만, RCU 의 사용성 이득은 공짜로 오는 것은 아닌데, ``Memory Footprint''
열에서 이를 볼 수 있습니다.
RCU 의 무조건적 레퍼런스 획득 지원은 곧 어떤 RCU 읽기 쓰레드에게 보이는
오브젝트는 그 읽기 쓰레드가 완료되기 전까지는 해제될 수 없음을 의미합니다.
따라서 RCU 는 무한한 메모리 사용량 가능성을 갖는데, 업데이트가 인공적으로
조절되지 않는한은 그렇습니다.
반면에, 레퍼런스 카운팅과 해저드 포인터는 정말로 동시의 읽기 쓰레드들이
레퍼런스 하고 있는 데이터 원소만을 유지할 겁니다.
\iffalse

However, RCU's ease-of-use advantage does not come
for free, as can be seen in the ``Memory Footprint'' row.
RCU's support of unconditional reference acquisition means that
it must avoid freeing any object reachable by a given
RCU reader until that reader completes.
RCU therefore has an unbounded memory footprint, at least unless updates
are throttled.
In contrast, reference counting and hazard pointers need to  retain only
those data elements actually referenced by concurrent readers.
\fi

이런 메모리 사용량과 획득 실패 사이의 미묘한 긴장감이 리눅스 커널에서는 일부
경우 RCU 와 레퍼런스 카운터를 함께 사용하는 것으로 해결되기도 합니다.
RCU 는 잠깐 사용되는 레퍼런스들에 사용되는데, 이는 RCU read-side 크리티컬
섹션들이 짧을 수 있음을 의미합니다.
이런 짧은 RCU read-side 크리티컬 섹션들은 곧 연관된 RCU grace period 들 역시
짧을 수 있어서, 메모리 사용량을 제한할 수 있음을 의미합니다.
긴 시간 사용될 수 있는 레퍼런스를 필요로 하는 일부 데이터 원소들을 위해서는
레퍼런스 카운팅이 사용됩니다.
이 말이 의미하는 바는 레퍼런스 획득 실패의 복잡도를 처리하는건 그런 일부 데이터
원소들에서만 필요시 된다는 뜻입니다:  대량의 레퍼런스 획득은 RCU 덕분에
고려되지 않습니다.
레퍼런스 카운팅을 다른 동기화 메커니즘과 결합하는 방법에 대한 더 많은 정보를
위해선
Section~\ref{sec:together:Refurbish Reference Counting} 을 보시기 바랍니다.
\iffalse

This tension between memory footprint and acquisition
failures is sometimes resolved within the Linux kernel by combining use
of RCU and reference counters.
RCU is used for short-lived references, which means that RCU read-side
critical sections can be short.
These short RCU read-side critical sections in turn mean that the corresponding
RCU grace periods can also be short, which limits the memory footprint.
For the few data elements that need longer-lived references, reference
counting is used.
This means that the complexity of reference-acquisition failure only
needs to be dealt with for those few data elements:  The bulk of
the reference acquisitions are unconditional, courtesy of RCU.
See Section~\ref{sec:together:Refurbish Reference Counting}
for more information on combining reference counting with other
synchronization mechanisms.
\fi

``Reclamation Forward Progress'' 열은 해저드 포인터가 non-blocking
업데이트를 제공할 수 있음을 이야기합니다~\cite{MagedMichael04a,HerlihyLM02}.
레퍼런스 카운팅은 구현에 따라서 그럴수도 그러지 않을수도 있습니다.
하지만, 시퀀스 락킹은 update-side 락 때문에 non-blocking 업데이트를 제공할 수
없습니다.
RCU 업데이트 쓰레드들은 읽기 쓰레드를 기다려야만 하는데, 이 역시 non-blocking
업데이트의 규칙을 완전히 벗어납니다.
하지만, 블록킹 오퍼레이션은 메모리를 해제하기 위한 기다림 뿐인 상황이
존재하는데, 많은 경우에 이런 상황은 non-blocking 만큼이나 좋은
상황입니다~\cite{MathieuDesnoyers2012URCU}.
\iffalse

The ``Reclamation Forward Progress'' row shows that hazard pointers
can provide non-blocking updates~\cite{MagedMichael04a,HerlihyLM02}.
Reference counting might or might not, depending on the implementation.
However, sequence locking cannot provide non-blocking updates, courtesy
of its update-side lock.
RCU updaters must wait on readers, which also rules out fully non-blocking
updates.
However, there are situations in which the only blocking operation is
a wait to free memory, which results in an situation that, for many
purposes, is as good as non-blocking~\cite{MathieuDesnoyers2012URCU}.
\fi

``Automatic Reclamation'' 열에 보여진 것처럼, 레퍼런스 카운팅만이 메모리 해제를
자동화 할 수 있는데, non-cyclic 데이터 구조들에서만 그렇습니다.

마지막으로, ``Lines of Code'' 열은 Pre-BSD 라우팅 테이블 구현의 크기를
보이는데, 상대적인 사용의 편리성에 대한 대략적 정보를 제공합니다.
그렇다곤 하나, 레퍼런스 카운팅과 시퀀스 락킹 구현은 버그가 존재하며, 정확히
동작하는 레퍼런스 카운팅 구현은 더 복잡할 것으로
여겨짐~\cite{Valois95a,MagedMichael95a}을 알아둘 필요가 있습니다.
그런 부분을 위해, 올바른 시퀀스 락킹 구현은 추가적인 또다른 동기화 메커니즘을
필요로 하여서, 예를 들어 해저드 포인터나 RCU 를 사용할 수 있는데, 시퀀스 락킹은
동시의 업데이트를 발견하고 다른 메커니즘은 안전한 레퍼런스 획득을 제공할 수
있을 겁니다.
\iffalse

As shown in the ``Automatic Reclamation'' row, only reference
counting can automate freeing of memory, and even then only
for non-cyclic data structures.

Finally, the ``Lines of Code'' row shows the size of the Pre-BSD
Routing Table implementations, giving a rough idea of relative ease of use.
That said, it is important to note that the reference-counting and
sequence-locking implementations are buggy, and that a correct
reference-counting implementation is considerably
more complex~\cite{Valois95a,MagedMichael95a}.
For its part, a correct sequence-locking implementation requires
the addition of some other synchronization mechanism, for example,
hazard pointers or RCU, so that sequence locking detects concurrent
updates and the other mechanism provides safe reference acquisition.
\fi

이런 테크닉들을 조합해서 또는 각각 사용하는 경험이 더 쌓여감에 따라서 이 섹션에
놓인 경험적 법칙은 수정될 수 있을 겁니다.
하지만, 이 섹션은 현재로써는 최선의 결과를 반영하고 있습니다.
\iffalse

As more experience is gained using these techniques, both separately
and in combination, the rules of thumb laid out in this section will
need to be refined.
However, this section does reflect the current state of the art.
\fi

\subsection{Which to Choose? (Production Use)}
\label{sec:defer:Which to Choose? (Production Use)}

This section points out a few publicly visible production uses of
hazard pointers, sequence locking, and RCU.
Reference counting is omitted, not because it is unimportant, but rather
because it is not only used pervasively, but heavily documented in textbooks
going back a half century.
One of the hoped-for benefits of listing production uses of these other
techniques is to provide examples to study---or to find bugs in, as
the case may be.\footnote{
	Kudos to Mathias Stearn, Matt Wilson, David Goldblatt,
	LiveJournal user fanf, Nadav Har'El, Avi Kivity, Dmitry Vyukov,
	Raul Guitterez S., and Twitter user @peo3 for locating a
	great many of these use cases.}

\subsubsection{Production Uses of Hazard Pointers}
\label{sec:defer:Production Uses of Hazard Pointers}

In 2010, Keith Bostic added hazard pointers to
WiredTiger~\cite{KeithBostic2010WiredTigerhazptr}.
MongoDB 3.0, released in 2015, included WiredTiger and thus hazard pointers.

In 2011, Samy Al Bahra added hazard pointers to the Concurrency Kit
library~\cite{SamyAlBahra2011ckhp}.

In 2014, Maxim Khizhinsky added hazard pointers to
libcds~\cite{MaximKhizhinsky2014libcdsHazptr}.

In 2015, David Gwynne introduced shared reference pointers, a form
of hazard pointers, to OpenBSD~\cite{DavidGwynne2015srp}.

In 2018, Maged Michael added hazard pointers to Facebook's Folly
library~\cite{MagedMichael2018FollyHazptr}, where it is used heavily.

\subsubsection{Production Uses of Sequence Locking}
\label{sec:defer:Production Uses of Sequence Locking}

The Linux kernel added sequence locking in
v2.5.60~\cite{JonathanCorbet2003seqlock}, having been generalized from
an ad-hoc technique used in x86's implementation of the
\co{gettimeofday()} system call.

In 2011, Samy Al Bahra added sequence locking to the Concurrency Kit
library~\cite{SamyAlBahra2011ckseqlock}.

A simple sequence locking implementation was added to \co{jemalloc()}
in 2018~\cite{DavidGoldblatt2018seqlock}.
The eigen library also has a special-purpose queue that is managed by
a mechanism resembling sequence locking.\footnote{
	\url{https://bitbucket.org/eigen/eigen/src/9fdbc9e653c1adc64db1078fd2ec899c1e33ba0c/unsupported/Eigen/CXX11/src/ThreadPool/RunQueue.h?at=default&fileviewer=file-view-default\#RunQueue.h-202}}

\subsubsection{Production Uses of RCU}
\label{sec:defer:Production Uses of RCU}

IBM's VM/XA is adopted passive serialization, a mechanism similar to
RCU, some time in the 1980s~\cite{Hennessy89}.

DYNIX/ptx adopted RCU in 1993~\cite{McKenney98,Slingwine95}.

The Linux kernel adopted Dipankar Sarma's implementation of RCU in
2002~\cite{Torvalds2.5.43}.

The userspace RCU project started in 2009~\cite{MathieuDesnoyers2009URCU}.

The Knot DNS project started using the userspace RCU
library in 2010~\cite{LubosSlovak2010KnotDNSRCU}.

In 2011, Samy Al Bahra added epochs
(a form of RCU~\cite{KeirAnthonyFraserPhD,KeirFraser2007withoutLocks})
to the Concurrency Kit
library~\cite{SamyAlBahra2011ckEpoch}.

NetBSD began using the aforementioned passive serialization with v6.0 in
2012~\cite{NetBSD2012pserialize}.
Among other things, passive serialization is used in
NetBSD packet filter (NPF)~\cite{MindaugasRasiukevicius2014NPFRCU}.

The OSv kernel added an RCU implementation in 2010~\cite{AviKivity2013OSvRCU},
later adding an RCU-protected linked list~\cite{AviKivity2013OSvRCUlist}
and an RCU-protected hash table~\cite{AviKivity2013OSvRCUhash}.

In 2015, Maxim Khizhinsky added RCU to
libcds~\cite{MaxKhiszinsky2015C++RCU}.

Mindaugas Rasiukevicius implemented libqsbr in 2016, which features
QSBR and epoch-based reclamation
(EBR)~\cite{MindaugasRasiukevicius2016libqsbr},
both of which are types of implementations of RCU.

Sheth et al.~\cite{HarshalSheth2016goRCU}
demonstrated the value of leveraging golang's garbage
collector to provide RCU-like functionality, and
the golang programming language provides a \co{Value} type that can
provide this functionality.\footnote{
	See \url{https://golang.org/pkg/sync/atomic/\#Value}, particularly
	the ``Example (ReadMostly)''.}

Matt Klein describes an RCU-like mechanism that is used in the Envoy
Proxy~\cite{MattKlein2017EnvoyRCU}.

\subsubsection{Summary of Production Uses}
\label{sec:defer:Summary of Production Uses}

Perhaps the time will come when sequence locking, hazard pointers, and
RCU are all as heavily used and as well known as are reference counters.
Until that time comes, the current production uses of these mechanisms
should help guide the choice of mechanism as well as showing how best
to apply each of them.

The next section discusses updates, a ticklish issue for many of the
read-mostly mechanisms described in this chapter.
