% defer/whichtochoose.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{Which to Choose?}
\label{sec:defer:Which to Choose?}

\begin{table*}
\rowcolors{1}{}{lightgray}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering\OneColumnHSpace{-.3in}
\begin{tabularx}{5.3in}{>{\raggedright\arraybackslash}p{1.1in}
    >{\raggedright\arraybackslash}p{1.2in}
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}p{.9in}}
	\toprule
	Property
		& Reference Counting
			& Hazard Pointers
				& Sequence Locks
					& RCU \\
%		  RC	  HP	  SL	  RCU \\
	\midrule
	Existence Guarantees
		& Complex
			& Yes
				& No
					& Yes \\
	Updates and Readers Progress Concurrently
		& Yes
			& Yes
				& No
					& Yes \\
	Contention Among Readers
		& High
			& None
				& None
					& None \\
	Reader Per\-/Critical\-/Section Overhead
		& N/A
			& N/A
				& Two \tco{smp_mb()}
					& Ranges from none to two
					  \tco{smp_mb()} \\
	Reader Per-Object Traversal Overhead
		& Read-modify-write atomic operations, memory\-/barrier
		  instructions, and cache misses
			& \tco{smp_mb()}
				& None, but unsafe
					& None (volatile accesses) \\
	Reader Forward Progress Guarantee
		& Lock free
			& Lock free
				& Blocking
					& Bounded wait free \\
	Reader Reference Acquisition
		& Can fail (conditional)
			& Can fail (conditional)
				& Unsafe
					& Cannot fail (unconditional) \\
	Memory Footprint
		& Bounded
			& Bounded
				& Bounded
					& Unbounded \\
	Reclamation Forward Progress
		& Lock free
			& Lock free
				& N/A
					& Blocking \\
	Automatic Reclamation
		& Yes
			& No
				& N/A
					& No \\
	Lines of Code
		& 94
			& 79
				& 79
					& 73 \\
	\bottomrule
\end{tabularx}
\caption{Which Deferred Technique to Choose?}
\label{tab:defer:Which Deferred Technique to Choose?}
\end{table*}

Table~\ref{tab:defer:Which Deferred Technique to Choose?}
는 이 챕터에서 소개한 네개의 미뤄두고 처리하기 테크닉들 중 무엇을
선택해야할지를 돕는 간단한 경험적 법칙을 제공합니다.

``Existence Guarantee'' 열에서 보인 것처럼, 링크된 데이터 원소들에 대한 존재
보장이 필요하다면 레퍼런스 카운팅, 해저드 포인터, 또는 RCU 를 사용해야 합니다.
시퀀스 락은 존재 보장을 제공하지 않고, 업데이트의 발견과 업데이트를 마주한
read-side 크리티컬 섹션의 재시도 기능을 제공합니다.
\iffalse

Table~\ref{tab:defer:Which Deferred Technique to Choose?}
provides some rough rules of thumb that can help you choose among the
four deferred-processing techniques presented in this chapter.

As shown in the ``Existence Guarantee'' row,
if you need existence guarantees for linked
data elements, you must use reference counting, hazard pointers, or RCU.
Sequence locks do not provide existence guarantees, instead providing
detection of updates, retrying any read-side critical sections
that do encounter an update.
\fi

물론, ``Updates and Readers Progress Concurrently'' 열에서 보인 것처럼, 이런
업데이트의 발견은 시퀀스 락킹이 업데이트 쓰레드와 읽기 쓰레드가 동시에 진행할
수는 없게 만듭니다.
무엇보다, 그런 진행을 방지하는 것이 시퀀스 락킹을 사용하는 첫번째 이유입니다!
이런 상황은 존재 보장과 업데이트 발견을 제공하기 위해서 시퀀스 락킹을 레퍼런스
카운팅, 해저드 포인터, 또는 RCU 와 함께 사용하는 방법을 보입니다.
실제로, 리눅스 커널은 경로 탐색을 할 때에 RCU 와 시퀀스 락킹을 함께 사용합니다.
\iffalse

Of course, as shown in the ``Updates and Readers Progress Concurrently''
row, this detection of updates implies
that sequence locking does not permit updaters and readers to make forward
progress concurrently.
After all, preventing such forward progress is the whole point of using
sequence locking in the first place!
This situation points the way to using sequence locking in conjunction
with reference counting, hazard pointers, or RCU in order to provide
both existence guarantees and update detection.
In fact, the Linux kernel combines RCU and sequence locking in
this manner during pathname lookup.
\fi

``Contention Among Readers'', ``Reader Per-Critical-Section Overhead'',
그리고 ``Reader Per-Object Traversal Overhead'' 열은 이 테크닉들의 대략적인
read-side 오버헤드를 보입니다.
레퍼런스 카운팅의 오버헤드는 읽기 쓰레드간의 완전히 순서 맞춰진
read-modify-write 어토믹 오퍼레이션이 각각의 모든 오브젝트 방문에 필요하기
때문에 상당히 클 수 있습니다.
해저드 포인터는 마주치는 각각의 데이터 원소에 메모리 배리어 오버헤드를 끼치고
시퀀스 락은 크리티컬 섹션을 실행하고자 하는 각 시도마다 두개의 메모리 배리어
오버헤드를 만듭니다.
RCU 구현의 오버헤드는 아예 없는 경우부터 각각의 read-side 크리티컬 섹션에서의
한쌍의 메모리 배리어까지 다양하고, 따라서 RCU 는 최고의 성능을 제공하는데, 많은
데이터 원소들을 마주치게 되는 read-side 크리티컬 섹션들에 대해서는 특히
그렇습니다.
\iffalse

The ``Contention Among Readers'', ``Reader Per-Critical-Section Overhead'',
and ``Reader Per-Object Traversal Overhead'' rows give a rough sense of
the read-side overhead of these techniques.
The overhead of reference counting can be quite large, with
contention among readers along with a fully ordered read-modify-write
atomic operation required for each and every object traversed.
Hazard pointers incur the overhead of a memory barrier for each data element
traversed, and sequence locks incur the overhead of a pair of memory barriers
for each attempt to execute the critical section.
The overhead of RCU implementations vary from nothing to that of a pair of
memory barriers for each read-side critical section, thus providing RCU
with the best performance, particularly for read-side critical sections
that traverse many data elements.
\fi

``Reader Forward Progress Guarantee'' 열은 RCU 만이 bounded wait-free
forward-progress 보장을 가짐을 보이는데, 이는 유한한 갯수의 인스트럭션들을
수행하는 것으로 유한한 방문을 할 수 있음을 의미합니다.

``Reader Reference Acquisition'' 열은 RCU 만이 무조건적으로 레퍼런스를 얻어오는
것이 가능함을 알립니다.
시퀀스 락의 항목은 ``Unsafe'' 라 표기되어 있는데, 다시 말하지만 시퀀스 락은
레퍼런스를 얻는게 아니라 업데이트를 발견하기 때문입니다.
\iffalse

The ``Reader Forward Progress Guarantee'' row shows that only RCU
has a bounded wait-free forward-progress guarantee, which means that
it can carry out a finite traversal by executing a bounded number of
instructions.

The ``Reader Reference Acquisition'' rows indicates that only RCU is
capable of unconditionally acquiring references.
The entry for sequence locks is ``Unsafe'' because, again, sequence locks
detect updates rather than acquiring references.
\fi

레퍼런스 카운팅과 해저드 포인터 둘 다 특정 레퍼런스 획득에 실패했을 때에는
횡단을 처음부터 다시 시작할 것이 요구됩니다.
이를 자세히 보기 위해, 오브젝트~A, B, C, 그리고~D 가 순서대로 담겨 있는 링크드
리스트에 다음과 같은 이벤트들이 발생한다고 생각해 봅시다:
\iffalse

Reference counting and hazard pointers both require that traversals be
restarted from the beginning if a given acquisition fails.
To see this, consider a linked list containing objects~A, B, C, and~D,
in that order, and the following series of events:
\fi

\begin{enumerate}
\item	한 읽기 쓰레드가 오브젝트~B 로의 레퍼런스를 얻습니다.
\item	업데이트 쓰레드가 오브젝트~B 를 제거하지만, 읽기 쓰레드가 레퍼런스를
	잡고 있으므로 해제하지는 않습니다.
	이 리스트는 이제 오브젝트~A, C, 그리고~D 를 가지고 있고, 오브젝트~B 의
	\co{->next} 포인터는 \co{HAZPTR_POISON} 으로 설정되어 있습니다.
\item	앞의 업데이트 쓰레드는 오브젝트~C 를 제거하고, 이에 의해 리스트는
	오브젝트~A 와~D 만 가지고 있게 됩니다.
	오브젝트~C 에는 레퍼런스가 잡혀 있지 않으므로, 곧바로 해제됩니다.
\item	앞의 읽기 쓰레드는 이제는 삭제된 오브젝트~B 의 다음 오브젝트로 넘어가려
	하지만, poison 값을 가지고 있는 \co{->next} 포인터는 이를 못하게
	합니다.
	이는 좋은 일인데, 이렇게 되지 않으면 오브젝트~B 의 \co{->next} 포인터는
	이미 해제된 메모리 영역을 가리킬 수도 있기 때문입니다.
\item	이 읽기 쓰레드는 따라서 리스트의 헤드부터 횡단을 다시 시작해야 합니다.
\iffalse

\item	A reader acquires a reference to object~B.
\item	An updater removes~object B, but refrains from freeing it because
	the reader holds a reference.
	The list now contains objects~A, C, and~D, and
	object~B's \co{->next} pointer is set to \co{HAZPTR_POISON}.
\item	The updater removes object~C, so that the list now contains
	objects~A and~D.
	Because there is no reference to object~C, it is immediately freed.
\item	The reader tries to advance to the successor of the object
	following the now-removed object~B, but the poisoned
	\co{->next} pointer prevents this.
	Which is a good thing, because object~B's \co{->next} pointer
	would otherwise point to the freelist.
\item	The reader must therefore restart its traversal from the head
	of the list.
\fi
\end{enumerate}

따라서, 레퍼런스를 획득하는데 실패했다면, 해저드 포인터나 레퍼런스 카운터를
사용하는 횡단은 처음부터 그 횡단을 재시작해야 합니다.
예를 들어 링크드 리스트를 담고 있는 트리와 같이 중첩된 링크드 데이터 구조의
경우 이 횡단은 가장 바깥의 데이터 구조로부터 재시작되어야 합니다.
이런 상황은 RCU 에 훨씬 사용하기 쉬운 이점을 가져다 줍니다.
\iffalse

Thus, when failing to acquire a reference, a hazard-pointer or
reference-counter traversal must restart that traversal from the
beginning.
In the case of nested linked data structures, for example, a
tree containing linked lists, the traversal must be restarted from
the outermost data structure.
This situation gives RCU a significant ease-of-use advantage.
\fi

하지만, RCU 의 사용성 이득은 공짜로 오는 것은 아닌데, ``Memory Footprint''
열에서 이를 볼 수 있습니다.
RCU 의 무조건적 레퍼런스 획득 지원은 곧 어떤 RCU 읽기 쓰레드에게 보이는
오브젝트는 그 읽기 쓰레드가 완료되기 전까지는 해제될 수 없음을 의미합니다.
따라서 RCU 는 무한한 메모리 사용량 가능성을 갖는데, 업데이트가 인공적으로
조절되지 않는한은 그렇습니다.
반면에, 레퍼런스 카운팅과 해저드 포인터는 정말로 동시의 읽기 쓰레드들이
레퍼런스 하고 있는 데이터 원소만을 유지할 겁니다.
\iffalse

However, RCU's ease-of-use advantage does not come
for free, as can be seen in the ``Memory Footprint'' row.
RCU's support of unconditional reference acquisition means that
it must avoid freeing any object reachable by a given
RCU reader until that reader completes.
RCU therefore has an unbounded memory footprint, at least unless updates
are throttled.
In contrast, reference counting and hazard pointers need to  retain only
those data elements actually referenced by concurrent readers.
\fi

이런 메모리 사용량과 획득 실패 사이의 미묘한 긴장감이 리눅스 커널에서는 일부
경우 RCU 와 레퍼런스 카운터를 함께 사용하는 것으로 해결되기도 합니다.
RCU 는 잠깐 사용되는 레퍼런스들에 사용되는데, 이는 RCU read-side 크리티컬
섹션들이 짧을 수 있음을 의미합니다.
이런 짧은 RCU read-side 크리티컬 섹션들은 곧 연관된 RCU grace period 들 역시
짧을 수 있어서, 메모리 사용량을 제한할 수 있음을 의미합니다.
긴 시간 사용될 수 있는 레퍼런스를 필요로 하는 일부 데이터 원소들을 위해서는
레퍼런스 카운팅이 사용됩니다.
이 말이 의미하는 바는 레퍼런스 획득 실패의 복잡도를 처리하는건 그런 일부 데이터
원소들에서만 필요시 된다는 뜻입니다:  대량의 레퍼런스 획득은 RCU 덕분에
고려되지 않습니다.
레퍼런스 카운팅을 다른 동기화 메커니즘과 결합하는 방법에 대한 더 많은 정보를
위해선
Section~\ref{sec:together:Refurbish Reference Counting} 을 보시기 바랍니다.
\iffalse

This tension between memory footprint and acquisition
failures is sometimes resolved within the Linux kernel by combining use
of RCU and reference counters.
RCU is used for short-lived references, which means that RCU read-side
critical sections can be short.
These short RCU read-side critical sections in turn mean that the corresponding
RCU grace periods can also be short, which limits the memory footprint.
For the few data elements that need longer-lived references, reference
counting is used.
This means that the complexity of reference-acquisition failure only
needs to be dealt with for those few data elements:  The bulk of
the reference acquisitions are unconditional, courtesy of RCU.
See Section~\ref{sec:together:Refurbish Reference Counting}
for more information on combining reference counting with other
synchronization mechanisms.
\fi

``Reclamation Forward Progress'' 열은 해저드 포인터가 non-blocking
업데이트를 제공할 수 있음을 이야기합니다~\cite{MagedMichael04a,HerlihyLM02}.
레퍼런스 카운팅은 구현에 따라서 그럴수도 그러지 않을수도 있습니다.
하지만, 시퀀스 락킹은 update-side 락 때문에 non-blocking 업데이트를 제공할 수
없습니다.
RCU 업데이트 쓰레드들은 읽기 쓰레드를 기다려야만 하는데, 이 역시 non-blocking
업데이트의 규칙을 완전히 벗어납니다.
하지만, 블록킹 오퍼레이션은 메모리를 해제하기 위한 기다림 뿐인 상황이
존재하는데, 많은 경우에 이런 상황은 non-blocking 만큼이나 좋은
상황입니다~\cite{MathieuDesnoyers2012URCU}.
\iffalse

The ``Reclamation Forward Progress'' row shows that hazard pointers
can provide non-blocking updates~\cite{MagedMichael04a,HerlihyLM02}.
Reference counting might or might not, depending on the implementation.
However, sequence locking cannot provide non-blocking updates, courtesy
of its update-side lock.
RCU updaters must wait on readers, which also rules out fully non-blocking
updates.
However, there are situations in which the only blocking operation is
a wait to free memory, which results in an situation that, for many
purposes, is as good as non-blocking~\cite{MathieuDesnoyers2012URCU}.
\fi

``Automatic Reclamation'' 열에 보여진 것처럼, 레퍼런스 카운팅만이 메모리 해제를
자동화 할 수 있는데, non-cyclic 데이터 구조들에서만 그렇습니다.

마지막으로, ``Lines of Code'' 열은 Pre-BSD 라우팅 테이블 구현의 크기를
보이는데, 상대적인 사용의 편리성에 대한 대략적 정보를 제공합니다.
그렇다곤 하나, 레퍼런스 카운팅과 시퀀스 락킹 구현은 버그가 존재하며, 정확히
동작하는 레퍼런스 카운팅 구현은 더 복잡할 것으로
여겨짐~\cite{Valois95a,MagedMichael95a}을 알아둘 필요가 있습니다.
그런 부분을 위해, 올바른 시퀀스 락킹 구현은 추가적인 또다른 동기화 메커니즘을
필요로 하여서, 예를 들어 해저드 포인터나 RCU 를 사용할 수 있는데, 시퀀스 락킹은
동시의 업데이트를 발견하고 다른 메커니즘은 안전한 레퍼런스 획득을 제공할 수
있을 겁니다.
\iffalse

As shown in the ``Automatic Reclamation'' row, only reference
counting can automate freeing of memory, and even then only
for non-cyclic data structures.

Finally, the ``Lines of Code'' row shows the size of the Pre-BSD
Routing Table implementations, giving a rough idea of relative ease of use.
That said, it is important to note that the reference-counting and
sequence-locking implementations are buggy, and that a correct
reference-counting implementation is considerably
more complex~\cite{Valois95a,MagedMichael95a}.
For its part, a correct sequence-locking implementation requires
the addition of some other synchronization mechanism, for example,
hazard pointers or RCU, so that sequence locking detects concurrent
updates and the other mechanism provides safe reference acquisition.
\fi

이런 테크닉들을 조합해서 또는 각각 사용하는 경험이 더 쌓여감에 따라서 이 섹션에
놓인 경험적 법칙은 수정될 수 있을 겁니다.
하지만, 이 섹션은 현재로써는 최선의 결과를 반영하고 있습니다.
\iffalse

As more experience is gained using these techniques, both separately
and in combination, the rules of thumb laid out in this section will
need to be refined.
However, this section does reflect the current state of the art.
\fi
