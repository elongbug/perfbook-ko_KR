% defer/whichtochoose.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{Which to Choose?}
\label{sec:defer:Which to Choose?}
%
\epigraph{Choose always the way that seems the best, however rough it
	  may be; custom will soon render it easy and agreeable.}
	  {\emph{Pythagoras}}

Section~\ref{sec:defer:Which to Choose? (Overview)}
은 높은 수준에서의 개요를 제공하고
Section~\ref{sec:defer:Which to Choose? (Details)}
에서는 이 챕터에서 보인 미뤄 처리하기 기법들 간의 차이를 자세히 설명합니다.
여기서의 이야기는 충분히 길어서 읽기 쓰레드가 순회 사이에 참조를 잡고 있지
않는, 그리고 원소들이 언제든 어디에든 더해지고 빼질 수 있는 연결된 데이터
구조를 가정합니다.
Section~\ref{sec:defer:Which to Choose? (Production Use)}
은 이어서 해저드 포인터, 시퀀스 락킹, 그리고 RCU 의 제품 단계에서 공개된 일부
사용 예를 짚어 보입니다.
이는 여러분이 이 기법들 중 어느것을 골라야 할 지에 대해 도움을 줄 것입니다.

\iffalse

Section~\ref{sec:defer:Which to Choose? (Overview)}
provides a high-level overview and then
Section~\ref{sec:defer:Which to Choose? (Details)}
provides a more detailed view
of the differences between the deferred-processing techniques presented
in this chapter.
This discussion assumes a linked data structure that is large enough
that readers do not hold references from one traversal to another,
and where elements might be added to and removed from the structure
at any location and at any time.
Section~\ref{sec:defer:Which to Choose? (Production Use)}
then points out a few publicly visible production uses of
hazard pointers, sequence locking, and RCU\@.
This discussion should help you to make an informed choice between
these techniques.

\fi

\subsection{Which to Choose? (Overview)}
\label{sec:defer:Which to Choose? (Overview)}

\begin{table*}
\rowcolors{1}{}{lightgray}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering\OneColumnHSpace{-.3in}
\begin{tabularx}{5.3in}{>{\raggedright\arraybackslash}p{1.1in}
    >{\raggedright\arraybackslash}p{1.0in}
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}p{.9in}}
	\toprule
	Property
		& Reference Counting
			& Hazard Pointers
				& Sequence Locks
					& RCU \\
%		  RC	  HP	  SL	  RCU \\
	\midrule
	Readers
		& Slow and unscalable
			& Fast and scalable
				& Fast and scalable
					& Fast and scalable \\
	Number of Protected Objects
		& Scalable
			& Unscalable
				& No protection
					& Scalable \\
	Duration of Protection
		& Can be long
			& Can be long
				& No protection
					& User must bound duration \\
	Need for Traversal Retries
		& If race with object deletion
			& If race with object deletion
				& If race with any update
					& Never \\
	\bottomrule
\end{tabularx}
\caption{Which Deferred Technique to Choose? (Overview)}
\label{tab:defer:Which Deferred Technique to Choose? (Overview)}
\end{table*}

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Overview)}
은 deferred-reclamation 기법을 다른 것과 차별화 시키는 높은 수준에서의 속성들
몇가지를 보입니다.

``Readers'' 열은
Figure~\ref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR}
에서 보인 결과들을 요약해 보이는데, 레퍼런스 카운팅을 제외한 모든 것들이 충분히
빠르고 확장되는 읽기 쓰레드를 보입니다.

``Number of Protected Objects'' 열은 각 기법의 읽기 보호를 기록하기 위해 필요한
외부 저장장치를 평가합니다.
RCU 는 quiescent state 에 의존하므로, 읽기 쓰레드들을 표현하기 위해 객체 내에도
외부에도 저장소를 필요로 하지 않습니다.
레퍼런스 카운팅은 각 객체의 구조 내에 하나의 정수를 사용할 수 있으며, 추가적인
저장소를 필요로 하지 않습니다.
해저드 포인터는 외부로부터 객체로의 포인터를 준비해야 하며, 주어진 CPU 나
쓰레드가 동시에 참조할 수도 있는 최대 갯수의 객체를 모두 다룰 수 있기에 충분한
포인터들을 가져야 합니다.
물론, 시퀀스 락은 포인터 순회 보호를 제공하지 않는데, 그것이 정적 데이터에만
보통 쓰이는 이유입니다.

\iffalse

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Overview)}
shows a few high-level properties that distinguish the deferred-reclamation
techniques from one another.

The ``Readers'' row summarizes the results presented in
Figure~\ref{fig:defer:Pre-BSD Routing Table Protected by RCU QSBR},
which shows that all but reference counting are enjoy reasonably
fast and scalable readers.

The ``Number of Protected Objects'' row evaluates each technique's need
for external storage with which to record reader protection.
RCU relies on quiescent states, and thus needs no storage to represent
readers, whether within or outside of the object.
Reference counting can use a single integer within each object in the
structure, and no additional storage is required.
Hazard pointers require external-to-object pointers be provisioned,
and that there be sufficient pointers to handle the maximum number of
objects that a given CPU or thread might need to reference simultaneously.
Of course, sequence locks provides no pointer-traversal protection,
which is why it is normally used on static data.

\fi

\QuickQuiz{
	사용자들은 왜 필요에 따라 동적으로 해저드 포인터를 할당할 수 없나요?

	\iffalse

	Why can't users dynamically allocate the hazard pointers as they
	are needed?

	\fi

}\QuickQuizAnswer{
	그럴 수 있습니다만, 메모리 할당 실패를 처리하기 위해 어떤 환경에서는
	읽기 쓰레드의 순회에 대한 추가적 오버헤드를 비용으로 지불합니다.

	\iffalse

	They can, but at the expense of additional reader-traversal
	overhead and, in some environments, the need to handle
	memory-allocation failure.

	\fi

}\QuickQuizEnd

``Duration of Proeduction'' 은 사용자가 특정 객체를 얼마나 긴 시간동안 보호할
수 있는지에 대한 (존재한다면) 제약을 이야기 합니다.
레퍼런스 카운팅과 해저드 포인터는 둘 다 부작용 없이 연장된 시간 동안 보호할 수
있습니다만, 심지어 단 하나의 객체로의 RCU 레퍼런스를 유지하는 것도 모든 다른
RCU 가 메모리 해제되는 것을 방지할 수 있습니다.
따라서 RCU 읽기 쓰레드는 시스템 메모리 부족을 방지하기 위해 상대적으로 짧아야
하며, SRCU, Tasks RCU, 그리고 Tasks Trace RCU 같은 특수 목적 구현은 이 규칙에
있어 예외가 됩니다.
다시 말하지만, 시퀀스 락은 포인터 순회 보호를 제공하지 않는데, 그것이 정적
데이터에만 보통 쓰이는 이유입니다.

``Need for Traversal Retries'' 열은 특정 객체로의 새로운 참조가 RCU 에서 그런
것처럼 무조건적으로 획득될 수 있는지, 또는 레퍼런스 카운팅, 해저드 포인터,
그리고 시퀀스 락에서와 같이 그 참조 획득이 실패할 수 있고 따라서 재시도를 해야
하게 하는지 이야기 합니다.
레퍼런스 카운팅과 해저드 포인터의 경우, 어떤 객체가 삭제되려 하는 중에 참조를
얻으려 할 때에만 재시도가 필요한데, 이 주제는 다음 섹션에서 더 자세히
다뤄집니다.
시퀀스 락킹은 물론 어떤 업데이트와 동시에 수행될 때에나 그 크리티컬 섹션을
재시도 해야만 합니다.

\iffalse

The ``Duration of Protection'' describes constraints (if any) on how
long a period of time a user may protect a given object.
Reference counting and hazard pointers can both protect objects for
extended time periods with no untoward side effects, but
maintaining an RCU reference to even one object prevents all other RCU
from being freed.
RCU readers must therefore be relatively short in order to avoid running
the system out of memory, with special-purpose implementations such
as SRCU, Tasks RCU, and Tasks Trace RCU being exceptions to this rule.
Again, sequence locks provide no pointer-traversal protection,
which is why it is normally used on static data.

The ``Need for Traversal Retries'' row tells whether a new reference to
a given object may be acquired unconditionally, as it can with RCU, or
whether the reference acquisition can fail, resulting in a retry
operation, which is the case for reference counting, hazard pointers,
and sequence locks.
In the case of reference counting and hazard pointers, retries are only
required if an attempt to acquire a reference to a given object while
that object is in the process of being deleted, a topic covered in more
detail in the next section.
Sequence locking must of course retry its critical section should it
run concurrently with any update.

\fi

\QuickQuiz{
	하지만 리눅스 커널의 \co{kref} 레퍼런스 카운터는 보장된 무조건적 참조
	획득을 허용하지 않나요?

	\iffalse

	But don't Linux-kernel \co{kref} reference counters allow
	guaranteed unconditional reference acquisition?

	\fi

}\QuickQuizAnswer{
	맞아요 그렇습니다, 하지만 그 보장은 참조가 이미 잡혀 있는 경우에만
	무조건적으로 적용됩니다.
	이를 명심하고,
	Section~\ref{sec:defer:Which to Choose?} 의 시작 부분의 문장, 특히
	``충분히 길어서 읽기 쓰레드가 순회 사이에 참조를 잡고 있지 않는''
	부분을 다시 보시기 바랍니다.

	\iffalse

	Yes they do, but the guarantee only applies unconditionally
	in cases where a reference is already held.
	With this in mind, please review the paragraph at the beginning of
	Section~\ref{sec:defer:Which to Choose?}, especially the part
	saying ``large enough that readers do not hold references from
	one traversal to another''.

	\fi

}\QuickQuizEnd

물론, 각 열은 각 상황마다 다른 정도의 중요성을 가질 겁니다.
예를 들어, 여러분의 현재 코드가 해저드 포인터에서 읽기 쪽에 확장성 문제가
있다면, 해저드 포인터가 참조 획득 재시도를 필요로 한다는 것은 여러분의 현재
코드가 이를 이미 처리하고 있으므로 문제가 되지 않습니다.
비슷하게, 커널과 낮은 단계 어플리케이션들이 그런 것처럼 반응 시간 고려가 이미
읽기 쓰레드 순회 시간을 제한하고 있다면, RCU 가 기간 제한 요구를 갖는다는 것은
여러분의 코드가 이미 그것을 처리하고 있으므로 문제 되지 않습니다.
같은 맥락에서, 읽기 쓰레드가 순회하고 있는 객체들에 이미 쓰기를 했어야만
한다면, 레퍼런스 카운터의 읽기 쪽 오버헤드는 그렇게 중요하지 않을 겁니다.
물론, 보호되어야 할 데이터가 정적으로 할당된 변수에 있다면, 시퀀스 락킹의
퐁니터 보호 불가함은 상관없습니다.

마지막으로, 해저드 포인터와 RCU 를 동적 지연 샘플링에 기반해 동적으로 바꿔
사용하려는 시도가~\cite{Balmau:2016:FRM:2935764.2935790} 있습니다.
이는 해저드 포인터와 RCU 사이의 선택을 수행시점으로 미루며, 선택의 책임을
소프트웨어에게 넘깁니다.

어쨌든, 이 표는 이 기법들 사이에서 선택을 할 때 큰 도움이 될 겁니다.
하지만 더 자세한 걸 원하는 분들은 다음 섹션을 이어서 읽기 바랍니다.

\iffalse

Of course, different rows will have different levels of importance in
different situations.
For example, if your current code is having read-side scalability problems
with hazard pointers, then it does not matter that hazard pointers can require
retrying reference acquisition because your current code already handles
this.
Similarly, if response-time considerations already limit the duration
of reader traversals, as is often the case in kernels and low-level
applications, then it does not matter that RCU has duration-limit
requirements because your code already meets them.
In the same vein, if readers must already write to the objects that they
are traversing, the read-side overhead of reference counters might
not be so important.
Of course, if the data to be protected is in statically allocated variables,
then sequence locking's inability to protect pointers is irrelevant.

Finally, there is some work on dynamically switching between hazard
pointers and RCU based on dynamic sampling of
delays~\cite{Balmau:2016:FRM:2935764.2935790}.
This defers the choice between hazard pointers and RCU to runtime,
and delegates responsibility for the decision to the software.

Nevertheless, this table should be of great help when choosing between
these techniques.
But those wishing more detail should continue on to the next section.

\fi

\subsection{Which to Choose? (Details)}
\label{sec:defer:Which to Choose? (Details)}

\begin{table*}
\rowcolors{1}{}{lightgray}
\renewcommand*{\arraystretch}{1.25}
\footnotesize
\centering\OneColumnHSpace{-.3in}
\begin{tabularx}{5.3in}{>{\raggedright\arraybackslash}p{1.1in}
    >{\raggedright\arraybackslash}p{1.2in}
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}X
    >{\raggedright\arraybackslash}p{.9in}}
	\toprule
	Property
		& Reference Counting
			& Hazard Pointers
				& Sequence Locks
					& RCU \\
%		  RC	  HP	  SL	  RCU \\
	\midrule
	Existence Guarantees
		& Complex
			& Yes
				& No
					& Yes \\
	Updates and Readers Progress Concurrently
		& Yes
			& Yes
				& No
					& Yes \\
	Contention Among Readers
		& High
			& None
				& None
					& None \\
	Reader Per\-/Critical\-/Section Overhead
		& N/A
			& N/A
				& Two \tco{smp_mb()}
					& Ranges from none to two
					  \tco{smp_mb()} \\
	Reader Per-Object Traversal Overhead
		& Read-modify-write atomic operations, memory\-/barrier
		  instructions, and cache misses
			& \tco{smp_mb()}
				& None, but unsafe
					& None (volatile accesses) \\
	Reader Forward Progress Guarantee
		& Lock free
			& Lock free
				& Blocking
					& Bounded wait free \\
	Reader Reference Acquisition
		& Can fail (conditional)
			& Can fail (conditional)
				& Unsafe
					& Cannot fail (unconditional) \\
	Memory Footprint
		& Bounded
			& Bounded
				& Bounded
					& Unbounded \\
	Reclamation Forward Progress
		& Lock free
			& Lock free
				& N/A
					& Blocking \\
	Automatic Reclamation
		& Yes
			& Use Case
				& N/A
					& Use Case \\
	Lines of Code
		& 94
			& 79
				& 79
					& 73 \\
	\bottomrule
\end{tabularx}
\caption{Which Deferred Technique to Choose?  (Details)}
\label{tab:defer:Which Deferred Technique to Choose?  (Details)}
\end{table*}

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Details)}
은 이 챕터에서 소개된 네개의 deferred-processing 기법들 중 하나를 선택해야 할
때 도움을 줄 수 있는 더 자세한 경험상의 법칙을 제공합니다.

``Existence Guarantee'' 열에 보이듯, 여러분이 연결된 데이터 원소들에 대한 존재
보장을 해야 한다면, 여러분은 레퍼런스 카운팅, 해저드 포인터, 또는 RCU 를
사용해야만 합니다.
시퀀스 락은 존재 보장을 제공하지 않는 대신 업데이트 탐자와 업데이트를 마주친
read-side 크리티컬 섹션의 재시도를 제공합니다.

물론, ``Updates and Readers Progress Concurrently'' 열에서 보였듯 이 업데이트
탐지는 시퀀스 락킹이 업데이트 쓰레드와 읽기 쓰레드가 동시에 진행을 내는 것을
허용하지 않음을 암시합니다.
어쨌건, 그런 진행을 방지하는 것이 시퀀스 락킹을 상요하는 첫번째 이유입니다!
이 상황은 시퀀스 락킹을 레퍼런스 카운팅, 해저드 포인터, 또는 RCU 와 결합해 존재
보장과 업데이트 탐지를 제공하는 방법들을 가리킵니다.
실제로, 리눅스 커널은 pathname 탐색 시에 RCU 와 시퀀스 락킹을 이 방법으로
결합해 사용합니다.

\iffalse

Table~\ref{tab:defer:Which Deferred Technique to Choose? (Details)}
provides more-detailed rules of thumb that can help you choose among the
four deferred-processing techniques presented in this chapter.

As shown in the ``Existence Guarantee'' row,
if you need existence guarantees for linked
data elements, you must use reference counting, hazard pointers, or RCU\@.
Sequence locks do not provide existence guarantees, instead providing
detection of updates, retrying any read-side critical sections
that do encounter an update.

Of course, as shown in the ``Updates and Readers Progress Concurrently''
row, this detection of updates implies
that sequence locking does not permit updaters and readers to make forward
progress concurrently.
After all, preventing such forward progress is the whole point of using
sequence locking in the first place!
This situation points the way to using sequence locking in conjunction
with reference counting, hazard pointers, or RCU in order to provide
both existence guarantees and update detection.
In fact, the Linux kernel combines RCU and sequence locking in
this manner during pathname lookup.

\fi

``Contention Among Readers'', ``Reader Per-Critical-Section Overhead'',
그리고 ``Reader Per-Object Traversal Overhead'' 열은 이 기법들의 read-side
오버헤드에 대한 대략적 느낌을 제공합니다.
레퍼런스 카운팅의 오버헤드는 상당히 클 수 있는데, 각 객체 순회마다 필요한
완전히 순서잡힌 read-modify-write 어토믹 오퍼레이션을 포함합니다.
해저드 포인터는 각 데이터 원소 순회마다 메모리 배리어 오버헤드를 일으키며,
시퀀스 락은 크리티컬 섹션을 수행하려 할 때마다 한 상의 메모리 배리어 오버헤드를
일으킵니다.
RCU 구현체들의 오버헤드는 제로부터 각 read-side 크리티컬 섹션마다의 한 쌍의
메모리 배리어까지 다양하며, 따라서 RCU 를 특히 많은 데이터 원소를 순회하는
read-side 크리티컬 섹션을 가진 경우에 대해 최고의 성능을 제공할 수 있게 합니다.
물론, 모든 deferred-processing 변종들의 read-side 오버헤드는 각 read-side
오퍼레이션이 더 많은 데이터를 처리하게끔 batching 을 사용해 줄일 수 있습니다.

\iffalse

The ``Contention Among Readers'', ``Reader Per-Critical-Section Overhead'',
and ``Reader Per-Object Traversal Overhead'' rows give a rough sense of
the read-side overhead of these techniques.
The overhead of reference counting can be quite large, with
contention among readers along with a fully ordered read-modify-write
atomic operation required for each and every object traversed.
Hazard pointers incur the overhead of a memory barrier for each data element
traversed, and sequence locks incur the overhead of a pair of memory barriers
for each attempt to execute the critical section.
The overhead of RCU implementations vary from nothing to that of a pair of
memory barriers for each read-side critical section, thus providing RCU
with the best performance, particularly for read-side critical sections
that traverse many data elements.
Of course, the read-side overhead of all deferred-processing variants can
be reduced by batching, so that each read-side operation covers more data.

\fi

\QuickQuiz{
	But didn't the answer to one of the quick quizzes in
	Section~\ref{sec:defer:Hazard Pointers}
	say that pairwise asymmetric barriers could eliminate the
	read-side \co{smp_mb()} from hazard pointers?
}\QuickQuizAnswer{
	Yes, it did.
	However, doing this could be argued to change hazard-pointers
	``Reclamation Forward Progress'' row (discussed later) from
	lock-free to blocking because a CPU spinning with interrupts
	disabled in the kernel would prevent the update-side portion of
	the asymmetric barrier from completing.
	In the Linux kernel, such blocking could in theory be prevented
	by building the kernel with \co{CONFIG_NO_HZ_FULL}, designating
	the relevant CPUs as \co{nohz_full} at boot time, ensuring that
	only one thread was ever runnable on a given CPU at a given
	time, and avoiding ever calling into the kernel.
	Alternatively, you could ensure that the kernel was free of any
	bugs that might cause CPUs to spin with interrupts disabled.

	Given that CPUs spinning in the Linux kernel with interrupts
	disabled seems to be rather rare, one might counter-argue that
	asymmetric-barrier hazard-pointer updates are non-blocking
	in practice, if not in theory.
}\QuickQuizEnd

The ``Reader Forward Progress Guarantee'' row shows that only RCU
has a bounded wait-free forward-progress guarantee, which means that
it can carry out a finite traversal by executing a bounded number of
instructions.

The ``Reader Reference Acquisition'' rows indicates that only RCU is
capable of unconditionally acquiring references.
The entry for sequence locks is ``Unsafe'' because, again, sequence locks
detect updates rather than acquiring references.
Reference counting and hazard pointers both require that traversals be
restarted from the beginning if a given acquisition fails.
To see this, consider a linked list containing objects~A, B, C, and~D,
in that order, and the following series of events:

\begin{enumerate}
\item	A reader acquires a reference to object~B.
\item	An updater removes~object B, but refrains from freeing it because
	the reader holds a reference.
	The list now contains objects~A, C, and~D, and
	object~B's \co{->next} pointer is set to \co{HAZPTR_POISON}.
\item	The updater removes object~C, so that the list now contains
	objects~A and~D\@.
	Because there is no reference to object~C, it is immediately freed.
\item	The reader tries to advance to the successor of the object
	following the now-removed object~B, but the poisoned
	\co{->next} pointer prevents this.
	Which is a good thing, because object~B's \co{->next} pointer
	would otherwise point to the freelist.
\item	The reader must therefore restart its traversal from the head
	of the list.
\end{enumerate}

Thus, when failing to acquire a reference, a hazard-pointer or
reference-counter traversal must restart that traversal from the
beginning.
In the case of nested linked data structures, for example, a
tree containing linked lists, the traversal must be restarted from
the outermost data structure.
This situation gives RCU a significant ease-of-use advantage.

However, RCU's ease-of-use advantage does not come
for free, as can be seen in the ``Memory Footprint'' row.
RCU's support of unconditional reference acquisition means that
it must avoid freeing any object reachable by a given
RCU reader until that reader completes.
RCU therefore has an unbounded memory footprint, at least unless updates
are throttled.
In contrast, reference counting and hazard pointers need to  retain only
those data elements actually referenced by concurrent readers.

This tension between memory footprint and acquisition
failures is sometimes resolved within the Linux kernel by combining use
of RCU and reference counters.
RCU is used for short-lived references, which means that RCU read-side
critical sections can be short.
These short RCU read-side critical sections in turn mean that the corresponding
RCU grace periods can also be short, which limits the memory footprint.
For the few data elements that need longer-lived references, reference
counting is used.
This means that the complexity of reference-acquisition failure only
needs to be dealt with for those few data elements:  The bulk of
the reference acquisitions are unconditional, courtesy of RCU\@.
See Section~\ref{sec:together:Refurbish Reference Counting}
for more information on combining reference counting with other
synchronization mechanisms.

The ``Reclamation Forward Progress'' row shows that hazard pointers
can provide non-blocking updates~\cite{MagedMichael04a,HerlihyLM02}.
Reference counting might or might not, depending on the implementation.
However, sequence locking cannot provide non-blocking updates, courtesy
of its update-side lock.
RCU updaters must wait on readers, which also rules out fully non-blocking
updates.
However, there are situations in which the only blocking operation is
a wait to free memory, which results in a situation that, for many
purposes, is as good as non-blocking~\cite{MathieuDesnoyers2012URCU}.

As shown in the ``Automatic Reclamation'' row, only reference
counting can automate freeing of memory, and even then only
for non-cyclic data structures.
Certain use cases for hazard pointers and RCU can provide automatic
reclamation using \emph{link counts}, which can be thought of as
reference counts, but applying only to incoming links from other
parts of the data structure~\cite{MagedMichael2018FollyHazptr}.

Finally, the ``Lines of Code'' row shows the size of the Pre-BSD
Routing Table implementations, giving a rough idea of relative ease of use.
That said, it is important to note that the reference-counting and
sequence-locking implementations are buggy, and that a correct
reference-counting implementation is considerably
more complex~\cite{Valois95a,MagedMichael95a}.
For its part, a correct sequence-locking implementation requires
the addition of some other synchronization mechanism, for example,
hazard pointers or RCU, so that sequence locking detects concurrent
updates and the other mechanism provides safe reference acquisition.

As more experience is gained using these techniques, both separately
and in combination, the rules of thumb laid out in this section will
need to be refined.
However, this section does reflect the current state of the art.

\subsection{Which to Choose? (Production Use)}
\label{sec:defer:Which to Choose? (Production Use)}

This section points out a few publicly visible production uses of
hazard pointers, sequence locking, and RCU\@.
Reference counting is omitted, not because it is unimportant, but rather
because it is not only used pervasively, but heavily documented in textbooks
going back a half century.
One of the hoped-for benefits of listing production uses of these other
techniques is to provide examples to study---or to find bugs in, as
the case may be.\footnote{
	Kudos to Mathias Stearn, Matt Wilson, David Goldblatt, LiveJournal
	user fanf, Nadav Har'El, Avi Kivity, Dmitry Vyukov, Raul Guitterez
	S., Twitter user @peo3, Paolo Bonzini, and Thomas Monjalon for
	locating a great many of these use cases.}

\subsubsection{Production Uses of Hazard Pointers}
\label{sec:defer:Production Uses of Hazard Pointers}

In 2010, Keith Bostic added hazard pointers to
WiredTiger~\cite{KeithBostic2010WiredTigerhazptr}.
MongoDB 3.0, released in 2015, included WiredTiger and thus hazard pointers.

In 2011, Samy Al Bahra added hazard pointers to the Concurrency Kit
library~\cite{SamyAlBahra2011ckhp}.

In 2014, Maxim Khizhinsky added hazard pointers to
libcds~\cite{MaximKhizhinsky2014libcdsHazptr}.

In 2015, David Gwynne introduced shared reference pointers, a form
of hazard pointers, to OpenBSD~\cite{DavidGwynne2015srp}.

In 2017--2018, the Rust-language
\co{arc-swap}~\cite{MichalVaner2018arc-swapHazptr} and
\co{conc}~\cite{crates.io.user.ticki2017concHazptr}
crates rolled their own implementations of hazard pointers.

In 2018, Maged Michael added hazard pointers to Facebook's Folly
library~\cite{MagedMichael2018FollyHazptr}, where it is used heavily.

\subsubsection{Production Uses of Sequence Locking}
\label{sec:defer:Production Uses of Sequence Locking}

The Linux kernel added sequence locking to v2.5.60 in
2003~\cite{JonathanCorbet2003seqlock}, having been generalized from
an ad-hoc technique used in x86's implementation of the
\co{gettimeofday()} system call.

In 2011, Samy Al Bahra added sequence locking to the Concurrency Kit
library~\cite{SamyAlBahra2011ckseqlock}.

Paolo Bonzini added a simple sequence-lock to the QEMU emulator in
2013~\cite{PaoloBonzini2013QEMUseqlock}.

Alexis Menard abstracted a sequence-lock implementation in Chromium
in 2016~\cite{AlexisMenard2016ChromiumSeqLock}.

A simple sequence locking implementation was added to \co{jemalloc()}
in 2018~\cite{DavidGoldblatt2018seqlock}.
The eigen library also has a special-purpose queue that is managed by
a mechanism resembling sequence locking.

\subsubsection{Production Uses of RCU}
\label{sec:defer:Production Uses of RCU}

IBM's VM/XA is adopted passive serialization, a mechanism similar to
RCU, some time in the 1980s~\cite{Hennessy89}.

DYNIX/ptx adopted RCU in 1993~\cite{McKenney98,Slingwine95}.

The Linux kernel adopted Dipankar Sarma's implementation of RCU in
2002~\cite{Torvalds2.5.43}.

The userspace RCU project started in 2009~\cite{MathieuDesnoyers2009URCU}.

The Knot DNS project started using the userspace RCU
library in 2010~\cite{LubosSlovak2010KnotDNSRCU}.
That same year, the OSv kernel added an RCU
implementation~\cite{AviKivity2013OSvRCU},
later adding an RCU-protected linked list~\cite{AviKivity2013OSvRCUlist}
and an RCU-protected hash table~\cite{AviKivity2013OSvRCUhash}.

In 2011, Samy Al Bahra added epochs
(a form of RCU~\cite{UCAM-CL-TR-579,KeirFraser2007withoutLocks})
to the Concurrency Kit
library~\cite{SamyAlBahra2011ckEpoch}.

NetBSD began using the aforementioned passive serialization with v6.0 in
2012~\cite{NetBSD2012pserialize}.
Among other things, passive serialization is used in
NetBSD packet filter (NPF)~\cite{MindaugasRasiukevicius2014NPFRCU}.

Paolo Bonzini added RCU support to the QEMU emulator in 2015 via a
friendly fork of the userspace RCU
library~\cite{MikeDay2013RCUqemu,PaoloBonzini2013QEMURCU}.

In 2015, Maxim Khizhinsky added RCU to
libcds~\cite{MaxKhiszinsky2015C++RCU}.

Mindaugas Rasiukevicius implemented libqsbr in 2016, which features
QSBR and epoch-based reclamation
(EBR)~\cite{MindaugasRasiukevicius2016libqsbr},
both of which are types of implementations of RCU\@.

Sheth et al.~\cite{HarshalSheth2016goRCU}
demonstrated the value of leveraging Go's garbage
collector to provide RCU-like functionality, and
the Go programming language provides a \co{Value} type that can
provide this functionality.\footnote{
	See \url{https://golang.org/pkg/sync/atomic/\#Value}, particularly
	the ``Example (ReadMostly)''.}

Matt Klein describes an RCU-like mechanism that is used in the Envoy
Proxy~\cite{MattKlein2017EnvoyRCU}.

Honnappa Nagarahalli added an RCU library to the Data Plane Development
Kit (DPDK) in 2018~\cite{HonnappaNagarahalli2018dpdkRCU}.

Stjepan Glavina merged an epoch-based RCU implementation into the
\co{crossbeam} set of concurrency-support ``crates'' for the Rust
language~\cite{StjepanGlavina2018RustRCU}.

Finally, any garbage-collected concurrent language (not just Go!) gets
the update side of an RCU implementation at zero incremental cost.

\subsubsection{Summary of Production Uses}
\label{sec:defer:Summary of Production Uses}

Perhaps the time will come when sequence locking, hazard pointers, and
RCU are all as heavily used and as well known as are reference counters.
Until that time comes, the current production uses of these mechanisms
should help guide the choice of mechanism as well as showing how best
to apply each of them.

The next section discusses updates, a ticklish issue for many of the
read-mostly mechanisms described in this chapter.
