% defer/rcufundamental.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\subsection{RCU Fundamentals}
\label{sec:defer:RCU Fundamentals}
\OriginallyPublished{Section}{sec:defer:RCU Fundamentals}{RCU Fundamentals}{Linux Weekly News}{PaulEMcKenney2007WhatIsRCUFundamentally}

이 섹션은 앞의 섹션에서 다루어졌지만 특정 예나 사용 경우에 독립적인 바닥의
것들을 다시 살펴봅니다.
실제 코드와 무척 가까운 삶을 사는 것을 선호하는 사람들은 이 섹션에서 다루는
기본적인 것들은 생략하고 싶을 겁니다.

RCU 는 세개의 기본적 메커니즘을 통해 만들어지는데, 첫번째 것은 삽입을 위해,
두번째 것은 삭제를 위해, 그리고 세번째 것은 읽기 쓰레드가 동시의 삽입과 삭제를
견딜 수 있게 하는데에 사용됩니다.
Section~\ref{sec:defer:Publish-Subscribe Mechanism}
은 삽입을 위해 사용되는 게시-구독 메커니즘을,
Section~\ref{sec:defer:Wait For Pre-Existing RCU Readers}
은 앞서서부터 존재하고 있는 RCU 읽기 쓰레드들을 기다리는 것이 삭제를 가능하게
하는지, 그리고
Section~\ref{sec:defer:Maintain Multiple Versions of Recently Updated Objects}
은 최근에 업데이트된 객체들의 여러 버전을 유지하는 것이 어떻게 동시의 삽입과
삭제를 허용하는지 이야기 합니다.
마지막으로,
Section~\ref{sec:defer:Summary of RCU Fundamentals}
은 RCU 의 기본을 요약합니다.

\iffalse

This section re-examines the ground covered in the previous section, but
independent of any particular example or use case.
People who prefer to live their lives very close to the actual code may
wish to skip the underlying fundamentals presented in this section.

RCU is made up of three fundamental mechanisms, the first being
used for insertion, the second being used for deletion, and the third
being used to allow readers to tolerate concurrent insertions and deletions.
Section~\ref{sec:defer:Publish-Subscribe Mechanism}
describes the publish-subscribe mechanism used for insertion,
Section~\ref{sec:defer:Wait For Pre-Existing RCU Readers}
describes how waiting for pre-existing RCU readers enabled deletion,
and
Section~\ref{sec:defer:Maintain Multiple Versions of Recently Updated Objects}
discusses how maintaining multiple versions of recently updated objects
permits concurrent insertions and deletions.
Finally,
Section~\ref{sec:defer:Summary of RCU Fundamentals}
summarizes RCU fundamentals.

\fi

\subsubsection{Publish-Subscribe Mechanism}
\label{sec:defer:Publish-Subscribe Mechanism}

RCU 읽기 쓰레드들은 RCU 업데이트 쓰레드들로부터 배제되지 않기 때문에, RCU 로
보호되는 데이터 구조는 읽기 쓰레드가 그것을 액세스 하고 있는 동안에도 변경될
수도 있습니다.
이 액세스된 데이터 항목은 옮겨졌거나, 삭제되었거나, 교체되었을 수도 있습니다.
이 데이터 구조는 읽기 쓰레드가 존재하는 동안 ``기다려주지'' 않기 때문에, 각
읽기 쓰레드의 액세스는 이 RCU 로 보호되는 데이터 항목의 현재 버전을 구독하고
있는 것으로 생각될 수 있습니다.
이에 대해 업데이트 쓰레드의 동작은 새로운 버전을 게재하는 것으로 생각될 수
있습니다.

\iffalse

Because RCU readers are not excluded by RCU updaters, an RCU-protected
data structure might change while a reader accesses it.
The accessed data item might be moved, removed, or replaced.
Because the data structure does not ``hold still'' for the reader,
each reader's access can be thought of as subscribing to the current
version of the RCU-protected data item.
For their part, updaters can be thought of as publishing new versions.

\fi

% @@@ Merge usage section into "Which to Choose?" and suggest choices.
% @@@ Should "RCU Exercises" move to "RCU Rescues"?

\begin{figure}[tbp]
\centering
\resizebox{3in}{!}{\includegraphics{defer/pubsub}}
\caption{Publication/Subscription Constraints}
\label{fig:defer:Publication/Subscription Constraints}
\end{figure}

불행히도,
Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}
에서 이야기 되었고
Section~\ref{sec:defer:Minimal Insertion and Deletion}
에서 반복해 이야기 되었듯, 이런 게재와 구독 오퍼레이션에 평범한 액세스를
사용하는 것은 현명치 못합니다.
그 대신 컴파일러와 CPU 모두에게 주의를 요함을 알릴 필요가 있는데,
Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers} 의
\co{ins_route()} (와 그 호출자) 와 \co{read_gptr()} 이 동시에 수행될 때의
상호작용을 그린
Figure~\ref{fig:defer:Publication/Subscription Constraints} 이 이를 잘 보이고
있습니다.

Figure~\ref{fig:defer:Publication/Subscription Constraints}
의 \co{ins_route()} 행은 초기화 전의 쓰레기 값을 갖는 새 \co{route} 구조체를
메모리 할당하는, \co{ins_route()} 의 호출자를 보입니다.
이 호출자는 이어서 새로 할당된 구조체를 초기화 하고, 이 새로운 \co{route}
구조체로의 포인터를 게재하는 \co{ins_route()} 를 호출합니다.
게재는 이 구조체의 내용에 영향을 끼치지 않으며, 따라서 게재 후에도 유효한 것이
됩니다.

\iffalse

Unfortunately, as laid out in
Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}
and reiterated in
Section~\ref{sec:defer:Minimal Insertion and Deletion},
it is unwise to use plain accesses for these publication and subscription
operations.
It is instead necessary to inform both the compiler and the CPU
of the need for care, as can be seen from
Figure~\ref{fig:defer:Publication/Subscription Constraints},
which illustrates interactions between concurrent executions of
\co{ins_route()} (and its caller) and \co{read_gptr()} from
Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}.

The \co{ins_route()} column from
Figure~\ref{fig:defer:Publication/Subscription Constraints}
shows \co{ins_route()}'s caller allocating a new \co{route} structure,
which then contains pre-initialization garbage.
The caller then initializes the newly allocated structure, and then
invokes \co{ins_route()} to publish a pointer to the new \co{route}
structure.
Publication does not affect the contents of the structure, which
therefore remain valid after publication.

\fi

이 그림의 \co{access_route()} 행은 구독되고 역참조되는 포인터를 보입니다.
이 역참조 오퍼레이션은 당연히 초기화 전의 쓰레기값이 아닌 유효한 \co{route}
구조체를 봐야 하는데 쓰레기 값을 역참조 하는 것은 메모리 오염, 시스템 깨짐,
그리고 시스템 정지를 유발할 수 있기 때문입니다.
앞에서 이야기 되었듯, 그런 쓰레기 값을 방지하는 것은 게재와 구독 오퍼레이션이
컴파일러와 CPU 모두에게 필요한 순서를 지켜줄 것을 알려야 함을 의미합니다.

게재는 \co{ins_route()} 의 호출자의 초기화가 실제 게재 오퍼레이션의 포인터 저장
전으로 순서지어질 것을 보장하는 \co{rcu_assign_pointer()} 에 의해 수행됩니다.
또한, \co{rcu_assign_pointer()} 는 동시의 읽기 쓰레드가 이 포인터의 기존 값이나
새 값만 보지, 이 두 값의 어떤 결합된 형태를 보지는 않는다는 의미로 어토믹해야만
합니다.
이 요구사항들은 C11 의 store-release 오퍼레이션에 의해 지켜지며, 실제로 리눅스
커널에서 \co{rcu_assign_pointer()} 는 C11 의 store-release 와 비슷한
\co{smp_store_release()} 를 사용해 정의됩니다.

\iffalse

The \co{access_route()} column from this same figure shows
the pointer being subscribed to and dereferenced.
This dereference operation absolutely must see a valid \co{route}
structure rather than pre-initialization garbage because referencing
garbage could result in memory corruption, crashes, and hangs.
As noted earlier, avoiding such garbage means that the publish and
subscribe operations must inform both the compiler and the CPU of the
need to maintain the needed ordering.

Publication is carried out by \co{rcu_assign_pointer()}, which ensures that
\co{ins_route()}'s caller's initialization is ordered before the actual
publication operation's store of the pointer.
In addition, \co{rcu_assign_pointer()} must be atomic in the sense that 
concurrent readers see either the old value of the pointer or the new
value of the pointer, but not some mash-up of these two values.
These requirements are met by the C11 store-release operation, and in
fact in the Linux kernel, \co{rcu_assign_pointer()} is defined in terms
of \co{smp_store_release()}, which is similar to C11 store-release.

\fi

동시의 업데이트들이 필요하다면 같은 포인터로의
동시적인\co{rcu_assign_pointer()} 호출을 중재하기 위해 어떤 종류의 동기화
메커니즘이 필요함을 알아두시기 바랍니다.
리눅스 커널에서, 락킹은 그러기 위해 선택됩니다만, 어떤 동기화 메커니즘이든
사용될 수 있습니다.
특히 가벼운 동기화 메커니즘의 예는
Chapter~\ref{chp:Data Ownership} 의 데이터 소유권입니다: 각 포인터가 특정
쓰레드에 의해 소유된다면, 해당 쓰레드는 해당 포인터로의
\co{rcu_assign_pointer()} 를 추가적인 동기화 오버헤드 없이 수행할 수 있습니다.

\iffalse

Note that if concurrent updates are required, some sort of synchronization
mechanism will be required to mediate among multiple concurrent
\co{rcu_assign_pointer()} calls on the same pointer.
In the Linux kernel, locking is the mechanism of choice, but pretty
much any synchronization mechanism may be used.
An example of a particularly lightweight synchronization mechanism is
Chapter~\ref{chp:Data Ownership}'s data ownership: If each pointer is
owned by a particular thread, then that thread may execute
\co{rcu_assign_pointer()} on that pointer with no additional
synchronization overhead.

\fi

\QuickQuiz{
	RCU 업데이트 쓰레드를 위한 데이터 소유권의 사용은 이 업데이트들이
	연관된 단일쓰레드 기반 코드의 것과 정확히 같은 명령들을 사용해 수행될
	수 있음을 의미하지 않나요?

	\iffalse

	Wouldn't use of data ownership for RCU updaters mean that
	the updates could use exactly the same sequence of instructions
	as would the corresponding single-threaded code?

	\fi

}\QuickQuizAnswer{
	어떤 경우들, 예를 들면 x86 이나 IBM 메인프레임과 같이 store-release
	오퍼레이션이 하나의 스토어 명령만을 만들어내는 TSO 시스템에서라면요.
	하지만, 완화된 순서 규칙의 시스템들은 메모리 배리어나 어쩌면
	store-releae 명령을 수행해야 합니다.
	또한, 데이터를 제거하는 것은 이 데이터 제거 전에 앞서서부터 존재해온
	읽기 쓰레드들을 기다려야 하므로 상당한 추가적 일을 필요로 합니다.

	\iffalse

	Sometimes, for example, on TSO systems such as x86 or the IBM
	mainframe where a store-release operation emits a single store
	instruction.
	However, weakly ordered systems must also emit a memory barrier
	or perhaps a store-release instruction.
	In addition, removing data requires quite a bit of additional
	work because it is necessary to wait for pre-existing readers
	before freeing the removed data.

	\fi

}\QuickQuizEnd

구독은 해당 포인터의 읽기가 역참조보다 먼저 수행될 것을 순서잡는
\co{rcu_dereference()} 에 의해 수행됩니다.
\co{rcu_assign_pointer()} 와 비슷하게, \co{rcu_dereference()} 는 읽혀진 값이
하나의 스토어에 의해서 만들어진 것이어야 한다는 점에서 원자적이어야 하는데,
예를 들어, 컴파일러는 이 읽기를 쪼개 수행하지 않아야 합니다.\footnote{
	즉, 컴파일러는 이 로드를
	Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans} 의 ``load
	tearing (로드 찢기)'' 로 설명된 것처럼 여러개의 작은 로드로 쪼개선
	안됩니다.}
불행히도, 컴파일러의 \co{rcu_dereference()} 지원은 여전히
작업중입니다~\cite{PaulEMcKennneyConsumeP0190R4,PaulEMcKenney2017markconsumeP0462R1,JFBastien2018P0750R1consume}.
그 중에는 리눅스 커널은 volatile 로드, 다양한 CPU 아키텍쳐의 세부 사항, 코딩
제약~\cite{PaulEMcKenney2014rcu-dereference} 에, 그리고 DEC
Alpha~\cite{ALPHA2002} 의 경우에는 메모리 배리어 인스트럭션에 의존해야 합니다.
하지만, 다른 아키텍쳐에서는 \co{rcu_dereference()} 가 하나의 로드
인스트럭션만을 만들어 내어서, 동일한 단일쓰레드 기반 코드와 같아집니다.
코딩 제약은
Section~\ref{sec:memorder:Address- and Data-Dependency Difficulties}
에서 자세히 다루어집니다만, 필드 선택 (\qtco{->}) 의 흔한 경우가 잘 동작합니다.
읽기 쪽 궁극적 성능을 필요로 하지 않는 소프트웨어라면 그 대신 비용이 있긴
하지만 필요한 순서 규칙을 제공하는 C11 acquire load 를 대신 사용할 수도
있습니다.
조만간 \co{rcu_dereference()} 의 더 가벼운 컴파일러 지원이 나오길 많은 사람들이
바라고 있습니다.

\iffalse

Subscription is carried out by \co{rcu_dereference()}, which orders
the subscription operation's load from the pointer is before the
dereference.
Similar to \co{rcu_assign_pointer()}, \co{rcu_dereference()} must be
atomic in the sense that the value loaded must be that from a single
store, for example, the compiler must not tear the load.\footnote{
	That is, the compiler must not break the load into multiple
	smaller loads, as described under ``load tearing'' in
	Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}.}
Unfortunately, compiler support for \co{rcu_dereference()} is at best
a work in progress~\cite{PaulEMcKennneyConsumeP0190R4,PaulEMcKenney2017markconsumeP0462R1,JFBastien2018P0750R1consume}.
In the meantime, the Linux kernel relies on volatile loads, the details of
the various CPU architectures, coding
restrictions~\cite{PaulEMcKenney2014rcu-dereference},
and, on DEC Alpha~\cite{ALPHA2002}, a memory-barrier instruction.
However, on other architectures, \co{rcu_dereference()} typically
emits a single load instruction, just as would the equivalent single-threaded
code.
The coding restrictions are described in more detail in
Section~\ref{sec:memorder:Address- and Data-Dependency Difficulties},
however, the common case of field selection (\qtco{->}) works quite well.
Software that does not require the ultimate in read-side performance
can instead use C11 acquire loads, which provide the needed ordering and
more, albeit at a cost.
It is hoped that lighter-weight compiler support for \co{rcu_dereference()}
will appear in due course.

\fi

요약하자면, 포인터의 게재를 위한 \co{rcu_assign_pointer()} 의 사용과 그것을
구독하기 위한 \co{rcu_dereference()} 의 사용은
Figure~\ref{fig:defer:Publication/Subscription Constraints}
에 그려진 ``Not OK'' 쓰레기 읽기를 방지합니다.
따라서 이 두개의 기능은 동기의 읽기를 망치지 않으면서 연결된 구조체들에 새
데이터를 추가할 수 있습니다.

\iffalse

In short, use of \co{rcu_assign_pointer()} for publishing pointers and
use of \co{rcu_dereference()} for subscribing to them successfully avoids the
``Not OK'' garbage loads depicted in
Figure~\ref{fig:defer:Publication/Subscription Constraints}.
These two primitives can therefore be used to add new data to linked
structures without disrupting concurrent readers.

\fi

\QuickQuiz{
	하지만 어떤 읽기 쓰레드가 어떤 링크드 리스트를 순회하는 동안 업데이트
	쓰레드들이 여러 데이터 아이템들을 이 리스트에 넣고 빼고 있다고 생각해
	봅시다.
	특히, 이 리스트가 초기에는 원소 A, B, 그리고~C 를 가지고 있고 어느
	업데이트 쓰레드가 원소 A 를 삭제하고 이어서 새 원소 D 를 이 리스트의
	끝에 추가했다고 해 봅시다.
	읽기 쓰레드는 \{A, B, C, D\} 를 볼 수 있는데, 그런 원소의 연속은 실제로
	존재한 적이 없는 것입니다!
	어떤 대안적 우주에서는 그게 ``동시의 읽기 쓰레드를 방해하지 않는다''
	라고 여겨집니까???

	\iffalse

	But suppose that updaters are adding and removing multiple data
	items from a linked list while a reader is iterating over that
	same list.
	Specifically, suppose that a list initially contains elements
	A, B, and~C, and that an updater removes element A and then
	adds a new element D at the end of the list.
	The reader might well see \{A, B, C, D\}, when that sequence of
	elements never actually ever existed!
	In what alternate universe would that qualify as ``not disrupting
	concurrent readers''???

	\fi

}\QuickQuizAnswer{
	순회하는 읽기 쓰레드가 순회의 전체 기간을 통틀어 존재한 원소들만 순회할
	필요가 있는 우주에서요.
	이 예에서, 그건 원소 B 와~C 일 겁니다.
	원소 A 와~D 는 이 순회의 각 부분에서만 존재했으므로, 이 읽기 쓰레드는
	그것들을 순회할 수 있게 허용되지만, 강요당하지는 않습니다.
	이는 읽기 쓰레드가 그저 단일 항목을 탐색하고 있는, 다른 항목들의 존재나
	부재를 신경쓰지 않는 일반적인 경우를 지원함을 알아두시기 바랍니다.

	더 강력한 일관성이 필요하다면, 더 높은 비용의 동기화 메커니즘들이
	필요한데, 예를 들면 sequence 락킹이나 reader-writer 락킹입니다.
	하지만 더 강한 일관성이 필요하지 \emph{않다면} (그리고 아주 많은 경우에
	그렇습니다), 왜 더 높은 비용을 냅니까?

	\iffalse

	In the universe where an iterating reader is only required to
	traverse elements that were present throughout the full duration
	of the iteration.
	In the example, that would be elements B and~C\@.
	Because elements A and~D were each present for only part of the
	iteration, the reader is permitted to iterate over them, but not
	obliged to.
	Note that this supports the common case where the reader is simply
	looking up a single item, and does not know or care about the
	presence or absence of other items.

	If stronger consistency is required, then higher-cost
	synchronization mechanisms are required, for example, sequence
	locking or reader-writer locking.
	But if stronger consistency is \emph{not} required (and it very often
	is not), then why pay the higher cost?

	\fi

}\QuickQuizEnd

읽기 쓰레드들을 방해하지 않으면서 연결된 구조에 데이터를 추가하는 것은 좋은
일입니다, 이는 싱글쓰레드 기반 읽기 쓰레드에 비해 추가적인 읽기쪽 비용을 높이지
않으면서도 행해질 수 있으니까요.
하지만, 많은 경우에 데이터의 삭제도 필요한데, 이게 다음 섹션의 주제입니다.

\iffalse

Adding data to a linked structure without disrupting readers is a good thing,
as are the cases where this can be done with no added read-side cost compared
to single-threaded readers.
However, in most cases it is also necessary to remove data, and this is the
subject of the next section.

\fi

\subsubsection{Wait For Pre-Existing RCU Readers}
\label{sec:defer:Wait For Pre-Existing RCU Readers}

그 가장 기본적인 형태에서, RCU 는 일이 끝나길 기다리는 방법입니다.
물론, 일이 끝나길 기다리기 위한 수많은 다른 방법들이 존재하는데, 레퍼런스
카운팅, reader-writer 락, 디벤트, 등등이 포함됩니다.
RCU 의 큰 장점은 (대충 말하자면) 20,000 개의 다른 것들을 명시적으로 그것들
각자를 추적할 필요 없이, 그리고 명시적 추적 방식에서는 피할 수 없는 성능 하락,
확장성 한계, 복잡한 데드락 시나리오, 그리고 메모리 누수 문제 없이 할 수 있다는
것입니다.

\iffalse

In its most basic form, RCU is a way of waiting for things to finish.
Of course, there are a great many other ways of waiting for things to
finish, including reference counts, reader-writer locks, events, and so on.
The great advantage of RCU is that it can wait for each of
(say) 20,000 different things without having to explicitly
track each and every one of them, and without having to worry about
the performance degradation, scalability limitations, complex deadlock
scenarios, and memory-leak hazards that are inherent in schemes
using explicit tracking.

\fi

RCU 의 경우, 기다려야 하는 것들 각각은 \emph{RCU 읽기 크리티컬 섹션} 이라고
불립니다.
Section~\ref{sec:defer:Toy Implementation} 에서 힌트가 주어진 것처럼, RCU 읽기
크리티컬 섹션은 \co{rcu_read_lock()} 기능으로 시작하고 연관된
\co{rcu_read_unlock()} 기능으로 완료됩니다.
RCU 읽기 크리티컬 섹션은 중첩될 수 있고, quiescent state 를 포함하지
않는다면 얼만큼의 코드든 포함할 수 있는데, 예를 들어 리눅스 커널에서는 컨텍스트
스위치가 하나의 quiescent state 이기 때문에 RCU 읽기 크리티컬 섹션 내에서
잠드는 게 불법입니다.\footnote{
	하지만, SRCU~\cite{PaulEMcKenney2006c} 라 불리는 특수한 형태의 RCU 는
	RCU 읽기 크리티컬 섹션 내에서의 일반적 잠들기를 허용합니다.}
여러분이 이 규칙을 따른다면, 여러분은 앞서서부터 존재해온 RCU 읽기 크리티컬
섹션을 \emph{얼마든지} 완료되길 기다릴 수 있으며, \co{synchronize_rcu()} 의
사용이그런 실제 기다림을 합니다.

\iffalse

In RCU's case, each of the things waited on is called an
\emph{RCU read-side critical section}.
As hinted at in
Section~\ref{sec:defer:Toy Implementation}, an RCU read-side critical
section starts with an \co{rcu_read_lock()} primitive, and ends with a
corresponding \co{rcu_read_unlock()} primitive.
RCU read-side critical sections can be nested, and may contain pretty
much any code, as long as that code does not contain a quiescent state,
for example, within the Linux kernel, it is illegal to sleep within
an RCU read-side critical section because a context switch is a quiescent
state.\footnote{
	However, a special form of RCU called SRCU~\cite{PaulEMcKenney2006c}
	does permit general sleeping in SRCU read-side critical sections.}
If you abide by these conventions, you can use RCU to wait for \emph{any}
pre-existing RCU read-side critical section to complete, and
\co{synchronize_rcu()} uses indirect means to do the actual
waiting~\cite{MathieuDesnoyers2012URCU,McKenney:2013:SDS:2483852.2483867}.

\fi

\begin{figure}[tbp]
\centering
\resizebox{3in}{!}{\includegraphics{defer/RCUGuaranteeFwd}}
\caption{RCU Reader and Later Grace Period}
\label{fig:defer:RCU Reader and Later Grace Period}
\end{figure}

RCU 읽기 크리티컬 섹션과 뒤따르는 RCU grace period 사이의 관계는
Figure~\ref{fig:defer:RCU Reader and Later Grace Period} 에 그려진 것처럼
만약-그렇다면 관계입니다.
어떤 크리티컬 섹션의 어떤 부분이든 주어진 grace period 의 시작을 앞섰다면, RCU
는 그 크리티컬 섹션 전체가 이 grace period 의 끝을 앞설 것을 보장합니다.
이 그림에서, \co{P0()} 의 \co{x} 로의 액세스는 \co{P1()} 의 이 변수로의
액세스를 앞서며, 따라서 이 \co{P1()} 의 \co{synchronize_rcu()} 호출로 만들어진
grace period 역시 앞섭니다.
따라서 \co{P0()} 의 \co{y} 로의 액세스 역시 \co{P1()} 의 액세스를 앞설 것이
보장됩니다.
이 경우, \co{r1} 의 마지막 값이 0이라면, \co{r2} 의 마지막 값은 0일 것이
보장됩니다.

\iffalse

The relationship between an RCU read-side critical section and a later
RCU grace period is an if-then relationship, as illustrated by
Figure~\ref{fig:defer:RCU Reader and Later Grace Period}.
If any portion of a given critical section precedes the beginning of
a given grace period, then RCU guarantees that all of that critical
section will precede the end of that grace period.
In the figure, \co{P0()}'s access to \co{x} precedes \co{P1()}'s access
to this same variable, and thus also precedes the grace period generated
by \co{P1()}'s call to \co{synchronize_rcu()}.
It is therefore guaranteed that \co{P0()}'s access to \co{y} will precede
\co{P1()}'s access.
In this case, if \co{r1}'s final value is 0, then \co{r2}'s final value
is guaranteed to also be 0.

\fi

\QuickQuiz{
	\co{r1} 과 \co{r2} 의 어떤 다른 마지막 값이
	Figure~\ref{fig:defer:RCU Reader and Later Grace Period} 에서
	가능한가요?

	What other final values of \co{r1} and \co{r2} are possible in
	Figure~\ref{fig:defer:RCU Reader and Later Grace Period}?
}\QuickQuizAnswer{
	\co{r1 == 0 && r2 == 0} 가능성이 책에서 이야기 되었습니다.
	\co{r1 == 0} 가 \co{r2 == 0} 를 의미함을 생각하면, \co{r1 == 0 && r2 ==
	1} 은 불가함을 알 수 있습니다.
	뒤이은 부분에선 \co{r1 == 1 && r2 == 1} 과 \co{r1 == 1 && r2 == 0} 가
	가능함을 보이겠습니다.

	\iffalse

	The \co{r1 == 0 && r2 == 0} possibility was called out in the text.
	Given that \co{r1 == 0} implies \co{r2 == 0}, we know that
	\co{r1 == 0 && r2 == 1} is forbidden.
	The following discussion will show that both
	\co{r1 == 1 && r2 == 1} and \co{r1 == 1 && r2 == 0} are possible.

	\fi

}\QuickQuizEnd

\begin{figure}[tbp]
\centering
\resizebox{3in}{!}{\includegraphics{defer/RCUGuaranteeRev}}
\caption{RCU Reader and Earlier Grace Period}
\label{fig:defer:RCU Reader and Earlier Grace Period}
\end{figure}

RCU 읽기 크리티컬 섹션과 그 앞의 RCU grace period 사이의 관계 또한
Figure~\ref{fig:defer:RCU Reader and Earlier Grace Period} 에 그려진 것과 같은
만약-그렇다면 관계입니다.
특정 크리티컬 섹션의 어떤 부분이든 특정 grace period 의 종료를 뒤따른다면, RCU
는 이 크리티컬 섹션 전체가 이 grace period 의 시작을 뒤따를 것을 보장합니다.
이 그림에서, \co{P0} 의 \co{y} 로의 액세스는 \co{P1()} 의 해당 변수로의
액세스를 뒤따르며, 따라서 \co{P1()} 의 \co{synchronize_rcu()} 호출로 생성된
grace period 를 뒤따릅니다.
따라서 \co{P0()} 의 \co{x} 로의 액세스는 \co{P1()} 의 액세스를 뒤따를 것이
보장됩니다.
이 경우, \co{r2} 의 마지막 값이 1이라면, \co{r1} 의 마지막 값은 1이 될 것이
보장됩니다.

\iffalse

The relationship between an RCU read-side critical section and an earlier
RCU grace period is also an if-then relationship, as illustrated by
Figure~\ref{fig:defer:RCU Reader and Earlier Grace Period}.
If any portion of a given critical section follows the end of
a given grace period, then RCU guarantees that all of that critical
section will follow the beginning of that grace period.
In the figure, \co{P0()}'s access to \co{y} follows \co{P1()}'s access
to this same variable, and thus follows the grace period generated by
\co{P1()}'s call to \co{synchronize_rcu()}.
It is therefore guaranteed that \co{P0()}'s access to \co{x} will follow
\co{P1()}'s access.  In this case, if \co{r2}'s final value is 1, then
\co{r1}'s final value is guaranteed to also be 1.

\fi

\QuickQuiz{
	\Cref{fig:defer:RCU Reader and Earlier Grace Period} 에서 \co{P0()} 의
	두 액세스가 반대 순서로 이루어지면 어떻게 될까요?

	\iffalse

	What would happen if the order of \co{P0()}'s two accesses was
	reversed in
	\cref{fig:defer:RCU Reader and Earlier Grace Period}?

	\fi

}\QuickQuizAnswer{
	분명 아무 일도 일어나지 않습니다.
	\co{P0()} 의 \co{x} 와 \co{y} 의 로드가 같은 RCU 읽기 크리티컬 섹션에서
	이루어진다는 것으로 충분합니다;
	그것들 사이의 순서는 관계없습니다.

	\iffalse

	Absolutely nothing would change.
	The fact that \co{P0()}'s loads from \co{x} and \co{y} are
	in the same RCU read-side critical section suffices;
	their order is irrelevant.

	\fi

}\QuickQuizEnd

\begin{figure}[tbp]
\centering
\resizebox{3in}{!}{\includegraphics{defer/RCUGuaranteeMid}}
\caption{RCU Reader Within Grace Period}
\label{fig:defer:RCU Reader Within Grace Period}
\end{figure}

마지막으로,
Figure~\ref{fig:defer:RCU Reader Within Grace Period} 에 보인 것과 같이, RCU
읽기 크리티컬 섹션은 RCU grace period 에 완전히 겹쳐질 수 있습니다.
이 경우, \co{r1} 의 마지막 값은 1 이고 \co{r2} 의 마지막 값은 0일 수 있습니다.

하지만, \co{r1} 의 마지막 값은 0 인데 \co{r2} 의 마지막 값은 1일 수는 없습니다.
이는 RCU 읽기 크리티컬 섹션이 하나의 grace period 를 완전히 겹쳤다는 것인데,
이는 불가능합니다 (또는 최소한 RCU 의 버그를 의미합니다).
RCU 의 읽기 쓰레드 기다리기 보장은 따라서 두개의 부분으로 이루어집니다:
(1)~만약 어떤 RCU 읽기 크리티컬 섹션의 어떤 부분이든 특정 grace period 의
시작을 앞선다면, 이 크리티컬 섹션의 모든 부분이 이 grace period 의 종료를
앞서게 된다.
(2)~만약 어떤 RCU 읽기 크리티컬 섹션의 어떤 부분이든 어떤 grace period 의 끝을
뒤따른다면, 이 크리티컬 섹션의 모든 부분이 이 grace period 의 시작을 뒤따른다.
이 정의는 거의 모든 RCU 기반 알고리즘에 충분합니다만 이보다 더 많은 걸 원하는
분을 위해 RCU 의 수행 가능한 정형적 모델이 리눅스 커널 v4.17 과 그 다음
버전들에서 가능한데, 
Section~\ref{sec:formal:Axiomatic Approaches and RCU} 에서 다뤄집니다.
또한, RCU 의 순서 강제 기능들이 훨씬 자세하게 Section~\ref{sec:memorder:RCU}
에서 다뤄집니다.

\iffalse

Finally, as shown in
Figure~\ref{fig:defer:RCU Reader Within Grace Period},
an RCU read-side critical section can be completely overlapped by
an RCU grace period.
In this case, \co{r1}'s final value is 1 and \co{r2}'s final value is 0.

However, it cannot be the case that \co{r1}'s final value is 0 and \co{r2}'s
final value is 1.
This would mean that an RCU read-side critical section had completely
overlapped a grace period, which is forbidden (or at the very least
constitutes a bug in RCU).
RCU's wait-for-readers guarantee therefore has two parts:
(1)~If any part of a given RCU read-side critical section precedes
the beginning of a given grace period, then the entirety of that
critical section precedes the end of that grace period.
(2)~If any part of a given RCU read-side critical section follows
the end of a given grace period, then the entirety of that
critical section follows the beginning of that grace period.
This definition is sufficient for almost all RCU-based algorithms, but
for those wanting more,
simple executable formal models of RCU are available
as part of Linux kernel v4.17 and later, as discussed in
Section~\ref{sec:formal:Axiomatic Approaches and RCU}.
In addition, RCU's ordering properties are examined in much
greater detail in Section~\ref{sec:memorder:RCU}.

\fi

\QuickQuiz{
	\Crefrange{fig:defer:RCU Reader and Later Grace Period}{fig:defer:RCU Reader Within Grace Period}
	의 \co{P0()} 의 액세스들이 스토어였다면 무슨 일이 일어날까요?

	\iffalse

	What would happen if \co{P0()}'s accesses in
	\crefrange{fig:defer:RCU Reader and Later Grace Period}{fig:defer:RCU Reader Within Grace Period}
	were stores?

	\fi

}\QuickQuizAnswer{
	정확히 동일한 순서 규칙이 적용되는데, 즉, (1)~만약 \co{P0()} 의 RCU
	읽기 크리티컬 섹션이 \co{P1()} 의 grace priod 의 시작을 앞섰다면,
	\co{P0()} 의 RCU 읽기 크리티컬 섹션의 모든 부분이 \co{P1()} 의 grace
	period 의 끝을 앞서게 되며, (2)~만약 \co{P0()} 의 RCU 읽기 크리티컬
	섹션의 어떤 부분이 \co{P1()} 의 grace period 의 종료를 뒤따랐다면,
	\co{P0()} 의 RCU 읽기 크리티컬 섹션의 모든 부분이 \co{P1()} 의 grace
	period 의 시작을 뒤따릅니다.

	쓰기를 포함하는 RCU 읽기 크리티컬 섹션은 좀 이상해 보일수도 있겠지만,
	RCU 는 그래도 괜찮습니다.
	이 능력은 리눅스 커널에서 빈번하게 사용되는데, 예를 들면 데이터
	구조로의 레퍼런스나 락을 잡기 위해서입니다.
	락이나 레퍼런스를 획득하는것은 메모리로의 어떤 쓰기를 초래하며, 이걸
	RCU 읽기 크리티컬 섹션 내에서 해도 됩니다.

	RCU 읽기 크리티컬 섹션이 쓰기를 갖는 것이 여전히 이상해 보인다면,
	reader-writer 락킹의 읽기 크리티컬 섹션에서의 쓰기 사용 경우를 선보인
	\cref{sec:count:Applying Exact Limit Counters}
	를 다시 읽어보시기 바랍니다.

	\iffalse

	The exact same ordering rules would apply, that is,
	(1)~If any part of \co{P0()}'s RCU read-side critical section
	preceded the beginning of \co{P1()}'s grace period, all of
	\co{P0()}'s RCU read-side critical section would precede the
	end of \co{P1()}'s grace period, and
	(2)~If any part of \co{P0()}'s RCU read-side critical section
	followed the end of \co{P1()}'s grace period, all of \co{P0()}'s
	RCU read-side critical section would follow the beginning of
	\co{P1()}'s grace period.

	It might seem strange to have RCU read-side critical sections
	containing writes, but RCU is just fine with this.
	This capability is used frequently in the Linux kernel, for
	example, acquiring a lock on or reference to a data structure.
	Acquiring either a lock or a reference results in a write
	to memory, and it is OK to do these within an RCU read-side
	critical section.

	If having writes in RCU read-side critical sections still seems
	strange, please review
	\cref{sec:count:Applying Exact Limit Counters},
	which presented a use case for writes in reader-writer locking
	read-side critical sections.

	\fi

}\QuickQuizEnd

RCU 의 읽기 쓰레드 기다리기 능력이
\crefrange{fig:defer:RCU Reader and Later Grace Period}
{fig:defer:RCU Reader Within Grace Period}
에 보인 것처럼 변수에 값 할당을 하기 위해 정말로 사용된다고 해도,
Section~\ref{sec:defer:Introduction to RCU} 에서 보인 것처럼 연결된
구조체들에서 제거된 데이터 항목을 안전하게 메모리 해제하기 위해 더 빈번히
사용됩니다.
일반적인 프로세스는 다음의 수도코드로 그려집니다:

\begin{enumerate}
\item	변경을 가하는데, 예를 들면 링크드 리스트에서 원소를 제거합니다.
\item	모든 앞서서부터 존재해온 RCU 읽기 크리티컬 섹션이 완료되기를 기다립니다
	(예를 들면, \co{synchronize_rcu()} 를 통해서).
\item	정리를 하는데, 예를 들면 앞서서 교체된 원소를 메모리 해제합니다.
\end{enumerate}

\iffalse

Although RCU's wait-for-readers capability really is sometimes used to
order the assignment of values to variables as shown in
\crefrange{fig:defer:RCU Reader and Later Grace Period}
{fig:defer:RCU Reader Within Grace Period},
it is more frequently used to safely free data elements removed from
a linked structure, as was done in
Section~\ref{sec:defer:Introduction to RCU}.
The general process is illustrated by the following pseudocode:

\begin{enumerate}
\item	Make a change, for example, remove an element from a linked list.
\item	Wait for all pre-existing RCU read-side critical sections to
	completely finish (for example, by using
	\co{synchronize_rcu()}).
\item	Clean up, for example, free the element that was replaced above.
\end{enumerate}

\fi

\begin{figure}[tbp]
\centering
\resizebox{2.5in}{!}{\includegraphics{defer/RCUGPorderingSummary}}
\caption{Summary of RCU Grace-Period Ordering Guarantees}
\label{fig:defer:Summary of RCU Grace-Period Ordering Guarantees}
\end{figure}

이 더욱 추상화 된 절차는
\crefrange{fig:defer:RCU Reader and Later Grace Period}
{fig:defer:RCU Reader Within Grace Period} 보다 더욱 추상화 된 다이어그램을
필요로 하는데, 특정 리트머스 테스트가 됩니다.
어쨌건, RCU 구현은 RCU 업데이트와 RCU 읽기 크리티컬 섹션의 형태와 무관하게
정확히 동작해야만 합니다.
Figure~\ref{fig:defer:Summary of RCU Grace-Period Ordering Guarantees}
가 네개의 가능한 시나리오를 시간이 위에서 아래로 흐르는 형태로 보이며 이 필요를
충족합니다.
각 시나리오에서, RCU 읽기 쓰레드는 왼쪽의 박스 더미로 표현되며 RCU 업데이트
쓰레드는 오른쪽 더비로 표현됩니다.

\iffalse

This more abstract procedure requires a more abstract diagram than
\crefrange{fig:defer:RCU Reader and Later Grace Period}
{fig:defer:RCU Reader Within Grace Period},
which are specific to a particular litmus test.
After all, and RCU implementation must work correctly regardless of
the form of the RCU updates and the RCU read-side critical sections.
Figure~\ref{fig:defer:Summary of RCU Grace-Period Ordering Guarantees}
fills this need, showing the four possible scenarios, with time
advancing from top to bottom within each scenario.
Within each scenario, an RCU reader is represented by the left-hand
stack of boxes and RCU updater by the right-hand stack.

\fi

첫번째 시나리오에서 읽기 쓰레드는 업데이트 쓰레드가 삭제를 시작하기 전에 수행을
시작하며, 따라서 이 읽기 쓰레드가 제거된 데이터 원소로의 레퍼런스를 가질 수
있습니다.
따라서, 이 업데이트 쓰레드는 이 원소를 이 읽기 쓰레드가 완료되기 전까지 메모리
해제하지 않아야 합니다.
두번째 시나리오에서 읽기 쓰레드는 이 제거가 완료되기 전까지 시작하지 않습니다.
이 읽기 쓰레드는 이미 제거된 데이터 원소로의 레퍼런스를 얻을 수 없으며, 따라서
이 원소는 이 읽기 쓰레드가 완료되기 전에 메모리 해제되어도 됩니다.
세번째 시나리오는 두번째와 같지만 언제 이 읽기 쓰레드가 이 원소로의 레퍼런스를
얻을 수 없는지, 여전이 이 읽기 쓰레드가 완료될 때까지 이 원소의 메모리 해제를
미뤄도 괜찮은지 보입니다.
네번째 마지막 시나리오에서는 이 읽기 쓰레드가 업데이트 쓰레드가 이 데이터
원소를 제거하기 전에 시작하지만 이 원소는 이 읽기 쓰레드가 완료되기 전에
(올바르지 못하게) 메모리 해제됩니다.
이 다이어그램은 따라서 RCU 의 읽기 쓰레드 기다리기 기능을 그립니다:
grace period 가 주어졌을 때, 각 읽기 쓰레드는 이 grace period 의 종료 전에
종료되며, 이 grace period 의 시작 후에 시작되거나 둘 다인데 이 grace period
내에 전체 크리티컬 섹션이 포함되는 경우입니다.

\iffalse

In the first scenario, the reader starts execution before the
updater starts the removal, so it is possible that this reader
has a reference to the removed data element.
Therefore, the updater must not free this element until after the
reader completes.
In the second scenario, the reader does not start execution until
after the removal has completed.
The reader cannot possibly obtain a reference to the already-removed
data element, so this element may be freed before the reader completes.
The third scenario is like the second, but illustrates that when the
reader cannot possibly obtain a reference to element, it is still
permissible to defer the freeing of that element until after the
reader completes.
In the fourth and final scenario, the reader starts execution before
the updater starts removing the data element, but this element
is (incorrectly) freed before the reader completed.
A correct RCU implementation will not allow this fourth scenario to
occur.
This diagram thus illustrates RCU's wait-for-readers functionality:
Given a grace period, each reader ends before the end of that grace
period, starts after the beginning of that grace period, or both, in
which case it is wholly contained within that grace period.

\fi

RCU 읽기 쓰레드는 업데이트가 진행중인 동안에도 진행을 할 수 있으므로, 다른 읽기
쓰레드는 이 데이터 구조의 상태에 대해 다른 해석을 할 수 있는데, 다음 섹션에서
이 주제를 다룹니다.

\iffalse

Because RCU readers can make forward progress while updates
are in progress, different readers might disagree about the state
of the data structure, a topic taken up by the next section.

\fi

\subsubsection{Maintain Multiple Versions of Recently Updated Objects}
\label{sec:defer:Maintain Multiple Versions of Recently Updated Objects}

이 섹션은 RCU 가 여러 버전의 데이터를 관리함으로써 어떻게 동기화로부터 자유로운
읽기 쓰레드를 수용하는지 이야기 합니다.
이 이야기는 \co{del_route()} 와 동시에 수행되는 읽기 쓰레드들이
(Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers} 을
참고하세요) 오래된 \co{route} 구조체 또는 빈 리스트를 볼 수도 있지만 어느 쪽이든
유효한 결과를 얻게 되는,
Section~\ref{sec:defer:Minimal Insertion and Deletion} 의
Figure~\ref{fig:defer:Deletion With Concurrent Readers} 에 의한 복수 버전의
소개로부터 시작합니다.
물론,
Figure~\ref{fig:defer:Insertion With Concurrent Readers}
를 자세히 보면 \co{ins_route()} 호출은 역시 동시의 읽기 쓰레드들이 다른
버전들을 보게 할 수 있음을 알 수 있습니다: 초기의 빈 리스트 또는 새로이 삽입된
\co{route} 구조체.
레퍼런스 카운팅
(Section~\ref{sec:defer:Reference Counting})
과 해저드 포인터
(Section~\ref{sec:defer:Hazard Pointers})
둘 다 동시의 읽기 쓰레드들이 다른 버전을 보게 할 수 있지만, RCU 의 가벼운 읽기
쓰레드는 이를 더욱 그럴 수 있게 합니다.

\iffalse

This section discusses how RCU accommodates synchronization-free readers
by maintaining multiple versions of data.
This discussion builds on the introduction of multiple versions by
Figure~\ref{fig:defer:Deletion With Concurrent Readers}
in
Section~\ref{sec:defer:Minimal Insertion and Deletion},
in which readers running concurrently with \co{del_route()}
(see Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers})
might see the old \co{route} structure or an empty list, but either
way get a valid result.
Of course, a closer look at
Figure~\ref{fig:defer:Insertion With Concurrent Readers}
shows that calls to \co{ins_route()} can also result in concurrent
readers seeing different versions: Either the initial empty list
or the newly inserted \co{route} structure.
Note that both reference counting
(Section~\ref{sec:defer:Reference Counting})
and hazard pointers
(Section~\ref{sec:defer:Hazard Pointers})
can also cause concurrent readers to see different versions, but
RCU's lightweight readers make this more likely.

\fi

\begin{figure}[tbp]
\centering
\resizebox{3in}{!}{\includegraphics{defer/multver}}
\caption{Multiple RCU Data-Structure Versions}
\label{fig:defer:Multiple RCU Data-Structure Versions}
\end{figure}

하지만, 복수의 버전을 유지하는 것은 더욱 놀라울 수 있습니다.
예를 들어,
읽기 쓰레드가 동시에 업데이트 되는 링크드 리스트를 순회하는 읽기 쓰레드가 있는
Figure~\ref{fig:defer:Multiple RCU Data-Structure Versions} 를 생각해
봅시다.\footnote{
	RCU 링크드 리스트 API 는
	Section~\ref{sec:defer:RCU Linux-Kernel API} 에서 찾을 수 있습니다.}
이 그림의 첫번째 열에서, 읽기 쓰레드는 데이터 아이템~A 를 참조하고, 두번째
줄에서는 B 로 넘어가서, 지금까지 B 가 뒤따르는 A 를 봤습니다.
세번째 줄에서는, 업데이트 쓰레드가 원소~A 를 제거하고 네번째 줄에서 업데이트
쓰레드가 이 리스트의 끝에 원소~E 를 추가합니다.
마지막 다섯번째 줄에서는 읽기 쓰레드가 순회를 완료해서 원소~A 부터~E 까지를
모두 봤습니다.

그런 리스트가 존재한 적은 없었다는 제외하면 말입니다.
이 상황은 다른 동시의 읽기 쓰레드가 다른 버전들을 보게 되는
Figure~\ref{fig:defer:Deletion With Concurrent Readers} 에 보인 상황보다도 더
놀라울 수도 있습니다.
대조적으로,
Figure~\ref{fig:defer:Multiple RCU Data-Structure Versions}
에서 읽기 쓰레드는 실제로는 존재한 적이 없는 버전을 보는 것입니다!

\iffalse

However, maintaining multiple versions can be even more surprising.
For example, consider
Figure~\ref{fig:defer:Multiple RCU Data-Structure Versions},
in which a reader is traversing a linked list that is concurrently
updated.\footnote{
	RCU linked-list APIs may be found in
	Section~\ref{sec:defer:RCU Linux-Kernel API}.}
In the first row of the figure, the reader is referencing data item~A,
and in the second row, it advances to~B, having thus far seen A followed by~B\@.
In the third row, an updater removes element~A and in the fourth row
an updater adds element~E to the end of the list.
In the fifth and final row, the reader completes its traversal, having
seeing elements~A through~E\@.

Except that there was no time at which such a list existed.
This situation might be even more surprising than that shown in
Figure~\ref{fig:defer:Deletion With Concurrent Readers},
in which different concurrent readers see different versions.
In contrast, in
Figure~\ref{fig:defer:Multiple RCU Data-Structure Versions}
the reader sees a version that never actually existed!

\fi

이 이상한 상황을 해결하는 한가지 방법은 완화된 의미론을 사용하는 것입니다.
읽기 쓰레드의 순회는 전체 순회 동안 존재한 모든 데이터 항목을 만날 수 있어야
하며 (B, C, 그리고~D), 그 순회의 한 부분 동안에만 존재한 데이터 항목은 볼수도
못볼수도 있습니다.
따라서, 이 특정 경우에는, 읽기 쓰레드의 순회가 이 모든 다섯개 원소를 만나는 게
완전히 합법적입니다.
이 결과가 문제시 되다면, 이 상황을 해결하는 또다른 방법은 더 강력한 동기화
메커니즘, 예를 들면 reader-writer 락킹이나 타임스탬프 또는 버저닝의 영리한
사용을 사용하는 것입니다.
물론, 더 강력한 메커니즘은 더 비용이 높을 것이지만, 그러면 또다시 이야기 하지만
엔지니어링 삶은 모두 선택과 트레이드오프에 대한 것입니다.

\iffalse

One way to resolve this strange situation is via weaker semanitics.
A reader traversal must encounter any data item that was present
during the full traversal (B, C, and~D), and might or might not
encounter data items that were present for only part of the
traversal (A and~E).
Therefore, in this particular case, it is perfectly legitimate for
the reader traveral to encounter all five elements.
If this outcome is problematic, another way to resolve this situation is
through use of stronger synchronization mechanisms, such as reader-writer
locking or clever use of timestamps or versioning.
Of course, stronger mechanisms will be more expensive, but then again
the engineering life is all about choices and tradeoffs.

\fi

이 상황은 이상하게 보일 수도 있겠으나, 이는 실제 세계와 완전하게 일관적입니다.
Section~\ref{sec:cpu:Overheads} 에서 보았듯이, 빛의 유한한 속도는 컴퓨터
시스템에서도 무시될 수 없으며, 이 시스템 바깥에서도 무시될 수 없는 것이 거의
분명합니다.
이는 결국 시스템 바깥의 실제 세계의 상태를 나타내는 시스템의 모든 데이터는 항상
그리고 영원히 시간이 지나있을 것이며, 따라서 실제 세계와는 비일관적일 것임을
의미합니다.
그 결과, 실제 세계 데이터를 다루는 알고리즘은 비일관된 데이터를 처리해야만
합니다.
많은 경우, 이런 알고리즘은 시스템 내부의 비일관성을 처리하는 데에도 완전히
기능할 것입니다.

\iffalse

Strange though this situation might seem, it is entirely consistent with
the real world.
As we saw in
Section~\ref{sec:cpu:Overheads},
the finite speed of light cannot be ignored within a computer system,
and it most certainly cannot be ignored outside of this system.
This in turn means that any data within the system representing state
in the real world outside of the system is always and forever outdated,
and thus inconsistent with the real world.
As a result, algorithms operating on real-world data must account for
inconsistent data.
In many cases, these algorithms are also perfectly capable of dealing
with inconsistencies within the system.

\fi

Section~\ref{sec:defer:Running Example}
에서 이야기 된 pre-BSD 패킷 라우팅 예가 그런 경우입니다.
라우팅 리스트의 내용물은 라우팅 프로토콜에 의해 설정되며, 이 프로토콜은 라우팅
비안정성을 막기 위해 상당한 지연을 (몇초 또는 심지어 몇분) 일으킵니다.
따라서, 일단 라우팅 업데이트가 특정 시스템에 일단 가해지면, 패킷들을 한동안은
잘못된 길로 보낼 수 있습니다.
이 업데이트가 진행되는 중의 몇 마이크로세컨드 동안 패킷 몇개를 더 잘못된 길로
보내는 것은 지연된 라우팅 업데이트를 처리하는 더 높은 단계의 똑같은 프로토콜
동작이 내부의 비일관성도 처리할 것이기 때문에 분명 문제가 안됩니다.

\iffalse

The pre-BSD packet routing example laid out in
Section~\ref{sec:defer:Running Example}
is a case in point.
The contents of a routing list is set by routing protocols, and these
protocols feature significant delays (seconds or even minutes) to avoid
routing instabilities.
Therefore, once a routing update reaches a given system,
it might well have been sending packets the wrong way for quite some time.
Sending a few more packets the wrong way for the few microseconds during
which the update is in flight is clearly not a problem because the same
higher-level protocol actions that deal with delayed routing updates
will also deal with internal inconsistencies.

\fi

비일관성을 감내해야 하는 것은 인터넷 라우팅만의 상황이 아닙니다.
반복하지만, 시스템 바깥의 상태를 추적하는 시스템 내의 데이터를 처리하는 모든
알고리즘은 비일관성을 감내해야 하는데, 보안 정책 (종종 사람으로 구성된 위원회에
의해 설정됩니다), 저장장치 구성, WiFi 액세스 포인트, 마이크로폰, 헤드셋,
카메라, 마우스, 프린터를 포함한 제거될 수 있는 하드웨어, 그 외에도 수많은
것들이 포함됩니다.
더욱이,
Figure~\ref{fig:defer:RCU Usage in the Linux Kernel} 에 보인 많은 수의 리눅스
커널 RCU API 사용은 리눅스 커널의 레퍼런스 카운팅의 많은 사용과 다른
프로젝트에서의 증가되는 해저드 포인터 사용과 엮여서 그런 비일관성에 대한 감내는
누군가가 상상할 수 있는 것보다 훨씬 더 일반적임을 보입니다.
이는 특히 단일 항목 탐색이 순회보다 훨씬 더 흔하다는 것을 놓고 보면 그렇습니다:
어쨌건, (1)~동시의 업데이트는 전체 순회보다는 단일 항목 탐색에 영향을 덜 끼칠
것입니다, 그리고 (2)~고립된 단일 항목 탐색은 그런 비일관성을 알아낼 수
없습니다.

\iffalse

Nor is Internet routing the only situation tolerating inconsistencies.
To repeat, any algorithm in which data within a system tracks
outside-of-system state must tolerate inconsistencies, which includes
security policies (often set by committees of humans), storage configuration,
and WiFi access points, to say nothing of removable hardware such as
microphones, headsets, cameras, mice, printers, and much else besides.
Furthermore, the large number of Linux-kernel RCU API uses shown in
Figure~\ref{fig:defer:RCU Usage in the Linux Kernel},
combined with the Linux kernel's heavy use of reference counting
and with increasing use of hazard pointers in other projects, demonstrates
that tolerance for such inconsistencies is more common than one might
imagine.
This is especially the case given that single-item lookups are much more
common than traversals:  After all, (1)~concurrent updates are less likely
to affect a single-item lookup than they are a full traversal, and
(2)~an isolated single-item lookup cannot detect such inconsistencies.

\fi

더 이론적인 시점에서 보면, RCU 읽기 쓰레드가 싱글 쓰레드 기반 프로그램에서
수행될 것과 정확히 동일한 기계 명령들을 수행함에도 불구하고 업데이트 쓰레드들과
완전하게 순서가 지어진 것으로 여겨지는 일부 특수한 경우도 존재합니다.
예를 들어,
페이지~\pageref{lst:defer:Insertion and Deletion With Concurrent Readers} 의
Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers} 으로
돌아가, 각 읽기 쓰레드가 평생 정확히 한번 \co{access_route()} 를 수행하며, 그
외에는 읽기 쓰레드와 업데이트 쓰레드 사이에 어떤 소통도 없다고 해봅시다.
\begin{fcvref}[ln:defer:Insertion and Deletion With Concurrent Readers]
그러면 \co{access_route()} 의 호출 각각은 이 코드 리스트의 \co{access_route()}
의 \clnref{access_rp} 에서 액세스 되는 \co{route} 구조체를 만들어낸
\co{ins_route()} 호출 뒤로 순서지어지고 모든 뒤따르는 \co{ins_route()} 나
\co{del_route()} 호출의 앞으로 순서지어질 수 있습니다.
\end{fcvref}

\iffalse

From a more theoretical viewpoint, there are even some special cases where
RCU readers can be considered to be fully ordered with updaters, despite
the fact that these readers might be executing the exact same sequence of
machine instructions that would be executed by a single-threaded program.
For example, referring back to
Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}
on page~\pageref{lst:defer:Insertion and Deletion With Concurrent Readers},
suppose that each reader thread invokes \co{access_route()} exactly
once during its lifetime, and that there is no other communication among
reader and updater threads.
\begin{fcvref}[ln:defer:Insertion and Deletion With Concurrent Readers]
Then each invocation of \co{access_route()} can be ordered after the
\co{ins_route()} invocation that produced the \co{route} structure
accessed by \clnref{access_rp} of the listing in \co{access_route()}
and ordered before any subsequent
\co{ins_route()} or \co{del_route()} invocation.
\end{fcvref}

\fi

요약하자면, 복수의 버전을 유지하는 것이 바로 RCU 읽기 쓰레드의 극단적으로 낮은
오버헤드를 가능하게 하는 것이며, 앞에서 이야기 되었듯 많은 알고리즘은 복수의
버전들로 인해 당황하지 않습니다.
하지만, 복수의 버전을 처리할 수 없는 알고리즘도 분명 존재합니다.
그런 알고리즘이 RCU 를 사용할 수 있게 조정하는 기술들도
존재합니다만~\cite{PaulEdwardMcKenneyPhD}, 이는 이 섹션의 범위 밖입니다.

\iffalse

In summary, maintaining multiple versions is exactly what enables the
extremely low overheads of RCU readers, and as noted earlier, many
algorithms are unfazed by multiple versions.
However, there are algorithms that absolutely cannot handle multiple versions.
There are techniques for adapting such algorithms to
RCU~\cite{PaulEdwardMcKenneyPhD},
but these are beyond the scope of this section.

\fi

\paragraph{Exercises}
\label{sec:defer:Exercises}

These examples assumed that a mutex was held across the entire
update operation, which would mean that there could be at most two
versions of the list active at a given time.

\QuickQuizSeries{%
\QuickQuizB{
	How would you modify the deletion example to permit more than two
	versions of the list to be active?
}\QuickQuizAnswerB{
	One way of accomplishing this is as shown in
	Listing~\ref{lst:defer:Concurrent RCU Deletion}.

\begin{listing}[htbp]
\begin{VerbatimL}
spin_lock(&mylock);
p = search(head, key);
if (p == NULL)
	spin_unlock(&mylock);
else {
	list_del_rcu(&p->list);
	spin_unlock(&mylock);
	synchronize_rcu();
	kfree(p);
}
\end{VerbatimL}
\caption{Concurrent RCU Deletion}
\label{lst:defer:Concurrent RCU Deletion}
\end{listing}

	Note that this means that multiple concurrent deletions might be
	waiting in \co{synchronize_rcu()}.
}\QuickQuizEndB
%
\QuickQuizE{
	How many RCU versions of a given list can be
	active at any given time?
}\QuickQuizAnswerE{
	That depends on the synchronization design.
	If a semaphore protecting the update is held across the grace period,
	then there can be at most two versions, the old and the new.

	However, suppose that only the search, the update, and the
	\co{list_replace_rcu()} were protected by a lock, so that
	the \co{synchronize_rcu()} was outside of that lock, similar
	to the code shown in
	Listing~\ref{lst:defer:Concurrent RCU Deletion}.
	Suppose further that a large number of threads undertook an
	RCU replacement at about the same time, and that readers
	are also constantly traversing the data structure.

	Then the following sequence of events could occur, starting from
	the end state of
	Figure~\ref{fig:defer:Multiple RCU Data-Structure Versions}:

	\begin{enumerate}
	\item	Thread~A traverses the list, obtaining a reference to
		Element~C.
	\item	Thread~B replaces Element~C with a new
		Element~F, then waits for its \co{synchronize_rcu()}
		call to return.
	\item	Thread~C traverses the list, obtaining a reference to
		Element~F.
	\item	Thread~D replaces Element~F with a new
		Element~G, then waits for its \co{synchronize_rcu()}
		call to return.
	\item	Thread~E traverses the list, obtaining a reference to
		Element~G.
	\item	Thread~F replaces Element~G with a new
		Element~H, then waits for its \co{synchronize_rcu()}
		call to return.
	\item	Thread~G traverses the list, obtaining a reference to
		Element~H.
	\item	And the previous two steps repeat quickly with additional
		new elements, so that all of them happen before any of
		the \co{synchronize_rcu()} calls return.
	\end{enumerate}

	Thus, there can be an arbitrary number of versions active,
	limited only by memory and by how many updates could be completed
	within a grace period.
	But please note that data structures that are updated so frequently
	are not likely to be good candidates for RCU\@.
	Nevertheless, RCU can handle high update rates when necessary.
}\QuickQuizEndE
}

\subsubsection{Summary of RCU Fundamentals}
\label{sec:defer:Summary of RCU Fundamentals}

This section has described the three fundamental components of RCU-based
algorithms:

\begin{enumerate}
\item	a publish-subscribe mechanism for adding new data,

\item	a way of waiting for pre-existing RCU readers to finish
	(see Section~\ref{sec:memorder:RCU} for more detail),
	and

\item	a discipline of maintaining multiple versions to permit
	change without harming or unduly delaying concurrent RCU readers.
\end{enumerate}

\QuickQuiz{
	How can RCU updaters possibly delay RCU readers, given that
	neither \co{rcu_read_lock()} nor \co{rcu_read_unlock()}
	spin or block?
}\QuickQuizAnswer{
	The modifications undertaken by a given RCU updater will cause the
	corresponding CPU to invalidate cache lines containing the data,
	forcing the CPUs running concurrent RCU readers to incur expensive
	cache misses.
	(Can you design an algorithm that changes a data structure
	\emph{without}
	inflicting expensive cache misses on concurrent readers?
	On subsequent readers?)
}\QuickQuizEnd

These three RCU components allow data to be updated in face of concurrent
readers that might be executing the same sequence of machine instructions
that would be used by a reader in a single-threaded implementation.
These RCU components can be combined in different ways to implement a
surprising variety of different types of RCU-based algorithms.
However, it is usually better to work at higher levels of abstraction.
To this end, the next section describes the Linux-kernel API, which
includes simple data structures such as lists.
