% defer/rcuintro.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\subsection{Introduction to RCU}
\label{sec:defer:Introduction to RCU}

앞의 섹션들에서 이야기된 접근법들은 좋은 확장성을 제공하지만 분명 Pre-BSD
라우팅 테이블에 이상적이진 않은 성능을 제공했습니다.
따라서, ``오직 너무 멀리 가본 사람만이 자기가 얼마나 멀리 갈 수 있는지 안다''
정신에 입각해,\footnote{
	T.~S.~Eliot 에게 사과드립니다.}
동시의 업데이트의 존재에도 불구하고 동시의 읽기 쓰레드들이 싱글 쓰레드
탐색에서와 동일한 어셈블리 언어 인스트럭션들을 수행하는 알고리즘을 통해 더 멀리
가보겠습니다.
물론, 이 칭찬할 만한 목표는 심각한 구현 가능성 질문을 불러일으킬 수
있겠습니다만, 시도도 하지 않으면 성공할 수도 없습니다!

\iffalse

The approaches discussed in the preceding sections have provided
good scalability but decidedly non-ideal performance for the
Pre-BSD routing table.
Therefore, in the spirit of ``only those who have gone too far
know how far you can go'',\footnote{
	With apologies to T.~S.~Eliot.}
we will go all the way, looking into algorithms in which concurrent
readers execute the same sequence of assembly language instructions as
would a single-threaded lookup, despite the presence of concurrent
updates.
Of course, this laudable goal might raise serious implementability
questions, but we cannot possibly succeed if we don't even try!

\fi

\subsubsection{Minimal Insertion and Deletion}
\label{sec:defer:Minimal Insertion and Deletion}

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{defer/RCUListInsertClassic}}
\caption{Insertion With Concurrent Readers}
\label{fig:defer:Insertion With Concurrent Readers}
\end{figure}

구현이 가능하긴 한지에 대한 걱정을 최소화 하기 위해, \co{NULL} 이거나 하나의
구조체로의 참조일 하나의 글로벌 포인터로 존재하는 최소한의 데이터 구조에 집중해
봅니다.
이 데이터 구조는 최소한의 것이긴 하지만, 제품 단계에서 상당히 많이 사용되는
것이기도 합니다~\cite{GeoffRomer2018C++DeferredReclamationP0561R4}.
삽입을 위한 고전적 방법이
Figure~\ref{fig:defer:Insertion With Concurrent Readers}
에 보여져 있는데, 위에서 아래로 시간이 흐름에 따라 달라지는 네개의 상태를
보입니다.
첫번째 열은 최초의 상태를 보이는데, \co{gptr} 이 \co{NULL} 입니다.
두번째 열에서, 우리는 물음표로 보여지듯 초기화 되지 않은 이 구조체를
할당합니다.
세번째 열에서, 우린 이 구조체를 초기화 합니다.
마지막으로, 네번째 열에서 우린 \co{gptr} 을 이 새로 할당되고 초기화 된 원소를
참조하도록 업데이트 합니다.

\iffalse

To minimize implementability concerns, we focus on a minimal
data structure, which consists of a single global pointer that is either
\co{NULL} or references a single structure.
Minimal though it might be, this data structure is heavily used in
production~\cite{GeoffRomer2018C++DeferredReclamationP0561R4}.
A classic approach for insertion is shown in
Figure~\ref{fig:defer:Insertion With Concurrent Readers},
which shows four states with time advancing from top to bottom.
The first row shows the initial state, with \co{gptr} equal to \co{NULL}.
In the second row, we have allocated a structure which is uninitialized,
as indicated by the question marks.
In the third row, we have initialized the structure.
Finally, in the fourth and final row, we have updated \co{gptr} to
reference the newly allocated and initialized element.

\fi

우린 이 \co{gptr} 로의 값 할당이 간단한 C-언어의 할당문을 사용할 수 있길 바랄
겁니다.
불행히도,
Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}
이 이 바람을 가로막습니다.
따라서, 업데이트 쓰레드는 간단한 C-언어 할당문 대신 이 그림에 보여진 것처럼
\co{smp_store_release()} 또는 뒤에서 보이겠지만 \co{rcu_assign_pointer()} 를
사용해야 합니다.

비슷하게, 어떤 사람들은 읽기 쓰레드가 \co{gptr} 의 값을 얻어오기 위해 하나의
C-언어 할당문을 사용할 수 있기를, 그리고 과거의 값인 \co{NULL} 이나 새로이
설치된 포인터를 읽어와 어떤 경우든 유효한 값을 읽올 것이 보장되기를 바랄
겁니다.
불행히도,
Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}
은 이 바람 역시 가로막습니다.
이 보장을 얻기 위해선, 읽기 쓰레드는 그 대신 \co{READ_ONCE()}, 또는, 뒤에서
보이겠지만 \co{rcu_dereference()} 를 사용해야 합니다.
하지만, 대부분의 현대 컴퓨터 시스템에서, 이 읽기 쪽 기능들은 싱글 쓰레드 기반
코드에서 일반적으로 사용될 것과 동일한 하나의 로드 인스트럭션으로 구현될 수
있습니다.

\iffalse

We might hope that this assignment to \co{gptr} could use a simple
C-language assignment statement.
Unfortunately,
Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}
dashes these hopes.
Therefore, the updater cannot use a simple C-language assignment, but
must instead use \co{smp_store_release()} as shown in the figure,
or, as will be seen, \co{rcu_assign_pointer()}.

Similarly, one might hope that readers could use a single C-language
assignment to fetch the value of \co{gptr}, and be guaranteed to either
get the old value of \co{NULL} or to get the newly installed pointer,
but either way see a valid result.
Unfortunately, Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}
dashes these hopes as well.
To obtain this guarantee, readers must instead use \co{READ_ONCE()},
or, as will be seen, \co{rcu_dereference()}.
However, on most modern computer systems, each of these read-side primitives
can be implemented with a single load instruction, exactly the instruction
that would normally be used in single-threaded code.

\fi

\Cref{fig:defer:Insertion With Concurrent Readers}
를 읽기 쓰레드의 시점에서 다시 보면, 앞의 세개 상태에서 모든 읽기 쓰레드는
\co{gptr} 을 \co{NULL} 값을 갖는 것으로 봅니다.
네번째 상태에 진입하면서, 일부 읽기 쓰레드는 \co{gptr} 이 여전히 \co{NULL} 값을
갖는다고 볼 수 있는 반면 다른 쓰레드들은 새로 설치된 원소를 참조하고 있는
것으로 볼 수 있지만, 어떤 시점 이후로는 모든 읽기 쓰레드가 이 새 원소를 보게 될
겁니다.
항상, 모든 읽기 쓰레드는 \co{gptr} 을 유효한 포인터를 담고 있다고 볼 겁니다.
따라서, 동시의 읽기 쓰레드들이 싱글 쓰레드 기반 코드에서 일반적으로 사용할 것과
동일한 기계 인스트럭션들을 수행하면서 새로운 데이터를 연결된 데이터 구조에
추가하는 것이 정말 가능합니다.
이 동시 읽기에의 비용이 없는 방법은 훌륭한 성능과 확장성을 제공하며, 리얼타임
사용처에서 뛰어나게 잘 사용될 수 있습니다.

\iffalse

Reviewing \cref{fig:defer:Insertion With Concurrent Readers}
from the viewpoint of readers, in the first three states all readers
see \co{gptr} having the value \co{NULL}.
Upon entering the fourth state, some readers might see \co{gptr} still
having the value \co{NULL} while others might see it referencing the
newly inserted element, but after some time, all readers will see this
new element.
At all times, all readers will see \co{gptr} as containing a valid pointer.
Therefore, it really is possible to add new data to linked data structures
while allowing concurrent readers to execute the same sequence of machine
instructions that is normally used in single-threaded code.
This no-cost approach to concurrent reading provides excellent performance
and scalability, and also is eminently suitable for real-time use.

\fi

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{defer/RCUListDeleteClassic}}
\caption{Deletion With Concurrent Readers}
\label{fig:defer:Deletion With Concurrent Readers}
\end{figure}

삽입은 물론 상당히 유용합니다만, 금방이든 더 나중이든, 데이터를 지워야 하기도
할 겁니다.
Figure~\ref{fig:defer:Deletion With Concurrent Readers}
에 보이듯, 첫번째 단계는 쉽습니다.
Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}
에서의 교훈을 다시 상기해 보면, \co{smp_store_release()} 가 이 포인터를
\co{NULL} 로 만들기 위해 사용되어, 이 그림의 첫번째 열에서 두번째 열로
넘어갑니다.
이 시점에서, 기존부터 존재하던 읽기 쓰레드는 \co{->addr} 는 42 값을 그리고
\co{->iface} 는 1 값을 갖는 것으로 볼 수 있지만, 새로 시작된 읽기 쓰레드는
\co{NULL} 포인터를 볼 것으로, 즉 동시의 읽기 쓰레드들이 이 그림의 ``2
Versions'' 로 표시된 것처럼 현 상태에 대해 다른 의견을 가질 수 있습니다.

\iffalse

Insertion is of course quite useful, but sooner or later, it will also
be necessary to delete data.
As can be seen in
Figure~\ref{fig:defer:Deletion With Concurrent Readers},
the first step is easy.
Again taking the lessons from
Section~\ref{sec:toolsoftrade:Shared-Variable Shenanigans}
to heart, \co{smp_store_release()} is used to \co{NULL} the pointer,
thus moving from the first row to the second in the figure.
At this point, pre-existing readers see the old structure with
\co{->addr} of 42 and \co{->iface} of 1, but new readers will see
a \co{NULL} pointer, that is, concurrent readers can disagree on
the state, as indicated by the ``2 Versions'' in the figure.

\fi

\QuickQuizSeries{%
\QuickQuizB{
	Figure~\ref{fig:defer:Deletion With Concurrent Readers}
	는 \co{NULL} 포인터를 저장하는데 왜 \co{smp_store_release()} 를
	사용하나요?
	\co{NULL} 포인터 저장에 대해 순서지을 구조체 초기화가 없다는 점을
	감안하면 \co{WRITE_ONCE()} 만으로도 이 경우에는 괜찮지 않을까요?

	\iffalse

	Why does
	Figure~\ref{fig:defer:Deletion With Concurrent Readers}
	use \co{smp_store_release()} given that it is storing
	a \co{NULL} pointer?
	Wouldn't \co{WRITE_ONCE()} work just as well in this case,
	given that there is no structure initialization to order
	against the store of the \co{NULL} pointer?

	\fi

}\QuickQuizAnswerB{
	맞아요, 그럴 겁니다.

	\co{NULL} 포인터가 할당되고 있을 뿐, 순서지을 것이 존재하지 않으므로,
	\co{smp_store_release()} 를 사용할 필요는없습니다.
	대조적으로, \co{NULL} 이 아닌 포인터를 할당할 때에는 그 포인터로
	가리켜지는 구조체의 초기화가 이 포인터의 할당 전에 행해졌음을 분명히
	하기 위해 \co{smp_store_release()} 가 사용되어야 합니다.

	짧게 말해서, \co{WRITE_ONCE()} 는 동작할 것이고, 어떤 아키텍쳐에서는
	약간의 CPU 시간을 아낄 겁니다.
	하지만, 뒤에서 보게 되겠지만, 소프투에어 엔지니어링 관점의 걱정은
	\co{smp_store_release()} 와 상당히 유사한 \co{rcu_assign_pointer()}
	라는 특수한 기능의 사용을 장려할 겁니다.

	\iffalse

	Yes, it would.

	Because a \co{NULL} pointer is being assigned, there is nothing
	to order against, so there is no need for \co{smp_store_release()}.
	In contrast, when assigning a non-\co{NULL} pointer, it is
	necessary to use \co{smp_store_release()} in order to ensure
	that initialization of the pointed-to structure is carried
	out before assignment of the pointer.

	In short, \co{WRITE_ONCE()} would work, and would
	save a little bit of CPU time on some architectures.
	However, as we will see, software-engineering concerns
	will motivate use of a special \co{rcu_assign_pointer()}
	that is quite similar to \co{smp_store_release()}.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	동시에 수행되는 읽기 쓰레드는
	Figure~\ref{fig:defer:Deletion With Concurrent Readers}
	에 그려진 수행 순서에 따르면 \co{gptr} 의 값에 대해 동의하지 않을 수
	있습니다.
	이건 뭔가 문제있지 않나요???

	\iffalse

	Readers running concurrently each other and with the procedure
	outlined in
	Figure~\ref{fig:defer:Deletion With Concurrent Readers}
	can disagree on the value of \co{gptr}.
	Isn't that just a wee bit problematic???

	\fi

}\QuickQuizAnswerE{
	꼭 그렇진 않습니다.

	Section~\ref{sec:cpu:Hardware Optimizations}
	와~\ref{sec:cpu:Hardware Free Lunch?}
	에서 힌트가 주어진 것처럼, 빛의 속도의 지연은 컴퓨터의 데이터는 그
	데이터가 실제로 모델링 하고자 의도된 바깥의 사실에 비교해서는 항상
	오래되어 있습니다.

	따라서 실제 세계의 알고리즘은 외부의 현실과 그 현실을 반영하는 컴퓨터
	내부 데이터의 비일관성을 감내해야만 합니다.
	이런 알고리즘들 여럿은 컴퓨터 내부 데이터에서의 비일관성도 어느정도는
	감내할 수 있습니다.
	Section~\ref{sec:datastruct:RCU-Protected Hash Table Discussion}
	이 이 점을 더 자세히 다룹니다.

	\iffalse

	Not necessarily.

	As hinted at in Sections~\ref{sec:cpu:Hardware Optimizations}
	and~\ref{sec:cpu:Hardware Free Lunch?},
	speed-of-light delays mean that a computer's data is always
	stale compared to whatever external reality that data is intended
	to model.

	Real-world algorithms therefore absolutely must tolerate
	inconsistancies between external reality and the in-computer
	data reflecting that reality.
	Many of those algorithms are also able to tolerate some degree
	of inconsistency within the in-computer data.
	Section~\ref{sec:datastruct:RCU-Protected Hash Table Discussion}
	discusses this point in more detail.

	\fi

	이런 비일관적이고 오래된 데이터를 감내해야 하는 필요성은 RCU 에만
	국한되지 않는다는 점을 알아두시기 바랍니다.
	이는 레퍼런스 카운팅, 해저드 포인터, 시퀀스 락, 그리고 심지어 일부 락킹
	사용 예에도 적용됩니다.
	예를 들어, 여러분이 락을 잡은 채 어떤 값을 계산하지만 그 값을 해당 락을
	해제한 후 사용한다면, 여러분은 오래된 데이터를 사용하고 있을 수
	있습니다.
	어쨌건, 그 값이 기반하고 있는 데이터는 그 락이 해제되는 순간 어떻게든
	변할 수도 있습니다.

	그러니, 그렇습니다, RCU 읽기 쓰레드는 오래되고 비일관적인 데이터를 볼
	수 있습니다, 하지만 아니요, 이게 문제여야만 할 이유는 없어요.
	그리고 필요하다면 그런 오래되고 비일관적인 데이터 문제를 막을 수 있는
	RCU 사용 패턴도 있습니다~\cite{Arcangeli03}.

	\iffalse

	Please note that this need to tolerate inconsistent and stale
	data is not limited to RCU\@.
	It also applies to reference counting, hazard pointers, sequence
	locks, and even to some locking use cases.
	For example, if you compute some quantity while holding a lock,
	but use that quantity after releasing that lock,
	you might well be using stale data.
	After all, the data that quantity is based on might change
	arbitrarily as soon as the lock is released.

	So yes, RCU readers can see stale and inconsistent data, but no,
	this is not necessarily problematic.
	And, when needed, there are RCU usage patterns that avoid both
	staleness and inconsistency~\cite{Arcangeli03}.

	\fi

}\QuickQuizEndE
}

우린 열~3 에서 볼 수 있듯 모든 기존부터 존재한 읽기 쓰레드들이 완료하길
기다리는 것만으로 단일 버전으로 돌아올 수 있습니다.
이 지점에서, 모든 기존부터 존재하던 읽기 쓰레드는 종료되었고, 뒤따르는 읽기
쓰레드는 어느 것도 기존 데이터 아이템으로의 경로를 갖지 못하므로, 그걸 참조하는
어떤 읽기 쓰레드도 존재할 수 없습니다.
따라서 그 아이템은 열~4 에서 보여지듯 안전히 메모리 해제될 수 있습니다.

따라서, 기존부터 존재한 읽기 쓰레드들이 완료되길 기다릴 방법이 존재한다면
읽기 쓰레드들이 싱글 쓰레드 수행 시에나 적합할 것과 동일한 기계
인스트럭션들만을 수행하면서도 연결된 데이터 구조에 데이터를 추가할 수도 삭제할
수도 있습니다.
그러니 앞서 했던 것들이 너무 멀리 간 것만은 아닐수도 있습니다!

하지만 어떻게 기존부터 존재한 읽기 쓰레드들이 실제로 완료되었다고 이야기 할 수
있을까요?
이 질문이 다음 섹션의 주제입니다.

\iffalse

We get back to a single version simply by waiting for all the
pre-existing readers to complete, as shown in row~3.
At that point, all the pre-existing readers are done, and no later
reader has a path to the old data item, so there can no longer be
any readers referencing it.
It may therefore be safely freed, as shown on row~4.

Thus, given a way to wait for pre-existing readers to complete,
it is possible to both add data to and remove data from a linked
data structure, despite the readers executing the same sequence
of machine instructions that would be appropriate for single-threaded
execution.
So perhaps going all the way was not too far after all!

But how can we tell when all of the pre-existing readers have in
fact completed?
This question is the topic of the next section.

\fi

\subsubsection{Waiting for Readers}
\label{sec:defer:Waiting for Readers}

읽기 쓰레드의 기다리기를 레퍼런스 카운팅 기반으로 하고 싶을 수 있겠습니다만,
Chapter~\ref{chp:Counting}
의
Figure~\ref{fig:count:Atomic Increment Scalability on x86}
는 현재의 레퍼런스 카운팅은
Section~\ref{sec:defer:Reference Counting}
에서 이미 보았듯 굉장한 오버헤드를 초래함을 보았습니다.
해저드 포인터는 이 오버헤드를 상당히 줄입니다만, 우리가
Section~\ref{sec:defer:Hazard Pointers}
에서 보았듯이, 완전히 없애진 못합니다.
그렇다고는 하나, 많은 RCU 구현이 매우 주의 깊은 캐시 지역적 카운터의 사용을
합니다.

\iffalse

It is tempting to base reader waiting on reference counting, but
Figure~\ref{fig:count:Atomic Increment Scalability on x86}
in
Chapter~\ref{chp:Counting}
shows that concurrent reference counting results in extreme overhead,
as we already saw in
Section~\ref{sec:defer:Reference Counting}.
Hazard pointers profoundly reduce this overhead, but, as we saw in
Section~\ref{sec:defer:Hazard Pointers}, not to zero.
Nevertheless, many RCU implementations make very careful cache-local
use of counters.

\fi

두번째 접근법은 메모리 동기화가 비쌈을 파악하고, 따라서 레지스터를 대신
사용하는데, 이는 각 CPU 또는 쓰레드의 프로그램 카운터 (PC) 로, 따라서 읽기
쓰레드에게는 적어도 동시의 업데이트의 부재 시에는 오버헤드를 일으키지 않습니다.
업데이트 쓰레드는 각 적절한 PC 를 반복적으로 살펴보고, 그 PC 가 읽기 쪽 코드
내에 위치해 있지 않다면, 연관된 CPU 또는 쓰레드는 조용한 상태 (quiescent state)
에 있는 것이며, 따라서 이는 새로이 제거된 데이터 원소로의 액세스를 할수도 있는
읽기 쓰레드는 모두 완료되었다는 신호가 됩니다.
모든 CPU 또는 쓰레드의 PC 가 모두 모든 읽기 쓰레드의 바깥에 있음이 확인된다면,
이 유예 기간 (grace period) 가 완료됩니다.
이 방법은 몇가지 심각한 기술적 어려움도 가지고 있는데, 메모리 순서 맞추기, 읽기
쓰레드에 의해 \emph{가끔} 호출되는 함수들, 그리고 항상 신나는 코드 모습
최적화가 포함됩니다.
그러나, 이 방법은 제품 단계에서 사용되었다고 이야기
됩니다~\cite{MikeAsh2015Apple}.

\iffalse

A second approach observes that memory synchronization is expensive,
and therefore uses registers instead, namely each CPU's or thread's
program counter (PC), thus imposing no overhead on readers, at least
in the absence of concurrent updates.
The updater polls each relevant PC, and if that PC is not within read-side
code, then the corresponding CPU or thread is within a quiescent state,
in turn signaling the completion of any reader that might have access
to the newly removed data element.
Once all CPU's or thread's PCs have been observed to be outside of any
reader, the grace period has completed.
Please note that this approach poses some serious challenges, including
memory ordering, functions that are \emph{sometimes} invoked from readers,
and ever-exciting code-motion optimizations.
Nevertheless, this approach is said to be used in
production~\cite{MikeAsh2015Apple}.

\fi

세번째 접근법은 모든 합리적 읽기 쓰레드의 수명을 충분히 넘어설 정도로 긴 고정된
시간동안 그냥 기다리는 것입니다~\cite{Jacobson93,AjuJohn95}.
이는 하드 리얼타임 시스템에서는 잘 동작합니다만~\cite{YuxinRen2018RTRCU},
그보다 덜 진귀한 환경에서라면, Murphy 는 비합리적일 정도로 오래 살아있는 읽기
쓰레드에도 준비해야 하는게 무척 중요하다고 말합니다.
이를 자세히 보기 위해, 그러는데 실패했을 때의 결과를 생각해 봅시다:
어떤 데이터 항목은 이 비합리적인 읽기 쓰레드가 여전히 그것을 참조하고 있는 동안
메모리 해제될 수 있고, 그 항목은 곧바로 재할당되어 심지어 다른 타입의 데이터
항목으로 사용되고 있을 수 있습니다.
그러면 이 비합리적 읽기 쓰레드와 부주의한 재할당자는 같은 메모리를 두개의 매우
다른 목적으로 사용하려 할 것입니다.
그 결과는 디버깅 하기에 무척 어려울 것입니다.

\iffalse

A third approach is to simply wait for a fixed period of time that is
long enough to comfortably exceed the lifetime of any reasonable
reader~\cite{Jacobson93,AjuJohn95}.
This can work quite well in hard real-time systems~\cite{YuxinRen2018RTRCU},
but in less exotic
settings, Murphy says that it is critically important to be prepared
even for unreasonably long-lived readers.
To see this, consider the consequences of failing do so:
A data item will be freed while the unreasonable reader is still
referencing it, and that item might well be immediately reallocated,
possibly even as a data item of some other type.
The unreasonable reader and the unwitting reallocator would then
be attempting to use the same memory for two very different purposes.
The ensuing mess will at best be exceedingly difficult to debug.

\fi

네번째 접근법은 영원히 기다리는 것으로, 그렇게 하는게 가장 비합리적인 읽기
쓰레드조차도 처리해 줄 것이라는 점에서 안전합니다.
이 접근법은 또한 ``메모리 누출'' 이라고도 불리며, 메모리 누출은 시기 상조의
그리고 불편한 리부팅을 요구한다는 사실 때문에 나쁜 평판을 가지고 있습니다.
그러나, 이는 업데이트 비율과 시스템 가동시간이 모두 꽤 정확히 그 한계가 정해져
있을 때라면 사용될 수 있는 전략입니다.
예를 들어, 이 방법은 시스템이 높은 가용성을 가진 클러스터여서 이 클러스터가
정말로 높은 가용성을 유지한다는 것을 분명히 하기 위해 주기적으로 고장나는
것이라면 잘 동작할 수 있습니다.\footnote{
	이 주기적 고장을 강제하는 프로그램은 가끔 ``chaos monkey'' 라고
	불립니다:
	\url{https://netflix.github.io/chaosmonkey/}.
	하지만, 너무 오래 수행되는 시스템에 의해 야기되는 혼란을 무시하는 것도
	실수가 될수도 있습니다.}
메모리를 누출하는 것은 또한 garbage collector 를 가진 경우에도 사용될 수
있을텐데, 이 경우는 garbage collector 가 이 누출을 막는 것으로 생각될 수
있습니다~\cite{Kung80}.
하지만, 여러분의 환경이 garbage collector 를 지원하지 않는다면, 마저
읽으십시오!

\iffalse

A fourth approach is to wait forever, secure in the knowledge that
doing so will accommodate even the most unreasonable reader.
This approach is also called ``leaking memory'', and has a bad reputation
due to the fact that memory leaks often require untimely and
inconvenient reboots.
Nevertheless, this is a viable strategy when the update rate and the
uptime are both sharply bounded.
For example, this approach could work well in a high-availability
cluster where systems were periodically crashed in order to ensure
that cluster really remained highly available.\footnote{
	The program that forces the periodic crashing is sometimes
	known as a ``chaos monkey'':
	\url{https://netflix.github.io/chaosmonkey/}.
	However, it might also be a mistake to neglect chaos caused
	by systems running for too long.}
Leaking the memory is also a viable strategy in environments having
garbage collectors, in which case the garbage collector can be thought
of as plugging the leak~\cite{Kung80}.
However, if your environment lacks a garbage collector, read on!

\fi

다섯번째 접근법은 전통적 세상을-멈추기 (stop-the-world) garbage collector 에
의해 예시되는 주기적으로 ``세상을 멈추기'' 를 사용해 주기적 고장내기를
막습니다.
이 방법은 또한 각 일하는 날의 끝마다 시스템의 전원을 끄는게 일반적 행동이었던,
어디나 있는 연결성 전의 수십년간 많이 사용되었습니다.
하지만, 오늘날의 항상 연결되어 있고 항상 켜져있는 세상에서는, 세상을 멈추기는
응답 시간을 크게 악화시킬 수 있는데, 이는 동시적 garbage collector 의 개발의
모티베이션 중 하나가 되었습니다~\cite{DavidFBacon2003RTGC}.
더 나아가, 우린 모든 앞서서부터 존재하고 있는 읽기 쓰레드가 모두 완료되기를
기다려야 하기는 하지만, 그것들이 동시에 완료되어야 할 필요는 없습니다.

\iffalse

A fifth approach avoids the period crashes in favor of periodically
``stopping the world'', as exemplified by the traditional stop-the-world
garbage collector.
This approach was also heavily used during the decades before
ubiquitous connectivity, when it was common practice to power systems
off at the end of each working day.
However, in today's always-connected always-on world, stopping the world
can gravely degrade response times, which has been one motivation for the
development of concurrent garbage collectors~\cite{DavidFBacon2003RTGC}.
Furthermore, although we need all pre-existing readers to complete, we do
not need them all to complete at the same time.

\fi

이 발견은 여섯번째 접근법을 이끌어내는데, 한번에 한 CPU 또는 쓰레드를 멈추는
것입니다.
이 방법은 읽기 쓰레드의 응답 시간을 전혀 악화시키지 않는다는 장점을 갖습니다.
더 나아가서, 많은 어플리케이션들이 이미 앞의 앞서서부터 존재하고 있는 읽기
스레드들이 모두 완료된 후에만 도달할 수 있는 상태 (\emph{quiescent state} 라
불립니다) 를 갖습니다.
트랜잭션 처리 시스템에서는, 한쌍의 연속된 트랜잭션 사이의 시간이 quiescent
state 일 수 있습니다.
반응형 시스템에서는, 연속된 한 쌍의 이벤트 사이의 상태가 quiescent state 일
겁니다.
Preemption 기반이지 않은 운영체제 커널에서는, 컨텍스트 스위치가 quiescent state
가 될 수 있습니다~\cite{McKenney98}.
어떤 형태든, 모든 CPU 그리고/또는 쓰레드가 하나의 quiescent state 를 지난다면,
이 시스템은 하나의 \emph{grace period} 를 완료했다고 이야기 되며, 이 지점에서는
이 grace period 의 시작 시점에서 존재했던 모든 읽기 쓰레드는 완료되었다는게
보장됩니다.
그 결과, 이 grace period 의 시작 전에 제거된 데이터 항목들은 메모리 해제되기에
안전합니다.\footnote{
	RCU 는 단순히 메모리 회수 미루기보다 훨씬 많은 걸 할 수 있으나, 
	회수 미루기는 RCU 의 가장 흔한 사용예이며, 따라서 시작하기에 훌륭한
	지점입니다.}

\iffalse

This observation leads to the sixth approach, which is stopping
one CPU or thread at a time.
This approach has the advantage of not degrading reader response times
at all, let alone gravely.
Furthermore, numerous applications already have states (termed
\emph{quiescent states}) that can be
reached only after all pre-existing readers are done.
In transaction-processing systems, the time between a pair of
successive transactions might be a quiescent state.
In reactive systems, the state between a pair of successive events
might be a quiescent state.
Within non-preemptive operating-systems kernels, a context switch can be
a quiescent state~\cite{McKenney98}.
Either way, once all CPUs and/or threads have passed through a quiescent
state, the system is said to have completed a \emph{grace period},
at which point all readers in existence at the start of that grace period
are guaranteed to have completed.
As a result, it is also guaranteed to be safe to free any removed data
items that were removed prior to the start of that grace period.\footnote{
	It is possible to do much more with RCU than simply defer
	reclamation of memory, but deferred reclamation is RCU's most
	common use case, and is therefore an excellent place to start.}

\fi

Preemption 이 없는 운영체제 커널에서 컨텍스트 스위치가 유효한 quiescent state 가 되려면 읽기 쓰레드는
Figure~\ref{fig:defer:Insertion With Concurrent Readers}
와~\ref{fig:defer:Deletion With Concurrent Readers}
의 \co{gptr} 포인터에 의해 얻어지는 데이터 구조 인스턴스를 참조하는 동안은
블록킹 되는 걸 방지해야만 합니다.
이 블록킹 방지 제약은 순수 스핀락에서도 비슷한 제약으로 존재하는데, 여기선 CPU
는 스핀락을 잡고 있는 동안 블록킹 되는게 금지됩니다.
이 제약이 없다면, 모든 CPU 는 블록된 쓰레드에 의해 잡혀 있는 스핀락을 획득하려
스핀하는 쓰레드들에 의해 소모될 수 있습니다.
이 스핀하는 쓰레드들은 그것들이 이 락을 획득하기 전까지는 CPU 를 놓지 않을
것이지만, 이 락을 쥐고 있는 쓰레드는 이 스핀하고 있는 쓰레드들 중 하나가 CPU 를
하나라도 놓기 전까지는 이 락을 놓아주지 못할 겁니다.
이는 고전적 데드락 환경이며, 이 데드락은 스핀락을 잡고 있는 동안은 블록킹을
방지하는 것으로 막아집니다.

\iffalse

Within a non-preemptive operating-system kernel, for context switch to be
a valid quiescent state, readers must be prohibited from blocking while
referencing a given instance data structure obtained via the \co{gptr}
pointer shown in
Figures~\ref{fig:defer:Insertion With Concurrent Readers}
and~\ref{fig:defer:Deletion With Concurrent Readers}.
This no-blocking constraint is consistent with similar constraints
on pure spinlocks, where a CPU is forbidden from blocking while
holding a spinlock.
Without this constraint, all CPUs might be consumed by threads
spinning attempting to acquire a spinlock held by a blocked thread.
The spinning threads will not relinquish their CPUs until they acquire
the lock, but the thread holding the lock cannot possibly release it
until one of the spinning threads relinquishes a CPU\@.
This is a classic deadlock situation, and this deadlock is avoided
by forbidding blocking while holding a spinlock.

\fi

다시, 이 동일한 제약이 \co{gptr} 을 역참조하는 읽기 쓰레드에게도 적용됩니다:
그런 쓰레드는 그것들이 이 가리켜진 데이터 항목을 사용하는 것을 마무리 하기
전까지는 블록되지 않아야 합니다.
업데이트 쓰레드가 막 \co{smp_store_release()} 를 수행하는 것을 완료한
Figure~\ref{fig:defer:Deletion With Concurrent Readers}
의 두번째 열로 돌아와서, CPU~0 이 컨텍스트 스위치를 했다고 생각해 봅시다.
읽기 쓰레드는 이 링크드 리스트를 순회하는 동안은 블록되는 것이 허용되지
않았으므로, 우린 CPU~0 에서 수행되었을 수도 있는 모든 앞의 읽기 쓰레드들이
완료되었다고 보장됩니다.
이 논리를 다른 CPU 들로 확장하면, 각 CPU 가 모두 컨텍스트 스위치 수행을
목격했다면, 모든 앞의 읽기 쓰레드가 완료되었음이, 새로이 제거된 데이터 원소를
참조하고 있는 어떤 읽기 쓰레드도 더이상 존재하지 않음이 보장됩니다.
그럼 이 업데이트 쓰레드는 안전하게 이 데이터 원소를 메모리 해제할 수 있어,
Figure~\ref{fig:defer:Deletion With Concurrent Readers}
의 가장 아래에 보인 상태에 도달합니다.

\iffalse

Again, this same constraint is imposed on reader threads dereferencing
\co{gptr}: such threads are not allowed to block until after
they are done using the pointed-to data item.
Returning to the second row of
Figure~\ref{fig:defer:Deletion With Concurrent Readers},
where the updater has just completed executing the \co{smp_store_release()},
imagine that CPU~0 executes a context switch.
Because readers are not permitted to block while traversing the linked
list, we are guaranteed that all prior readers that might have been running on
CPU~0 will have completed.
Extending this line of reasoning to the other CPUs, once each CPU has
been observed executing a context switch, we are guaranteed that all
prior readers have completed, and that there are no longer any reader
threads referencing the newly removed data element.
The updater can then safely free that data element, resulting in the
state shown at the bottom of
Figure~\ref{fig:defer:Deletion With Concurrent Readers}.

\fi

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{defer/QSBRGracePeriod}}
\caption{QSBR: Waiting for Pre-Existing Readers}
\label{fig:defer:QSBR: Waiting for Pre-Existing Readers}
\end{figure}

이 방법은 \emph{quiescent state based reclamation}
(QSBR)~\cite{ThomasEHart2006a} 라고 명명되었습니다.
하나의 QSBR 방법이
Figure~\ref{fig:defer:QSBR: Waiting for Pre-Existing Readers}
에 시간이 이 그림의 꼭대기에서 아래로 흐르는 모습으로 그려져 있습니다.
CPU~1 은 현재 데이터 항목을 제거하는 \co{WRITE_ONCE()} 를 수행하고 (아마도 이
포인터 값을 앞서 읽었고 자신을 적절한 동기화를 하고 있게 했을 겁니다), 읽기
쓰레드를 기다립니다.
이 대기 오퍼레이션은 즉각적인 컨텍스트 스위치를 초래하는데, 이는 quiescent
state 로 (핑크색 원으로 표시되어 있습니다), CPU~1 에서의 모든 앞선 읽기는
완료되었음을 의미합니다.
이어서, CPU~2 가 컨텍스트 스위치를 하여, CPU~1 과~2 의 모든 읽기 쓰레드는 이제
완료되었음이 알려집니다.
마지막으로, CPU~3 이 컨텍스트 스위치를 합니다.
이 지점에서, 전체 시스템의 모든 읽기 쓰레드는 완료되었음이 알려지며, 따라서
grace period 가 종료되어 CPU~1 이 오래된 데이터 항목을 메모리 해제하는 것을
허용합니다.

\iffalse

This approach is termed \emph{quiescent state based reclamation}
(QSBR)~\cite{ThomasEHart2006a}.
A QSBR schematic is shown in
Figure~\ref{fig:defer:QSBR: Waiting for Pre-Existing Readers},
with time advancing from the top of the figure to the bottom.
CPU~1 does the \co{WRITE_ONCE()} that removes the current data
item (presumably having previously read the pointer value and
availed itself of appropriate synchronization), then waits
for readers.
This wait operation results in an immediate context switch, which is a
quiescent state (denoted by the pink circle), which in turn means that
all prior reads on CPU~1 have completed.
Next, CPU~2 does a context switch, so that all readers on CPUs~1 and~2
are now known to have completed.
Finally, CPU~3 does a context switch.
At this point, all readers throughout the entire system are known to
have completed, so the grace period ends, permitting CPU~1 to free
the old data item.

\fi

\QuickQuiz{
	Figure~\ref{fig:defer:QSBR: Waiting for Pre-Existing Readers} 에서,
	CPU~3 의 이 오래된 데이터 항목으로의 액세스를 했을 수 있는 읽기
	쓰레드는 이 grace period 가 시작하기도 전에 이미 완료되었어요!
	그런데 왜 CPU~3 의 마지막 컨텍스트 스위치를 신경쓰나요???

	\iffalse

	In Figure~\ref{fig:defer:QSBR: Waiting for Pre-Existing Readers},
	the last of CPU~3's readers that could possibly have
	access to the old data item ended before the grace period
	even started!
	So why would anyone bother waiting until CPU~3's later context
	switch???

	\fi

}\QuickQuizAnswer{
	이 대기는 읽기 쓰레드들이 싱글쓰레드 상황에서나 적절한 것과 똑같은
	인스트럭션들을 사용할 수 있게 해주기 때문입니다.
	달리 말하자면, 이 추가적인 ``과잉의'' 대기가 읽기 쪽의 훌륭한 성능,
	확장성, 그리고 리얼타임 응답을 가능하게 합니다.

	\iffalse

	Because that waiting is exactly what enables readers to use
	the same sequence of instructions that is appropriate for
	single-theaded situations.
	In other words, this additional ``redundant'' waiting enables
	excellent read-side performance, scalability, and real-time
	response.

	\fi

}\QuickQuizEnd

\subsubsection{Toy Implementation}
\label{sec:defer:Toy Implementation}

제품 수준 QSBR 구현은 무척 복잡할 수 있지만, preemption 기반이 아닌 리눅스
커널에서의 장난감 수준 구현은 굉장히 간단합니다:

\iffalse

Although production-quality QSBR implementations can be quite complex,
a toy non-preemptive Linux-kernel implementation is exceedingly simple:

\fi

\begin{VerbatimN}[samepage=true]
void synchronize_rcu(void)
{
	int cpu;

	for_each_online_cpu(cpu)
		sched_setaffinity(current->pid, cpumask_of(cpu));
}
\end{VerbatimN}

\co{for_each_online_cpu()} 기능은 모든 CPU 를 순회하고,
\co{sched_setaffinity()} 함수는 현재 쓰레드가 명시된 CPU 에서 수행되게 하는데,
이는 이 대상 CPU 가 컨텍스트 스위치를 수행하게끔 강제합니다.
따라서, \co{for_each_online_cpu()} 가 완료되고 나면, 각 CPU 는 한번의 컨텍스트
스위치는 수행한 것인데, 이는 곧 모든 앞서서부터 존재해온 읽기 쓰레드가 모두
완료되었음을 보장합니다.

\iffalse

The \co{for_each_online_cpu()} primitive iterates over all CPUs, and
the \co{sched_setaffinity()} function causes the current thread to
execute on the specified CPU, which forces the destination CPU to execute
a context switch.
Therefore, once the \co{for_each_online_cpu()} has completed, each CPU
has executed a context switch, which in turn guarantees that
all pre-existing reader threads have completed.

\fi

\begin{listing}[tbp]
\begin{fcvlabel}[ln:defer:Insertion and Deletion With Concurrent Readers]
\begin{VerbatimL}[commandchars=\\\[\]]
struct route *gptr;

int access_route(int (*f)(struct route *rp))
{
	int ret = -1;
	struct route *rp;

	rcu_read_lock();
	rp = rcu_dereference(gptr);
	if (rp)
		ret = f(rp);		\lnlbl[access_rp]
	rcu_read_unlock();
	return ret;
}

struct route *ins_route(struct route *rp)
{
	struct route *old_rp;

	spin_lock(&route_lock);
	old_rp = gptr;
	rcu_assign_pointer(gptr, rp);
	spin_unlock(&route_lock);
	return old_rp;
}

int del_route(void)
{
	struct route *old_rp;

	spin_lock(&route_lock);
	old_rp = gptr;
	RCU_INIT_POINTER(gptr, NULL);
	spin_unlock(&route_lock);
	synchronize_rcu();
	free(old_rp);
	return !!old_rp;
}
\end{VerbatimL}
\end{fcvlabel}
\caption{Insertion and Deletion With Concurrent Readers}
\label{lst:defer:Insertion and Deletion With Concurrent Readers}
\end{listing}

이 방법은 제품 수준이 \emph{아님을} 알아 두시기 바랍니다.
여러개의 특수 상황에 대한 처리와 여러개의 강력한 최적화의 필요는 제품 수준
구현이 무척 복잡함을 의미합니다.
이에 더해, preemption 기반 환경을 위한 RCU 구현은 읽기 쓰레드가 실제로 무언가를
더할 것을 필요로 하는데, 리얼타임이 아닌 리눅스 커널 환경에서는
\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 을 각각 \co{preempt_disable()}
과 \co{preempt_enable()} 로 간단히 정의하는 것으로 될 수 있습니다.\footnote{
	Preemption 되는 읽기쪽 크리티컬 섹션을 다루는 어떤 장난감 수준 RCU
	구현들이 Appendix~\ref{chp:app:``Toy'' RCU Implementations} 에 보여져
	있습니다.}
그러나, 이 간단한 preemption 불가 방법은 이론적으로 완벽하며, 읽기 쪽 동기화를
동시의 업데이트가 있음에도 불구하고 비용 없이 제공하는게 가능함을 보입니다.
실제로,
Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}
은 어떻게 읽기 (\co{access_route()}),
Figure~\ref{fig:defer:Insertion With Concurrent Readers} 의 삽입,
(\co{ins_route()})
Figure~\ref{fig:defer:Deletion With Concurrent Readers} 의 삭제가
(\co{del_route()} 구현될 수 있는지 보입니다.
(약간 더 그럴싸한 라우팅 테이블은
Section~\ref{sec:defer:RCU for Pre-BSD Routing} 에 보여져 있습니다.)

\iffalse

Please note that this approach is \emph{not} production quality.
Correct handling of a number of corner cases and the need for a number
of powerful optimizations mean that production-quality implementations
are quite complex.
In addition, RCU implementations for preemptible environments
require that readers actually do something, which in non-real-time
Linux-kernel environments can be as simple as defining
\co{rcu_read_lock()} and \co{rcu_read_unlock()} as \co{preempt_disable()}
and \co{preempt_enable()}, respectively.\footnote{
	Some toy RCU implementations that handle preempted
	read-side critical sections are shown in
	Appendix~\ref{chp:app:``Toy'' RCU Implementations}.}
However, this simple non-preemptible approach is conceptually complete,
and demonstrates that it really is possible to provide read-side
synchronization at zero cost, even in the face of concurrent updates.
In fact,
Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}
shows how reading (\co{access_route()}),
Figure~\ref{fig:defer:Insertion With Concurrent Readers}'s
insertion (\co{ins_route()}) and
Figure~\ref{fig:defer:Deletion With Concurrent Readers}'s
deletion (\co{del_route()}) can
be implemented.
(A slightly more capable routing table is shown in
Section~\ref{sec:defer:RCU for Pre-BSD Routing}.)

\fi

\QuickQuizSeries{%
\QuickQuizB{
	Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}
	의 \co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 의 요점이 뭔가요?
	이 quiescent state 들이 스스로 자신을 이야기하게 하는건 어떤가요?

	\iffalse

	What is the point of \co{rcu_read_lock()} and \co{rcu_read_unlock()} in
	Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}?
	Why not just let the quiescent states speak for themselves?

	\fi

}\QuickQuizAnswerB{
	읽기 쓰레드들은 quiescent state 를 가로지를 수 없음을 기억하세요.
	예를 들어, 리눅스 커널에서 RCU 읽기 쓰레드는 컨텍스트 스위치를 수행할
	수 없습니다.
	\co{rcu_read_lock()} 과 \co{rcu_read_unlock()} 의 사용은 올바르지 않게
	위치된 quiescent state 들을 디버깅 할 수 있게 하고, 그러지 않으면 찾기
	어렵고 간헐적으로 나타나며 무척 파괴적인 버그를 찾기 쉽게 해줍니다.

	\iffalse

	Recall that readers are not permitted to pass through a quiescent
	state.
	For example, within the Linux kernel, RCU readers are not permitted
	to execute a context switch.
	Use of \co{rcu_read_lock()} and \co{rcu_read_unlock()} enables
	debug checks for improperly placed quiescent states, making it
	easy to find bugs that would otherwise be difficult to find,
	intermittent, and quite destructive.

	\fi

}\QuickQuizEndB
%
\QuickQuizE{
	Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}
	의 \co{rcu_dereference()}, \co{rcu_assign_pointer()}, 그리고
	\co{RCU_INIT_POINTER()} 의 요점이 뭔가요?
	그냥 \co{READ_ONCE()}, \co{smp_store_release()}, 그리고
	\co{WRITE_ONCE()} 를 각각 대신 사용하는 건 어떤가요?

	\iffalse

	What is the point of \co{rcu_dereference()}, \co{rcu_assign_pointer()}
	and \co{RCU_INIT_POINTER()} in
	Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}?
	Why not just use \co{READ_ONCE()}, \co{smp_store_release()}, and
	\co{WRITE_ONCE()}, respectively?

	\fi

}\QuickQuizAnswerE{
	RCU 특정 API 들은 제안된 교체와 실제로 비슷한 의미를 가집니다만, RCU
	특정 API 가 RCU 포인터가 아닌 것들에 대해 호출되었을 때, 그리고 그
	거꾸로인 상황에 문제를 제기하는 정적 분석 디버깅 검사를 가능하게
	합니다.

	\iffalse

	The RCU-specific APIs do have similar semantics to the suggested
	replacements, but also enable static-analysis debugging checks
	that complain if an RCU-specific API is invoked on a non-RCU
	pointer and vice versa.

	\fi

}\QuickQuizEndE
}

Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}
으로 돌아가서, \co{route_lock} 이 \co{ins_route()} 와 \co{del_route()} 를
호출하는 동시의 업데이트들 사이의 동기화를 위해 사용되었음을 알아두시기
바랍니다.
하지만, 이 락은 \co{access_route()} 를 호출하는 읽기 쓰레드에 의해서는 획득되지
않습니다:
읽기 쓰레드들은 그대신
\cref{sec:defer:Waiting for Readers} 에서 이야기 된 QSBR 기법을 통해
보호됩니다.

\co{ins_route()} 는
Figure~\ref{fig:defer:Insertion With Concurrent Readers} 가 항상 \co{NULL} 일
거라고 가정하는 \co{gptr} 의 기존 값을 리턴할 뿐임을 알아 두시기 바랍니다.
이는 \co{NULL} 이 아닌 값을 가지고 뭘 할지 알아내는 건 호출자의 책임이며, 읽기
쓰레드들이 확정되지 않은 기간동안 그에 대한 참조를 하고 있을 수도 있다는 사실에
의해 복잡해지는 일입니다.
호출자는 다음 접근법 중 하나를 사용할 수도 있을 겁니다:

\iffalse

Referring back to
Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers},
note that \co{route_lock} is used to synchronize between concurrent updaters
invoking \co{ins_route()} and \co{del_route()}.
However, this lock is not acquired by readers invoking \co{access_route()}:
Readers are instead protected by the QSBR techniques described in
\cref{sec:defer:Waiting for Readers}.

Note that \co{ins_route()} simply returns the old value of \co{gptr}, which
Figure~\ref{fig:defer:Insertion With Concurrent Readers} assumed would
always be \co{NULL}.
This means that it is the caller's responsibility to figure out what to
do with a non-\co{NULL} value, a task complicated by the fact that
readers might still be referencing it for an indeterminate period of time.
Callers might use one of the following approaches:

\fi

\begin{enumerate}
\item	가리켜진 구조체의 안전한 메모리 해제를 위해 \co{synchronize_rcu()} 를
	사용합니다.
	이 방법은 RCU 관점에서는 올바르지만, 소프트웨어 엔지니어링 관점에서는
	새기 쉬운 API 문제를 갖는다고 논쟁될 수도 있습니다.
\item	리턴된 포인터가 \co{NULL} 이 아닌지 단정을 짓습니다.
\item	이전의 값을 복원하기 위해 \co{ins_route()} 의 다음 호출로 리턴된
	포인터를 넘깁니다.
\end{enumerate}

대조적으로, \co{del_route()} 는 새로 삭제된 데이터 항목을 안전하게 메모리
해제하기 위해 \co{synchronize_rcu()} 와 \co{free()} 를 사용합니다.

\iffalse

\begin{enumerate}
\item	Use \co{synchronize_rcu()} to safely free the pointed-to structure.
	Although this approach is correct from an RCU perspective, it
	arguably has software-engineering leaky-API problems.
\item	Trip an assertion if the returned pointer is non-\co{NULL}.
\item	Pass the returned pointer to a later invocation of
	\co{ins_route()} to restore the earlier value.
\end{enumerate}

In contrast, \co{del_route()} uses \co{synchronize_rcu()} and
\co{free()} to safely free the newly deleted data item.

\fi

\QuickQuiz{
	하지만 기존 구조체가 메모리 해제되어야 하지만 \co{ins_route()} 의
	호출자가 성능에 대한 고려 때문 또는 이 호출자가 RCU 읽기 크리티컬 섹션
	내에서 수행되고 있다던지 해서 블록될 수 없다면 어떻게 하죠?

	\iffalse

	But what if the old structure needs to be freed, but the caller
	of \co{ins_route()} cannot block, perhaps due to performance
	considerations or perhaps because the caller is executing within
	an RCU read-side critical section?

	\fi

}\QuickQuizAnswer{
	Section~\ref{sec:defer:Wait For Pre-Existing RCU Readers}
	에서 이야기되는 \co{call_rcu()} 함수가 비동기적 grace period 대기를
	허용합니다.

	\iffalse

	A \co{call_rcu()} function, which is described in
	Section~\ref{sec:defer:Wait For Pre-Existing RCU Readers},
	permits asynchronous grace-period waits.

	\fi

}\QuickQuizEnd

이 예는 RCU 로 보호되는 데이터 구조를 읽고 업데이트 하는 하나의 일반적 접근법을
보이고 있습니다만, 매우 다양한 사용 예가 존재하며, 많은 것들이
Section~\ref{sec:defer:RCU Usage} 에서 다뤄집니다.

요약하자면, 싱글쓰레드 기반 읽기 함수에 의해 수행될 것과 동일한 구성의 기계
인스트럭션을 수행하는 읽기 쓰레드에 의해 순회될 수 있는 연결된 동시적 데이터
구조들을 만드는게 정말 가능합니다.
다음 섹션은 RCU 의 고수준 특성들을 요약합니다.

\iffalse

This example shows one general approach to reading and updating
RCU-protected data structures, however, there is quite a variety
of use cases, several of which are covered in
Section~\ref{sec:defer:RCU Usage}.

In summary, it is in fact possible to create concurrent linked data
structures that can be traversed by readers executing the same sequence
of machine instructions that would be executed by single-threaded readers.
The next section summarizes RCU's high-level properties.

\fi

\subsubsection{RCU Properties}
\label{sec:defer:RCU Properties}

A key RCU property is that reads need not wait for updates.
This property enables RCU implementations to provide low-cost or even
no-cost readers, resulting in low overhead and excellent scalability.
This property also allows RCU readers and updaters to make useful
concurrent forward progress.
In contrast, conventional synchronization primitives must enforce strict
mutual exclusion using expensive instructions, thus increasing overhead
and degrading scalability, but also typically prohibiting readers and
updaters from making useful concurrent forward progress.

\QuickQuiz{
	Doesn't Section~\ref{sec:defer:Sequence Locks}'s seqlock
	also permit readers and updaters to make useful concurrent
	forward progress?
}\QuickQuizAnswer{
	Yes and no.
	Although seqlock readers can run concurrently with
	seqlock writers, whenever this happens, the \co{read_seqretry()}
	primitive will force the reader to retry.
	This means that any work done by a seqlock reader running concurrently
	with a seqlock updater will be discarded and the redone upon retry.
	So seqlock readers can \emph{run} concurrently with updaters,
	but they cannot actually get any work done in this case.

	In contrast, RCU readers can perform useful work even in presence
	of concurrent RCU updaters.

	However, both reference counters
	(Section~\ref{sec:defer:Reference Counting})
	and hazard pointers
	(Section~\ref{sec:defer:Hazard Pointers})
	really do permit useful concurrent forward progress for both
	updaters and readers, just at somewhat greater cost.
	Please see
	Section~\ref{sec:defer:Which to Choose?}
	for a comparison of these different solutions to the
	deferred-reclamation problem.
}\QuickQuizEnd

RCU delimits readers with \co{rcu_read_lock()} and \co{rcu_read_unlock()},
and ensures that each reader has a coherent view of each object
(see \cref{fig:defer:Deletion With Concurrent Readers}) by
maintaining multiple versions of objects and using update-side primitives
such as \co{synchronize_rcu()} to ensure that objects are not
freed until after the completion of all readers that might be using them.
RCU uses \co{rcu_assign_pointer()} and \co{rcu_dereference()} to provide
efficient and scalable mechanisms for publishing and reading new versions
of an object, respectively.
These mechanisms distribute the work among read and
update paths in such a way as to make read paths extremely fast, using
replication and weakening optimizations in a manner similar to
hazard pointers, but without the need for read-side retries.
In some cases, including \co{CONFIG_PREEMPT=n} Linux kernels,
RCU's read-side primitives have zero overhead.

But are these properties actually useful in practice?
This question is taken up by the next section.

\subsubsection{Practical Applicability}
\label{sec:defer:Practical Applicability}

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{defer/linux-RCU}}
\caption{RCU Usage in the Linux Kernel}
\label{fig:defer:RCU Usage in the Linux Kernel}
\end{figure}

RCU has been used in the Linux kernel since
October 2002~\cite{Torvalds2.5.43}.
Use of the RCU API has increased substantially since that time,
as can be seen in
Figure~\ref{fig:defer:RCU Usage in the Linux Kernel}.
In fact, code very similar to that in
Listing~\ref{lst:defer:Insertion and Deletion With Concurrent Readers}
is used in the Linux kernel.
RCU has enjoyed heavy use both prior to and since its acceptance
in the Linux kernel, as discussed in
\cref{sec:defer:RCU Related Work}.

It is therefore safe to say that RCU enjoys wide practical applicability.

The minimal example discussed in this section is a good introduction to RCU\@.
However, effective use of RCU often requires that you think differently
about your problem.
It is therefore useful to examine RCU's fundamentals, a task taken up
by the following section.
