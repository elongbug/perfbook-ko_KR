% cpu/hwfreelunch.tex

\section{Hardware Free Lunch?}
\label{sec:cpu:Hardware Free Lunch?}

동시성이 최근들어 기존보다 주목을 받게 된 것은
페이지~\pageref{fig:intro:Clock-Frequency Trend for Intel CPUs} 의
Figure~\ref{fig:intro:Clock-Frequency Trend for Intel CPUs} 에 나타난대로
무어의 법칙에 의한 싱글 쓰레드 성능 증가(또는 ``공짜
점심''~\cite{HerbSutter2008EffectiveConcurrency})가 멈췄기 때문입니다.
이 섹션에서는 하드웨어 설계자들이 ``공짜 점심''을 약간이라도 다시 가져올 수
있는 몇가지 방법을 간략히 알아봅니다.

\iffalse
The major reason that concurrency has been receiving so much focus over
the past few years is the end of Moore's-Law induced single-threaded
performance increases
(or ``free lunch''~\cite{HerbSutter2008EffectiveConcurrency}),
as shown in
Figure~\ref{fig:intro:Clock-Frequency Trend for Intel CPUs} on
page~\pageref{fig:intro:Clock-Frequency Trend for Intel CPUs}.
This section briefly surveys a few ways that hardware designers
might be able to bring back some form of the ``free lunch''.
\fi

하지만, 앞의 섹션에서는 동시성을 노출하는데 생기는 현저한 하드웨어적 문제를
알아봤습니다.
하드웨어 설계자들이 직면하는 강력한 물리적 한계점들 중 하나는 빛의 유한한
속도입니다.
페이지~\pageref{fig:cpu:System Hardware Architecture} 의
Figure~\ref{fig:cpu:System Hardware Architecture} 에 보여진 것처럼, 빛은
진공에서 1.8 GHz 클락 시간동안 8 센티미터만을 왕복할 수 있습니다.
이 거리는 5 GHz 클락에서는 3 센티미터로 줄어듭니다.
근래 컴퓨터 시스템의 크기에 비교해 보면 둘 다 비교적 작은 거리입니다.

\iffalse
However, the preceding section presented some substantial hardware
obstacles to exploiting concurrency.
One severe physical limitation that hardware designers face is the
finite speed of light.
As noted in
Figure~\ref{fig:cpu:System Hardware Architecture} on
page~\pageref{fig:cpu:System Hardware Architecture},
light can travel only about an 8-centimeters round trip
in a vacuum during the duration of a 1.8 GHz clock period.
This distance drops to about 3 centimeters for a 5 GHz clock.
Both of these distances are relatively small compared to the size
of a modern computer system.
\fi

상황이 더 나빠지는게, 실리콘에서의 전자파는 진공에서의 빛에 비해 3-30 배 느리게
움직이고, 일반적인 클락 주파수에 맞춰 움직이는 논리 회로들은 더욱 느리게
동작합니다. 예를 들어, 메모리 접근은 접근 요청이 시스템의 나머지 영역으로
넘어가기 전에 로컬 캐쉬 검색의 완료를 기다려야 합니다.
더욱이, 예를 들어 CPU 와 메인 메모리 사이의 통신의 경우와 같이, 전기 신호를 한
실리콘 다이에서 다른 다이로 넘기기 위해서는 상대적으로 느린 속도와 큰 파워의
드라이버가 필요합니다.

\iffalse
To make matters even worse, electric waves in silicon move from three to
thirty times more slowly than does light in a vacuum, and common
clocked logic constructs run still more slowly, for example, a
memory reference may need to wait for a local cache lookup to complete
before the request may be passed on to the rest of the system.
Furthermore, relatively low speed and high power drivers are required
to move electrical signals from one silicon die to another, for example,
to communicate between a CPU and main memory.
\fi

\QuickQuiz{}
	하지만 개별의 전자들은 컨덕터 내에서조차도 그렇게 빠르지 않아요!!!
	세미컨덕터에서 발견된 저전력의 컨덕터 안에서의 전자 이동 속도는 초당
	겨우 1 \emph{밀리미터} 정도라구요.
	뭔가요???

	\iffalse
	But individual electrons don't move anywhere near that fast,
	even in conductors!!!
	The electron drift velocity in a conductor under the low voltages
	found in semiconductors is on the order of only one \emph{millimeter}
	per second.
	What gives???
	\fi
\QuickQuizAnswer{
	전자 이동 속도는 긴 시간동안의 개별 전자들의 이동을 추적합니다.
	개별 전자들은 꽤 무작위적으로 튀어다니고, 따라서 그들의 순간 속도는
	매우 빠르지만 긴 시간으로 보게 되면 그렇게 멀리 이동하지는 않습니다.
	여기서, 전자들은 대부분의 시간을 고속으로 이동하는데 소모하지만 긴
	시간으로 보면 어디에도 가지 않는 통근자와도 같습니다.
	이런 통근자들의 속도는 시속 70 마일(113 킬로미터) 정도지만, 지구의
	표면에 비교해 보는 긴 시간동안의 이동 속도는 제로에 가까울 겁니다.

	\iffalse
	Electron drift velocity tracks the long-term movement of individual
	electrons.
	It turns out that individual electrons bounce around quite
	randomly, so that their instantaneous speed is very high, but
	over the long term, they don't move very far.
	In this, electrons resemble long-distance commuters, who
	might spend most of their time traveling at full highway
	speed, but over the long term going nowhere.
	These commuters' speed might be 70 miles per hour
	(113 kilometers per hour), but their long-term drift velocity
	relative to the planet's surface is zero.
	\fi

	따라서, 우리는 전자의 이동속도가 아니라 순간적 속도에 주의를 기울여야
	합니다.
	하지만, 전자의 순간적 속도라 하더라도 빛의 속도에는 발끝도 따라가지
	못합니다.
	컨덕터에서 측정된 전자파의 속도는 더도 아니고 덜도 아니고 빛의 속도의
	발끝은 따라가고 있는데, 이 때문에 여전히 미스테리는 풀리지 않습니다.

	\iffalse
	Therefore, we should pay attention not to the electrons'
	drift velocity, but to their instantaneous velocities.
	However, even their instantaneous velocities are nowhere near
	a significant fraction of the speed of light.
	Nevertheless, the measured velocity of electric waves
	in conductors \emph{is} a substantial fraction of the
	speed of light, so we still have a mystery on our hands.
	\fi

	하나 더 있는 트릭은 전자는 그 음극의 성질로 인해 다른 전자와
	상당히(원자적 관점에서요) 상호착용을 한다는 것입니다.
	이 상호작용은 광자에 의해 이끌어지는데, 광자는 \emph{바로} 빛의 속도로
	움직입니다.
	따라서 전기학에서의 전자라 해도, 대부분의 일을 하는건 광자입니다.

	통근자 비유를 이어가 보자면, 운전자는 다른 운전자에게 사고나 교통
	혼잡들을 알리는데 스마트폰을 사용할 수 있고, 이로 인해 교통 상황의
	변화를 개별 차들의 순간 속도보다 훨씬 빠르게 전파할 수 있는 겁니다.
	이 전기학과 교통상황 사이의 비유를 요약하자면 다음과 같습니다:

	\iffalse
	The other trick is that electrons interact with each other at
	significant distances (from an atomic perspective, anyway),
	courtesy of their negative charge.
	This interaction is carried out by photons, which \emph{do}
	move at the speed of light.
	So even with electricity's electrons, it is photons
	doing most of the fast footwork.

	Extending the commuter analogy, a driver might use a smartphone
	to inform other drivers of an accident or congestion, thus
	allowing a change in traffic flow to propagate much faster
	than the instantaneous velocity of the individual cars.
	Summarizing the analogy between electricity and traffic flow:
	\fi

	\begin{enumerate}
	\item	전자의 (매우 낮은) 이동 속도는 통근자의 장시간 속도와 비슷해서,
		둘 다 제로에 가깝습니다.
	\item	전자의 (여전히 낮은) 순간 속도는 통행 중인 차의 순간 속도와 비슷합니다.
		둘 다 이동 속도에 비해선 높지만, 변화가 전달되는 속도에 비교하면 굉장이 작습니다.
	\item	전자파의 (훨씬 높은) 전달 속도는 대부분 전자들 사이에서
		전자기력을 전달하는 광자의 덕분입니다.
		유사하게, 교통 상황은 운전자 사이의 커뮤니케이션으로 인해 훨씬
		빠르게 바뀔 수 있습니다.
		이것은 이미 교통 혼잡에 빠져 있는 운전자에겐 큰 도움이 되지
		않듯이, 이미 주어진 캐퍼시터에 잡혀 있는 전자들에겐 큰 도움이
		되지 않습니다.
	\end{enumerate}

	\iffalse
	\begin{enumerate}
	\item	The (very low) drift velocity of an electron is similar
		to the long-term velocity of a commuter, both being
		very nearly zero.
	\item	The (still rather low) instantaneous velocity of
		an electron is similar to the instantaneous velocity
		of a car in traffic.
		Both are much higher than the drift velocity, but
		quite small compared to the rate at which changes
		propagate.
	\item	The (much higher) propagation velocity of an electric
		wave is primarily due to photons transmitting
		electromagnetic force among the electrons.
		Similarly, traffic patterns can change quite quickly
		due to communication among drivers.
		Not that this is necessarily of much help to the
		drivers already stuck in traffic, any more than it
		is to the electrons already pooled in a given capacitor.
	\end{enumerate}
	\fi

	물론, 이 주제를 완전히 이해하려면 전자기학을 공부해야 할겁니다.

	\iffalse
	Of course, to fully understand this topic, you should read
	up on electrodynamics.
	\fi
} \QuickQuizEnd

(하드웨어에도 소프트웨어에도) 이를 개선할 기술은 더도 말고 덜도 말고 약간만 있습니다:

\begin{enumerate}
\item	3D 융합,
\item	훌륭한 물질과 프로세스들,
\item	전자를 빛으로 대체하는것,
\item	특수 목적의 가속기, 그리고
\item	존재하는 병렬 소프트웨어.
\end{enumerate}

이것들 각각을 다음 섹션에서 설명합니다.

\iffalse
There are nevertheless some technologies (both hardware and software)
that might help improve matters:

\begin{enumerate}
\item	3D integration,
\item	Novel materials and processes,
\item	Substituting light for electricity,
\item	Special-purpose accelerators, and
\item	Existing parallel software.
\end{enumerate}

Each of these is described in one of the following sections.
\fi

\subsection{3D Integration}
\label{sec:cpu:3D Integration}

3차원 융합 (3DI) 는 매우 얇은 실리콘 다이들을 수직으로 쌓아 올려 붙이는
기술입니다.
이 기술은 잠재적 이득을 제공하지만, 또한 대단한 공정적
어려움~\cite{JohnKnickerbocker2008:3DI} 을 품고 있습니다.

\iffalse
3-dimensional integration (3DI) is the practice of bonding
very thin silicon dies to each other in a vertical stack.
This practice provides potential benefits, but also poses
significant fabrication challenges~\cite{JohnKnickerbocker2008:3DI}.
\fi

\begin{figure}[tb]
\begin{center}
\resizebox{3in}{!}{\includegraphics{cpu/3DI}}
\end{center}
\caption{Latency Benefit of 3D Integration}
\label{fig:cpu:Latency Benefit of 3D Integration}
\end{figure}

3DI 가 가져올 수 있는 가장 중요한 이점은 Figure~\ref{fig:cpu:Latency Benefit of
3D Integration} 에 그려진대로, 시스템 전체적으로 짧아지는 경로의 길이일
것입니다.
해당 그림에서는 3 센티미터의 실리콘 다이가 제개의 1.5 센티미터 다이들의 더미로
바뀌었고, 각 레이어 사이의 거리가 상당히 얇다는 것을 고려하면 이론적으로
시스템을 관통하는 최대 경로의 길이가 두배 가까이 줄어든 셈입니다.
또한, 설계와 배치에 충분한 고려를 한다면, (느리고 전력도 많이 소모할) 수평적인
전자적 연결들은 빠르기도 하고 전력 소모도 적은, 짧은 수직적 전자적 연결로
대체될 수 있을 것입니다.

\iffalse
Perhaps the most important benefit of 3DI is decreased path length through
the system, as shown in
Figure~\ref{fig:cpu:Latency Benefit of 3D Integration}.
A 3-centimeter silicon die is replaced with a stack of four 1.5-centimeter
dies, in theory decreasing the maximum path through the system by a factor
of two, keeping in mind that each layer is quite thin.
In addition, given proper attention to design and placement,
long horizontal electrical connections (which are both slow and
power hungry) can be replaced by short vertical electrical connections,
which are both faster and more power efficient.
\fi

하지만, 클락으로 동작하는 논리회로의 수준들로 인한 지연은 3D 융합으로 감소되진
못할 것이고, 상기한 장점들을 달성하면서도 상품화하기 위해서는 3D 융합에서의
상당한 수준의 제조, 테스트, 전력 제공, 그리고 발열 처리 등의 문제들이
해결되어야 합니다.
발열 처리는 훌륭한 열의 전도체이지만 전자에는 절연체인 다이아몬드에 기반한
반도체를 사용해 해결될 수 있을 것입니다.
그렇지만, 웨이퍼를 만들기 위한 커다란 단일 다이아몬드 크리스탈을 만드는 것은
어려운 것으로 알려져 있습니다.
또한, 이런 기술들 중 어느 것도 몇몇 사람들은 이미 익숙해진 이 문제에 커다란
개선을 가져다 주진 못할 것 같습니다.
그렇지만, 짐 그레이의 ``연기나는 털투성이
골프공들''~\cite{JimGray2002SmokingHairyGolfBalls} 로 가기 위해서는
해결되어야만 하는 단계입니다.

\iffalse
However, delays due to levels of clocked logic will not be decreased
by 3D integration, and significant manufacturing, testing, power-supply,
and heat-dissipation problems must be solved for 3D integration to
reach production while still delivering on its promise.
The heat-dissipation problems might be solved using
semiconductors based on diamond, which is a good conductor
for heat, but an electrical insulator.
That said, it remains difficult to grow large single diamond crystals,
to say nothing of slicing them into wafers.
In addition, it seems unlikely that any of these technologies will be able to
deliver the exponential increases to which some people have become accustomed.
That said, they may be necessary steps on the path to the late Jim Gray's
``smoking hairy golf balls''~\cite{JimGray2002SmokingHairyGolfBalls}.
\fi

\subsection{Novel Materials and Processes}
\label{sec:cpu:Novel Materials and Processes}

스티븐 호킹은 반도체 제조사들이 두개의 근본적 문제를 가지고 있다고 이야기했다고
합니다: (1) 빛의 제한된 속도와 (2) 물질의 원자성의
본질~\cite{BryanGardiner2007}.
반도체 제조사에서 이런 제약을 해결해 보려 하는건 가능하겠지만, 이런 근본적
한계들을 비켜나가는데 집중해온 연구와 개발 과정에서 얻어진 몇가지 방법만이
존재할 뿐입니다.

\iffalse
Stephen Hawking is said to have claimed that semiconductor manufacturers
have but two fundamental problems: (1) the finite speed of light and
(2) the atomic nature of matter~\cite{BryanGardiner2007}.
It is possible that semiconductor manufacturers are approaching these
limits, but there are nevertheless a few avenues of research and
development focused on working around these fundamental limits.
\fi

물질의 원자성의 본질에 대한 한개의 회피책은 보다 큰 기기가 실현 불가능하도록
작은 기기의 전자적 특성을 흉내내게 하는, ``high-k dielectric'' 이라 불리는
물질들입니다.
이 물질들은 일부 쉽게 해결하기 어려운 제조 공정 문제를 가지고 있지만,
선도자들이 한걸음 더 나아가게 하는데 도움을 줄수도 있습니다.
또다른 좀 더 신기한 회피법은 하나의 전자는 여러 에너지 레벨을 가질 수 있다는
점을 이용해 여러 비트들을 하나의 전자에 저장하는 것입니다.
이 방법이 상품화된 반도체 기기에서 안정적으로 동작하게 될 수 있을지는 아직
확실하지 않습니다.

또다른 제안된 회피책은 훨씬 작은 기기 크기들을 이용하는 ``quantum dot''
방법입니다만 아직 연구 단계에 머물러 있습니다.

\iffalse
One workaround for the atomic nature of matter are so-called
``high-K dielectric'' materials, which allow larger devices to mimic the
electrical properties of infeasibly small devices.
These materials pose some severe fabrication challenges, but nevertheless
may help push the frontiers out a bit farther.
Another more-exotic workaround stores multiple bits in a single electron,
relying on the fact that a given electron can exist at a number of
energy levels.
It remains to be seen if this particular approach can be made to work
reliably in production semiconductor devices.

Another proposed workaround is the ``quantum dot'' approach that
allows much smaller device sizes, but which is still in the research
stage.
\fi

\subsection{Light, Not Electrons}
\label{sec:cpu:Light, Not Electrons}

Although the speed of light would be a hard limit, the fact is that
semiconductor devices are limited by the speed of electricity rather
than that of light, given that electric waves in semiconductor materials
move at between 3\% and 30\% of the speed of light in a vacuum.
The use of copper connections on silicon devices is one way to increase
the speed of electricity, and it is quite possible that additional
advances will push closer still to the actual speed of light.
In addition, there have been some experiments with tiny optical fibers
as interconnects within and between chips, based on the fact that
the speed of light in glass is more than 60\% of the speed of light
in a vacuum.
One obstacle to such optical fibers is the inefficiency conversion
between electricity and light and vice versa, resulting in both
power-consumption and heat-dissipation problems.

That said, absent some fundamental advances in the field of physics,
any exponential increases in the speed of data flow
will be sharply limited by the actual speed of light in a vacuum.

\subsection{Special-Purpose Accelerators}
\label{sec:cpu:Special-Purpose Accelerators}

A general-purpose CPU working on a specialized problem is often spending
significant time and energy doing work that is only tangentially related
to the problem at hand.
For example, when taking the dot product of a pair of vectors, a
general-purpose CPU will normally use a loop (possibly unrolled)
with a loop counter.
Decoding the instructions, incrementing the loop counter, testing this
counter, and branching back to the
top of the loop are in some sense wasted effort: the real goal is
instead to multiply corresponding elements of the two vectors.
Therefore, a specialized piece of hardware designed specifically to
multiply vectors could get the job done more quickly and with less
energy consumed.

This is in fact the motivation for the vector instructions present in
many commodity microprocessors.
Because these instructions operate on multiple data items simultaneously,
they would permit a dot product to be computed with less instruction-decode
and loop overhead.

Similarly, specialized hardware can more efficiently encrypt and decrypt,
compress and decompress, encode and decode, and many other tasks besides.
Unfortunately, this efficiency does not come for free.
A computer system incorporating this specialized hardware will contain
more transistors, which will consume some power even when not in use.
Software must be modified to take advantage of this specialized hardware,
and this specialized hardware must be sufficiently generally useful
that the high up-front hardware-design costs can be spread over enough
users to make the specialized hardware affordable.
In part due to these sorts of economic considerations, specialized
hardware has thus far appeared only for a few application areas,
including graphics processing (GPUs), vector processors (MMX, SSE,
and VMX instructions), and, to a lesser extent, encryption.

Unlike the server and PC arena, smartphones have long used a wide
variety of hardware accelerators.
These hardware accelerators are often used for media decoding,
so much so that a high-end MP3 player might be able to play audio
for several minutes---with its CPU fully powered off the entire time.
The purpose of these accelerators is to improve energy efficiency
and thus extend battery life: special purpose hardware can often
compute more efficiently than can a general-purpose CPU.
This is another example of the principle called out in
Section~\ref{sec:intro:Generality}: Generality is almost never free.

Nevertheless, given the end of Moore's-Law-induced single-threaded
performance increases, it seems safe to predict that there will
be an increasing variety of special-purpose hardware going forward.

\subsection{Existing Parallel Software}
\label{sec:cpu:Existing Parallel Software}

Although multicore CPUs seem to have taken the computing industry
by surprise, the fact remains that shared-memory parallel computer
systems have been commercially available for more than a quarter
century.
This is more than enough time for significant parallel software
to make its appearance, and it indeed has.
Parallel operating systems are quite commonplace, as are parallel
threading libraries, parallel relational database management systems, 
and parallel numerical software.
Use of existing parallel software can go a long ways towards solving any
parallel-software crisis we might encounter.

Perhaps the most common example is the parallel relational database
management system.
It is not unusual for single-threaded programs, often written in
high-level scripting languages, to access a central relational
database concurrently.
In the resulting highly parallel system, only the database need actually
deal directly with parallelism.
A very nice trick when it works!
