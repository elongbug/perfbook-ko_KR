% cpu/hwfreelunch.tex
% mainfile: ../perfbook.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\section{Hardware Free Lunch?}
\label{sec:cpu:Hardware Free Lunch?}
%
\epigraph{The great trouble today is that there are too many people looking
	  for someone else to do something for them.
	  The solution to most of our troubles is to be found in everyone
	  doing something for themselves.}
	 {\emph{Henry Ford, updated}}

지난 몇년간 동시성이 그렇게 많은 주목을 받게 된 주요한 이유는
page~\pageref{fig:intro:Clock-Frequency Trend for Intel CPUs} 의
Figure~\ref{fig:intro:Clock-Frequency Trend for Intel CPUs}
에도 보여져 있는, 무어의 법칙으로 인한 단일쓰레드 성능 증가 (또는 ``공짜
점심-free lunch-''~\cite{HerbSutter2008EffectiveConcurrency}) 의 종료입니다.
이 섹션은 하드웨어 설계자들이 이 ``공짜 점심'' 을 다시 가져올 수 있는 몇가지
방법에 대해 간단히 알아봅니다.

하지만, 앞의 섹션은 동시성을 노출시키는데 대한 상당한 하드웨어 상의 장애물
몇가지를 보였습니다.
하드웨어 설계자들이 마주치는 상당한 물리적 한계 중 하나는 제한된 빛의
속도입니다.
Page~\pageref{fig:cpu:System Hardware Architecture} 의
Figure~\ref{fig:cpu:System Hardware Architecture}
에서도 이야기 되었듯, 빛은 1.8\,GHz 클락 기간동안 진공관 내에서 8-센티미터
거리밖에 왕복하지 못합니다.
이는 5\,GHz 클락에서는 3~센티미터로 줄어듭니다.
이 거리들 둘 다 현대 컴퓨터 시스템의 크기에 비교해 상대적으로 작습니다.

\iffalse

The major reason that concurrency has been receiving so much focus over
the past few years is the end of \IXalt{Moore's-Law}{Moore's Law}
induced single-threaded
performance increases
(or ``free lunch''~\cite{HerbSutter2008EffectiveConcurrency}),
as shown in
Figure~\ref{fig:intro:Clock-Frequency Trend for Intel CPUs} on
page~\pageref{fig:intro:Clock-Frequency Trend for Intel CPUs}.
This section briefly surveys a few ways that hardware designers
might bring back the ``free lunch''.

However, the preceding section presented some substantial hardware
obstacles to exploiting concurrency.
One severe physical limitation that hardware designers face is the
finite speed of light.
As noted in
Figure~\ref{fig:cpu:System Hardware Architecture} on
page~\pageref{fig:cpu:System Hardware Architecture},
light can manage only about an 8-centimeters round trip in a vacuum
during the duration of a 1.8\,GHz clock period.
This distance drops to about 3~centimeters for a 5\,GHz clock.
Both of these distances are relatively small compared to the size
of a modern computer system.

\fi

더 나빠질 여지가 있는 것이, 반도체 내에서의 전자기파는 빛이 진공 속에서 그런
것에 비해 세배에서 서른배까지 느리게 움직이며, 일반적인 클락 기반의 하드웨어
구조는 이를 더 느리게 만드는데, 예를 들어 하나의 메모리 참조는 이 요청이
시스템의 나머지 부분에 넘겨지기 전까지 로컬 캐쉬 탐색이 완료되길 기다려야 할 수
있습니다.
더 나아가, 예를 들어 CPU 와 메인 메모리 간의 통신의 경우 전자신호를 하나의
반도체에서 다음 것으로 이동시키기 위해 상대적으로 낮은 스피드와 높은 전력의
드라이버가 필요합니다.

\iffalse

To make matters even worse, electric waves in silicon move from three to
thirty times more slowly than does light in a vacuum, and common
clocked logic constructs run still more slowly, for example, a
memory reference may need to wait for a local cache lookup to complete
before the request may be passed on to the rest of the system.
Furthermore, relatively low speed and high power drivers are required
to move electrical signals from one silicon die to another, for example,
to communicate between a CPU and main memory.

\fi

\QuickQuiz{
	하지만 전자 각각은 그렇게 빠르게 전혀 움직이지 못해요, 컨덕터
	(conductor) 내에서도요!!!
	세미컨덕터 전압 수준에서의 컨덕터 내 전자의 속도는 초당 오직
	\emph{밀리미터} 수준이라고요.
	어떻게 된거죠???

	\iffalse

	But individual electrons don't move anywhere near that fast,
	even in conductors!!!
	The electron drift velocity in a conductor under semiconductor
	voltage levels is on the order of only one \emph{millimeter}
	per second.
	What gives???

	\fi

}\QuickQuizAnswer{
	전자의 표류 속도는 개별 전자의 장시간 이동을 추적해서 나옵니다.
	개별 전자들은 상당히 무작위적으로 튀어다니며, 따라서 그들의 순간적
	속도는 매우 높지만, 장시간으로 보면 그리 많이 움직이지 않았음이
	드러났습니다.
	여기서 전자는 그들의 시간 대부분을 완전한 고속도로에서의 속도로
	여행하지만 장기적으로는 어디로도 가지 않는 장거리 통근자를 닮았습니다.
	이런 커뮤터의 속도는 시간당 70마일 (시속 113 킬로미터) 는 될테지만, 이
	행성의 표면에 상대적으로 측정한 그들의 장기간 표류 속도는 0에 수렴할
	겁니다.

	따라서, 우린 전자의 표류 속도가 아니라 순간 속도에 주목해야 합니다.
	하지만, 그 순간 속도조차 빛의 속도의 발끝에도 가지 못합니다.
	하지만, 컨덕터 내에서 측정된 전자기파의 속도는 빛의 속도에 조금은
	근접하며, 따라서 여전히 미스터리가 남아있습니다.

	\iffalse

	Electron drift velocity tracks the long-term movement of individual
	electrons.
	It turns out that individual electrons bounce around quite
	randomly, so that their instantaneous speed is very high, but
	over the long term, they don't move very far.
	In this, electrons resemble long-distance commuters, who
	might spend most of their time traveling at full highway
	speed, but over the long term go nowhere.
	These commuters' speed might be 70 miles per hour
	(113 kilometers per hour), but their long-term drift velocity
	relative to the planet's surface is zero.

	Therefore, we should pay attention not to the electrons'
	drift velocity, but to their instantaneous velocities.
	However, even their instantaneous velocities are nowhere near
	a significant fraction of the speed of light.
	Nevertheless, the measured velocity of electric waves
	in conductors \emph{is} a substantial fraction of the
	speed of light, so we still have a mystery on our hands.

	\fi

	또다른 트릭은 전자가 (원자적 관점에서 보면) 상당한 거리에 있는 다른
	전자들과 상호작용을 한다는 겁니다, 그것들의 음전하 덕분에요.
	이 상호작용은 빛의 속도로 움직이는 포톤 (photon) 에 의해 행해집니다.
	따라서 전자기파의 전자가 있지만, 빠른 일의 대부분을 하는건 포톤입니다.

	통근자 비유를 연장해 보자면, 운전자는 사고나 교통체증을 다른 운전자에게
	알리기 위해 스마트폰을 사용할 수도 있고, 따라서 교통 흐름 상의 변화는
	개별 차의 순간 속도보다도 훨씬 빠르게 전파될 수 있습니다.
	전자기파와 교통 흐름간의 비유를 요약하자면:

	\iffalse

	The other trick is that electrons interact with each other at
	significant distances (from an atomic perspective, anyway),
	courtesy of their negative charge.
	This interaction is carried out by photons, which \emph{do}
	move at the speed of light.
	So even with electricity's electrons, it is photons
	doing most of the fast footwork.

	Extending the commuter analogy, a driver might use a smartphone
	to inform other drivers of an accident or congestion, thus
	allowing a change in traffic flow to propagate much faster
	than the instantaneous velocity of the individual cars.
	Summarizing the analogy between electricity and traffic flow:

	\fi

	\begin{enumerate}
	\item	(무척 느린) 전자의 표류 속도는 통근자의 장기적 속도에 유사해서,
		둘 다 거의 0에 가깝습니다.
	\item	(여전히 느린) 전자의 순간 속도는 도로위의 자동차의 속도와
		유사합니다.
		둘 다 표류 속도에 비해선 무척 빠르지만, 변화가 전파되는 속도에
		비하면 상당히 느립니다.
	\item	(훨씬 빠른) 전자기파의 전파 속도는 기본적으로 포톤이 전자기력을
		전자들 사이에 전달하기 때문입니다.
		비슷하게, 교통 상황은 운전자간의 소통 때문에 상당히 빨리 변화될
		수 있습니다.
		이게 이미 교통체증에 빠진 운전자에겐 특정 커패시터 (capacitor)
		에 빠진 전자에게만큼이나 도움이 되진 못하겠지만요.

	\iffalse

	\item	The (very low) drift velocity of an electron is similar
		to the long-term velocity of a commuter, both being
		very nearly zero.
	\item	The (still rather low) instantaneous velocity of
		an electron is similar to the instantaneous velocity
		of a car in traffic.
		Both are much higher than the drift velocity, but
		quite small compared to the rate at which changes
		propagate.
	\item	The (much higher) propagation velocity of an electric
		wave is primarily due to photons transmitting
		electromagnetic force among the electrons.
		Similarly, traffic patterns can change quite quickly
		due to communication among drivers.
		Not that this is necessarily of much help to the
		drivers already stuck in traffic, any more than it
		is to the electrons already pooled in a given capacitor.

	\fi

	\end{enumerate}

	물론, 이 주제를 완전히 이해하려면, 전기역학을 읽어보셔야 합니다.

	\iffalse

	Of course, to fully understand this topic, you should read
	up on electrodynamics.

	\fi

}\QuickQuizEnd

하지만 이것들을 개선시킬 기술이 (하드웨어적으로도 소프트웨어적으로도) 몇가지
있습니다.

\begin{enumerate}
\item	3D 통합,
\item	첨단의 물질과 프로세스,
\item	빛으로 전자기를 대체하기,
\item	특수 목적 가속기, 그리고
\item	현존하는 병렬 소프트웨어.
\end{enumerate}

이것들 각각을 다음 섹션들에서 다룹니다.

\iffalse

There are nevertheless some technologies (both hardware and software)
that might help improve matters:

\begin{enumerate}
\item	3D integration,
\item	Novel materials and processes,
\item	Substituting light for electricity,
\item	Special-purpose accelerators, and
\item	Existing parallel software.
\end{enumerate}

Each of these is described in one of the following sections.

\fi

\subsection{3D Integration}
\label{sec:cpu:3D Integration}

3차원 통합 (3DI) 는 매우 얇은 실리콘 다이들을 수직으로 쌓아 붙이는 것입니다.
이는 잠재적 이득을 제공하지만, 또한 심각한 제작 상의 도전을
가져옵니다~\cite{JohnKnickerbocker2008:3DI}.

\iffalse

3-dimensional integration (3DI) is the practice of bonding
very thin silicon dies to each other in a vertical stack.
This practice provides potential benefits, but also poses
significant fabrication challenges~\cite{JohnKnickerbocker2008:3DI}.

\fi

\begin{figure}[tb]
\centering
\resizebox{3in}{!}{\includegraphics{cpu/3DI}}
\caption{Latency Benefit of 3D Integration}
\label{fig:cpu:Latency Benefit of 3D Integration}
\end{figure}

3DI 의 가장 중요한 이득은 아마도
Figure~\ref{fig:cpu:Latency Benefit of 3D Integration}
에 보인 것처럼 시스템 전체를 관통하는 길이의 단축입니다.
3-센티미터 실리콘 다이가 네개의 1.5-센티미터 다이의 더미로 변경되면, 각 층의
두께는 무척 얇다는 점을 고려하면 이론상 시스템 전체 관통 최대 거리가 두배로
줄어들게 됩니다.
또한, 설계와 배치에 충분한 주의를 기울인다면, 길다란 수평적 (느리고 전력을 많이
소모하는) 전자기적 연결은 더 짧고 전력을 덜 소모하는, 짧은 수직적 전자기적
연결로 교체될 수 있습니다.

하지만, 클락 기반 논리회로 때문에 발생하는 지연은 3D 통합으로도 줄어들지
않으며, 그 예상되는 이득을 그대로 가져가면서 제품단까지 3D 통합이 사용되기 전에
상당한 제조, 테스팅, 전력 공급, 그리고 열 처리 상의 문제가 해결되어야 합니다.
열처리 문제는 다이아몬드 기반의 반도체를 사용해 해결될 수도 있는데, 이는 열
문제에 있어선 좋은 도체이지만 전자 절연체로써는 별로입니다.
그렇지만, 커다란 하나의 다이아몬드 덩어리를 얻기는 여전히 어려우며, 그걸
웨이퍼로 잘라내는 것의 어려움은 말할 필요도 없습니다.
또한, 이 기술 중 어느 것도 몇몇 사람들이 받은 정도를 넘어서 폭발적 증가를
제공할 수 있지는 않을 것 같습니다.
그렇다곤 하나, 최근의 Jim Gray 의 
``smoking hairy golf balls''~\cite{JimGray2002SmokingHairyGolfBalls}
로의 여정에는 필요한 단계가 될 수 있습니다.

\iffalse

Perhaps the most important benefit of 3DI is decreased path length through
the system, as shown in
Figure~\ref{fig:cpu:Latency Benefit of 3D Integration}.
A 3-centimeter silicon die is replaced with a stack of four 1.5-centimeter
dies, in theory decreasing the maximum path through the system by a factor
of two, keeping in mind that each layer is quite thin.
In addition, given proper attention to design and placement,
long horizontal electrical connections (which are both slow and
power hungry) can be replaced by short vertical electrical connections,
which are both faster and more power efficient.

However, delays due to levels of clocked logic will not be decreased
by 3D integration, and significant manufacturing, testing, power-supply,
and heat-dissipation problems must be solved for 3D integration to
reach production while still delivering on its promise.
The heat-dissipation problems might be solved using
semiconductors based on diamond, which is a good conductor
for heat, but an electrical insulator.
That said, it remains difficult to grow large single diamond crystals,
to say nothing of slicing them into wafers.
In addition, it seems unlikely that any of these technologies will be able to
deliver the exponential increases to which some people have become accustomed.
That said, they may be necessary steps on the path to the late Jim Gray's
``smoking hairy golf balls''~\cite{JimGray2002SmokingHairyGolfBalls}.

\fi

\subsection{Novel Materials and Processes}
\label{sec:cpu:Novel Materials and Processes}

Stephen Hawking 은 반도체 제조사들이 두가지 기본적 문제를 가지고 있다고 이야기
했다고 알려져 있습니다: (1) 한정된 빛의 속도와 (2) 물질의 원자적
본성~\cite{BryanGardiner2007}.
반도체 제조사들이 이런 한계를 해결하려 노력하고 있을 수 있지만, 이 근본적
한계를 회피하는데 주목하는 연구와 개발 노력도 있습니다.

원자적 본성을 회피하기 위한 한가지 노력은 ``high-K dielectric'' 물질이라 불리는
것으로, 커다란 기기들이 있을 수 없을만큼 작은 기기들의 전자적 특성을 흉내내게
하는 것입니다.
이런 물질들은 심각한 제조상의 도전을 갖지만, 첨단을 조금 더 앞으로 나아가게
하는것을 도울수도 있을 겁니다.
또다른 더 색다른 방법은 여러 비트를 하나의 전자에 저장하는 것으로 특정 전자가
여러 수준의 에너지를 가지고 존재할 수 있다는 사실에 기반합니다.
이 특정 시도가 제품 수준의 반도체 기기에서 안정적으로 동작할 수 있는지는
두고봐야 합니다.

\iffalse

Stephen Hawking is said to have claimed that semiconductor manufacturers
have but two fundamental problems: (1) the finite speed of light and
(2) the atomic nature of matter~\cite{BryanGardiner2007}.
It is possible that semiconductor manufacturers are approaching these
limits, but there are nevertheless a few avenues of research and
development focused on working around these fundamental limits.

One workaround for the atomic nature of matter are so-called
``high-K dielectric'' materials, which allow larger devices to mimic the
electrical properties of infeasibly small devices.
These materials pose some severe fabrication challenges, but nevertheless
may help push the frontiers out a bit farther.
Another more-exotic workaround stores multiple bits in a single electron,
relying on the fact that a given electron can exist at a number of
energy levels.
It remains to be seen if this particular approach can be made to work
reliably in production semiconductor devices.

\fi

제안된 또다른 방법은 ``quntum dot'' 방법으로 훨씬 더 작은 크기의 기기가
가능하게 하지만, 여전히 연구 단계에 있습니다.

여기서의 한가지 도전사항은 최근의 많은 하드웨어 기기 수준 해결책은 어떤 원자가
어디에 위치했는지 매우 꼼꼼하게 제어해야 한다는
것입니다~\cite{MichaelJKelly2017DeviceLevel}.
따라서 누구든 원자들을 칩 위의 수십억개의 기기 위에 하나씩 위치시킬 수 있는
좋은 방법을 찾는 사람은 가장 훌륭한 자랑할 권한을 가질 겁니다, 다른게 없다면요!

\iffalse

Another proposed workaround is the ``quantum dot'' approach that
allows much smaller device sizes, but which is still in the research
stage.

One challenge is that many recent hardware-device-level breakthroughs
require very tight control of which atoms are placed
where~\cite{MichaelJKelly2017DeviceLevel}.
It therefore seems likely that whoever finds a good way to hand-place
atoms on each of the billions of devices on a chip will have most
excellent bragging rights, if nothing else!

\fi

\subsection{Light, Not Electrons}
\label{sec:cpu:Light, Not Electrons}

빛의 속도가 강한 제약이 되긴 하겠지만, 진실은 반도체 기기들은 빛의 속도가
아니라 전자기의 속도에 의해 제약되며, 반도체 물질 내에서의 전자기파는
진공에서의 빛의 속도의 3\,\% 에서 30\,\% 정도로 움직인다는 것입니다.
실리콘 기기들 사이에 구리로 만들어진 연결부위를 사용하는 것은 전자기의 속도를
증가시키는 한 방법이며, 실제 빛의 속도까지 이를 나아가게끔 하는 추가적인 발전도
상당히 가능할 겁니다.
또한, 유리 내에서의 빛의 속도는 진공에서의 빛의 속도의 60\,\% 를 넘는다는
사실에 기반한, 칩 내에서 그리고 칩간 연결을 위해 작은 광섬유를 사용하는 실험이
있었습니다.
그런 광섬유 사용을 막는 문제는 전자기와 빛 사이, 그리고 그 반대의 변환에서의
비효율성으로, 이는 전력 소모와 열 처리 문제를 유발합니다.

그러나, 물리 분야에서의 근본적 발전이 있지 않고서는 데이터 흐름의 어떤 폭발적
증가도 진공에서의 빛의 속도에 제한될 겁니다.

\iffalse

Although the speed of light would be a hard limit, the fact is that
semiconductor devices are limited by the speed of electricity rather
than that of light, given that electric waves in semiconductor materials
move at between 3\,\% and 30\,\% of the speed of light in a vacuum.
The use of copper connections on silicon devices is one way to increase
the speed of electricity, and it is quite possible that additional
advances will push closer still to the actual speed of light.
In addition, there have been some experiments with tiny optical fibers
as interconnects within and between chips, based on the fact that
the speed of light in glass is more than 60\,\% of the speed of light
in a vacuum.
One obstacle to such optical fibers is the inefficiency conversion
between electricity and light and vice versa, resulting in both
power-consumption and heat-dissipation problems.

That said, absent some fundamental advances in the field of physics,
any exponential increases in the speed of data flow
will be sharply limited by the actual speed of light in a vacuum.

\fi

\subsection{Special-Purpose Accelerators}
\label{sec:cpu:Special-Purpose Accelerators}

특수한 문제를 위해 일하는 범용 CPU 는 종종 상당한 시간과 전력을 해당 문제에
핵심적이지는 않은 부분을 처리하는데 사용합니다.
예를 들어, 두개의 벡터의 내적을 구할 때, 범용 CPU 는 일반적으로 (루프 언롤링 -
loop unrolling - 이 적용되지 않은) 루프 카운터를 가지고 루프를 돌릴 겁니다.
이 명령들을 디코딩하고 루프 카운터를 증가시키고 이 카운터를 검사하고 이 루프의
시작지점으로 수행 흐름을 되돌리는 것은 어떤 면에서 불필요한 노력입니다: 진짜
목표는 이 두개의 벡터의 연관된 원소들을 곱하는 것입니다.
따라서, 벡터들을 곱하기 위해서만 설계된 하드웨어의 특수한 부분은 더 적은 전력을
사용하며 이 일을 더 빨리 끝낼 수 있습니다.

이는 실제로 많은 상용 마이크로프로세서에 존재하는 벡터 명령의 동기 부여가
되었습니다.
이 명령들은 여러 데이터 아이템을 동시적으로 처리하기 때문에, 내적 계산을 더
적은 명령 디코딩과 루프 오버헤드를 가지고 처리할 수 있게 합니다.

\iffalse

A general-purpose CPU working on a specialized problem is often spending
significant time and energy doing work that is only tangentially related
to the problem at hand.
For example, when taking the dot product of a pair of vectors, a
general-purpose CPU will normally use a loop (possibly unrolled)
with a loop counter.
Decoding the instructions, incrementing the loop counter, testing this
counter, and branching back to the
top of the loop are in some sense wasted effort: the real goal is
instead to multiply corresponding elements of the two vectors.
Therefore, a specialized piece of hardware designed specifically to
multiply vectors could get the job done more quickly and with less
energy consumed.

This is in fact the motivation for the vector instructions present in
many commodity microprocessors.
Because these instructions operate on multiple data items simultaneously,
they would permit a dot product to be computed with less instruction-decode
and loop overhead.

\fi

비슷하게, 특수화된 하드웨어는 암호화와 복호화, 압축과 압축 해제, 인코딩과
디코딩, 그리고 그 외에도 많은 다른 작업들을 더 효율적으로 처리할 수 있습니다.
불행히도, 이 효율성은 공짜로 오지 않습니다.
이 특수 하드웨어를 가진 컴퓨터 시스템은 더 많은 트랜지스터를 가질 것인데, 이는
실제 사용되지 않고 있을 때에도 전력을 조금 소비하게 됩니다.
소프트웨어는 이 특수화된 하드웨어의 장점을 취하기 위해 수정되어야만 하며, 이
특수화된 하드웨어는 해당 하드웨어를 위한 설계 비용이 많은 사용자들에게 나뉘어져
그 가격이 구매할 만한 낮은 가격이 될 수 있게끔 충분히 범용적이어야만 합니다.
부분적으로는 이런 종류의 경제적 고려사항 때문에 특수화된 하드웨어는 지금까지는
일부 어플리케이션 영역에서만 사용되어왔는데, 이는 그래픽 처리 (GPU), 벡터 처리
(MMS, SSE, 그리고 VMX 명령들), 그리고, 더 적은 정도로, 암호화 정도에만
사용되어왔습니다.
심지어 이 영역에서조차 예상한 만큼의 성능 증가를 얻기는 항상 쉽지만은 않은데,
예를 들어 열처리 문제 등
때문입니다~\cite{VladKrasnov2017SIMDfreqscale,DanielLemire2018SIMDfreqscale,TravisDowns2020SIMDfreqscale}.

\iffalse

Similarly, specialized hardware can more efficiently encrypt and decrypt,
compress and decompress, encode and decode, and many other tasks besides.
Unfortunately, this efficiency does not come for free.
A computer system incorporating this specialized hardware will contain
more transistors, which will consume some power even when not in use.
Software must be modified to take advantage of this specialized hardware,
and this specialized hardware must be sufficiently generally useful
that the high up-front hardware-design costs can be spread over enough
users to make the specialized hardware affordable.
In part due to these sorts of economic considerations, specialized
hardware has thus far appeared only for a few application areas,
including graphics processing (GPUs), vector processors (MMX, SSE,
and VMX instructions), and, to a lesser extent, encryption.
And even in these areas, it is not always easy to realize the expected
performance gains, for example, due to thermal
throttling~\cite{VladKrasnov2017SIMDfreqscale,DanielLemire2018SIMDfreqscale,TravisDowns2020SIMDfreqscale}.

\fi

서버와 PC 쪽과 달리, 스마트폰은 다양한 하드웨어 가속기를 오랫동안 사용해
왔습니다.
이 하드웨어 가속기는 종종 첨단 MP3 플레이어가 CPU 는 완전히 꺼져있는 상태에서도
음악을 수분간 재생할 수도 있도록 미디어 디코딩에 종종 사용되었습니다.
이런 가속기들의 목표는 전력 효율을 개선시키고 배터리 수명을 늘리기
위함이었습니다: 특수 목적 하드웨어는 범용 CPU 보다 종종 더 효율적으로
연산작업을 합니다.
이는 Section~\ref{sec:intro:Generality} 에서 이야기되는 규칙의 또하나의
예입니다: 범용성은 거의 항상 공짜가 아닙니다.

하지만, \IXalt{Moore's-Law}{Moore's Law} 에 의한 싱글쓰레드 성능 증가의 종료를
생각해 보면, 다양한 특수 목적 하드웨어의 출현이 늘어날 것이라 생각해도 안전할
겁니다.

\iffalse

Unlike the server and PC arena, smartphones have long used a wide
variety of hardware accelerators.
These hardware accelerators are often used for media decoding,
so much so that a high-end MP3 player might be able to play audio
for several minutes---with its CPU fully powered off the entire time.
The purpose of these accelerators is to improve energy efficiency
and thus extend battery life: special purpose hardware can often
compute more efficiently than can a general-purpose CPU\@.
This is another example of the principle called out in
Section~\ref{sec:intro:Generality}: Generality is almost never free.

Nevertheless, given the end of \IXalt{Moore's-Law}{Moore's Law}-induced
single-threaded performance increases, it seems safe to assume that
increasing varieties of special-purpose hardware will appear.

\fi

\subsection{Existing Parallel Software}
\label{sec:cpu:Existing Parallel Software}

멀티코어 CPU 가 컴퓨터 산업계를 놀라게 한 듯 보이지만, 실제로는 공유 메모리
병렬 컴퓨터 시스템이 판매되기 시작한지 25년도 넘게 지났습니다.
이는 상당한 병렬 소프트웨어가 나타나기에 충분한 시간이며, 실제로 그랬습니다.
병렬 운영체제는 상당히 흔해졌으며, 병렬 쓰레딩 라이브러리, 병렬 관계형
데이터베이스 관리 시스템, 그리고 병렬 수학 소프트웨어도 그렇습니다.
존재하는 병렬 소프트웨어의 사용은 우리가 마주칠 수 있는 모든 병렬 소프트웨어
참사를 해결하는 데에 상당한 진전을 가능하게 합니다.

이런 가장 흔한 예는 병렬 관계형 데이터베이스 관리 시스템일 겁니다.
싱글 쓰레드 프로그램이 중심의 관계형 데이터베이스에 동시적으로 접근하기 위해
고수준의 스크립트 언어로 쓰여있는 경우가 드물지 않습니다.
그 결과 만들어지는 고도로 병렬화된 시스템에서는 데이터베이스만이 실제로
병렬성을 직접 다루게 됩니다.
동작할 때에는 매우 훌륭한 트릭입니다!

\iffalse

Although multicore CPUs seem to have taken the computing industry
by surprise, the fact remains that shared-memory parallel computer
systems have been commercially available for more than a quarter
century.
This is more than enough time for significant parallel software
to make its appearance, and it indeed has.
Parallel operating systems are quite commonplace, as are parallel
threading libraries, parallel relational database management systems, 
and parallel numerical software.
Use of existing parallel software can go a long ways towards solving any
parallel-software crisis we might encounter.

Perhaps the most common example is the parallel relational database
management system.
It is not unusual for single-threaded programs, often written in
high-level scripting languages, to access a central relational
database concurrently.
In the resulting highly parallel system, only the database need actually
deal directly with parallelism.
A very nice trick when it works!

\fi
