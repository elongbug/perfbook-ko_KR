% cpu/cpu.tex
% SPDX-License-Identifier: CC-BY-SA-3.0

\QuickQuizChapter{chp:Hardware and its Habits}{Hardware and its Habits}

\epigraph{Premature abstraction is the root of all evil}
	 {\emph{A cast of thousands}}

대부분의 사람들은 시스템간에 메세지를 주고받는 것은 단일 시스템 안에서 간단한
계산을 하는 것보다 비싸다는 것을 직관적으로 이해하고 있습니다.
하지만, 단일 공유메모리 시스템 안에서 쓰레드간에 커뮤니케이션하는 것도 매우
비쌀 수 있다는 것은 항상 앞의 이야기만큼 분명해 보이진 않습니다.
그래서 이 챕터는 하나의 공유메모리 시스템에서 동기화와 커뮤니케이션의 비용에
대해서 알아봅니다.
이 몇장의 내용은 공유메모리 병렬 하드웨어 설계의 겉면만 훑어 볼 겁니다; 더 깊이
알고 싶은 독자분들은 Hennessy 와 Patterson 의 고전 교과서~\cite{Hennessy95a} 의
최신판을 보면 좋을 겁니다.
\iffalse

Most people have an intuitive understanding that passing messages between
systems is considerably more expensive than performing simple calculations
within the confines of a single system.
However, it is not always so clear that communicating among threads within
the confines of a single shared-memory system can also be quite expensive.
This chapter therefore looks at the cost of synchronization and communication
within a shared-memory system.
These few pages can do no more than scratch the surface of shared-memory
parallel hardware design; readers desiring more detail would do well
to start with a recent edition of Hennessy and Patterson's classic
text~\cite{Hennessy2011,Hennessy95a}.
\fi

\QuickQuiz{}
	왜 병렬 프로그래머가 하드웨어의 로우 레벨 요소들까지 배워야 하죠?
	하이 레벨의 추상 계층만 보는게 더 쉽고, 낫고, 더 일반적이지 않겠어요?

	\iffalse
	Why should parallel programmers bother learning low-level
	properties of the hardware?
	Wouldn't it be easier, better, and more general to remain at
	a higher level of abstraction?
	\fi
\QuickQuizAnswer{
	하드웨어의 세세한 내용들은 무시하는게 더 쉬울 수 있을 겁니다만,
	많은 경우 그건 바보같은 짓일 수 있습니다.
	병렬성의 모든 목적이 성능 향상일 뿐이란걸 인정하신다면, 그리고 성능은
	하드웨어의 디테일한 부분들에 의존적인 걸 인정하신다면, 논리적으로 병렬
	프로그래머들은 하드웨어에 대해 최소 조금은 알아야 한다는 결론을 얻을 수
	있을 겁니다.

	이건 대부분의 엔지니어링 교훈에서 나오는 이야기입니다.
	\emph{당신}이라면 콘크리트와 철강에 대해 이해하지 못하는 엔지니어가
	설계한 다리를 사용하시겠습니까?
	아니라면, 왜 병렬 프로그래머가 최소한 \emph{조금의} 하드웨어에 대한
	이해 없이 훌륭한 병렬 소프트웨어를 만들 수 있을 거라고 생각하시나요?

\iffalse
	It might well be easier to ignore the detailed properties of
	the hardware, but in most cases it would be quite foolish
	to do so.
	If you accept that the only purpose of parallelism is to
	increase performance, and if you further accept that
	performance depends on detailed properties of the hardware,
	then it logically follows that parallel programmers are going
	to need to know at least a few hardware properties.

	This is the case in most engineering disciplines.
	Would \emph{you} want to use a bridge designed by an
	engineer who did not understand the properties of
	the concrete and steel making up that bridge?
	If not, why would you expect a parallel programmer to be
	able to develop competent parallel software without at least
	\emph{some} understanding of the underlying hardware?
\fi
} \QuickQuizEnd

\input{cpu/overview}
\input{cpu/overheads}
\input{cpu/hwfreelunch}
\input{cpu/swdesign}

자, 정리해 보죠:

\begin{enumerate}
\item	좋은 소식. 멀티코어 시스템이 저렴하고 어디서든 구할 수 있게 되었습니다.
\item	더 좋은 소식도 있어요: 많은 동기화 오퍼레이션의 오버헤드는 2000년대
	초의 병렬 시스템에서 그랬던 것보다 훨씬 낮아졌습니다.
\item	나쁜 소식은 캐시 미스의 오버헤드는, 특히 큰 시스템에서는 여전히 높다는
	것입니다.
\end{enumerate}

이 책의 뒷부분에서는 이 나쁜 소식을 처리하는 방법들을 설명합니다.

\iffalse
So, to sum up:

\begin{enumerate}
\item	The good news is that multicore systems are inexpensive and
	readily available.
\item	More good news:  The overhead of many synchronization operations
	is much lower than it was on parallel systems from the early 2000s.
\item	The bad news is that the overhead of cache misses is still high,
	especially on large systems.
\end{enumerate}

The remainder of this book describes ways of handling this bad news.
\fi

특히, Chapter~\ref{chp:Tools of the Trade} 에서는 병렬 프로그래밍에서 사용되는
일부 로우 레벨 도구들을 다룰 거고, Chapter~\ref{chp:Counting} 에서는 병렬
카운팅에서의 문제와 해결책을 알아볼겁니다. 그리고 Chapter~\ref{cha:Partitioning
and Synchronization Design} 에서는 성능과 확장성을 올릴 수 있는 설계 원칙을
이야기해 봅니다.

\iffalse
In particular,
Chapter~\ref{chp:Tools of the Trade} will cover some of the low-level
tools used for parallel programming,
Chapter~\ref{chp:Counting} will investigate problems and solutions to
parallel counting, and
Chapter~\ref{cha:Partitioning and Synchronization Design}
will discuss design disciplines that promote performance and scalability.
\fi
